{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from molfeat.trans.pretrained.hf_transformers import HFExperiment\n",
    "from molfeat.trans.pretrained.hf_transformers import HFModel\n",
    "from molfeat.store import ModelInfo\n",
    "from molfeat.store import ModelStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datamol as dm\n",
    "# from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\n",
    "\n",
    "# data = dm.freesolv().iloc[:100]\n",
    "# transformer = PretrainedHFTransformer(kind=\"ChemGPT-4.7M\", notation=\"selfies\")\n",
    "# features = transformer(data[\"smiles\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChemGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemgpt_4M = ModelInfo(\n",
    "    name = \"ChemGPT-4.7M\",\n",
    "    inputs = \"selfies\",\n",
    "    type=\"pretrained\",\n",
    "    group=\"huggingface\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"ChemGPT (4.7M params) is a transformer model for generative molecular modeling, which was pretrained on the PubChem10M dataset.\",\n",
    "    representation=\"line-notation\",\n",
    "    require_3D=False,\n",
    "    tags = [\"ChemGPT\", 'huggingface', \"transformers\", \"GPTNeo\", \"PubChem\", \"selfies\", \"small\"],\n",
    "    authors= ['Nathan Frey',\n",
    "        'Ryan Soklaski',\n",
    "        'Simon Axelrod',\n",
    "        'Siddharth Samsi',\n",
    "        'Rafael Gomez-Bombarelli',\n",
    "        'Connor Coley',\n",
    "        'Vijay Gadepally'\n",
    "    ],\n",
    "    reference = \"10.26434/chemrxiv-2022-3s512\" \n",
    ")\n",
    "\n",
    "\n",
    "chemgpt_1B = ModelInfo(\n",
    "    name = \"ChemGPT-1.2B\",\n",
    "    inputs = \"selfies\",\n",
    "    type=\"pretrained\",\n",
    "    group=\"huggingface\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"ChemGPT (1.2B params) is a transformer model for generative molecular modeling, which was pretrained on the PubChem10M dataset.\",\n",
    "    representation=\"line-notation\",\n",
    "    require_3D=False,\n",
    "    tags = [\"ChemGPT\", 'huggingface', \"transformers\", \"GPTNeo\", \"PubChem\", \"selfies\", \"huge\"],\n",
    "    authors= ['Nathan Frey',\n",
    "        'Ryan Soklaski',\n",
    "        'Simon Axelrod',\n",
    "        'Siddharth Samsi',\n",
    "        'Rafael Gomez-Bombarelli',\n",
    "        'Connor Coley',\n",
    "        'Vijay Gadepally'\n",
    "    ],\n",
    "    reference = \"10.26434/chemrxiv-2022-3s512\" \n",
    ")\n",
    "\n",
    "chemgpt_19M = ModelInfo(\n",
    "    name = \"ChemGPT-19M\",\n",
    "    inputs = \"selfies\",\n",
    "    type=\"pretrained\",\n",
    "    group=\"huggingface\",\n",
    "    version=0,\n",
    "    submitter=\"Datamol\",\n",
    "    description=\"ChemGPT (19M params) is a transformers model for generative molecular modeling, which was pretrained on the PubChem10M dataset.\",\n",
    "    representation=\"line-notation\",\n",
    "    require_3D=False,\n",
    "    tags = [\"ChemGPT\", 'huggingface', \"transformers\", \"GPTNeo\", \"PubChem\", \"selfies\", \"large\"],\n",
    "    authors= ['Nathan Frey',\n",
    "        'Ryan Soklaski',\n",
    "        'Simon Axelrod',\n",
    "        'Siddharth Samsi',\n",
    "        'Rafael Gomez-Bombarelli',\n",
    "        'Connor Coley',\n",
    "        'Vijay Gadepally'\n",
    "    ],\n",
    "    reference = \"10.26434/chemrxiv-2022-3s512\" \n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ChemGPT, we need to patch the tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer_4M = AutoTokenizer.from_pretrained(\"ncfrey/ChemGPT-4.7M\")\n",
    "tokenizer_1B = AutoTokenizer.from_pretrained(\"ncfrey/ChemGPT-1.2B\")\n",
    "tokenizer_19M = AutoTokenizer.from_pretrained(\"ncfrey/ChemGPT-19M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModel.from_pretrained(\"ncfrey/ChemGPT-4.7M\")\n",
    "# model.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_tokenizer(tokenizer):\n",
    "    # unk\n",
    "    tokenizer.unk_token = \"[UNK]\"\n",
    "    tokenizer.unk_token_id = tokenizer.vocab.get(tokenizer.unk_token)\n",
    "\n",
    "    # cls\n",
    "    tokenizer.cls_token = \"[CLS]\"\n",
    "    tokenizer.cls_token_id = tokenizer.vocab.get(tokenizer.cls_token)\n",
    "\n",
    "    # pad\n",
    "    tokenizer.pad_token = \"[PAD]\"\n",
    "    tokenizer.pad_token_id = tokenizer.vocab.get(tokenizer.pad_token)\n",
    "\n",
    "    # bos\n",
    "    tokenizer.bos_token = \"[CLS]\"\n",
    "    tokenizer.bos_token_id = tokenizer.vocab.get(tokenizer.bos_token)\n",
    "    \n",
    "    # sep\n",
    "    tokenizer.sep_token = \"[SEP]\"\n",
    "    tokenizer.sep_token_id = tokenizer.vocab.get(tokenizer.sep_token)\n",
    "    \n",
    "    # EN: My guess is that the EOS token is the one that is wrong\n",
    "    # eos\n",
    "    tokenizer.eos_token = \"[SEP]\"\n",
    "    tokenizer.eos_token_id = tokenizer.vocab.get(tokenizer.eos_token)\n",
    "    \n",
    "    # mask\n",
    "    tokenizer.mask_token = \"[MASK]\"\n",
    "    tokenizer.mask_token_id = tokenizer.vocab.get(tokenizer.mask_token)\n",
    "    \n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_4M = patch_tokenizer(tokenizer_4M)\n",
    "tokenizer_19M = patch_tokenizer(tokenizer_19M)\n",
    "tokenizer_1B = patch_tokenizer(tokenizer_1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model_4M = AutoModelForCausalLM.from_pretrained(\"ncfrey/ChemGPT-4.7M\")\n",
    "model_1B = AutoModelForCausalLM.from_pretrained(\"ncfrey/ChemGPT-1.2B\")\n",
    "model_19M = AutoModelForCausalLM.from_pretrained(\"ncfrey/ChemGPT-19M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patch_model_from_tokenizer(model, tokenizer):\n",
    "    \"\"\"This is copied from Factory.patch_hgf_config_from_tokenizer\"\"\"\n",
    "    config = model.config\n",
    "\n",
    "    conf_dict_data = {}\n",
    "    for conf_key in [\n",
    "        \"bos_token_id\",\n",
    "        \"bos_token\",\n",
    "        \"eos_token_id\",\n",
    "        \"eos_token\", \n",
    "        \"pad_token_id\",\n",
    "        \"pad_token\",\n",
    "        \"unk_token_id\",\n",
    "        \"unk_token\",\n",
    "        \"mask_token_id\",\n",
    "        \"mask_token\",\n",
    "        \"sep_token_id\",\n",
    "        \"sep_token\",\n",
    "        \"cls_token_id\",\n",
    "        \"cls_token\",\n",
    "\n",
    "    ]:\n",
    "        if hasattr(config, conf_key):\n",
    "            conf_dict_data[conf_key] = getattr(tokenizer, conf_key)\n",
    "    for conf_key in [\"forced_eos_token_id\", \"decoder_start_token_id\"]:\n",
    "        if hasattr(config, conf_key):\n",
    "            conf_dict_data[conf_key] = tokenizer.eos_token_id\n",
    "    #conf_dict_data[\"vocab_size\"] = len(tokenizer)\n",
    "    # if this is false, there is a big issue\n",
    "    #print(config.vocab_size)\n",
    "    #print(conf_dict_data[\"vocab_size\"])\n",
    "    #assert conf_dict_data[\"vocab_size\"] == config.vocab_size, \"Vocab size mismatch\"\n",
    "    \n",
    "    config.update(conf_dict_data)\n",
    "    model.config = config\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4M = patch_model_from_tokenizer(model_4M, tokenizer_4M)\n",
    "model_19M = patch_model_from_tokenizer(model_19M, tokenizer_19M)\n",
    "model_1B = patch_model_from_tokenizer(model_1B, tokenizer_1B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedModel\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "isinstance(tokenizer_4M, PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a492157c2254d3ab127f690010e0773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 07:37:55 | WARNING | google.auth._default | No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
      "\u001b[32m2023-05-04 07:39:40.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmolfeat.trans.pretrained.hf_transformers\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mModel saved to gs://molfeat-store-prod/artifacts/huggingface/ChemGPT-4.7M/0/model.save\u001b[0m\n",
      "\u001b[32m2023-05-04 07:39:43.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmolfeat.store.modelstore\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mSuccessfuly registered model ChemGPT-4.7M !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chempgtp_4M_model = HFModel.register_pretrained(model_4M, tokenizer_4M, chemgpt_4M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e10bf5d6d04c4991c8458b8140ae45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-04 07:41:40.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmolfeat.trans.pretrained.hf_transformers\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mModel saved to gs://molfeat-store-prod/artifacts/huggingface/ChemGPT-19M/0/model.save\u001b[0m\n",
      "\u001b[32m2023-05-04 07:41:43.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmolfeat.store.modelstore\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mSuccessfuly registered model ChemGPT-19M !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chempgtp_19M_model = HFModel.register_pretrained(model_19M, tokenizer_19M, chemgpt_19M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169a8f0d44b3413786ffbb694dd78f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-05-04 08:38:27.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmolfeat.trans.pretrained.hf_transformers\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mModel saved to gs://molfeat-store-prod/artifacts/huggingface/ChemGPT-1.2B/0/model.save\u001b[0m\n",
      "\u001b[32m2023-05-04 08:38:32.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmolfeat.store.modelstore\u001b[0m:\u001b[36mregister\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mSuccessfuly registered model ChemGPT-1.2B !\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chempgtp_1B_model = HFModel.register_pretrained(model_1B, tokenizer_1B, chemgpt_1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<molfeat.trans.pretrained.hf_transformers.HFModel at 0x1819435e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chempgtp_19M_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamol as dm\n",
    "import platformdirs\n",
    "\n",
    "# remove chemgpt local dir\n",
    "try:\n",
    "    chemgpt_local_dir = dm.fs.join(platformdirs.user_cache_dir(\"molfeat\"), \"ChemGPT-4.7M\")\n",
    "    mapper = dm.fs.get_mapper(chemgpt_local_dir)\n",
    "    mapper.fs.delete(chemgpt_local_dir, recursive=True)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# make sure we clear the cache of the function\n",
    "from molfeat.trans.pretrained.hf_transformers import HFModel\n",
    "HFModel._load_or_raise.cache_clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m\u001b[36mChemBERTa-77M-MLM\u001b[m\u001b[m          \u001b[1m\u001b[36mgin_supervised_edgepred\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mDeepChem-ChemBERTa-77M-MLM\u001b[m\u001b[m \u001b[1m\u001b[36mgin_supervised_infomax\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36m_lock_files\u001b[m\u001b[m                \u001b[1m\u001b[36mmaccs\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mconformers\u001b[m\u001b[m                 \u001b[1m\u001b[36mpcqm4mv2_graphormer_base\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mcustom_model_store\u001b[m\u001b[m         \u001b[1m\u001b[36mprecomputed\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mgin_supervised_contextpred\u001b[m\u001b[m \u001b[1m\u001b[36mtreedecomp\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls /Users/manu/Library/Caches/molfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8368287cba498bbe01f181a2f715bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/738 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baec5eefc60e4809942ad1bcd65a0b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 15:34:43 | WARNING | google.auth._default | No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "import datamol as dm\n",
    "import os\n",
    "from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # annoying huggingface warning\n",
    "data = dm.freesolv().iloc[:100]\n",
    "transformer = PretrainedHFTransformer(kind=\"ChemGPT-1.2B\", notation=\"selfies\")\n",
    "features = transformer(data[\"smiles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 256)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molfeat-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd64925fe6617865d410306d2b64fa69b44b63a36aad85fd11f7d4e4dc7609f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
