{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"What is molfeat ?","text":"<p>Molfeat is a hub of molecular featurizers. It supports a wide variety of out-of-the-box molecular featurizers and can be easily extended to include your own custom featurizers.</p> <ul> <li>\ud83d\ude80 Fast, with a simple and efficient API.</li> <li>\ud83d\udd04 Unify pre-trained molecular embeddings and hand-crafted featurizers in a single package.</li> <li>\u2795 Easily add your own featurizers through plugins.</li> <li>\ud83d\udcc8 Benefit from increased performance through a trouble-free caching system.</li> </ul> <p>Visit our website at https://molfeat.datamol.io.</p>"},{"location":"index.html#installation","title":"Installation","text":""},{"location":"index.html#installing-molfeat","title":"Installing Molfeat","text":"<p>Use mamba:</p> <pre><code>mamba install -c conda-forge molfeat\n</code></pre> <p>Tips: You can replace <code>mamba</code> by <code>conda</code>.</p> <p>Note: We highly recommend using a Conda Python distribution to install Molfeat. The package is also pip installable if you need it: <code>pip install molfeat</code>.</p>"},{"location":"index.html#installing-plugins","title":"Installing Plugins","text":"<p>The functionality of molfeat can be extended through plugins. The use of a plugin system ensures that the core package remains easy to install and as light as possible, while making it easy to extend its functionality with plug-and-play components. Additionally, it ensures that plugins can be developed independently from the core package, removing the bottleneck of a central party that reviews and approves new plugins. Consult the molfeat documentation for more details on how to create your own plugins.</p> <p>However, this does imply that the installation of a plugin is plugin-dependent: please consult the relevant documentation to learn more.</p>"},{"location":"index.html#optional-dependencies","title":"Optional dependencies","text":"<p>Not all featurizers in Molfeat core package are supported by default. Some featurizers require additional dependencies. If you try to use a featurizer that requires additional dependencies, Molfeat will raise an error and tell you which dependencies are missing and how to install them.</p> <ul> <li>To install <code>dgl</code>: run <code>mamba install -c dglteam \"dgl&lt;=2.0\"</code> # there is some issue with \"dgl&gt;2.0.0\" related to graphbolt</li> <li>To install <code>dgllife</code>: run <code>mamba install -c conda-forge dgllife</code></li> <li>To install <code>fcd_torch</code>: run <code>mamba install -c conda-forge fcd_torch</code></li> <li>To install <code>pyg</code>: run <code>mamba install -c conda-forge pytorch_geometric</code></li> <li>To install <code>graphormer-pretrained</code>: run <code>mamba install -c conda-forge graphormer-pretrained</code></li> <li>To install <code>map4</code>: see https://github.com/reymond-group/map4</li> <li>To install <code>bio-embeddings</code>: run <code>mamba install -c conda-forge 'bio-embeddings &gt;=0.2.2'</code></li> </ul> <p>If you install Molfeat using pip, there are optional dependencies that can be installed with the main package. For example, <code>pip install \"molfeat[all]\"</code> allows installing all the compatible optional dependencies for small molecule featurization. There are other options such as <code>molfeat[dgl]</code>, <code>molfeat[graphormer]</code>, <code>molfeat[transformer]</code>, <code>molfeat[viz]</code>, and <code>molfeat[fcd]</code>.</p>"},{"location":"index.html#how-to-cite","title":"How to cite","text":"<p>Please cite Molfeat if you use it in your research: .</p>"},{"location":"benchmark.html","title":"Why should you care?","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 <p>Unlike many other machine learning domains, molecular featurization (i.e. the process of transforming a molecule into a vector) lacks a consistently good default. It is still an open question how to best capture the complexity of molecular data with a unified representation. Which molecular representation works best depends largely on which task you are modeling. To achieve optimal performance, it is wise to experiment with a variety of featurization schemes, from structural fingerprints to physicochemical descriptors and pre-trained embeddings.</p> In\u00a0[\u00a0]: Copied! <pre>! pip install autosklearn\n</pre> ! pip install autosklearn In\u00a0[2]: Copied! <pre>import os\nimport tqdm\nimport fsspec\nimport pickle\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport datamol as dm\nimport matplotlib.pyplot as plt\nimport autosklearn.classification\nimport autosklearn.regression\nfrom collections import defaultdict\nfrom rdkit.Chem import SaltRemover\n\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom molfeat.trans.fp import FPVecTransformer\nfrom molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\n</pre> import os import tqdm import fsspec import pickle import warnings import numpy as np import pandas as pd import datamol as dm import matplotlib.pyplot as plt import autosklearn.classification import autosklearn.regression from collections import defaultdict from rdkit.Chem import SaltRemover  from sklearn.metrics import mean_absolute_error, roc_auc_score from sklearn.model_selection import GroupShuffleSplit from sklearn.neighbors import KNeighborsClassifier  from molfeat.trans.fp import FPVecTransformer from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer In\u00a0[3]: Copied! <pre># Making the output less verbose\nwarnings.simplefilter(\"ignore\")\nos.environ[\"PYTHONWARNINGS\"] = \"ignore\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ndm.disable_rdkit_log()\n</pre> # Making the output less verbose warnings.simplefilter(\"ignore\") os.environ[\"PYTHONWARNINGS\"] = \"ignore\" os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" dm.disable_rdkit_log() In\u00a0[4]: Copied! <pre>def load_dataset(uri: str, readout_col: str):\n    \"\"\"Loads the MoleculeNet dataset\"\"\"\n    df = pd.read_csv(uri)\n    smiles = df[\"smiles\"].values\n    y = df[readout_col].values\n    return smiles, y\n\n\ndef preprocess_smiles(smi):\n    \"\"\"Preprocesses the SMILES string\"\"\"\n    mol = dm.to_mol(smi, ordered=True, sanitize=False)    \n    try: \n        mol = dm.sanitize_mol(mol)\n    except: # noqa: E722\n        mol = None\n            \n    if mol is None: \n        return\n        \n    mol = dm.standardize_mol(mol, disconnect_metals=True)\n    remover = SaltRemover.SaltRemover()\n    mol = remover.StripMol(mol, dontRemoveEverything=True)\n\n    return dm.to_smiles(mol)\n\n\ndef scaffold_split(smiles):\n    \"\"\"In line with common practice, we will use the scaffold split to evaluate our models\"\"\"\n    scaffolds = [dm.to_smiles(dm.to_scaffold_murcko(dm.to_mol(smi))) for smi in smiles]\n    splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n    return next(splitter.split(smiles, groups=scaffolds))\n</pre> def load_dataset(uri: str, readout_col: str):     \"\"\"Loads the MoleculeNet dataset\"\"\"     df = pd.read_csv(uri)     smiles = df[\"smiles\"].values     y = df[readout_col].values     return smiles, y   def preprocess_smiles(smi):     \"\"\"Preprocesses the SMILES string\"\"\"     mol = dm.to_mol(smi, ordered=True, sanitize=False)         try:          mol = dm.sanitize_mol(mol)     except: # noqa: E722         mol = None                  if mol is None:          return              mol = dm.standardize_mol(mol, disconnect_metals=True)     remover = SaltRemover.SaltRemover()     mol = remover.StripMol(mol, dontRemoveEverything=True)      return dm.to_smiles(mol)   def scaffold_split(smiles):     \"\"\"In line with common practice, we will use the scaffold split to evaluate our models\"\"\"     scaffolds = [dm.to_smiles(dm.to_scaffold_murcko(dm.to_mol(smi))) for smi in smiles]     splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)     return next(splitter.split(smiles, groups=scaffolds))  In\u00a0[5]: Copied! <pre># Setup the featurizers\ntrans_ecfp = FPVecTransformer(kind=\"ecfp:6\", n_jobs=-1)\ntrans_mordred = FPVecTransformer(kind=\"mordred\", replace_nan=True, n_jobs=-1)\ntrans_chemberta = PretrainedHFTransformer(kind='ChemBERTa-77M-MLM', notation='smiles')\n</pre> # Setup the featurizers trans_ecfp = FPVecTransformer(kind=\"ecfp:6\", n_jobs=-1) trans_mordred = FPVecTransformer(kind=\"mordred\", replace_nan=True, n_jobs=-1) trans_chemberta = PretrainedHFTransformer(kind='ChemBERTa-77M-MLM', notation='smiles') In\u00a0[6]: Copied! <pre># Prepare the Lipophilicity dataset\nsmiles, y_true = load_dataset(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\", \"exp\")\nsmiles = np.array([preprocess_smiles(smi) for smi in smiles])\nsmiles = np.array([smi for smi in smiles if dm.to_mol(smi) is not None])\n\nfeats_ecfp, ind_ecfp = trans_ecfp(smiles, ignore_errors=True)\nfeats_mordred, ind_mordred = trans_mordred(smiles, ignore_errors=True)\nfeats_chemberta, ind_chemberta = trans_chemberta(smiles, ignore_errors=True)\n\nX = {\n    \"ECFP\": feats_ecfp[ind_ecfp],\n    \"Mordred\": feats_mordred[ind_mordred],\n    \"ChemBERTa\": feats_chemberta[ind_chemberta],\n}\n</pre> # Prepare the Lipophilicity dataset smiles, y_true = load_dataset(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\", \"exp\") smiles = np.array([preprocess_smiles(smi) for smi in smiles]) smiles = np.array([smi for smi in smiles if dm.to_mol(smi) is not None])  feats_ecfp, ind_ecfp = trans_ecfp(smiles, ignore_errors=True) feats_mordred, ind_mordred = trans_mordred(smiles, ignore_errors=True) feats_chemberta, ind_chemberta = trans_chemberta(smiles, ignore_errors=True)  X = {     \"ECFP\": feats_ecfp[ind_ecfp],     \"Mordred\": feats_mordred[ind_mordred],     \"ChemBERTa\": feats_chemberta[ind_chemberta], } In\u00a0[7]: Copied! <pre># Train a model\ntrain_ind, test_ind = scaffold_split(smiles)\n\nlipo_scores = {}\nfor name, feats in X.items():\n    \n    # Train\n    automl = autosklearn.regression.AutoSklearnRegressor(\n        memory_limit=24576, \n        # For practicality\u2019s sake, limit this to 5 minutes! \n        # (x3 = 15 min in total)\n        time_left_for_this_task=180,  \n        n_jobs=1,\n        seed=1,\n    )\n    automl.fit(feats[train_ind], y_true[train_ind])\n    \n    # Predict and evaluate\n    y_hat = automl.predict(feats[test_ind])\n    \n    # Evaluate\n    mae = mean_absolute_error(y_true[test_ind], y_hat)\n    lipo_scores[name] = mae\n\nlipo_scores\n</pre> # Train a model train_ind, test_ind = scaffold_split(smiles)  lipo_scores = {} for name, feats in X.items():          # Train     automl = autosklearn.regression.AutoSklearnRegressor(         memory_limit=24576,          # For practicality\u2019s sake, limit this to 5 minutes!          # (x3 = 15 min in total)         time_left_for_this_task=180,           n_jobs=1,         seed=1,     )     automl.fit(feats[train_ind], y_true[train_ind])          # Predict and evaluate     y_hat = automl.predict(feats[test_ind])          # Evaluate     mae = mean_absolute_error(y_true[test_ind], y_hat)     lipo_scores[name] = mae  lipo_scores <pre>[WARNING] [2023-03-27 11:14:52,884:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:15:09,140:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:15:10,575:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:17:53,162:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:17:55,897:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:18:08,224:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:20:48,340:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:20:53,717:Client-EnsembleBuilder] No runs were available to build an ensemble from\n[WARNING] [2023-03-27 11:20:54,100:Client-EnsembleBuilder] No runs were available to build an ensemble from\n</pre> Out[7]: <pre>{'ECFP': 0.72650517992544,\n 'Mordred': 0.5792950477372836,\n 'ChemBERTa': 0.7396155151199458}</pre> In\u00a0[8]: Copied! <pre># Prepare the ClinTox dataset\nsmiles, y_true = load_dataset(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/clintox.csv.gz\", \"CT_TOX\")\nsmiles = np.array([preprocess_smiles(smi) for smi in smiles])\nsmiles = np.array([smi for smi in smiles if smi is not None])\n\nfeats_ecfp, ind_ecfp = trans_ecfp(smiles, ignore_errors=True)\nfeats_mordred, ind_mordred = trans_mordred(smiles, ignore_errors=True)\nfeats_chemberta, ind_chemberta = trans_chemberta(smiles, ignore_errors=True)\n\nX = {\n    \"ECFP\": feats_ecfp[ind_ecfp],\n    \"Mordred\": feats_mordred[ind_mordred],\n    \"ChemBERTa\": feats_chemberta[ind_chemberta],\n}\n</pre> # Prepare the ClinTox dataset smiles, y_true = load_dataset(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/clintox.csv.gz\", \"CT_TOX\") smiles = np.array([preprocess_smiles(smi) for smi in smiles]) smiles = np.array([smi for smi in smiles if smi is not None])  feats_ecfp, ind_ecfp = trans_ecfp(smiles, ignore_errors=True) feats_mordred, ind_mordred = trans_mordred(smiles, ignore_errors=True) feats_chemberta, ind_chemberta = trans_chemberta(smiles, ignore_errors=True)  X = {     \"ECFP\": feats_ecfp[ind_ecfp],     \"Mordred\": feats_mordred[ind_mordred],     \"ChemBERTa\": feats_chemberta[ind_chemberta], } <pre>[11:23:45] Unusual charge on atom 0 number of radical electrons set to zero\n[11:23:46] Unusual charge on atom 0 number of radical electrons set to zero\n[11:23:47] Unusual charge on atom 0 number of radical electrons set to zero\n[11:23:47] Unusual charge on atom 0 number of radical electrons set to zero\n[11:23:47] Unusual charge on atom 0 number of radical electrons set to zero\n</pre> In\u00a0[9]: Copied! <pre># Train a model\ntrain_ind, test_ind = scaffold_split(smiles)\n\nclintox_scores = {}\nfor name, feats in X.items():\n    \n    # Train\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        memory_limit=24576, \n        # For practicality\u2019s sake, limit this to 5 minutes! \n        # (x3 = 15 min in total)\n        time_left_for_this_task=180,\n        n_jobs=1,\n        seed=1,\n    )\n    automl.fit(feats[train_ind], y_true[train_ind])\n    \n    # Predict and evaluate\n    y_hat = automl.predict_proba(feats[test_ind])\n    y_hat = y_hat[:, 1]\n    \n    # Evaluate\n    auroc = roc_auc_score(y_true[test_ind], y_hat)\n    clintox_scores[name] = auroc\n\nclintox_scores\n</pre> # Train a model train_ind, test_ind = scaffold_split(smiles)  clintox_scores = {} for name, feats in X.items():          # Train     automl = autosklearn.classification.AutoSklearnClassifier(         memory_limit=24576,          # For practicality\u2019s sake, limit this to 5 minutes!          # (x3 = 15 min in total)         time_left_for_this_task=180,         n_jobs=1,         seed=1,     )     automl.fit(feats[train_ind], y_true[train_ind])          # Predict and evaluate     y_hat = automl.predict_proba(feats[test_ind])     y_hat = y_hat[:, 1]          # Evaluate     auroc = roc_auc_score(y_true[test_ind], y_hat)     clintox_scores[name] = auroc  clintox_scores <pre>[WARNING] [2023-03-27 11:30:21,940:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n\tModels besides current dummy model: 0\n\tDummy models: 1\n[WARNING] [2023-03-27 11:30:38,533:Client-EnsembleBuilder] No models better than random - using Dummy losses!\n\tModels besides current dummy model: 0\n\tDummy models: 1\n</pre> Out[9]: <pre>{'ECFP': 0.5345833333333333, 'Mordred': 0.5633333333333334, 'ChemBERTa': 0.665}</pre> In\u00a0[10]: Copied! <pre># Specify some meta-data\n\nBASE_CMPD_URI = \"https://github.com/rdkit/benchmarking_platform/raw/master/compounds/DUD/cmp_list_DUD\"\nCMPD_EXT = \".dat.gz\"\n\nBASE_SPLIT_URI = \"https://github.com/rdkit/benchmarking_platform/raw/master/query_lists/data_sets_I/DUD/training_DUD\"\nSPLIT_EXT = \".pkl\"\n\n# Out of practicality, we only use the first 10 targets\nTARGETS = [\n    \"ace\",\n    \"ache\",\n    \"ar\",\n    \"cdk2\",\n    \"cox2\",\n    \"dhfr\",\n    \"egfr\",\n    \"er_agonist\",\n    \"fgfr1\",\n    \"fxa\",\n]\n</pre> # Specify some meta-data  BASE_CMPD_URI = \"https://github.com/rdkit/benchmarking_platform/raw/master/compounds/DUD/cmp_list_DUD\" CMPD_EXT = \".dat.gz\"  BASE_SPLIT_URI = \"https://github.com/rdkit/benchmarking_platform/raw/master/query_lists/data_sets_I/DUD/training_DUD\" SPLIT_EXT = \".pkl\"  # Out of practicality, we only use the first 10 targets TARGETS = [     \"ace\",     \"ache\",     \"ar\",     \"cdk2\",     \"cox2\",     \"dhfr\",     \"egfr\",     \"er_agonist\",     \"fgfr1\",     \"fxa\", ] In\u00a0[11]: Copied! <pre>def get_compounds_for_target(target: str):\n    \"\"\"Loads the structural data\"\"\"\n    df = pd.DataFrame()\n    for subset in [\"actives\", \"decoys\"]:\n        df_ = pd.read_csv(f\"{BASE_CMPD_URI}_{target}_{subset}{CMPD_EXT}\", sep=\"\\t\")\n        df_[\"subset\"] = subset\n        df_[\"target\"] = 1 if subset == \"actives\" else 0\n        df = pd.concat([df, df_])\n    return df\n\n\ndef get_train_decoy_split_for_target(target: str, no_of_actives: int = 20):\n    \"\"\"Loads the proposed split of the benchmark\"\"\"\n    with fsspec.open(f\"{BASE_SPLIT_URI}_{target}_{no_of_actives}{SPLIT_EXT}\", \"rb\") as fd:\n        data = pickle.load(fd)\n    return data[:no_of_actives], data[no_of_actives:]\n</pre> def get_compounds_for_target(target: str):     \"\"\"Loads the structural data\"\"\"     df = pd.DataFrame()     for subset in [\"actives\", \"decoys\"]:         df_ = pd.read_csv(f\"{BASE_CMPD_URI}_{target}_{subset}{CMPD_EXT}\", sep=\"\\t\")         df_[\"subset\"] = subset         df_[\"target\"] = 1 if subset == \"actives\" else 0         df = pd.concat([df, df_])     return df   def get_train_decoy_split_for_target(target: str, no_of_actives: int = 20):     \"\"\"Loads the proposed split of the benchmark\"\"\"     with fsspec.open(f\"{BASE_SPLIT_URI}_{target}_{no_of_actives}{SPLIT_EXT}\", \"rb\") as fd:         data = pickle.load(fd)     return data[:no_of_actives], data[no_of_actives:] In\u00a0[12]: Copied! <pre>results = defaultdict(dict)\n\nfor target in tqdm.tqdm(TARGETS, leave=False):\n\n    # Load the structures (i.e. SMILES)\n    df = get_compounds_for_target(target)\n    n_actives = len(df[df[\"subset\"] == \"actives\"])\n\n    smiles = df[\"SMILES\"].values\n    smiles = np.array([smi for smi in smiles if dm.to_mol(smi) is not None])\n\n    # Featurize\n    feats_ecfp, ind_ecfp = trans_ecfp(smiles, ignore_errors=True)\n    feats_mordred, ind_mordred = trans_mordred(smiles, ignore_errors=True)\n    feats_chemberta, ind_chemberta = trans_chemberta(smiles, ignore_errors=True)\n\n    X = {\n        \"ECFP\": feats_ecfp[ind_ecfp],\n        \"Mordred\": feats_mordred[ind_mordred],\n        \"ChemBERTa\": feats_chemberta[ind_chemberta],\n    }\n\n    # Get the train-test split\n    train_active_ind, train_decoy_ind = get_train_decoy_split_for_target(target, no_of_actives=20)\n    train_decoy_ind = [i + n_actives for i in train_decoy_ind]\n\n    for feat_name, feats in X.items():\n\n        # Train the model\n        knn = KNeighborsClassifier()\n        train_ind = np.concatenate([train_active_ind, train_decoy_ind])\n        test_ind = np.array([i for i in range(len(df)) if i not in train_ind])\n        knn.fit(feats[train_ind], df.iloc[train_ind][\"target\"].values)\n\n        # Get targets and predictions\n        y_true = df.iloc[test_ind][\"target\"].values\n        y_pred = knn.predict_proba(feats[test_ind])[:, 1]\n\n        # Compute the recovery score\n        auc = roc_auc_score(y_true, y_pred)\n        results[feat_name][target] = auc\n</pre> results = defaultdict(dict)  for target in tqdm.tqdm(TARGETS, leave=False):      # Load the structures (i.e. SMILES)     df = get_compounds_for_target(target)     n_actives = len(df[df[\"subset\"] == \"actives\"])      smiles = df[\"SMILES\"].values     smiles = np.array([smi for smi in smiles if dm.to_mol(smi) is not None])      # Featurize     feats_ecfp, ind_ecfp = trans_ecfp(smiles, ignore_errors=True)     feats_mordred, ind_mordred = trans_mordred(smiles, ignore_errors=True)     feats_chemberta, ind_chemberta = trans_chemberta(smiles, ignore_errors=True)      X = {         \"ECFP\": feats_ecfp[ind_ecfp],         \"Mordred\": feats_mordred[ind_mordred],         \"ChemBERTa\": feats_chemberta[ind_chemberta],     }      # Get the train-test split     train_active_ind, train_decoy_ind = get_train_decoy_split_for_target(target, no_of_actives=20)     train_decoy_ind = [i + n_actives for i in train_decoy_ind]      for feat_name, feats in X.items():          # Train the model         knn = KNeighborsClassifier()         train_ind = np.concatenate([train_active_ind, train_decoy_ind])         test_ind = np.array([i for i in range(len(df)) if i not in train_ind])         knn.fit(feats[train_ind], df.iloc[train_ind][\"target\"].values)          # Get targets and predictions         y_true = df.iloc[test_ind][\"target\"].values         y_pred = knn.predict_proba(feats[test_ind])[:, 1]          # Compute the recovery score         auc = roc_auc_score(y_true, y_pred)         results[feat_name][target] = auc <pre> 30%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                                                                                       | 3/10 [02:39&lt;06:23, 54.78s/it][11:35:54] Explicit valence for atom # 1 C greater than permitted\n 40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                                                                    | 4/10 [03:17&lt;04:49, 48.17s/it][11:36:34] Explicit valence for atom # 6 C greater than permitted\n 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                   | 9/10 [16:00&lt;01:53, 113.93s/it][11:49:14] Explicit valence for atom # 1 C greater than permitted\n[11:49:14] Explicit valence for atom # 1 C greater than permitted\n[11:49:14] Explicit valence for atom # 20 C greater than permitted\n[11:49:14] Explicit valence for atom # 19 C greater than permitted\n[11:49:14] Explicit valence for atom # 1 C greater than permitted\n[11:49:14] Explicit valence for atom # 20 C greater than permitted\n[11:49:14] Explicit valence for atom # 11 C greater than permitted\n[11:49:15] Explicit valence for atom # 20 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 20 C greater than permitted\n[11:49:15] Explicit valence for atom # 19 C greater than permitted\n[11:49:15] Explicit valence for atom # 21 C greater than permitted\n[11:49:15] Explicit valence for atom # 18 C greater than permitted\n[11:49:15] Explicit valence for atom # 23 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 20 C greater than permitted\n[11:49:15] Explicit valence for atom # 25 C greater than permitted\n[11:49:15] Explicit valence for atom # 27 C greater than permitted\n[11:49:15] Explicit valence for atom # 24 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 26 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 28 C greater than permitted\n[11:49:15] Explicit valence for atom # 27 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 26 C greater than permitted\n[11:49:15] Explicit valence for atom # 28 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 18 C greater than permitted\n[11:49:15] Explicit valence for atom # 17 C greater than permitted\n[11:49:15] Explicit valence for atom # 17 C greater than permitted\n[11:49:15] Explicit valence for atom # 29 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] [11:49:15] Explicit valence for atom # 1 C greater than permitted\nExplicit valence for atom # 18 C greater than permitted\n[11:49:15] Explicit valence for atom # 26 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 25 C greater than permitted\n[11:49:15] Explicit valence for atom # 25 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 29 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:15] Explicit valence for atom # 1 C greater than permitted\n[11:49:16] Explicit valence for atom # 25 C greater than permitted\n[11:49:16] Explicit valence for atom # 25 C greater than permitted\n[11:49:16] Explicit valence for atom # 24 C greater than permitted\n[11:49:16] Explicit valence for atom # 1 C greater than permitted\n[11:49:16] Explicit valence for atom # 1 C greater than permitted\n[11:49:16] Explicit valence for atom # 1 C greater than permitted\n                                                                                                                                                                                                                                      \r</pre> In\u00a0[13]: Copied! <pre># Replicate the figure from https://doi.org/10.1021/ci400466r\n\nxs = list(range(len(TARGETS)))\n\necfp_scores = [results[\"ECFP\"][target] for target in TARGETS]\nmordred_scores = [results[\"Mordred\"][target] for target in TARGETS]\nchemberta_scores = [results[\"ChemBERTa\"][target] for target in TARGETS]\n\nfig, ax = plt.subplots(figsize=(10, 6))\nfor scores, label in zip([ecfp_scores, mordred_scores, chemberta_scores], [\"ECFP\", \"Mordred\", \"ChemBERTa\"]):\n    ax.plot(xs, scores, label=label)\n\nax.set_xlabel(\"Target\")\nax.set_ylabel(\"AUC\")\nax.set_xticks(xs)\nax.set_xticklabels(TARGETS, rotation=90)\nax.legend()\n</pre> # Replicate the figure from https://doi.org/10.1021/ci400466r  xs = list(range(len(TARGETS)))  ecfp_scores = [results[\"ECFP\"][target] for target in TARGETS] mordred_scores = [results[\"Mordred\"][target] for target in TARGETS] chemberta_scores = [results[\"ChemBERTa\"][target] for target in TARGETS]  fig, ax = plt.subplots(figsize=(10, 6)) for scores, label in zip([ecfp_scores, mordred_scores, chemberta_scores], [\"ECFP\", \"Mordred\", \"ChemBERTa\"]):     ax.plot(xs, scores, label=label)  ax.set_xlabel(\"Target\") ax.set_ylabel(\"AUC\") ax.set_xticks(xs) ax.set_xticklabels(TARGETS, rotation=90) ax.legend() Out[13]: <pre>&lt;matplotlib.legend.Legend at 0x7fc9a7e6f220&gt;</pre>"},{"location":"benchmark.html#use-cases","title":"Use cases\u00b6","text":"<p>Molecular representations / featurizers are an integral part of any molecular modelling workflow and are commonly used for:</p> <ul> <li>Search - to find molecules with similar electronic properties, similar structures, or similar biological activity for a target.</li> <li>Clustering - to group molecules based on their features and derive hypotheses around the relationship between structure and activity</li> <li>Modeling - to build QSAR model for molecular property/activity prediction</li> </ul>"},{"location":"benchmark.html#importance-of-the-choice-of-molecular-representation","title":"Importance of the choice of molecular representation\u00b6","text":"<p>To demonstrate the impact a featurizer can have, we establish two simple benchmarks:</p> <ol> <li>To demonstrate the impact on modeling, we will use two datasets from MoleculeNet [1].</li> <li>To demonstrate the impact on search, we will use the RDKit Benchmarking Platform [2, 3].</li> </ol> <p>We will compare the performance of three different featurizers:</p> <ul> <li>ECFP6 [4]: Binary, circular fingerprints where each bit indicates the presence of particular substructures of a radius up to 3 bonds away from an atom.</li> <li>Mordred [5]: Continuous descriptors with more than 1800 2D and 3D descriptors.</li> <li>ChemBERTa [6]: Learned representations from a pre-trained SMILES transformer model.</li> </ul> <p>Tl;dr - Importance of molecular representation</p> <p> No featurizer consistently stood out for either task or even within a task category:  <ul> <li><p>Modeling:  The Mordred featurizer outperforms the next best featurizer by ~20% on the Lipophilicity prediction task. On ClinTox, however, things are reversed and ChemBERTa outperforms the other featurizers by ~about 18%.</p> </li> <li><p>Search: ECFP outperforms ChemBERTa and Mordred and is the best option across the board, although it's target dependent.</p> </li> </ul> <p>These quick examples show the context-dependent nature and thus the importance of experimenting with trying different featurizers. In short, the perfect molecular featurizer doesn\u2019t exist (yet!). All have their pros and cons depending on the data and the downstream task.</p> </p>"},{"location":"benchmark.html#modeling","title":"Modeling\u00b6","text":"<p>We will compare the performance on two datasets using scikit-learn AutoML [7, 8] models.</p>"},{"location":"benchmark.html#lipophilicity","title":"Lipophilicity\u00b6","text":"<p>Lipophilicity is a regression task with 4200 molecules</p>"},{"location":"benchmark.html#clintox","title":"ClinTox\u00b6","text":""},{"location":"benchmark.html#conclusion","title":"Conclusion\u00b6","text":"Dataset Metric Representation Score Rank Lipophilicity MAE \u2193 ECFP 0.727 1 Mordred 0.579 0 ChemBERTa 0.740 2 ClinTox AUROC \u2191 ECFP 0.535 2 Mordred 0.563 1 ChemBERTa 0.665 0 <p>We can see that for Lipophilicity, the Mordred featurizer proves most powerful, outperforming the next best featurizer by ~20%. For ClinTox, however, the results are reversed and it's instead ChemBERTa that outperforms the other featurizers by ~18%. This shows the importance of trying different featurizers. Luckily, with Molfeat, this is now much easier to do!</p>"},{"location":"benchmark.html#search","title":"Search\u00b6","text":"<p>We will now evaluate the performance of the featurizers on various search tasks from the RDKit Benchmarking Platform [2, 3].</p>"},{"location":"benchmark.html#conclusion","title":"Conclusion\u00b6","text":"<p>For search, we observe yet again another ranking. It now seems that ECFP is the best option across the board, although it's target dependent.</p> <p>Conclusion</p> <p> There is no single \"best\" molecular featurizer. With Molfeat, it is now easier than ever to experiment with a diverse set of popular featurizers to ensure you pick the best one for your task of interest! </p>"},{"location":"benchmark.html#citations","title":"Citations\u00b6","text":"<ol> <li>Wu, Z., Ramsundar, B., Feinberg, E. N., Gomes, J., Geniesse, C., Pappu, A. S., ... &amp; Pande, V. (2018). MoleculeNet: a benchmark for molecular machine learning. Chemical science, 9(2), 513-530.</li> <li>Riniker, S., Fechner, N., &amp; Landrum, G. A. (2013). Heterogeneous classifier fusion for ligand-based virtual screening: or, how decision making by committee can be a good thing. Journal of chemical information and modeling, 53(11), 2829-2836.</li> <li>Riniker, S., &amp; Landrum, G. A. (2013). Open-source platform to benchmark fingerprints for ligand-based virtual screening. Journal of cheminformatics, 5(1), 26.</li> <li>Rogers, D., &amp; Hahn, M. (2010). Extended-connectivity fingerprints. Journal of chemical information and modeling, 50(5), 742-754.</li> <li>Moriwaki, H., Tian, Y. S., Kawashita, N., &amp; Takagi, T. (2018). Mordred: a molecular descriptor calculator. Journal of cheminformatics, 10(1), 1-14.</li> <li>Chithrananda, S., Grand, G., &amp; Ramsundar, B. (2020). Chemberta: Large-scale self-supervised pretraining for molecular property prediction. arXiv preprint arXiv:2010.09885.</li> <li>Efficient and Robust Automated Machine Learning Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum and Frank Hutter Advances in Neural Information Processing Systems 28 (2015)</li> <li>Auto-Sklearn 2.0: The Next Generation Matthias Feurer, Katharina Eggensperger, Stefan Falkner, Marius Lindauer and Frank Hutter* arXiv:2007.04074 [cs.LG], 2020</li> </ol>"},{"location":"license.html","title":"License","text":"<pre><code>Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2023 datamol.io\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n</code></pre>"},{"location":"usage.html","title":"Usage","text":""},{"location":"usage.html#structure","title":"Structure","text":"<p>Molfeat is organized in three main modules:</p> <ul> <li><code>molfeat.store</code>: The model store loads, lists and registers all featurizers.</li> <li><code>molfeat.calc</code>: A calculator is a callable that featurizes a single molecule. </li> <li><code>molfeat.trans</code>: A transformer is a scikit-learn compatible class that wraps a calculator in a featurization pipeline.</li> </ul> <p>Learn more about the different types of featurizers</p> <p>Consult this tutorial to dive deeper into the differences between the calculator and transformer. It provides a good overview of the different types of featurizers and has pointers for learning about more advanced features. </p>"},{"location":"usage.html#quick-api-tour","title":"Quick API Tour","text":"<p>Community contribution</p> <p>Curious how molfeat can simplify training QSAR models? See this tutorial contributed by @PatWalters:  </p> <pre><code>import datamol as dm\nfrom molfeat.calc import FPCalculator\nfrom molfeat.trans import MoleculeTransformer\nfrom molfeat.store.modelstore import ModelStore\n\n# Load some dummy data\ndata = dm.data.freesolv().sample(100).smiles.values\n\n# Featurize a single molecule\ncalc = FPCalculator(\"ecfp\")\ncalc(data[0])\n\n# Define a parallelized featurization pipeline\nmol_transf = MoleculeTransformer(calc, n_jobs=-1)\nmol_transf(data)\n\n# Easily save and load featurizers\nmol_transf.to_state_yaml_file(\"state_dict.yml\")\nmol_transf = MoleculeTransformer.from_state_yaml_file(\"state_dict.yml\")\nmol_transf(data)\n\n# List all available featurizers\nstore = ModelStore()\nstore.available_models\n\n# Find a featurizer and learn how to use it\nmodel_card = store.search(name=\"ChemBERTa-77M-MLM\")[0]\nmodel_card.usage()\n</code></pre>"},{"location":"usage.html#faq","title":"FAQ","text":""},{"location":"usage.html#what-is-a-molecular-featurizer","title":"What is a molecular featurizer ?","text":"<p>A molecular featurizer is a function or model that provides numerical representations for molecular structures. These numerical features serve as inputs for machine learning models, enabling them to predict molecular properties and activities, design novel molecules, perform molecular analyses, or conduct searches for similar molecules.</p>"},{"location":"usage.html#why-so-many-molecular-featurizers-in-molfeat","title":"Why so many molecular featurizers in <code>molfeat</code>?","text":"<p>The reason for providing a diverse range of molecular featurizers in <code>molfeat</code> is to address the inherent uncertainty in determining which molecular representation performs best for a given task. Different featurization methods exist, such as using physico-chemical descriptors, molecular structure fingerprints, deep learning embeddings, and more. The effectiveness of these representations varies depending on the specific application. Therefore, the availability of multiple featurizers in <code>molfeat</code> ensures that users can access the most suitable featurizer for their unique needs.</p>"},{"location":"usage.html#what-is-the-difference-between-a-calculator-and-a-featurizer-in-molfeat","title":"What is the difference between a calculator and a featurizer in <code>molfeat</code>?","text":"<p>In <code>molfeat</code>,</p> <ul> <li>a <code>calculator</code> operates on individual molecules and specifies the process of transforming an input molecule into a numerical representation.</li> <li>a <code>featurizer</code>  works with batches of molecules, leveraging the efficiency of deep learning models on batch processing. Some  <code>featurizers</code> uses a <code>calculator</code> internally to feature each molecule individually and then stitch their outputs together. Additionally, <code>featurizers</code> offer convenient tools, such as parallelism and caching, to optimize the computation of molecular representations efficiently.</li> </ul> <p><code>molfeat</code> has been designed with utmost flexibility, recognizing that the actions users wish to perform with molecular data can be vast and diverse, and there often isn't a single \"right\" way to approach them.</p>"},{"location":"usage.html#what-functions-should-i-be-familiar-with-when-using-the-featurizer-classes","title":"What functions should I be familiar with when using the featurizer classes ?","text":"<p>When using a <code>featurizer</code> in <code>molfeat</code>, you should be familiar with the following functions:</p> <ul> <li><code>preprocess()</code>: This method performs preprocessing of your input molecules to ensure compatibility with the expected featurizer class you are using. It's essential to note that the preprocessing steps are not automatically applied to your inputs to maintain independence from the molecular transformation. The preprocess function takes your molecule inputs, along with optional labels, and can be redefined when creating a custom featurizer.</li> </ul> <ul> <li><code>transform()</code>: This method operates on a batch of molecules and returns a list of representations, where the actual featurization occurs. In cases where featurization fails, the position can be denoted as <code>None</code>, especially when you choose to <code>ignore_errors</code>.</li> <li><code>_transform()</code>: This method operates on a single input molecule, performing the actual featurization.</li> <li><code>__call__()</code>: This method uses <code>transform()</code> under the hood and provides convenient arguments, such as enforcing the datatype defined during the initialization of your model, to the outputs. If you specify <code>ignore_errors</code>, a vector of indexes where featurization did not fail will also be returned.</li> </ul> <p>In addition to the methods described above, PretrainedMolTransformer introduces the following functions:</p> <ul> <li><code>_embed()</code>: For pre-trained models that benefit from batched featurization, this method is internally called during transform instead of an internal calculator.</li> <li><code>_convert()</code>: This method is called by the transformer to convert the molecule input into the expected format of the underlying ML model. For example, for a pre-trained language model expecting SELFIES strings, we will perform the conversion to SELFIES strings here.</li> </ul>"},{"location":"usage.html#i-am-getting-an-error-and-i-am-not-sure-what-to-do","title":"I am getting an error and I am not sure what to do ?","text":"<p>When encountering an error during the featurization process, you have a couple of options to handle it:</p> <ul> <li>Ignore Errors: You can choose to set the <code>ignore_errors</code> parameter to <code>True</code> when using the featurizer. This allows the featurizer to continue processing even if it encounters errors on some molecules in your dataset. The featurizer will still attempt to calculate representations for all molecules, and any molecules that failed featurization will have their position in the output list marked as <code>None</code>.</li> </ul> <ul> <li>Increase Verbosity: If you're unsure about the specific errors occurring during featurization, you can set the verbosity of the featurizer to True. This will enable the featurizer to log all errors encountered during the process, providing more detailed information about the cause of the issue, since because of the above features, some silent errors are often caught but not propagated.</li> </ul> <p>For example, the following will ensure that all errors are logged.</p> <pre><code>from molfeat.trans.concat import FeatConcat\nfrom molfeat.trans.fp import FPVecTransformer\nimport numpy as np\nfeaturizer = MoleculeTransformer(..., dtype=np.float32, verbose=True)\nfeaturizer([\"CSc1nc2cc3c(cc2[nH]1)N(Cc1ccc(S(=O)(=O)c2ccccc2)cc1)CCC3\"], enforce_dtype=True)\n</code></pre>"},{"location":"usage.html#what-are-the-base-featurizers-class-in-molfeat-and-how-to-use-them","title":"What are the base featurizers class in molfeat and how to use them ?","text":"Class Module Why? BaseFeaturizer <code>molfeat.trans.base</code> Lowest level featurizer class. All featurizers (even if not molecular) inherit from this class. It's recommended to use <code>MoleculeTransformer</code> as the root class instead. MoleculeTransformer <code>molfeat.trans.base</code> <ul><li> Base class for all molecule featurizers. This is where you start if you want to implement a new featurizer.</li><li> You can provide either an existing <code>calculator</code> or your own (a python callable) directly to define a new <code>featurizer</code>.</li></ul> PrecomputedMolTransformer <code>molfeat.trans.base</code> Class for dealing with precomputed features. You can leverage this class to compute features, save them in a file, and reload them after for other tasks efficiently. See this tutorial! FeatConcat <code>molfeat.trans.concat</code> Convenient class for concatenating multiple vector-featurizers automatically. If you want to combine multiple 'fingerprints' and descriptors, this is the class you use. See example! PretrainedMolTransformer <code>molfeat.trans.pretrained.base</code> Base class for all <code>pretrained featurizers</code>. A <code>pretrained featurizer</code> is a <code>featurizer</code> that is derived from a pretrained machine learning model. Implement a subclass of this to define your new pretrained featurizer. See example! PretrainedDGLTransformer <code>molfeat.trans.pretrained.dgl_pretrained</code> Base class for all <code>dgl pretrained featurizers</code>. You can initialize a new dgl/dgllife pretrained model as a <code>molfeat featurizer</code> easily using this class. You only need to add the dgl model object to a store. See this example! PretrainedHFTransformer <code>molfeat.trans.pretrained.hf_transformer</code> Base class for all <code>huggingface pretrained featurizers</code>. You can initialize a new \ud83e\udd17 Transformers pretrained model as a <code>molfeat featurizer</code> easily using this class. See this example!"},{"location":"api/molfeat.calc.html","title":"<code>Calculators</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.get_calculator","title":"<code>get_calculator(name, **params)</code>","text":"<p>Get molecular calculator based on name</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the featurizer</p> required <code>params</code> <code>dict</code> <p>Parameters of the featurizer</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>When featurizer is not supported</p> <p>Returns:</p> Name Type Description <code>featurizer</code> <p>Callable</p> Source code in <code>molfeat/calc/__init__.py</code> <pre><code>def get_calculator(name: str, **params):\n    \"\"\"Get molecular calculator based on name\n\n    Args:\n        name: Name of the featurizer\n        params (dict): Parameters of the featurizer\n\n    Raises:\n        ValueError: When featurizer is not supported\n\n    Returns:\n        featurizer: Callable\n    \"\"\"\n    if not isinstance(name, str):\n        return name\n\n    CALC_MAP = {k.lower(): v for k, v in _CALCULATORS.items()}\n    name = name.lower()\n    if name in FP_FUNCS.keys():\n        featurizer = FPCalculator(name, **params)\n    elif name == \"desc3d\":\n        featurizer = RDKitDescriptors3D(**params)\n    elif name == \"desc2d\":\n        featurizer = RDKitDescriptors2D(**params)\n    elif name == \"mordred\":\n        featurizer = MordredDescriptors(**params)\n    elif name == \"cats\":\n        featurizer = CATS(**params)\n    elif name == \"cats2d\":\n        params[\"use_3d_distances\"] = False\n        featurizer = CATS(**params)\n    elif name == \"cats3d\":\n        params[\"use_3d_distances\"] = True\n        featurizer = CATS(**params)\n    elif name == \"pharm2d\":\n        featurizer = Pharmacophore2D(**params)\n    elif name == \"pharm3d\":\n        featurizer = Pharmacophore3D(**params)\n    elif name.startswith(\"usr\"):\n        params[\"method\"] = name\n        featurizer = USRDescriptors(**params)\n    elif name == \"electroshape\":\n        featurizer = ElectroShapeDescriptors(**params)\n    elif name in [\"scaffoldkeys\", \"skeys\", \"scaffkeys\"]:\n        featurizer = ScaffoldKeyCalculator(**params)\n    elif name == \"none\":\n        featurizer = None\n    # for any generic calculator that has been automatically registered\n    elif name in CALC_MAP.keys():\n        featurizer = CALC_MAP[name](**params)\n    else:\n        raise ValueError(f\"{name} is not a supported internal featurizer\")\n    return featurizer\n</code></pre>"},{"location":"api/molfeat.calc.html#serializable-calculator-are-the-base-abstract-class-for-implementing-your-calculators","title":"Serializable Calculator are the base abstract class for implementing your calculators.","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator","title":"<code>SerializableCalculator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Interface to define a serializable calculator</p> Subclassing SerializableCalculator <p>When subclassing a calculator, you must implement the call method. If your calculator also implements a <code>batch_compute</code> method, it will be used by <code>MoleculeTransformer</code> to accelerate featurization.</p> <pre><code>from molfeat.calc import SerializableCalculator\n\nclass MyCalculator(SerializableCalculator):\n\n    def __call__(self, mol, **kwargs):\n        # you have to implement this\n        ...\n\n    def __len__(self):\n        # you don't have to implement this but are encouraged to do so\n        # this is used to determine the length of the output\n        ...\n\n    @property\n    def columns(self):\n        # you don't have to implement this\n        # use this to return the name of each entry returned by your featurizer\n        ...\n\n    def batch_compute(self, mols:list, **dm_parallelized_kwargs):\n        # you don't need to implement this\n        # but you should if there is an efficient batching process\n        # By default dm.parallelized arguments will also be passed as input\n        ...\n</code></pre> Source code in <code>molfeat/calc/base.py</code> <pre><code>class SerializableCalculator(abc.ABC, metaclass=_CalculatorMeta):\n    \"\"\"Interface to define a serializable calculator\n\n    ???+ tip \"Subclassing SerializableCalculator\"\n        When subclassing a calculator, you must implement the __call__ method.\n        If your calculator also implements a `batch_compute` method, it will be used\n        by `MoleculeTransformer` to accelerate featurization.\n\n        ```python\n        from molfeat.calc import SerializableCalculator\n\n        class MyCalculator(SerializableCalculator):\n\n            def __call__(self, mol, **kwargs):\n                # you have to implement this\n                ...\n\n            def __len__(self):\n                # you don't have to implement this but are encouraged to do so\n                # this is used to determine the length of the output\n                ...\n\n            @property\n            def columns(self):\n                # you don't have to implement this\n                # use this to return the name of each entry returned by your featurizer\n                ...\n\n            def batch_compute(self, mols:list, **dm_parallelized_kwargs):\n                # you don't need to implement this\n                # but you should if there is an efficient batching process\n                # By default dm.parallelized arguments will also be passed as input\n                ...\n        ```\n    \"\"\"\n\n    @abc.abstractmethod\n    def __call__(self, *args, **kwargs):\n        pass\n\n    @classmethod\n    def from_state_dict(cls, state: dict, override_args: Optional[dict] = None):\n        \"\"\"Load from state dictionary\n\n        Args:\n            state: dictionary to use to create the the calculator\n            overrride_args: optional dictionary of arguments to override the ones in the state dict\n                at construction of the new object\n        \"\"\"\n        cls_name = state.get(\"name\", cls.__name__)\n        module_name = state.get(\"module\", cls.__module__)\n        module = importlib.import_module(module_name)\n        klass = getattr(module, cls_name)\n        kwargs = state[\"args\"].copy()\n        kwargs.update(**(override_args or {}))\n        return klass(**kwargs)\n\n    def to_state_dict(self):\n        \"\"\"Get the state dictionary\"\"\"\n        state_dict = {}\n        state_dict[\"name\"] = self.__class__.__name__\n        state_dict[\"module\"] = self.__class__.__module__\n        state_dict[\"args\"] = self.__getstate__()\n        state_dict[\"_molfeat_version\"] = MOLFEAT_VERSION\n        # we would like to keep input arguments as is.\n        signature = inspect.signature(self.__init__)\n        val = {k: v.default for k, v in signature.parameters.items()}\n        to_remove = [k for k in state_dict[\"args\"] if k not in val.keys()]\n        for k in to_remove:\n            state_dict[\"args\"].pop(k)\n        return state_dict\n\n    def to_state_json(self) -&gt; str:\n        \"\"\"Output this instance as a JSON representation\"\"\"\n        return json.dumps(self.to_state_dict())\n\n    def to_state_yaml(self) -&gt; str:\n        \"\"\"Output this instance as a YAML representation\"\"\"\n        return yaml.dump(self.to_state_dict(), Dumper=yaml.SafeDumper)\n\n    def to_state_json_file(self, filepath: str):\n        \"\"\"Save the state of this instance as a JSON file\"\"\"\n        with fsspec.open(filepath, \"w\") as f:\n            f.write(self.to_state_json())  # type: ignore\n\n    def to_state_yaml_file(self, filepath: str):\n        \"\"\"Save the state of this instance as a YAML file\"\"\"\n        with fsspec.open(filepath, \"w\") as f:\n            f.write(self.to_state_yaml())  # type: ignore\n\n    @classmethod\n    def from_state_json(\n        cls,\n        state_json: str,\n        override_args: Optional[dict] = None,\n    ):\n        state_dict = yaml.safe_load(state_json)\n        return cls.from_state_dict(state_dict, override_args=override_args)\n\n    @classmethod\n    def from_state_yaml(\n        cls,\n        state_yaml: str,\n        override_args: Optional[dict] = None,\n    ):\n        state_dict = yaml.load(state_yaml, Loader=yaml.SafeLoader)\n        return cls.from_state_dict(state_dict, override_args=override_args)\n\n    @classmethod\n    def from_state_json_file(\n        cls,\n        filepath: str,\n        override_args: Optional[dict] = None,\n    ):\n        with fsspec.open(filepath, \"r\") as f:\n            featurizer = cls.from_state_json(f.read(), override_args=override_args)  # type: ignore\n        return featurizer\n\n    @classmethod\n    def from_state_yaml_file(\n        cls,\n        filepath: str,\n        override_args: Optional[dict] = None,\n    ):\n        with fsspec.open(filepath, \"r\") as f:\n            featurizer = cls.from_state_yaml(f.read(), override_args=override_args)  # type: ignore\n        return featurizer\n\n    @classmethod\n    def from_state_file(\n        cls,\n        state_path: str,\n        override_args: Optional[dict] = None,\n    ):\n        if state_path.endswith(\"yaml\") or state_path.endswith(\"yml\"):\n            return cls.from_state_yaml_file(filepath=state_path, override_args=override_args)\n        elif state_path.endswith(\"json\"):\n            return cls.from_state_json_file(filepath=state_path, override_args=override_args)\n        elif state_path.endswith(\"pkl\"):\n            with fsspec.open(state_path, \"rb\") as IN:\n                return joblib.load(IN)\n        raise ValueError(\n            \"Only files with 'yaml' or 'json' format are allowed. \"\n            \"The filename must be ending with `yaml`, 'yml' or 'json'.\"\n        )\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator.from_state_dict","title":"<code>from_state_dict(state, override_args=None)</code>  <code>classmethod</code>","text":"<p>Load from state dictionary</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>dict</code> <p>dictionary to use to create the the calculator</p> required <code>overrride_args</code> <p>optional dictionary of arguments to override the ones in the state dict at construction of the new object</p> required Source code in <code>molfeat/calc/base.py</code> <pre><code>@classmethod\ndef from_state_dict(cls, state: dict, override_args: Optional[dict] = None):\n    \"\"\"Load from state dictionary\n\n    Args:\n        state: dictionary to use to create the the calculator\n        overrride_args: optional dictionary of arguments to override the ones in the state dict\n            at construction of the new object\n    \"\"\"\n    cls_name = state.get(\"name\", cls.__name__)\n    module_name = state.get(\"module\", cls.__module__)\n    module = importlib.import_module(module_name)\n    klass = getattr(module, cls_name)\n    kwargs = state[\"args\"].copy()\n    kwargs.update(**(override_args or {}))\n    return klass(**kwargs)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Get the state dictionary</p> Source code in <code>molfeat/calc/base.py</code> <pre><code>def to_state_dict(self):\n    \"\"\"Get the state dictionary\"\"\"\n    state_dict = {}\n    state_dict[\"name\"] = self.__class__.__name__\n    state_dict[\"module\"] = self.__class__.__module__\n    state_dict[\"args\"] = self.__getstate__()\n    state_dict[\"_molfeat_version\"] = MOLFEAT_VERSION\n    # we would like to keep input arguments as is.\n    signature = inspect.signature(self.__init__)\n    val = {k: v.default for k, v in signature.parameters.items()}\n    to_remove = [k for k in state_dict[\"args\"] if k not in val.keys()]\n    for k in to_remove:\n        state_dict[\"args\"].pop(k)\n    return state_dict\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator.to_state_json","title":"<code>to_state_json()</code>","text":"<p>Output this instance as a JSON representation</p> Source code in <code>molfeat/calc/base.py</code> <pre><code>def to_state_json(self) -&gt; str:\n    \"\"\"Output this instance as a JSON representation\"\"\"\n    return json.dumps(self.to_state_dict())\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator.to_state_json_file","title":"<code>to_state_json_file(filepath)</code>","text":"<p>Save the state of this instance as a JSON file</p> Source code in <code>molfeat/calc/base.py</code> <pre><code>def to_state_json_file(self, filepath: str):\n    \"\"\"Save the state of this instance as a JSON file\"\"\"\n    with fsspec.open(filepath, \"w\") as f:\n        f.write(self.to_state_json())  # type: ignore\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator.to_state_yaml","title":"<code>to_state_yaml()</code>","text":"<p>Output this instance as a YAML representation</p> Source code in <code>molfeat/calc/base.py</code> <pre><code>def to_state_yaml(self) -&gt; str:\n    \"\"\"Output this instance as a YAML representation\"\"\"\n    return yaml.dump(self.to_state_dict(), Dumper=yaml.SafeDumper)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.base.SerializableCalculator.to_state_yaml_file","title":"<code>to_state_yaml_file(filepath)</code>","text":"<p>Save the state of this instance as a YAML file</p> Source code in <code>molfeat/calc/base.py</code> <pre><code>def to_state_yaml_file(self, filepath: str):\n    \"\"\"Save the state of this instance as a YAML file\"\"\"\n    with fsspec.open(filepath, \"w\") as f:\n        f.write(self.to_state_yaml())  # type: ignore\n</code></pre>"},{"location":"api/molfeat.calc.html#fingerprints","title":"<code>Fingerprints</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator","title":"<code>FPCalculator</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>Fingerprint bit calculator for a molecule</p> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>class FPCalculator(SerializableCalculator):\n    \"\"\"Fingerprint bit calculator for a molecule\"\"\"\n\n    def __init__(\n        self,\n        method: str,\n        length: Optional[int] = None,\n        counting: bool = False,\n        **method_params,\n    ):\n        \"\"\"Compute the given fingeprint for a molecule\n\n        !!! note\n            For efficiency reason, count fingerprints are hashed and potentially\n            re-folded and the count corresponds to the number of bits set to true\n\n        Args:\n            method (str): Name of the fingerprint method to use. See FPCalculator.available_fingerprints() for a list\n            length (int, optional): Length of the fingerprint. Defaults to None.\n                The default corresponds to the fingerpint default.\n            counting (bool, optional): Whether to use the count version of the fingerprint\n            method_params (dict): any parameters to the fingerprint algorithm.\n                See FPCalculator.default_parameters(method) for all the parameters required by a given method.\n        \"\"\"\n        self.method = method.lower()\n        self.counting = counting or \"-count\" in self.method\n        if self.counting and \"-count\" not in self.method:\n            self.method = self.method + \"-count\"\n        self.input_length = length\n        if self.method not in FP_FUNCS:\n            raise ValueError(f\"Method {self.method} is not a supported featurizer\")\n        default_params = copy.deepcopy(FP_DEF_PARAMS[method])\n        unknown_params = set(method_params.keys()).difference(set(default_params.keys()))\n        if unknown_params:\n            logger.error(f\"Params: {unknown_params} are not valid for {method}\")\n        self.params = default_params\n        self.params.update(\n            {k: method_params[k] for k in method_params if k in default_params.keys()}\n        )\n        self._length = self._set_length(length)\n\n    @staticmethod\n    def available_fingerprints():\n        \"\"\"Get the list of available fingerprints\"\"\"\n        return list(FP_FUNCS.keys())\n\n    @staticmethod\n    def default_parameters(method: str):\n        \"\"\"Get the default parameters for a given fingerprint method\n\n        Args:\n            method: name of the fingerprint method\n        \"\"\"\n        return FP_DEF_PARAMS[method].copy()\n\n    @property\n    def columns(self):\n        \"\"\"\n        Get the name of all the descriptors of this calculator\n        \"\"\"\n        return [f\"fp_{i}\" for i in range(self._length)]\n\n    def __len__(self):\n        \"\"\"Return the length of the calculator\"\"\"\n        return self._length\n\n    def _set_length(self, length=None):\n        \"\"\"Get the length of the featurizer\"\"\"\n        fplen = length\n        len_key = None\n        if self.method == \"maccs\":\n            fplen = 167\n        elif self.method == \"estate\":\n            fplen = 79\n        elif self.method == \"erg\":\n            fplen = 315\n        elif self.method == \"rdkit-count\" and not fplen:\n            fplen = 2048\n        elif \"nBits\" in self.params.keys():\n            len_key = \"nBits\"\n            fplen = self.params[len_key]\n        elif \"n_permutations\" in self.params.keys():\n            # special case for mhfp\n            len_key = \"n_permutations\"\n            fplen = self.params[len_key]\n        elif \"fpSize\" in self.params.keys():\n            len_key = \"fpSize\"\n            fplen = self.params[len_key]\n        elif \"dimensions\" in self.params.keys():\n            len_key = \"dimensions\"\n            fplen = self.params[len_key]\n        if len_key is not None and length:\n            self.params[len_key] = length\n            fplen = length\n        return fplen\n\n    def __call__(self, mol: Union[dm.Mol, str], raw: bool = False):\n        r\"\"\"\n        Compute the Fingerprint of a molecule\n\n        Args:\n            mol: the molecule of interest\n            raw: whether to keep original datatype or convert to numpy. Useful for rdkit's similarity functions\n\n        Returns:\n            props (np.ndarray): list of computed rdkit molecular descriptors\n        \"\"\"\n        mol = dm.to_mol(mol)\n\n        fp_func = FP_FUNCS[self.method]\n        if self.method in FP_GENERATORS:\n            fp_func = fp_func(**self.params)\n            if self.counting:\n                fp_val = fp_func.GetCountFingerprint(mol)\n            else:\n                fp_val = fp_func.GetFingerprint(mol)\n        else:\n            fp_val = fp_func(mol, **self.params)\n        if self.counting:\n            fp_val = fold_count_fp(fp_val, self._length)\n        if not raw:\n            fp_val = to_numpy(fp_val)\n        if self.counting and raw:\n            # converint the counted values to SparseInt again\n            fp_val = to_fp(fp_val, bitvect=False)\n        return fp_val\n\n    def __getstate__(self):\n        # EN: note that the state is standardized with all the parameter\n        # because of the possibility of default changing after\n        state = {}\n        state[\"length\"] = self.input_length\n        state[\"input_length\"] = self.input_length\n        state[\"method\"] = self.method\n        state[\"counting\"] = self.counting\n        state[\"params\"] = {\n            k: (v if v.__class__.__name__ not in SERIALIZABLE_CLASSES else v.__class__.__name__)\n            for k, v in self.params.items()\n        }\n        return state\n\n    def __setstate__(self, state: dict):\n        \"\"\"Set the state of the featurizer\"\"\"\n        self.__dict__.update(state)\n        self.params = {\n            k: (v if v not in SERIALIZABLE_CLASSES else SERIALIZABLE_CLASSES[v]())\n            for k, v in self.params.items()\n        }\n        self._length = self._set_length(self.input_length)\n\n    def to_state_dict(self):\n        \"\"\"Get the state dictionary\"\"\"\n        state_dict = super().to_state_dict()\n        cur_params = self.params\n        default_params = copy.deepcopy(FP_DEF_PARAMS[state_dict[\"args\"][\"method\"]])\n\n        state_dict[\"args\"].update(\n            {\n                k: (\n                    cur_params[k]\n                    if cur_params[k].__class__.__name__ not in SERIALIZABLE_CLASSES\n                    else cur_params[k].__class__.__name__\n                )\n                for k in cur_params\n                if (cur_params[k] != default_params[k] and cur_params[k] is not None)\n            }\n        )\n        # we want to keep all the additional parameters in the state dict\n        return state_dict\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the name of all the descriptors of this calculator</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.__call__","title":"<code>__call__(mol, raw=False)</code>","text":"<p>Compute the Fingerprint of a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>raw</code> <code>bool</code> <p>whether to keep original datatype or convert to numpy. Useful for rdkit's similarity functions</p> <code>False</code> <p>Returns:</p> Name Type Description <code>props</code> <code>ndarray</code> <p>list of computed rdkit molecular descriptors</p> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], raw: bool = False):\n    r\"\"\"\n    Compute the Fingerprint of a molecule\n\n    Args:\n        mol: the molecule of interest\n        raw: whether to keep original datatype or convert to numpy. Useful for rdkit's similarity functions\n\n    Returns:\n        props (np.ndarray): list of computed rdkit molecular descriptors\n    \"\"\"\n    mol = dm.to_mol(mol)\n\n    fp_func = FP_FUNCS[self.method]\n    if self.method in FP_GENERATORS:\n        fp_func = fp_func(**self.params)\n        if self.counting:\n            fp_val = fp_func.GetCountFingerprint(mol)\n        else:\n            fp_val = fp_func.GetFingerprint(mol)\n    else:\n        fp_val = fp_func(mol, **self.params)\n    if self.counting:\n        fp_val = fold_count_fp(fp_val, self._length)\n    if not raw:\n        fp_val = to_numpy(fp_val)\n    if self.counting and raw:\n        # converint the counted values to SparseInt again\n        fp_val = to_fp(fp_val, bitvect=False)\n    return fp_val\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.__init__","title":"<code>__init__(method, length=None, counting=False, **method_params)</code>","text":"<p>Compute the given fingeprint for a molecule</p> <p>Note</p> <p>For efficiency reason, count fingerprints are hashed and potentially re-folded and the count corresponds to the number of bits set to true</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Name of the fingerprint method to use. See FPCalculator.available_fingerprints() for a list</p> required <code>length</code> <code>int</code> <p>Length of the fingerprint. Defaults to None. The default corresponds to the fingerpint default.</p> <code>None</code> <code>counting</code> <code>bool</code> <p>Whether to use the count version of the fingerprint</p> <code>False</code> <code>method_params</code> <code>dict</code> <p>any parameters to the fingerprint algorithm. See FPCalculator.default_parameters(method) for all the parameters required by a given method.</p> <code>{}</code> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>def __init__(\n    self,\n    method: str,\n    length: Optional[int] = None,\n    counting: bool = False,\n    **method_params,\n):\n    \"\"\"Compute the given fingeprint for a molecule\n\n    !!! note\n        For efficiency reason, count fingerprints are hashed and potentially\n        re-folded and the count corresponds to the number of bits set to true\n\n    Args:\n        method (str): Name of the fingerprint method to use. See FPCalculator.available_fingerprints() for a list\n        length (int, optional): Length of the fingerprint. Defaults to None.\n            The default corresponds to the fingerpint default.\n        counting (bool, optional): Whether to use the count version of the fingerprint\n        method_params (dict): any parameters to the fingerprint algorithm.\n            See FPCalculator.default_parameters(method) for all the parameters required by a given method.\n    \"\"\"\n    self.method = method.lower()\n    self.counting = counting or \"-count\" in self.method\n    if self.counting and \"-count\" not in self.method:\n        self.method = self.method + \"-count\"\n    self.input_length = length\n    if self.method not in FP_FUNCS:\n        raise ValueError(f\"Method {self.method} is not a supported featurizer\")\n    default_params = copy.deepcopy(FP_DEF_PARAMS[method])\n    unknown_params = set(method_params.keys()).difference(set(default_params.keys()))\n    if unknown_params:\n        logger.error(f\"Params: {unknown_params} are not valid for {method}\")\n    self.params = default_params\n    self.params.update(\n        {k: method_params[k] for k in method_params if k in default_params.keys()}\n    )\n    self._length = self._set_length(length)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the calculator</p> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the length of the calculator\"\"\"\n    return self._length\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Set the state of the featurizer</p> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>def __setstate__(self, state: dict):\n    \"\"\"Set the state of the featurizer\"\"\"\n    self.__dict__.update(state)\n    self.params = {\n        k: (v if v not in SERIALIZABLE_CLASSES else SERIALIZABLE_CLASSES[v]())\n        for k, v in self.params.items()\n    }\n    self._length = self._set_length(self.input_length)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.available_fingerprints","title":"<code>available_fingerprints()</code>  <code>staticmethod</code>","text":"<p>Get the list of available fingerprints</p> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>@staticmethod\ndef available_fingerprints():\n    \"\"\"Get the list of available fingerprints\"\"\"\n    return list(FP_FUNCS.keys())\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.default_parameters","title":"<code>default_parameters(method)</code>  <code>staticmethod</code>","text":"<p>Get the default parameters for a given fingerprint method</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>name of the fingerprint method</p> required Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>@staticmethod\ndef default_parameters(method: str):\n    \"\"\"Get the default parameters for a given fingerprint method\n\n    Args:\n        method: name of the fingerprint method\n    \"\"\"\n    return FP_DEF_PARAMS[method].copy()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.fingerprints.FPCalculator.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Get the state dictionary</p> Source code in <code>molfeat/calc/fingerprints.py</code> <pre><code>def to_state_dict(self):\n    \"\"\"Get the state dictionary\"\"\"\n    state_dict = super().to_state_dict()\n    cur_params = self.params\n    default_params = copy.deepcopy(FP_DEF_PARAMS[state_dict[\"args\"][\"method\"]])\n\n    state_dict[\"args\"].update(\n        {\n            k: (\n                cur_params[k]\n                if cur_params[k].__class__.__name__ not in SERIALIZABLE_CLASSES\n                else cur_params[k].__class__.__name__\n            )\n            for k in cur_params\n            if (cur_params[k] != default_params[k] and cur_params[k] is not None)\n        }\n    )\n    # we want to keep all the additional parameters in the state dict\n    return state_dict\n</code></pre>"},{"location":"api/molfeat.calc.html#cats","title":"<code>CATS</code>","text":"<p>CATS 2D and 3D implementation based on original work by Rajarshi Guha rguha@indiana.edu 08/26/07 and Chris Arthur 1/11/2015 Rdkit port This version modernizes the code, improve performance, add supports for 3D as well as allowing distance binning. see: https://masterchemoinfo.u-strasbg.fr/Documents/Conferences/Lecture1_Pharmacophores_Schneider.pdf</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS","title":"<code>CATS</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>Cats descriptors calculator based on PPPs (potential pharmacophore points). Can be either 2D or 3D.</p> <p>!!! note:     We need to consider all pairwise combination of the 6 PPPs described in <code>CATS2D.SMARTS</code>     which would be $P(6,2) + 6$. However, as we only consider lexicographic order, the total size     is then $\frac{P(6,2)}{2} + 6 = 21$, explaining the size of <code>CATS2D.DESCRIPTORS</code></p> <p>Tip</p> <p>The CATS descriptor are sensitive to the number of atoms in a molecule, meaning, you would get different results if you add or remove hydrogen atoms</p> Source code in <code>molfeat/calc/cats.py</code> <pre><code>class CATS(SerializableCalculator):\n    \"\"\"Cats descriptors calculator based on PPPs (potential pharmacophore points). Can be either 2D or 3D.\n\n    !!! note:\n        We need to consider all pairwise combination of the 6 PPPs described in `CATS2D.SMARTS`\n        which would be $P(6,2) + 6$. However, as we only consider lexicographic order, the total size\n        is then $\\frac{P(6,2)}{2} + 6 = 21$, explaining the size of `CATS2D.DESCRIPTORS`\n\n    !!! tip\n        The CATS descriptor are sensitive to the number of atoms in a molecule, meaning, you would get different\n        results if you add or remove hydrogen atoms\n\n    \"\"\"\n\n    SMARTS = {\n        \"D\": [\"[!$([#6,H0,-,-2,-3])]\"],\n        \"A\": [\"[!$([#6,F,Cl,Br,I,o,s,nX3,#7v5,#15v5,#16v4,#16v6,*+1,*+2,*+3])]\"],\n        \"P\": [\"[*+]\", \"[#7H2]\"],\n        \"N\": [\"[*-]\", \"[C&amp;$(C(=O)O),P&amp;$(P(=O)),S&amp;$(S(=O)O)]\"],\n        \"L\": [\n            \"[Cl,Br,I]\",\n            \"[S;D2;$(S(C)(C))]\",\n            \"[C;D2;$(C(=C)(=C))]\",\n            \"[C;D3;$(C(=C)(C)(C))]\",\n            \"[C;D4;$(C(C)(C)(C)(C))]\",\n            \"[C;D3;H1;$(C(C)(C)(C))]\",\n            \"[C;D2;H2;$(C(C)(C))]\",\n        ],\n        \"R\": [\"[a]\"],\n    }\n\n    DESCRIPTORS = [\n        \"DD\",\n        \"AD\",\n        \"DP\",\n        \"DN\",\n        \"DL\",\n        \"DR\",\n        \"AA\",\n        \"AP\",\n        \"AN\",\n        \"AL\",\n        \"AR\",\n        \"PP\",\n        \"NP\",\n        \"LP\",\n        \"PR\",\n        \"NN\",\n        \"LN\",\n        \"NR\",\n        \"LL\",\n        \"LR\",\n        \"RR\",\n    ]\n\n    MAX_DIST_DEFAULT_2D = 8\n    MAX_DIST_DEFAULT_3D = 5\n\n    def __init__(\n        self,\n        max_dist: Union[float, int] = None,\n        bins: List[int] = None,\n        scale: str = \"raw\",\n        use_3d_distances: bool = False,\n        **kwargs,\n    ):\n        \"\"\"Calculator for the CATS descriptors.\n\n        `max_dist` and `bins` will both determine the length of the fingerprint vector,\n        which you can get by calling `len(calc)`\n\n        Args:\n            max_dist: Maximum distance between pairs. When set to None, the default for 2D is\n                set to `max_dist=8` and for 3D to `max_dist=5`.\n            bins: Bins to use. Defaults to equal spacing `[0, max_dist[`.\n            scale: How to scale the values. Supported values are:\n                 - 'raw' for the raw values.\n                 - 'num' for values normalized by the number of atoms.\n                 - 'count' for scaling based on occurence of the PPP.\n            use_3d_distances: Whether to use the 3D distances instead of the topological distances.\n                If set to True, the input molecules must contain a conformer.\n            kwargs: silently ignored extra parameters for compatibility with other calculators.\n        \"\"\"\n\n        # Set the max_dist default is set to None\n        if max_dist is None:\n            if use_3d_distances:\n                max_dist = CATS.MAX_DIST_DEFAULT_3D\n            else:\n                max_dist = CATS.MAX_DIST_DEFAULT_2D\n\n        self.max_dist = max_dist\n        self.use_3d_distances = use_3d_distances\n\n        if bins is None:\n            bins = list(np.arange(1, np.floor(self.max_dist + 1), 1))\n\n        # we don't allow interaction that exceed our distance threshold.\n        bins = [x for x in bins if x &lt;= self.max_dist]\n\n        # we start distance indexing at 0\n        if 0 not in bins:\n            bins += [0]\n\n        self.bins = list(sorted(bins))\n\n        self.scale = scale\n\n        self._set_columns()\n\n    def _set_columns(self):\n        self._columns = []\n        for label in self.DESCRIPTORS:\n            for i in range(len(self.bins)):\n                self._columns.append(f\"{label}.bins-{i}\")\n\n    @classmethod\n    @functools.lru_cache(maxsize=None)\n    def _pattern_to_mols(cls, smarts_dict=None):\n        \"\"\"Convert dict of list of smarts to rdkit molecules\"\"\"\n\n        if smarts_dict is None:\n            smarts_dict = cls.SMARTS\n\n        smarts_mols = ddict(list)\n        for label, patterns in smarts_dict.items():\n            patterns = [dm.from_smarts(patt) for patt in patterns]\n            smarts_mols[label] = patterns\n\n        return smarts_mols\n\n    def _get_pcore_group(self, mol: Union[dm.Mol, str]):\n        \"\"\"\n        Assign a PPP (potential pharmacophore points) to individual atoms of a molecule.\n\n        !!! note\n            The return value is a list of length `N_atoms` of the\n            input molecule. The i'th element of the list contains\n            a list of PPP labels that were identified for the i'th atom\n\n        Args:\n            mol: the molecule of interest\n\n        Returns:\n            ppp_labels (List[list]): list of all PPP labels for each atoms\n        \"\"\"\n\n        smarts_mols = CATS._pattern_to_mols()\n\n        ppp_labels = [\"\" for x in range(0, mol.GetNumAtoms())]\n        for label, patterns in smarts_mols.items():\n            for pattern in patterns:\n                matched = False\n                for matchbase in mol.GetSubstructMatches(pattern, uniquify=True):\n                    for idx in matchbase:\n                        if ppp_labels[idx] == \"\":\n                            ppp_labels[idx] = [label]\n                        else:\n                            tmp = ppp_labels[idx]\n                            tmp.append(label)\n                            ppp_labels[idx] = tmp\n                    matched = True\n                if matched:\n                    break\n        return ppp_labels\n\n    def _get_ppp_matrix(self, n_atoms: int, ppp_labels: List):\n        \"\"\"Compute PPP matrix from label list\n\n        Args:\n            n_atoms (int): number of atoms\n            ppp_labels (list): PPP labels returned by\n\n        Returns:\n            pppm (dict): PPP matrix where the keys are the coordinate\n        \"\"\"\n\n        pppm = {}\n        for i in range(0, n_atoms):\n            ppp_i = ppp_labels[i]\n            if ppp_i == \"\":\n                continue\n            for j in range(0, n_atoms):\n                ppp_j = ppp_labels[j]\n                if ppp_j == \"\":\n                    continue\n                pairs = []\n                for x in ppp_i:\n                    for y in ppp_j:\n                        if (x, y) not in pairs and (y, x) not in pairs:\n                            ## make sure to add the labels in increasing\n                            ## lexicographical order\n                            if x &lt; y:\n                                tmp = (x, y)\n                            else:\n                                tmp = (y, x)\n                            pairs.append(tmp)\n                pppm[(i, j)] = pairs\n        return pppm\n\n    def _calculate(self, mol, dist_mat):\n        \"\"\"Calculate the CATS2D descriptors for current molecule, given a distance matrix\"\"\"\n\n        n_atoms = mol.GetNumAtoms()\n        ppp_labels = self._get_pcore_group(mol)\n        ppp_mat = self._get_ppp_matrix(n_atoms, ppp_labels)\n\n        # get the counturence of each of the PPP's\n        ppp_count = dict(zip([\"D\", \"N\", \"A\", \"P\", \"L\", \"R\"], [0] * 6))\n        for label in ppp_labels:\n            for ppp in label:\n                ppp_count[ppp] = ppp_count[ppp] + 1\n\n        # lets calculate the CATS2D raw descriptor\n        # bins: a, b, c ==&gt; [a, b], [b, c], [c, *]\n        # a is always 0\n        desc = [[0 for x in range(len(self.bins))] for x in range(0, len(self.DESCRIPTORS))]\n        for (x, y), labels in ppp_mat.items():\n            dist = dist_mat[x, y]\n            # ignore all interactions greater than the max distance we set\n            # we cannot have negative distance\n            if dist &gt; self.max_dist or dist &lt; 0:\n                continue\n\n            for pair in labels:\n                idx = self.DESCRIPTORS.index(f\"{pair[0]}{pair[1]}\")\n                vals = desc[idx]\n                dist_bin = np.digitize(dist, self.bins)\n                # indexing at 0\n                vals[dist_bin - 1] += 1\n                desc[idx] = vals\n\n        if self.scale == \"num\":\n            for row in range(0, len(desc)):\n                for col in range(0, len(desc[0])):\n                    desc[row][col] = float(desc[row][col]) / n_atoms\n\n        elif self.scale == \"count\":\n            #  get the scaling factors\n            facs = [0] * len(self.DESCRIPTORS)\n            count = 0\n            for ppp in self.DESCRIPTORS:\n                facs[count] = ppp_count[ppp[0]] + ppp_count[ppp[1]]\n                count += 1\n\n            # each row in desc corresponds to a PPP pair\n            # so the scale factor is constant over cols of a row\n            count = 0\n            for i in range(0, len(desc)):\n                if facs[i] == 0:\n                    continue\n                for j in range(0, len(desc[0])):\n                    desc[i][j] = desc[i][j] / float(facs[i])\n\n        res = []\n        for row in desc:\n            for col in row:\n                res.append(col)\n        return res\n\n    def __len__(self):\n        \"\"\"Return the length of the calculator\"\"\"\n        return len(self._columns)\n\n    def __call__(self, mol: Union[dm.Mol, str], conformer_id: int = -1):\n        \"\"\"Get CATS 2D descriptors for a molecule\n\n        Args:\n            mol: the molecule of interest.\n            conformer_id: Optional conformer id. Only relevant when `use_3d_distances`\n                is set to True.\n\n        Returns:\n            props (np.ndarray): list of computed rdkit molecular descriptors\n        \"\"\"\n\n        mol = dm.to_mol(mol)\n\n        if self.use_3d_distances:\n            if mol.GetNumConformers() &lt; 1:  # type: ignore\n                raise ValueError(\"Expected a molecule with conformers information.\")\n\n            dist_mat = Get3DDistanceMatrix(mol, confId=conformer_id)\n\n        else:\n            dist_mat = GetDistanceMatrix(mol).astype(int)\n\n        out = self._calculate(mol, dist_mat)\n        return to_numpy(out)\n\n    @property\n    def columns(self):\n        \"\"\"Get the descriptors columns\"\"\"\n        return self._columns\n\n    def __getstate__(self):\n        \"\"\"Serialize the class for pickling.\"\"\"\n        state = {}\n        state[\"max_dist\"] = self.max_dist\n        state[\"bins\"] = self.bins\n        state[\"scale\"] = self.scale\n        state[\"use_3d_distances\"] = self.use_3d_distances\n        return state\n\n    def __setstate__(self, state: dict):\n        \"\"\"Reload the class from pickling.\"\"\"\n        self.__dict__.update(state)\n        self._set_columns()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the descriptors columns</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS.__call__","title":"<code>__call__(mol, conformer_id=-1)</code>","text":"<p>Get CATS 2D descriptors for a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest.</p> required <code>conformer_id</code> <code>int</code> <p>Optional conformer id. Only relevant when <code>use_3d_distances</code> is set to True.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>props</code> <code>ndarray</code> <p>list of computed rdkit molecular descriptors</p> Source code in <code>molfeat/calc/cats.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], conformer_id: int = -1):\n    \"\"\"Get CATS 2D descriptors for a molecule\n\n    Args:\n        mol: the molecule of interest.\n        conformer_id: Optional conformer id. Only relevant when `use_3d_distances`\n            is set to True.\n\n    Returns:\n        props (np.ndarray): list of computed rdkit molecular descriptors\n    \"\"\"\n\n    mol = dm.to_mol(mol)\n\n    if self.use_3d_distances:\n        if mol.GetNumConformers() &lt; 1:  # type: ignore\n            raise ValueError(\"Expected a molecule with conformers information.\")\n\n        dist_mat = Get3DDistanceMatrix(mol, confId=conformer_id)\n\n    else:\n        dist_mat = GetDistanceMatrix(mol).astype(int)\n\n    out = self._calculate(mol, dist_mat)\n    return to_numpy(out)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Serialize the class for pickling.</p> Source code in <code>molfeat/calc/cats.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Serialize the class for pickling.\"\"\"\n    state = {}\n    state[\"max_dist\"] = self.max_dist\n    state[\"bins\"] = self.bins\n    state[\"scale\"] = self.scale\n    state[\"use_3d_distances\"] = self.use_3d_distances\n    return state\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS.__init__","title":"<code>__init__(max_dist=None, bins=None, scale='raw', use_3d_distances=False, **kwargs)</code>","text":"<p>Calculator for the CATS descriptors.</p> <p><code>max_dist</code> and <code>bins</code> will both determine the length of the fingerprint vector, which you can get by calling <code>len(calc)</code></p> <p>Parameters:</p> Name Type Description Default <code>max_dist</code> <code>Union[float, int]</code> <p>Maximum distance between pairs. When set to None, the default for 2D is set to <code>max_dist=8</code> and for 3D to <code>max_dist=5</code>.</p> <code>None</code> <code>bins</code> <code>List[int]</code> <p>Bins to use. Defaults to equal spacing <code>[0, max_dist[</code>.</p> <code>None</code> <code>scale</code> <code>str</code> <p>How to scale the values. Supported values are:  - 'raw' for the raw values.  - 'num' for values normalized by the number of atoms.  - 'count' for scaling based on occurence of the PPP.</p> <code>'raw'</code> <code>use_3d_distances</code> <code>bool</code> <p>Whether to use the 3D distances instead of the topological distances. If set to True, the input molecules must contain a conformer.</p> <code>False</code> <code>kwargs</code> <p>silently ignored extra parameters for compatibility with other calculators.</p> <code>{}</code> Source code in <code>molfeat/calc/cats.py</code> <pre><code>def __init__(\n    self,\n    max_dist: Union[float, int] = None,\n    bins: List[int] = None,\n    scale: str = \"raw\",\n    use_3d_distances: bool = False,\n    **kwargs,\n):\n    \"\"\"Calculator for the CATS descriptors.\n\n    `max_dist` and `bins` will both determine the length of the fingerprint vector,\n    which you can get by calling `len(calc)`\n\n    Args:\n        max_dist: Maximum distance between pairs. When set to None, the default for 2D is\n            set to `max_dist=8` and for 3D to `max_dist=5`.\n        bins: Bins to use. Defaults to equal spacing `[0, max_dist[`.\n        scale: How to scale the values. Supported values are:\n             - 'raw' for the raw values.\n             - 'num' for values normalized by the number of atoms.\n             - 'count' for scaling based on occurence of the PPP.\n        use_3d_distances: Whether to use the 3D distances instead of the topological distances.\n            If set to True, the input molecules must contain a conformer.\n        kwargs: silently ignored extra parameters for compatibility with other calculators.\n    \"\"\"\n\n    # Set the max_dist default is set to None\n    if max_dist is None:\n        if use_3d_distances:\n            max_dist = CATS.MAX_DIST_DEFAULT_3D\n        else:\n            max_dist = CATS.MAX_DIST_DEFAULT_2D\n\n    self.max_dist = max_dist\n    self.use_3d_distances = use_3d_distances\n\n    if bins is None:\n        bins = list(np.arange(1, np.floor(self.max_dist + 1), 1))\n\n    # we don't allow interaction that exceed our distance threshold.\n    bins = [x for x in bins if x &lt;= self.max_dist]\n\n    # we start distance indexing at 0\n    if 0 not in bins:\n        bins += [0]\n\n    self.bins = list(sorted(bins))\n\n    self.scale = scale\n\n    self._set_columns()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the calculator</p> Source code in <code>molfeat/calc/cats.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the length of the calculator\"\"\"\n    return len(self._columns)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.cats.CATS.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Reload the class from pickling.</p> Source code in <code>molfeat/calc/cats.py</code> <pre><code>def __setstate__(self, state: dict):\n    \"\"\"Reload the class from pickling.\"\"\"\n    self.__dict__.update(state)\n    self._set_columns()\n</code></pre>"},{"location":"api/molfeat.calc.html#pharmacophore","title":"<code>Pharmacophore</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D","title":"<code>Pharmacophore2D</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>2D Pharmacophore.</p> <p>The fingerprint is computed using <code>Generate.Gen2DFingerprint</code> from RDKit.</p> <p>An explanation of pharmacophore fingerprints and how the bits are set is available in the RDKit book. In particular the following figure describes the process. { align=left }</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>class Pharmacophore2D(SerializableCalculator):\n    \"\"\"2D Pharmacophore.\n\n    The fingerprint is computed using `Generate.Gen2DFingerprint` from RDKit.\n\n    An explanation of pharmacophore fingerprints and how the bits are set\n    is available in the RDKit book. In particular the following figure describes the process.\n    ![Pharmacophore](https://www.rdkit.org/docs/_images/picture_10.jpg){ align=left }\n    \"\"\"\n\n    def __init__(\n        self,\n        factory: Union[str, MolChemicalFeatureFactory] = \"pmapper\",\n        length: Optional[int] = 2048,\n        useCounts: bool = None,\n        minPointCount: int = None,\n        maxPointCount: int = None,\n        shortestPathsOnly: bool = None,\n        includeBondOrder: bool = None,\n        skipFeats: List[str] = None,\n        trianglePruneBins: bool = None,\n        bins: List[Tuple[int, int]] = None,\n        **kwargs,\n    ):\n        \"\"\"Pharmacophore computation.\n\n        Args:\n            factory: Which features factory to use. One of \"default\", \"cats\", \"gobbi\" , \"pmapper\" or path\n                to a feature definition or a feature factory object\n            length: Optional desired length. If provided, the fp will be refold or padded to that length.\n                If set to None, fallback to the default for the provided sig factory.\n            minPointCount: Minimum number of points.\n            maxPointCount: Maximum number of points.\n            trianglePruneBins: Whether to prune the triangle inequality.\n            includeBondOrder: Whether to consider bond order.\n            shortestPathsOnly: Whether to only use the shortest path between pharmacophores.\n            useCounts: Whether take into account the count information. This will also impact how the folding works.\n            bins: Bins to use.\n        \"\"\"\n\n        self.factory = factory\n        self.useCounts = useCounts\n        self.minPointCount = minPointCount\n        self.maxPointCount = maxPointCount\n        self.shortestPathsOnly = shortestPathsOnly\n        self.includeBondOrder = includeBondOrder\n        self.skipFeats = skipFeats\n        self.trianglePruneBins = trianglePruneBins\n        self.bins = bins\n\n        self.length = length\n\n        self._init_sig_factory()\n\n    def __call__(self, mol: Union[dm.Mol, str], raw: bool = False):\n        \"\"\"Compute the Pharmacophore fingeprint for the input molecule.\n\n        Args:\n            mol: the molecule of interest\n            raw: Whether to return the raw fingerprint or a Numpy array.\n\n        Returns:\n            fp: the computed fingerprint as a Numpy array or as a raw object.\n        \"\"\"\n\n        # Get a molecule\n        mol = dm.to_mol(mol)\n\n        if mol is None:\n            raise ValueError(\"The input molecule is not valid.\")\n\n        # Get distance matrix\n        use_bond_order = self.sig_factory.includeBondOrder\n        d_mat = rdmolops.GetDistanceMatrix(mol, use_bond_order)\n\n        # Generate the fingerprint\n        fp = Generate.Gen2DFingerprint(mol, self.sig_factory, dMat=d_mat)\n\n        # Posprocessing\n        if self.length and self._should_fold:\n            # refold the fingerprint\n            fp = fold_count_fp(fp, dim=self.length, binary=not (self.useCounts or False))\n            if raw:\n                fp = to_fp(fp, bitvect=True)\n\n        if not raw:\n            fp = to_numpy(fp)\n\n        return fp\n\n    def _init_sig_factory(self):\n        \"\"\"Init the feature factory for this pharmacophore.\"\"\"\n\n        self.sig_factory = get_sig_factory(\n            self.factory,\n            useCounts=self.useCounts,\n            minPointCount=self.minPointCount,\n            maxPointCount=self.maxPointCount,\n            shortestPathsOnly=self.shortestPathsOnly,\n            includeBondOrder=self.includeBondOrder,\n            skipFeats=self.skipFeats,\n            trianglePruneBins=self.trianglePruneBins,\n            bins=self.bins,\n        )\n\n        # Reinject used params to the class attributes\n        # It might be useful in case the default values are changed\n        # and when serializing the object.\n        self.useCounts = self.sig_factory.useCounts\n        self.minPointCount = self.sig_factory.minPointCount\n        self.maxPointCount = self.sig_factory.maxPointCount\n        self.shortestPathsOnly = self.sig_factory.shortestPathsOnly\n        self.includeBondOrder = self.sig_factory.includeBondOrder\n        self.skipFeats = self.sig_factory.skipFeats\n        self.trianglePruneBins = self.sig_factory.trianglePruneBins\n        self.bins = self.sig_factory.GetBins()\n\n    @property\n    @functools.lru_cache(maxsize=None)\n    def _should_fold(self):\n        return self.sig_factory.GetSigSize() != len(self)\n\n    @property\n    def feature_factory(self):\n        return self.sig_factory.featFactory\n\n    def __len__(self):\n        \"\"\"Returns the length of the pharmacophore\"\"\"\n        return self.length or self.sig_factory.GetSigSize()\n\n    @property\n    def columns(self):\n        \"\"\"Get the name of all the descriptors of this calculator.\"\"\"\n\n        if not self.length:\n            return [self.sig_factory.GetBitDescription(x) for x in range(len(self))]\n        else:\n            return [f\"Desc:{i}\" for i in range(self.length)]\n\n    def __getstate__(self):\n        \"\"\"Serialize the class for pickling.\"\"\"\n        state = {}\n        state[\"factory\"] = self.factory\n        state[\"useCounts\"] = self.useCounts\n        state[\"minPointCount\"] = self.minPointCount\n        state[\"maxPointCount\"] = self.maxPointCount\n        state[\"shortestPathsOnly\"] = self.shortestPathsOnly\n        state[\"includeBondOrder\"] = self.includeBondOrder\n        state[\"skipFeats\"] = self.skipFeats\n        state[\"trianglePruneBins\"] = self.trianglePruneBins\n        state[\"bins\"] = self.bins\n        state[\"length\"] = self.length\n        return state\n\n    def __setstate__(self, state: dict):\n        \"\"\"Reload the class from pickling.\"\"\"\n        self.__dict__.update(state)\n        self._init_sig_factory()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the name of all the descriptors of this calculator.</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D.__call__","title":"<code>__call__(mol, raw=False)</code>","text":"<p>Compute the Pharmacophore fingeprint for the input molecule.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>raw</code> <code>bool</code> <p>Whether to return the raw fingerprint or a Numpy array.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>fp</code> <p>the computed fingerprint as a Numpy array or as a raw object.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], raw: bool = False):\n    \"\"\"Compute the Pharmacophore fingeprint for the input molecule.\n\n    Args:\n        mol: the molecule of interest\n        raw: Whether to return the raw fingerprint or a Numpy array.\n\n    Returns:\n        fp: the computed fingerprint as a Numpy array or as a raw object.\n    \"\"\"\n\n    # Get a molecule\n    mol = dm.to_mol(mol)\n\n    if mol is None:\n        raise ValueError(\"The input molecule is not valid.\")\n\n    # Get distance matrix\n    use_bond_order = self.sig_factory.includeBondOrder\n    d_mat = rdmolops.GetDistanceMatrix(mol, use_bond_order)\n\n    # Generate the fingerprint\n    fp = Generate.Gen2DFingerprint(mol, self.sig_factory, dMat=d_mat)\n\n    # Posprocessing\n    if self.length and self._should_fold:\n        # refold the fingerprint\n        fp = fold_count_fp(fp, dim=self.length, binary=not (self.useCounts or False))\n        if raw:\n            fp = to_fp(fp, bitvect=True)\n\n    if not raw:\n        fp = to_numpy(fp)\n\n    return fp\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Serialize the class for pickling.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Serialize the class for pickling.\"\"\"\n    state = {}\n    state[\"factory\"] = self.factory\n    state[\"useCounts\"] = self.useCounts\n    state[\"minPointCount\"] = self.minPointCount\n    state[\"maxPointCount\"] = self.maxPointCount\n    state[\"shortestPathsOnly\"] = self.shortestPathsOnly\n    state[\"includeBondOrder\"] = self.includeBondOrder\n    state[\"skipFeats\"] = self.skipFeats\n    state[\"trianglePruneBins\"] = self.trianglePruneBins\n    state[\"bins\"] = self.bins\n    state[\"length\"] = self.length\n    return state\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D.__init__","title":"<code>__init__(factory='pmapper', length=2048, useCounts=None, minPointCount=None, maxPointCount=None, shortestPathsOnly=None, includeBondOrder=None, skipFeats=None, trianglePruneBins=None, bins=None, **kwargs)</code>","text":"<p>Pharmacophore computation.</p> <p>Parameters:</p> Name Type Description Default <code>factory</code> <code>Union[str, MolChemicalFeatureFactory]</code> <p>Which features factory to use. One of \"default\", \"cats\", \"gobbi\" , \"pmapper\" or path to a feature definition or a feature factory object</p> <code>'pmapper'</code> <code>length</code> <code>Optional[int]</code> <p>Optional desired length. If provided, the fp will be refold or padded to that length. If set to None, fallback to the default for the provided sig factory.</p> <code>2048</code> <code>minPointCount</code> <code>int</code> <p>Minimum number of points.</p> <code>None</code> <code>maxPointCount</code> <code>int</code> <p>Maximum number of points.</p> <code>None</code> <code>trianglePruneBins</code> <code>bool</code> <p>Whether to prune the triangle inequality.</p> <code>None</code> <code>includeBondOrder</code> <code>bool</code> <p>Whether to consider bond order.</p> <code>None</code> <code>shortestPathsOnly</code> <code>bool</code> <p>Whether to only use the shortest path between pharmacophores.</p> <code>None</code> <code>useCounts</code> <code>bool</code> <p>Whether take into account the count information. This will also impact how the folding works.</p> <code>None</code> <code>bins</code> <code>List[Tuple[int, int]]</code> <p>Bins to use.</p> <code>None</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __init__(\n    self,\n    factory: Union[str, MolChemicalFeatureFactory] = \"pmapper\",\n    length: Optional[int] = 2048,\n    useCounts: bool = None,\n    minPointCount: int = None,\n    maxPointCount: int = None,\n    shortestPathsOnly: bool = None,\n    includeBondOrder: bool = None,\n    skipFeats: List[str] = None,\n    trianglePruneBins: bool = None,\n    bins: List[Tuple[int, int]] = None,\n    **kwargs,\n):\n    \"\"\"Pharmacophore computation.\n\n    Args:\n        factory: Which features factory to use. One of \"default\", \"cats\", \"gobbi\" , \"pmapper\" or path\n            to a feature definition or a feature factory object\n        length: Optional desired length. If provided, the fp will be refold or padded to that length.\n            If set to None, fallback to the default for the provided sig factory.\n        minPointCount: Minimum number of points.\n        maxPointCount: Maximum number of points.\n        trianglePruneBins: Whether to prune the triangle inequality.\n        includeBondOrder: Whether to consider bond order.\n        shortestPathsOnly: Whether to only use the shortest path between pharmacophores.\n        useCounts: Whether take into account the count information. This will also impact how the folding works.\n        bins: Bins to use.\n    \"\"\"\n\n    self.factory = factory\n    self.useCounts = useCounts\n    self.minPointCount = minPointCount\n    self.maxPointCount = maxPointCount\n    self.shortestPathsOnly = shortestPathsOnly\n    self.includeBondOrder = includeBondOrder\n    self.skipFeats = skipFeats\n    self.trianglePruneBins = trianglePruneBins\n    self.bins = bins\n\n    self.length = length\n\n    self._init_sig_factory()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D.__len__","title":"<code>__len__()</code>","text":"<p>Returns the length of the pharmacophore</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __len__(self):\n    \"\"\"Returns the length of the pharmacophore\"\"\"\n    return self.length or self.sig_factory.GetSigSize()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore2D.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Reload the class from pickling.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __setstate__(self, state: dict):\n    \"\"\"Reload the class from pickling.\"\"\"\n    self.__dict__.update(state)\n    self._init_sig_factory()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D","title":"<code>Pharmacophore3D</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>3D Pharmacophore.</p> <p>The fingerprint is computed using <code>pmapper</code>.</p> <p>This featurizer supports building a consensus pharmacophore from a set of molecules.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>class Pharmacophore3D(SerializableCalculator):\n    \"\"\"3D Pharmacophore.\n\n    The fingerprint is computed using [`pmapper`](https://github.com/DrrDom/pmapper).\n\n    This featurizer supports building a consensus pharmacophore from a set of molecules.\n    \"\"\"\n\n    def __init__(\n        self,\n        factory: Union[str, MolChemicalFeatureFactory] = \"pmapper\",\n        length: int = 2048,\n        bin_step: float = 1,\n        min_features: int = 2,\n        max_features: int = 3,\n        use_modulo: bool = True,\n        tolerance: float = 0,\n    ):\n        \"\"\"Pharmacophore computation.\n\n        Args:\n            factory: Which features factory to use. One of \"default\", \"cats\", \"gobbi\" , \"pmapper\" or path\n                to a feature definition or a feature factory object\n            length: Optional desired length. If provided, the fp will be refold or padded to that length.\n                If set to None, fallback to the default for the provided sig factory.\n            bin_step: Bin step to use.\n            min_features: Minimum number of features to use.\n            max_features: Maximum number of features to use.\n            use_modulo: whether to use modulo to compute the pharmacophore fingerprint\n            tolerance: tolerance value to use when computing the pharmacophore fingerprint\n        \"\"\"\n\n        self.factory = factory\n        self.length = length\n        self.bin_step = bin_step\n        self.min_features = min_features\n        self.max_features = max_features\n        self.use_modulo = use_modulo\n        self.tolerance = tolerance\n\n        self._init_feature_factory()\n\n    def __call__(self, mol: Union[dm.Mol, str], conformer_id: int = -1, raw: bool = False):\n        \"\"\"Compute the Pharmacophore fingeprint for the input molecule.\n\n        Args:\n            mol: the molecule of interest\n            conformer_id: the conformer id to use.\n            raw: Whether to return the raw fingerprint or a Numpy array.\n\n        Returns:\n            fp: the computed fingerprint as a Numpy array.\n        \"\"\"\n\n        # Get a molecule\n        mol = dm.to_mol(mol)\n\n        if mol is None:\n            raise ValueError(\"The input molecule is not valid.\")\n\n        if mol.GetNumConformers() &lt; 1:  # type: ignore\n            raise ValueError(\"Expected a molecule with conformers information.\")\n\n        # Get the features for the mol\n        features = self.get_features(mol, conformer_id=conformer_id)\n\n        # Convert features dataframe to coordinates\n        if features.empty:\n            features_coords = []\n        else:\n            features_coords = features[[\"feature_name\", \"coords\"]].values.tolist()\n\n        # Compute the fingerprint\n        fp = self.compute_fp_from_coords(features_coords, raw=raw)\n\n        return fp\n\n    def consensus_fp(\n        self,\n        mols: List[dm.Mol],\n        align: bool = True,\n        conformer_id: int = -1,\n        copy: bool = True,\n        min_samples_ratio: float = 0.5,\n        eps: float = 2,\n        raw: bool = False,\n        **cluster_kwargs,\n    ):\n        \"\"\"Compute a consensus fingerprint from a list of molecules.\n\n        Args:\n            mols: a list of molecules.\n            align: Whether to align the conformers of the molecules.\n            conformer_id: Optional conformer id.\n            copy: Whether to copy the molecules before clustering.\n            min_samples_ratio: Percentages of mols that must contain a pharmacophoric point\n                to be considered as a core point.\n            eps: The maximum distance between two samples for one to be considered as\n                in the neighborhood of the other.\n            raw: Whether to return the raw fingerprint or a Numpy array.\n            cluster_kwargs: additional keyword arguments for the clustering algorithm.\n        \"\"\"\n\n        # Get all the features\n        features = self.get_features_from_many(\n            mols,\n            keep_mols=True,\n            align=align,\n            conformer_id=conformer_id,\n            copy=copy,\n        )\n\n        # Retrieve the aligned molecules\n        mols = features.groupby(\"mol_index\").first()[\"mol\"].tolist()\n        # Cluster the features\n        clustered_features = self.cluster_features(\n            features, min_samples_ratio=min_samples_ratio, eps=eps, **cluster_kwargs\n        )\n        # Convert features dataframe to coordinates\n        if clustered_features.empty:\n            features_coords = []\n        else:\n            features_coords = clustered_features[[\"feature_name\", \"coords\"]].values.tolist()\n        # Compute the fingerprint\n        fp = self.compute_fp_from_coords(features_coords, raw=raw)\n\n        return fp\n\n    def _init_feature_factory(self):\n        \"\"\"Init the feature factory.\"\"\"\n        self.feature_factory = get_feature_factory(self.factory)\n\n    def get_features(self, mol: dm.Mol, conformer_id: int = -1) -&gt; pd.DataFrame:\n        \"\"\"Retrieve the features for a given molecule.\n\n        Args:\n            mol: the molecule of interest\n\n        Returns:\n            features: the features as a Numpy array\n        \"\"\"\n        features_data = []\n\n        # Extract the features for this molecule\n        features = self.feature_factory.GetFeaturesForMol(mol, confId=conformer_id)\n\n        # Extract all the feature atom indices for this molecule\n        for feature in features:\n            datum = {}\n            datum[\"feature_id\"] = feature.GetId()\n            datum[\"feature_name\"] = feature.GetFamily()\n            datum[\"feature_type\"] = feature.GetType()\n            datum[\"atom_indices\"] = feature.GetAtomIds()\n            datum[\"coords\"] = np.array(feature.GetPos())\n\n            features_data.append(datum)\n\n        features_data = pd.DataFrame(features_data)\n\n        return features_data\n\n    def get_features_from_many(\n        self,\n        mols: List[dm.Mol],\n        align: bool = True,\n        conformer_id: int = -1,\n        copy: bool = True,\n        keep_mols: bool = False,\n    ):\n        \"\"\"Extract all the features from a list of molecules after an optional\n        alignement step.\n\n        Args:\n            mols: List of molecules with conformers.\n            align: Whether to align the conformers of the molecules.\n            conformer_id: Optional conformer id.\n            copy: Whether to copy the molecules before clustering.\n            keep_mols: Whether to keep the molecules in the returned dataframe.\n        \"\"\"\n\n        if not all([mol.GetNumConformers() &gt;= 1 for mol in mols]):\n            raise ValueError(\"One or more input molecules is missing a conformer.\")\n\n        # Make a copy of the molecules since they are going to be modified\n        if copy:\n            mols = [dm.copy_mol(mol) for mol in mols]\n\n        # Align the conformers\n        if align:\n            mols, _ = commons.align_conformers(mols, copy=False, conformer_id=conformer_id)\n\n        all_features = pd.DataFrame()\n\n        for i, mol in enumerate(mols):\n            features = self.get_features(mol)\n            features[\"mol_index\"] = i\n\n            if keep_mols:\n                features[\"mol\"] = mol\n\n            all_features = pd.concat([all_features, features], ignore_index=True)\n\n        return all_features\n\n    def compute_fp_from_coords(\n        self,\n        features_coords: List[Tuple[str, Tuple[float]]],\n        raw: bool = False,\n    ):\n        \"\"\"Compute a fingerprint from a list of features.\n\n        Args:\n            features_coords: Features coords: `[('A', (1.23, 2.34, 3.45)), ('A', (4.56, 5.67, 6.78)), ...]`.\n            raw: Whether to return the raw fingerprint or a Numpy array.\n        \"\"\"\n\n        # Init the pmapper engine\n        ph_engine = Pharm(bin_step=self.bin_step)\n        # Convert coords to list in case those are arrays\n        features_coords = [(name, tuple(coords)) for name, coords in features_coords]\n        # Load pharmacophore points\n        ph_engine.load_from_feature_coords(features_coords)\n        # Init the iterator over the pharmacophore points\n        points_iterator = ph_engine.iterate_pharm(\n            min_features=self.min_features,\n            max_features=self.max_features,\n            tol=self.tolerance,\n            return_feature_ids=False,\n        )\n\n        # Compute the fingerprint\n        on_bits = set()\n        for h in points_iterator:\n            if self.use_modulo:\n                on_bits.add(int(h, 16) % self.length)  # type: ignore\n            else:\n                random.seed(int(h, 16))  # type: ignore\n                on_bits.add(random.randrange(self.length))\n\n        if raw:\n            return np.array(on_bits)\n\n        fp = np.zeros(self.length, dtype=int)\n        fp[list(on_bits)] = 1\n\n        return fp\n\n    def cluster_features(\n        self,\n        features: pd.DataFrame,\n        min_samples_ratio: float = 0.5,\n        n_mols: int = None,\n        eps: float = np.inf,\n        **kwargs,\n    ):\n        \"\"\"Cluster a set of pharmacophoric features using OPTICS.\n        The only reason why we are not using SpectralClustering is because of the need to provide\n        the number of clusters.\n\n        Args:\n            features: A dataframe of features.\n            min_samples_ratio: Percentages of mols that must contain a pharmacophoric point\n                to be considered as a core point.\n            n_mols: Optional number of compounds to compute `min_samples` from the\n                `min_samples_ratio` value. If not set it will use `mol_index` from\n                the `features` dataframe.\n            eps: The maximum distance between two samples for one to be considered as\n                in the neighborhood of the other. This is max_eps in OPTICS\n            kwargs: Any additional parameters to pass to `sklearn.cluster.OPTICS`.\n        \"\"\"\n\n        if n_mols is None:\n            n_mols = len(features[\"mol_index\"].unique())\n\n        # Compute min_samples\n        min_samples = max(int(round(min_samples_ratio * n_mols, 0)), 1)\n        clusters = []\n        feature_id = 0\n        for _, rows in features.groupby(\"feature_name\"):\n            feature_name = rows.iloc[0][\"feature_name\"]\n            if min_samples &gt; rows.shape[0]:\n                logger.info(\n                    f\"Feature {feature_name} does not have enough molecule ({len(rows)}), skipping\"\n                )\n                continue\n            coords = np.vstack(rows[\"coords\"].values)\n\n            # Init clustering\n            optics = OPTICS(min_samples=min_samples, max_eps=eps, **kwargs)\n            optics = optics.fit(coords)\n            labels = optics.labels_\n            # a node that is not a core would basically be a node that cannot be labeled\n            # thus border nodes are considered core\n            core_samples_mask = np.zeros_like(labels, dtype=bool)\n            core_samples_mask[labels == 1] = True\n\n            # Find the centroids (consensus points)\n            unique_labels = set(labels)\n            for k in unique_labels:\n                if k == -1:\n                    continue\n                class_member_mask = labels == k\n                cluster_coords = coords[class_member_mask &amp; core_samples_mask]\n                if len(cluster_coords) == 0:\n                    continue\n                cluster_centroid = cluster_coords.mean(axis=0)\n\n                cluster = {}\n                cluster[\"feature_id\"] = feature_id\n                cluster[\"feature_name\"] = feature_name\n                cluster[\"coords\"] = cluster_centroid\n                cluster[\"cluster_size\"] = len(cluster_coords)\n\n                clusters.append(cluster)\n                feature_id += 1\n\n        clusters = pd.DataFrame(clusters)\n\n        return clusters\n\n    ## Viz methods\n\n    def show(\n        self,\n        mol: dm.Mol,\n        features: pd.DataFrame = None,\n        alpha: float = 1.0,\n        sphere_radius: float = 0.4,\n        show_legend: bool = True,\n    ):\n        \"\"\"Show a 3D view of a given molecule with the pharmacophoric features.\n\n        Args:\n            mol: the molecule of interest\n            alpha: Alpha value for the colors (currently not working).\n            sphere_radius: Radius of the spheres for the features.\n            show_legend: Display the legend (the layout is bad but at least it\n                shows the legend).\n        \"\"\"\n\n        if features is None:\n            features = self.get_features(mol)\n\n        return viz.show_pharm_features(\n            mol,\n            features=features,\n            feature_factory=self.feature_factory,\n            alpha=alpha,\n            sphere_radius=sphere_radius,\n            show_legend=show_legend,\n        )\n\n    def show_many(\n        self,\n        mols: List[dm.Mol],\n        align: bool = True,\n        conformer_id: int = -1,\n        copy: bool = True,\n        min_samples_ratio: float = 0.5,\n        eps: float = 2,\n        alpha: float = 1.0,\n        sphere_radius: float = 0.4,\n        show_legend: bool = True,\n    ):\n        \"\"\"Show a 3D view of a given molecule with the pharmacophoric features.\n\n        Args:\n            mols: a list of molecules.\n            align: Whether to align the conformers of the molecules.\n            conformer_id: Optional conformer id.\n            copy: Whether to copy the molecules before clustering.\n            min_samples_ratio: Percentages of mols that must contain a pharmacophoric point\n                to be considered as a core point.\n            eps: The maximum distance between two samples for one to be considered as\n                in the neighborhood of the other.\n            alpha: Alpha value for the colors (currently not working).\n            sphere_radius: Radius of the spheres for the features.\n            show_legend: Display the legend (the layout is bad but at least it\n                shows the legend).\n        \"\"\"\n\n        # Get all the features\n        features = self.get_features_from_many(\n            mols,\n            keep_mols=True,\n            align=align,\n            conformer_id=conformer_id,\n            copy=copy,\n        )\n\n        # Retrieve the aligned molecules\n        mols = features.groupby(\"mol_index\").first()[\"mol\"].tolist()\n\n        # Cluster the features\n        clustered_features = self.cluster_features(\n            features,\n            min_samples_ratio=min_samples_ratio,\n            eps=eps,\n        )\n\n        return viz.show_pharm_features(\n            mols,\n            features=clustered_features,\n            feature_factory=self.feature_factory,\n            alpha=alpha,\n            sphere_radius=sphere_radius,\n            show_legend=show_legend,\n        )\n\n    def __getstate__(self):\n        \"\"\"Serialize the class for pickling.\"\"\"\n        state = {}\n        state[\"factory\"] = self.factory\n        state[\"length\"] = self.length\n        state[\"bin_step\"] = self.bin_step\n        state[\"min_features\"] = self.min_features\n        state[\"max_features\"] = self.max_features\n        state[\"use_modulo\"] = self.use_modulo\n        state[\"tolerance\"] = self.tolerance\n        return state\n\n    def __setstate__(self, state: dict):\n        \"\"\"Reload the class from pickling.\"\"\"\n        self.__dict__.update(state)\n        self._init_feature_factory()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.__call__","title":"<code>__call__(mol, conformer_id=-1, raw=False)</code>","text":"<p>Compute the Pharmacophore fingeprint for the input molecule.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>conformer_id</code> <code>int</code> <p>the conformer id to use.</p> <code>-1</code> <code>raw</code> <code>bool</code> <p>Whether to return the raw fingerprint or a Numpy array.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>fp</code> <p>the computed fingerprint as a Numpy array.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], conformer_id: int = -1, raw: bool = False):\n    \"\"\"Compute the Pharmacophore fingeprint for the input molecule.\n\n    Args:\n        mol: the molecule of interest\n        conformer_id: the conformer id to use.\n        raw: Whether to return the raw fingerprint or a Numpy array.\n\n    Returns:\n        fp: the computed fingerprint as a Numpy array.\n    \"\"\"\n\n    # Get a molecule\n    mol = dm.to_mol(mol)\n\n    if mol is None:\n        raise ValueError(\"The input molecule is not valid.\")\n\n    if mol.GetNumConformers() &lt; 1:  # type: ignore\n        raise ValueError(\"Expected a molecule with conformers information.\")\n\n    # Get the features for the mol\n    features = self.get_features(mol, conformer_id=conformer_id)\n\n    # Convert features dataframe to coordinates\n    if features.empty:\n        features_coords = []\n    else:\n        features_coords = features[[\"feature_name\", \"coords\"]].values.tolist()\n\n    # Compute the fingerprint\n    fp = self.compute_fp_from_coords(features_coords, raw=raw)\n\n    return fp\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Serialize the class for pickling.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Serialize the class for pickling.\"\"\"\n    state = {}\n    state[\"factory\"] = self.factory\n    state[\"length\"] = self.length\n    state[\"bin_step\"] = self.bin_step\n    state[\"min_features\"] = self.min_features\n    state[\"max_features\"] = self.max_features\n    state[\"use_modulo\"] = self.use_modulo\n    state[\"tolerance\"] = self.tolerance\n    return state\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.__init__","title":"<code>__init__(factory='pmapper', length=2048, bin_step=1, min_features=2, max_features=3, use_modulo=True, tolerance=0)</code>","text":"<p>Pharmacophore computation.</p> <p>Parameters:</p> Name Type Description Default <code>factory</code> <code>Union[str, MolChemicalFeatureFactory]</code> <p>Which features factory to use. One of \"default\", \"cats\", \"gobbi\" , \"pmapper\" or path to a feature definition or a feature factory object</p> <code>'pmapper'</code> <code>length</code> <code>int</code> <p>Optional desired length. If provided, the fp will be refold or padded to that length. If set to None, fallback to the default for the provided sig factory.</p> <code>2048</code> <code>bin_step</code> <code>float</code> <p>Bin step to use.</p> <code>1</code> <code>min_features</code> <code>int</code> <p>Minimum number of features to use.</p> <code>2</code> <code>max_features</code> <code>int</code> <p>Maximum number of features to use.</p> <code>3</code> <code>use_modulo</code> <code>bool</code> <p>whether to use modulo to compute the pharmacophore fingerprint</p> <code>True</code> <code>tolerance</code> <code>float</code> <p>tolerance value to use when computing the pharmacophore fingerprint</p> <code>0</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __init__(\n    self,\n    factory: Union[str, MolChemicalFeatureFactory] = \"pmapper\",\n    length: int = 2048,\n    bin_step: float = 1,\n    min_features: int = 2,\n    max_features: int = 3,\n    use_modulo: bool = True,\n    tolerance: float = 0,\n):\n    \"\"\"Pharmacophore computation.\n\n    Args:\n        factory: Which features factory to use. One of \"default\", \"cats\", \"gobbi\" , \"pmapper\" or path\n            to a feature definition or a feature factory object\n        length: Optional desired length. If provided, the fp will be refold or padded to that length.\n            If set to None, fallback to the default for the provided sig factory.\n        bin_step: Bin step to use.\n        min_features: Minimum number of features to use.\n        max_features: Maximum number of features to use.\n        use_modulo: whether to use modulo to compute the pharmacophore fingerprint\n        tolerance: tolerance value to use when computing the pharmacophore fingerprint\n    \"\"\"\n\n    self.factory = factory\n    self.length = length\n    self.bin_step = bin_step\n    self.min_features = min_features\n    self.max_features = max_features\n    self.use_modulo = use_modulo\n    self.tolerance = tolerance\n\n    self._init_feature_factory()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Reload the class from pickling.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def __setstate__(self, state: dict):\n    \"\"\"Reload the class from pickling.\"\"\"\n    self.__dict__.update(state)\n    self._init_feature_factory()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.cluster_features","title":"<code>cluster_features(features, min_samples_ratio=0.5, n_mols=None, eps=np.inf, **kwargs)</code>","text":"<p>Cluster a set of pharmacophoric features using OPTICS. The only reason why we are not using SpectralClustering is because of the need to provide the number of clusters.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>DataFrame</code> <p>A dataframe of features.</p> required <code>min_samples_ratio</code> <code>float</code> <p>Percentages of mols that must contain a pharmacophoric point to be considered as a core point.</p> <code>0.5</code> <code>n_mols</code> <code>int</code> <p>Optional number of compounds to compute <code>min_samples</code> from the <code>min_samples_ratio</code> value. If not set it will use <code>mol_index</code> from the <code>features</code> dataframe.</p> <code>None</code> <code>eps</code> <code>float</code> <p>The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is max_eps in OPTICS</p> <code>inf</code> <code>kwargs</code> <p>Any additional parameters to pass to <code>sklearn.cluster.OPTICS</code>.</p> <code>{}</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def cluster_features(\n    self,\n    features: pd.DataFrame,\n    min_samples_ratio: float = 0.5,\n    n_mols: int = None,\n    eps: float = np.inf,\n    **kwargs,\n):\n    \"\"\"Cluster a set of pharmacophoric features using OPTICS.\n    The only reason why we are not using SpectralClustering is because of the need to provide\n    the number of clusters.\n\n    Args:\n        features: A dataframe of features.\n        min_samples_ratio: Percentages of mols that must contain a pharmacophoric point\n            to be considered as a core point.\n        n_mols: Optional number of compounds to compute `min_samples` from the\n            `min_samples_ratio` value. If not set it will use `mol_index` from\n            the `features` dataframe.\n        eps: The maximum distance between two samples for one to be considered as\n            in the neighborhood of the other. This is max_eps in OPTICS\n        kwargs: Any additional parameters to pass to `sklearn.cluster.OPTICS`.\n    \"\"\"\n\n    if n_mols is None:\n        n_mols = len(features[\"mol_index\"].unique())\n\n    # Compute min_samples\n    min_samples = max(int(round(min_samples_ratio * n_mols, 0)), 1)\n    clusters = []\n    feature_id = 0\n    for _, rows in features.groupby(\"feature_name\"):\n        feature_name = rows.iloc[0][\"feature_name\"]\n        if min_samples &gt; rows.shape[0]:\n            logger.info(\n                f\"Feature {feature_name} does not have enough molecule ({len(rows)}), skipping\"\n            )\n            continue\n        coords = np.vstack(rows[\"coords\"].values)\n\n        # Init clustering\n        optics = OPTICS(min_samples=min_samples, max_eps=eps, **kwargs)\n        optics = optics.fit(coords)\n        labels = optics.labels_\n        # a node that is not a core would basically be a node that cannot be labeled\n        # thus border nodes are considered core\n        core_samples_mask = np.zeros_like(labels, dtype=bool)\n        core_samples_mask[labels == 1] = True\n\n        # Find the centroids (consensus points)\n        unique_labels = set(labels)\n        for k in unique_labels:\n            if k == -1:\n                continue\n            class_member_mask = labels == k\n            cluster_coords = coords[class_member_mask &amp; core_samples_mask]\n            if len(cluster_coords) == 0:\n                continue\n            cluster_centroid = cluster_coords.mean(axis=0)\n\n            cluster = {}\n            cluster[\"feature_id\"] = feature_id\n            cluster[\"feature_name\"] = feature_name\n            cluster[\"coords\"] = cluster_centroid\n            cluster[\"cluster_size\"] = len(cluster_coords)\n\n            clusters.append(cluster)\n            feature_id += 1\n\n    clusters = pd.DataFrame(clusters)\n\n    return clusters\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.compute_fp_from_coords","title":"<code>compute_fp_from_coords(features_coords, raw=False)</code>","text":"<p>Compute a fingerprint from a list of features.</p> <p>Parameters:</p> Name Type Description Default <code>features_coords</code> <code>List[Tuple[str, Tuple[float]]]</code> <p>Features coords: <code>[('A', (1.23, 2.34, 3.45)), ('A', (4.56, 5.67, 6.78)), ...]</code>.</p> required <code>raw</code> <code>bool</code> <p>Whether to return the raw fingerprint or a Numpy array.</p> <code>False</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def compute_fp_from_coords(\n    self,\n    features_coords: List[Tuple[str, Tuple[float]]],\n    raw: bool = False,\n):\n    \"\"\"Compute a fingerprint from a list of features.\n\n    Args:\n        features_coords: Features coords: `[('A', (1.23, 2.34, 3.45)), ('A', (4.56, 5.67, 6.78)), ...]`.\n        raw: Whether to return the raw fingerprint or a Numpy array.\n    \"\"\"\n\n    # Init the pmapper engine\n    ph_engine = Pharm(bin_step=self.bin_step)\n    # Convert coords to list in case those are arrays\n    features_coords = [(name, tuple(coords)) for name, coords in features_coords]\n    # Load pharmacophore points\n    ph_engine.load_from_feature_coords(features_coords)\n    # Init the iterator over the pharmacophore points\n    points_iterator = ph_engine.iterate_pharm(\n        min_features=self.min_features,\n        max_features=self.max_features,\n        tol=self.tolerance,\n        return_feature_ids=False,\n    )\n\n    # Compute the fingerprint\n    on_bits = set()\n    for h in points_iterator:\n        if self.use_modulo:\n            on_bits.add(int(h, 16) % self.length)  # type: ignore\n        else:\n            random.seed(int(h, 16))  # type: ignore\n            on_bits.add(random.randrange(self.length))\n\n    if raw:\n        return np.array(on_bits)\n\n    fp = np.zeros(self.length, dtype=int)\n    fp[list(on_bits)] = 1\n\n    return fp\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.consensus_fp","title":"<code>consensus_fp(mols, align=True, conformer_id=-1, copy=True, min_samples_ratio=0.5, eps=2, raw=False, **cluster_kwargs)</code>","text":"<p>Compute a consensus fingerprint from a list of molecules.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Mol]</code> <p>a list of molecules.</p> required <code>align</code> <code>bool</code> <p>Whether to align the conformers of the molecules.</p> <code>True</code> <code>conformer_id</code> <code>int</code> <p>Optional conformer id.</p> <code>-1</code> <code>copy</code> <code>bool</code> <p>Whether to copy the molecules before clustering.</p> <code>True</code> <code>min_samples_ratio</code> <code>float</code> <p>Percentages of mols that must contain a pharmacophoric point to be considered as a core point.</p> <code>0.5</code> <code>eps</code> <code>float</code> <p>The maximum distance between two samples for one to be considered as in the neighborhood of the other.</p> <code>2</code> <code>raw</code> <code>bool</code> <p>Whether to return the raw fingerprint or a Numpy array.</p> <code>False</code> <code>cluster_kwargs</code> <p>additional keyword arguments for the clustering algorithm.</p> <code>{}</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def consensus_fp(\n    self,\n    mols: List[dm.Mol],\n    align: bool = True,\n    conformer_id: int = -1,\n    copy: bool = True,\n    min_samples_ratio: float = 0.5,\n    eps: float = 2,\n    raw: bool = False,\n    **cluster_kwargs,\n):\n    \"\"\"Compute a consensus fingerprint from a list of molecules.\n\n    Args:\n        mols: a list of molecules.\n        align: Whether to align the conformers of the molecules.\n        conformer_id: Optional conformer id.\n        copy: Whether to copy the molecules before clustering.\n        min_samples_ratio: Percentages of mols that must contain a pharmacophoric point\n            to be considered as a core point.\n        eps: The maximum distance between two samples for one to be considered as\n            in the neighborhood of the other.\n        raw: Whether to return the raw fingerprint or a Numpy array.\n        cluster_kwargs: additional keyword arguments for the clustering algorithm.\n    \"\"\"\n\n    # Get all the features\n    features = self.get_features_from_many(\n        mols,\n        keep_mols=True,\n        align=align,\n        conformer_id=conformer_id,\n        copy=copy,\n    )\n\n    # Retrieve the aligned molecules\n    mols = features.groupby(\"mol_index\").first()[\"mol\"].tolist()\n    # Cluster the features\n    clustered_features = self.cluster_features(\n        features, min_samples_ratio=min_samples_ratio, eps=eps, **cluster_kwargs\n    )\n    # Convert features dataframe to coordinates\n    if clustered_features.empty:\n        features_coords = []\n    else:\n        features_coords = clustered_features[[\"feature_name\", \"coords\"]].values.tolist()\n    # Compute the fingerprint\n    fp = self.compute_fp_from_coords(features_coords, raw=raw)\n\n    return fp\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.get_features","title":"<code>get_features(mol, conformer_id=-1)</code>","text":"<p>Retrieve the features for a given molecule.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Mol</code> <p>the molecule of interest</p> required <p>Returns:</p> Name Type Description <code>features</code> <code>DataFrame</code> <p>the features as a Numpy array</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def get_features(self, mol: dm.Mol, conformer_id: int = -1) -&gt; pd.DataFrame:\n    \"\"\"Retrieve the features for a given molecule.\n\n    Args:\n        mol: the molecule of interest\n\n    Returns:\n        features: the features as a Numpy array\n    \"\"\"\n    features_data = []\n\n    # Extract the features for this molecule\n    features = self.feature_factory.GetFeaturesForMol(mol, confId=conformer_id)\n\n    # Extract all the feature atom indices for this molecule\n    for feature in features:\n        datum = {}\n        datum[\"feature_id\"] = feature.GetId()\n        datum[\"feature_name\"] = feature.GetFamily()\n        datum[\"feature_type\"] = feature.GetType()\n        datum[\"atom_indices\"] = feature.GetAtomIds()\n        datum[\"coords\"] = np.array(feature.GetPos())\n\n        features_data.append(datum)\n\n    features_data = pd.DataFrame(features_data)\n\n    return features_data\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.get_features_from_many","title":"<code>get_features_from_many(mols, align=True, conformer_id=-1, copy=True, keep_mols=False)</code>","text":"<p>Extract all the features from a list of molecules after an optional alignement step.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Mol]</code> <p>List of molecules with conformers.</p> required <code>align</code> <code>bool</code> <p>Whether to align the conformers of the molecules.</p> <code>True</code> <code>conformer_id</code> <code>int</code> <p>Optional conformer id.</p> <code>-1</code> <code>copy</code> <code>bool</code> <p>Whether to copy the molecules before clustering.</p> <code>True</code> <code>keep_mols</code> <code>bool</code> <p>Whether to keep the molecules in the returned dataframe.</p> <code>False</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def get_features_from_many(\n    self,\n    mols: List[dm.Mol],\n    align: bool = True,\n    conformer_id: int = -1,\n    copy: bool = True,\n    keep_mols: bool = False,\n):\n    \"\"\"Extract all the features from a list of molecules after an optional\n    alignement step.\n\n    Args:\n        mols: List of molecules with conformers.\n        align: Whether to align the conformers of the molecules.\n        conformer_id: Optional conformer id.\n        copy: Whether to copy the molecules before clustering.\n        keep_mols: Whether to keep the molecules in the returned dataframe.\n    \"\"\"\n\n    if not all([mol.GetNumConformers() &gt;= 1 for mol in mols]):\n        raise ValueError(\"One or more input molecules is missing a conformer.\")\n\n    # Make a copy of the molecules since they are going to be modified\n    if copy:\n        mols = [dm.copy_mol(mol) for mol in mols]\n\n    # Align the conformers\n    if align:\n        mols, _ = commons.align_conformers(mols, copy=False, conformer_id=conformer_id)\n\n    all_features = pd.DataFrame()\n\n    for i, mol in enumerate(mols):\n        features = self.get_features(mol)\n        features[\"mol_index\"] = i\n\n        if keep_mols:\n            features[\"mol\"] = mol\n\n        all_features = pd.concat([all_features, features], ignore_index=True)\n\n    return all_features\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.show","title":"<code>show(mol, features=None, alpha=1.0, sphere_radius=0.4, show_legend=True)</code>","text":"<p>Show a 3D view of a given molecule with the pharmacophoric features.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Mol</code> <p>the molecule of interest</p> required <code>alpha</code> <code>float</code> <p>Alpha value for the colors (currently not working).</p> <code>1.0</code> <code>sphere_radius</code> <code>float</code> <p>Radius of the spheres for the features.</p> <code>0.4</code> <code>show_legend</code> <code>bool</code> <p>Display the legend (the layout is bad but at least it shows the legend).</p> <code>True</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def show(\n    self,\n    mol: dm.Mol,\n    features: pd.DataFrame = None,\n    alpha: float = 1.0,\n    sphere_radius: float = 0.4,\n    show_legend: bool = True,\n):\n    \"\"\"Show a 3D view of a given molecule with the pharmacophoric features.\n\n    Args:\n        mol: the molecule of interest\n        alpha: Alpha value for the colors (currently not working).\n        sphere_radius: Radius of the spheres for the features.\n        show_legend: Display the legend (the layout is bad but at least it\n            shows the legend).\n    \"\"\"\n\n    if features is None:\n        features = self.get_features(mol)\n\n    return viz.show_pharm_features(\n        mol,\n        features=features,\n        feature_factory=self.feature_factory,\n        alpha=alpha,\n        sphere_radius=sphere_radius,\n        show_legend=show_legend,\n    )\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.Pharmacophore3D.show_many","title":"<code>show_many(mols, align=True, conformer_id=-1, copy=True, min_samples_ratio=0.5, eps=2, alpha=1.0, sphere_radius=0.4, show_legend=True)</code>","text":"<p>Show a 3D view of a given molecule with the pharmacophoric features.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Mol]</code> <p>a list of molecules.</p> required <code>align</code> <code>bool</code> <p>Whether to align the conformers of the molecules.</p> <code>True</code> <code>conformer_id</code> <code>int</code> <p>Optional conformer id.</p> <code>-1</code> <code>copy</code> <code>bool</code> <p>Whether to copy the molecules before clustering.</p> <code>True</code> <code>min_samples_ratio</code> <code>float</code> <p>Percentages of mols that must contain a pharmacophoric point to be considered as a core point.</p> <code>0.5</code> <code>eps</code> <code>float</code> <p>The maximum distance between two samples for one to be considered as in the neighborhood of the other.</p> <code>2</code> <code>alpha</code> <code>float</code> <p>Alpha value for the colors (currently not working).</p> <code>1.0</code> <code>sphere_radius</code> <code>float</code> <p>Radius of the spheres for the features.</p> <code>0.4</code> <code>show_legend</code> <code>bool</code> <p>Display the legend (the layout is bad but at least it shows the legend).</p> <code>True</code> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def show_many(\n    self,\n    mols: List[dm.Mol],\n    align: bool = True,\n    conformer_id: int = -1,\n    copy: bool = True,\n    min_samples_ratio: float = 0.5,\n    eps: float = 2,\n    alpha: float = 1.0,\n    sphere_radius: float = 0.4,\n    show_legend: bool = True,\n):\n    \"\"\"Show a 3D view of a given molecule with the pharmacophoric features.\n\n    Args:\n        mols: a list of molecules.\n        align: Whether to align the conformers of the molecules.\n        conformer_id: Optional conformer id.\n        copy: Whether to copy the molecules before clustering.\n        min_samples_ratio: Percentages of mols that must contain a pharmacophoric point\n            to be considered as a core point.\n        eps: The maximum distance between two samples for one to be considered as\n            in the neighborhood of the other.\n        alpha: Alpha value for the colors (currently not working).\n        sphere_radius: Radius of the spheres for the features.\n        show_legend: Display the legend (the layout is bad but at least it\n            shows the legend).\n    \"\"\"\n\n    # Get all the features\n    features = self.get_features_from_many(\n        mols,\n        keep_mols=True,\n        align=align,\n        conformer_id=conformer_id,\n        copy=copy,\n    )\n\n    # Retrieve the aligned molecules\n    mols = features.groupby(\"mol_index\").first()[\"mol\"].tolist()\n\n    # Cluster the features\n    clustered_features = self.cluster_features(\n        features,\n        min_samples_ratio=min_samples_ratio,\n        eps=eps,\n    )\n\n    return viz.show_pharm_features(\n        mols,\n        features=clustered_features,\n        feature_factory=self.feature_factory,\n        alpha=alpha,\n        sphere_radius=sphere_radius,\n        show_legend=show_legend,\n    )\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.get_feature_factory","title":"<code>get_feature_factory(factory)</code>","text":"<p>Build a feature factory.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def get_feature_factory(\n    factory: Union[str, MolChemicalFeatureFactory]\n) -&gt; MolChemicalFeatureFactory:\n    \"\"\"Build a feature factory.\"\"\"\n\n    if isinstance(factory, MolChemicalFeatureFactory):\n        feature_factory = factory\n\n    elif factory == \"pmapper\":\n        with pkg_resources.path(\"pmapper\", \"smarts_features.fdef\") as fdef_name:\n            feature_factory = ChemicalFeatures.BuildFeatureFactory(str(fdef_name))  # type: ignore\n\n    elif factory == \"gobbi\":\n        feature_factory = Gobbi_Pharm2D.factory.featFactory\n\n    elif factory == \"cats\":\n        with pkg_resources.open_text(\"molfeat.data\", \"cats_features.fdef\") as instream:\n            feature_factory = ChemicalFeatures.BuildFeatureFactoryFromString(instream.read())  # type: ignore\n\n    elif factory == \"default\":\n        # Load default feature definition file\n        fdefFile = os.path.join(RDConfig.RDDataDir, \"BaseFeatures.fdef\")\n        feature_factory = ChemicalFeatures.BuildFeatureFactory(fdefFile)  # type: ignore\n\n    elif dm.fs.exists(factory):\n        with fsspec.open(factory, \"r\") as instream:\n            fdef = instream.read()\n            feature_factory = ChemicalFeatures.BuildFeatureFactoryFromString(fdef)  # type: ignore\n\n    else:\n        raise ValueError(f\"The factory '{factory}' is not supported.\")\n\n    return feature_factory\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.get_sig_factory","title":"<code>get_sig_factory(factory, useCounts=None, minPointCount=None, maxPointCount=None, shortestPathsOnly=None, includeBondOrder=None, skipFeats=None, trianglePruneBins=None, bins=None, init_factory=True)</code>","text":"<p>Build a signature factory.</p> Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def get_sig_factory(\n    factory: Union[str, MolChemicalFeatureFactory],\n    useCounts: bool = None,\n    minPointCount: int = None,\n    maxPointCount: int = None,\n    shortestPathsOnly: bool = None,\n    includeBondOrder: bool = None,\n    skipFeats: List[str] = None,\n    trianglePruneBins: bool = None,\n    bins: List[Tuple[int, int]] = None,\n    init_factory: bool = True,\n):\n    \"\"\"Build a signature factory.\"\"\"\n\n    # Get feature factory\n    feature_factory = get_feature_factory(factory)\n\n    # Get default params and override them as needed\n    params, bins = get_sig_factory_params(\n        factory,\n        useCounts=useCounts,\n        minPointCount=minPointCount,\n        maxPointCount=maxPointCount,\n        shortestPathsOnly=shortestPathsOnly,\n        includeBondOrder=includeBondOrder,\n        skipFeats=skipFeats,\n        trianglePruneBins=trianglePruneBins,\n        bins=bins,\n    )\n\n    # Build signature factory\n    sig_factory = SigFactory(feature_factory, **params)\n\n    # Set bins\n    sig_factory.SetBins(bins)\n\n    # Init the factory\n    if init_factory:\n        sig_factory.Init()\n\n    return sig_factory\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.pharmacophore.get_sig_factory_params","title":"<code>get_sig_factory_params(factory_name, useCounts=None, minPointCount=None, maxPointCount=None, shortestPathsOnly=None, includeBondOrder=None, skipFeats=None, trianglePruneBins=None, bins=None)</code>","text":"<p>Get the default parameter for a given sig factory allowing some of them to be overriden.</p> <p>Parameters:</p> Name Type Description Default <code>factory_name</code> <code>str</code> <p>The name of the factory.</p> required Source code in <code>molfeat/calc/pharmacophore.py</code> <pre><code>def get_sig_factory_params(\n    factory_name: str,\n    useCounts: bool = None,\n    minPointCount: int = None,\n    maxPointCount: int = None,\n    shortestPathsOnly: bool = None,\n    includeBondOrder: bool = None,\n    skipFeats: List[str] = None,\n    trianglePruneBins: bool = None,\n    bins: List[Tuple[int, int]] = None,\n) -&gt; Tuple[Dict[str, Any], list]:\n    \"\"\"Get the default parameter for a given sig factory allowing some of them to be overriden.\n\n    Args:\n        factory_name: The name of the factory.\n    \"\"\"\n\n    # Get default params.\n\n    if factory_name == \"cats\":\n        default_bins = [\n            (0, 1),\n            (1, 2),\n            (2, 3),\n            (3, 4),\n            (4, 5),\n            (5, 6),\n            (6, 7),\n            (7, 8),\n            (8, 9),\n        ]\n        params = dict(\n            useCounts=True,\n            minPointCount=2,\n            maxPointCount=2,\n            trianglePruneBins=True,\n            shortestPathsOnly=True,\n            includeBondOrder=False,\n        )\n\n    elif factory_name == \"gobbi\":\n        default_bins = [(2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 100)]\n        params = dict(\n            useCounts=False,\n            minPointCount=2,\n            maxPointCount=3,\n            trianglePruneBins=True,\n            shortestPathsOnly=True,\n            includeBondOrder=False,\n        )\n\n    elif factory_name == \"pmapper\":\n        default_bins = [(2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 100)]\n        params = dict(\n            useCounts=False,\n            minPointCount=2,\n            maxPointCount=3,\n            trianglePruneBins=False,\n            shortestPathsOnly=True,\n            includeBondOrder=False,\n        )\n\n    elif factory_name == \"default\":\n        params = dict(\n            useCounts=False,\n            minPointCount=2,\n            maxPointCount=3,\n            trianglePruneBins=False,\n            shortestPathsOnly=True,\n            skipFeats=[\"ZnBinder\", \"LumpedHydrophobe\"],\n            includeBondOrder=False,\n        )\n        default_bins = [(2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 100)]\n\n    else:\n        raise ValueError(f\"Default values for {factory_name} are not known.\")\n\n    # Override default params when set.\n\n    if minPointCount is not None:\n        params[\"minPointCount\"] = minPointCount\n\n    if maxPointCount is not None:\n        params[\"maxPointCount\"] = maxPointCount\n\n    if trianglePruneBins is not None:\n        params[\"trianglePruneBins\"] = trianglePruneBins\n\n    if includeBondOrder is not None:\n        params[\"includeBondOrder\"] = includeBondOrder\n\n    if useCounts is not None:\n        params[\"useCounts\"] = useCounts\n\n    if skipFeats is not None:\n        params[\"skipFeats\"] = skipFeats  # type: ignore\n\n    if shortestPathsOnly is not None:\n        params[\"shortestPathsOnly\"] = shortestPathsOnly\n\n    bins = bins or default_bins\n\n    return params, bins\n</code></pre>"},{"location":"api/molfeat.calc.html#scaffold-keys","title":"<code>Scaffold Keys</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator","title":"<code>ScaffoldKeyCalculator</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>Implementation of the Scaffold Keys described in <code>Identification of Bioisosteric Scaffolds using Scaffold Keys</code> by Peter Ertl</p> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>class ScaffoldKeyCalculator(SerializableCalculator):\n    \"\"\"\n    Implementation of the Scaffold Keys described in\n    `Identification of Bioisosteric Scaffolds using Scaffold Keys` by Peter Ertl\n    \"\"\"\n\n    DESCRIPTORS = [\n        \"n_atom_in_rings\",\n        \"n_atom_in_conjugated_ring\",\n        \"n_atoms_not_in_conjugated_ring\",\n        \"n_atom_in_chain\",\n        \"n_atom_exocyclic\",\n        \"n_nitrogen\",\n        \"n_nitrogen_in_ring\",\n        \"n_oxygen\",\n        \"n_oxygen_in_ring\",\n        \"n_sulfur\",\n        \"n_heteroatoms\",\n        \"n_heteroatoms_in_ring\",\n        \"n_atom_spiro_atoms\",\n        \"n_heteroatom_more_than_2_conn\",\n        \"n_carbon_atleast_2_heteroatoms\",\n        \"n_atom_at_least_2_nei_more_than_2_conn\",\n        \"abs_scaffold_format_charge\",\n        \"n_bonds\",\n        \"n_multiple_non_conj_ring_bonds\",\n        \"n_bonds_2_heteroatoms\",\n        \"n_carbon_het_carbon_het_bonds\",\n        \"n_bonds_at_least_3_conn\",\n        \"n_exocyclic_single_bonds_carbon\",\n        \"n_exocyclic_single_bonds_nitrogen\",\n        \"n_non_ring_bonds_2_conj_rings\",\n        \"n_non_ring_bonds_conj_nonconj_rings\",\n        \"n_bonds_atoms_with_at_least_one_nei_with_2_conn\",\n        \"n_simple_rings\",\n        \"size_largest_ring\",\n        \"n_simple_rings_no_heteroatoms\",\n        \"n_simple_rings_1_heteroatoms\",\n        \"n_simple_rings_2_heteroatoms\",\n        \"n_simple_rings_at_least_3_heteroatoms\",\n        \"n_simple_non_conj_5_atoms_rings\",\n        \"n_simple_non_conj_6_atoms_rings\",\n        \"n_ring_system\",\n        \"n_ring_system_with_2_non_conj_simple_ring\",\n        \"n_ring_system_with_2_conj_simple_ring\",\n        \"n_ring_system_with_conj_non_conj_simple_ring\",\n        \"n_ring_system_with_3_conj_simple_ring\",\n        \"n_ring_system_with_3_non_conj_simple_ring\",\n        \"n_ring_system_with_greater_one_conj_nonconj_simple_ring\",\n    ]\n\n    NORM_PARAMS = pd.read_csv(\n        Path(molfeat.__file__).parents[0].joinpath(\"data/skey_parameters.csv\"),\n        index_col=0,\n    ).loc[DESCRIPTORS]\n\n    def __init__(\n        self, normalize: bool = False, verbose: bool = False, use_scaffold: bool = False, **kwargs\n    ):\n        \"\"\"\n        Init of the scaffold key function\n\n        Args:\n            normalize: whether to normalize the value of the feature\n            verbose: whether to log errors\n            use_scaffold: whether to convert the molecule into scaffold first\n        \"\"\"\n        self.normalize = normalize\n        self.verbose = verbose\n        self.use_scaffold = use_scaffold\n\n    def __getstate__(self):\n        \"\"\"Get state of the scaffold key function\"\"\"\n        state = {}\n        state[\"normalize\"] = self.normalize\n        state[\"verbose\"] = self.verbose\n        state[\"use_scaffold\"] = self.use_scaffold\n        return state\n\n    def __len__(self):\n        return len(self.DESCRIPTORS)\n\n    @classmethod\n    def compute_normalization(cls, features: np.ndarray):\n        \"\"\"Normalize input features. The normalization parameters are\n        computed by the scaffolds of 2.1M molecules from CHEMBL 29.\n        \"\"\"\n        return (features - cls.NORM_PARAMS[\"mean\"]) / cls.NORM_PARAMS[\"std\"]\n\n    def n_atom_in_rings(self, mol: dm.Mol):\n        \"\"\"1. number of ring atoms\"\"\"\n        sm = dm.from_smarts(\"[r]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_atom_in_conjugated_ring(self, mol: dm.Mol):\n        \"\"\"2. number of atoms in conjugated rings\"\"\"\n        ri = mol.GetRingInfo()\n        n = 0\n        for ring in ri.AtomRings():\n            if _is_ring_fully_conjugated(mol, ring):\n                n += len(ring)\n        return n\n\n    def n_atoms_not_in_conjugated_ring(self, mol: dm.Mol):\n        \"\"\"\n        3. number of atoms not in conjugated rings\n        (i.e. atoms in aliphatic rings and non-ring atoms)\n        \"\"\"\n        # EN: replace conjugation by aromatic\n        ri = mol.GetRingInfo()\n        n = 0\n        for ring in ri.AtomRings():\n            if not _is_ring_fully_conjugated(mol, ring):\n                n += len(ring)\n        return n\n\n    def n_atom_in_chain(self, mol: dm.Mol):\n        \"\"\"4. number atoms in chains (not counting double-connected exo-chain atoms)\"\"\"\n        sm = dm.from_smarts(\"[!r;!$(*=[r])]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_atom_exocyclic(self, mol: dm.Mol):\n        \"\"\"5. number of exocyclic atoms (connected by multiple bonds to a ring)\"\"\"\n        sm = dm.from_smarts(\"[!r;!$(*-[r])&amp;$(*~[r])]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_nitrogen(self, mol: dm.Mol):\n        \"\"\"6. number of nitrogen\"\"\"\n        sm = dm.from_smarts(\"[#7]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_nitrogen_in_ring(self, mol: dm.Mol):\n        \"\"\"7. number of nitrogen in rings\"\"\"\n        sm = dm.from_smarts(\"[#7;r]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_oxygen(self, mol: dm.Mol):\n        \"\"\"8. number of oxygen\"\"\"\n        sm = dm.from_smarts(\"[#8]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_oxygen_in_ring(self, mol: dm.Mol):\n        \"\"\"9. number of oxygen in rings\"\"\"\n        sm = dm.from_smarts(\"[#8]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_sulfur(self, mol: dm.Mol):\n        \"\"\"10. number of sulfur atoms\"\"\"\n        sm = dm.from_smarts(\"[#16]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_heteroatoms(self, mol: dm.Mol):\n        \"\"\"11. number of heteroatoms\"\"\"\n\n        sm = dm.from_smarts(\"[!#1&amp;!#6]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_heteroatoms_in_ring(self, mol: dm.Mol):\n        \"\"\"12. number of heteroatoms in rings\"\"\"\n        sm = dm.from_smarts(\"[!#1&amp;!#6&amp;r]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_atom_spiro_atoms(self, mol: dm.Mol):\n        \"\"\"13. number of spiro atoms\"\"\"\n        return Desc.CalcNumSpiroAtoms(mol)\n\n    def n_heteroatom_more_than_2_conn(self, mol: dm.Mol):\n        \"\"\"14. number of heteroatoms with more than 2 connections\"\"\"\n        sm = dm.from_smarts(\"[!#1;!#6;!D1!D0;!D2]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_carbon_atleast_2_heteroatoms(self, mol: dm.Mol):\n        \"\"\"15. number of carbon atoms connected to at least 2 heteroatoms\"\"\"\n        n_atoms = 0\n        for atom in mol.GetAtoms():\n            tmp = [x for x in atom.GetNeighbors() if x.GetAtomicNum() not in [1, 6]]\n            n_atoms += len(tmp) &gt;= 2\n        return n_atoms\n\n    def n_atom_at_least_2_nei_more_than_2_conn(self, mol: dm.Mol):\n        \"\"\"16. Number of atoms where at least 2 connected atoms have more than 2 connections\"\"\"\n        n_atoms = 0\n        for atom in mol.GetAtoms():\n            tmp = [x for x in atom.GetNeighbors() if len(x.GetNeighbors()) &gt; 2]\n            n_atoms += len(tmp) &gt; 2\n        return n_atoms\n\n    def abs_scaffold_format_charge(self, mol: dm.Mol):\n        \"\"\"17. absolute value of the scaffold formal charge\"\"\"\n        charge = GetFormalCharge(mol)\n        return abs(charge)\n\n    def n_bonds(self, mol: dm.Mol):\n        \"\"\"18. number of bonds\"\"\"\n        return mol.GetNumBonds()\n\n    def n_multiple_non_conj_ring_bonds(self, mol: dm.Mol):\n        \"\"\"19. number of multiple, nonconjugated ring bonds\"\"\"\n        extracted_rings = []\n        nr_multiple_bonds_infcr = 0  # infcr: in not fully conjugated ring\n        rings = Chem.GetSymmSSSR(mol)\n        for i in range(len(rings)):\n            extracted_rings.append(list(rings[i]))\n        for ring in extracted_rings:\n            if not _is_ring_fully_conjugated(mol, ring):\n                nr_multiple_bonds_infcr += _n_multiple_bond_in_ring(mol, ring)\n        return nr_multiple_bonds_infcr\n\n    def n_bonds_2_heteroatoms(self, mol: dm.Mol):\n        \"\"\"20. number of bonds connecting 2 heteroatoms\"\"\"\n        sm = dm.from_smarts(\"[!#1&amp;!#6]~[!#1&amp;!#6]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_carbon_het_carbon_het_bonds(self, mol: dm.Mol):\n        \"\"\"21. number of bonds connecting 2 heteroatoms through 2 carbons\"\"\"\n        sm = dm.from_smarts(\"[!#1&amp;!#6]~[#6]~[#6]~[!#1&amp;!#6]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_bonds_at_least_3_conn(self, mol: dm.Mol):\n        \"\"\"22. number of bonds with at least 3 connections on both its atoms\"\"\"\n        sm = dm.from_smarts(\"[$([!#1](~[!#1])(~[!#1])~[!#1])][$([!#1](~[!#1])(~[!#1])~[!#1])]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_exocyclic_single_bonds_carbon(self, mol: dm.Mol):\n        \"\"\"23. number of exocyclic single bonds where a ring atom is carbon\"\"\"\n        sm = dm.from_smarts(\"[!R;!#1]-[#6;R]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_exocyclic_single_bonds_nitrogen(self, mol: dm.Mol):\n        \"\"\"24. number of exocyclic single bonds where a ring atom is nitrogen\"\"\"\n        sm = dm.from_smarts(\"[!R;!#1]-[#7;R]\")\n        return len(mol.GetSubstructMatches(sm, uniquify=True))\n\n    def n_non_ring_bonds_2_conj_rings(self, mol: dm.Mol):\n        \"\"\"25. number of non-ring bonds connecting 2 nonconjugated rings\"\"\"\n        # EN: this is interpretated literally as bonds and not path\n        ring_atom_conj_state = _ring_atom_state(mol)\n        sm = dm.from_smarts(\"[R:1]!@[R:2]\")\n        bond_list = mol.GetSubstructMatches(sm, uniquify=True)\n        result = 0\n        for a_start, a_end in bond_list:\n            s_state = ring_atom_conj_state.get(a_start)\n            e_state = ring_atom_conj_state.get(a_end)\n            if False in s_state and False in e_state:\n                result += 1\n        return result\n\n    def n_non_ring_bonds_conj_nonconj_rings(self, mol: dm.Mol):\n        \"\"\"\n        26. number of non-ring bonds connecting 2 rings,\n        one of them conjugated and one non-conjugated\n        \"\"\"\n        # EN: this is interpretated literally as bonds and not path\n\n        ring_atom_conj_state = _ring_atom_state(mol)\n        sm = dm.from_smarts(\"[R:1]!@[R:2]\")\n        bond_list = mol.GetSubstructMatches(sm, uniquify=True)\n        result = 0\n        for a_start, a_end in bond_list:\n            s_state = ring_atom_conj_state.get(a_start)\n            e_state = ring_atom_conj_state.get(a_end)\n            if (True in s_state and False in e_state) or (False in s_state and True in e_state):\n                result += 1\n        return result\n\n    def n_bonds_atoms_with_at_least_one_nei_with_2_conn(self, mol: dm.Mol):\n        \"\"\"\n        27. number of bonds where both atoms have at least one neighbor\n        (not considering the bond atoms) with more than 2 connections\n        \"\"\"\n        result = 0\n        huge_conn = list(\n            itertools.chain(*mol.GetSubstructMatches(dm.from_smarts(\"[*;!D0;!D1;!D2]\"), uniquify=1))\n        )\n        for bond in mol.GetBonds():\n            a_start, a_end = bond.GetBeginAtom(), bond.GetEndAtom()\n            # we need to exclud the bond atom themselves\n            allowed_conn_table = [\n                x for x in huge_conn if x not in [a_start.GetIdx(), a_end.GetIdx()]\n            ]\n            if any([x.GetIdx() in allowed_conn_table for x in a_start.GetNeighbors()]) and any(\n                [y.GetIdx() in allowed_conn_table for y in a_end.GetNeighbors()]\n            ):\n                result += 1\n        return result\n\n    def n_simple_rings(self, mol: dm.Mol):\n        \"\"\"28. number of simple rings\"\"\"\n        ri = mol.GetRingInfo()\n        return ri.NumRings()\n\n    def size_largest_ring(self, mol: dm.Mol):\n        \"\"\"29. Size of the largest ring\"\"\"\n        ri = mol.GetRingInfo()\n        max_ring_size = max((len(r) for r in ri.AtomRings()), default=0)\n        return max_ring_size\n\n    def n_simple_rings_no_heteroatoms(self, mol: dm.Mol):\n        \"\"\"30. number of simple rings with no heteroatoms\"\"\"\n        ri = mol.GetRingInfo()\n        n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n        return sum(1 for x in n_heteros if x == 0)\n\n    def n_simple_rings_1_heteroatoms(self, mol: dm.Mol):\n        \"\"\"31. number of simple rings with 1 heteroatom\"\"\"\n        ri = mol.GetRingInfo()\n        n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n        return sum(1 for x in n_heteros if x == 1)\n\n    def n_simple_rings_2_heteroatoms(self, mol: dm.Mol):\n        \"\"\"32. number of simple rings with 2 heteroatom\"\"\"\n        ri = mol.GetRingInfo()\n        n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n        return sum(1 for x in n_heteros if x == 2)\n\n    def n_simple_rings_at_least_3_heteroatoms(self, mol: dm.Mol):\n        \"\"\"33. number of simple rings with 3 or more heteroatoms\"\"\"\n        ri = mol.GetRingInfo()\n        n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n        return sum(1 for x in n_heteros if x &gt;= 3)\n\n    def n_simple_non_conj_5_atoms_rings(self, mol: dm.Mol):\n        \"\"\"34. number of simple non-conjugated rings with 5 atoms\"\"\"\n        ri = mol.GetRingInfo()\n        n = 0\n        for ring in ri.AtomRings():\n            if not _is_ring_fully_conjugated(mol, ring) and len(ring) == 5:\n                n += 1\n        return n\n\n    def n_simple_non_conj_6_atoms_rings(self, mol: dm.Mol):\n        \"\"\"35. number of simple non-conjugated rings with 6 atoms\"\"\"\n        ri = mol.GetRingInfo()\n        n = 0\n        for ring in ri.AtomRings():\n            if not _is_ring_fully_conjugated(mol, ring) and len(ring) == 6:\n                n += 1\n        return n\n\n    def n_ring_system(self, mol: dm.Mol):\n        \"\"\"36. number of ring systems\"\"\"\n        simple_rings, ring_system, _ = _get_ring_system(mol)\n        return len(ring_system)\n\n    def n_ring_system_with_2_non_conj_simple_ring(self, mol: dm.Mol):\n        \"\"\"37. number of rings systems with 2 non-conjugated simple rings\"\"\"\n        simple_rings, _, ring_map = _get_ring_system(mol)\n        conj_rings_map = dict(\n            (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n        )\n        result = 0\n        for ring_set in ring_map:\n            n_not_conj = sum(not conj_rings_map[rnum] for rnum in ring_set)\n            result += n_not_conj == 2\n        return result\n\n    def n_ring_system_with_2_conj_simple_ring(self, mol: dm.Mol):\n        \"\"\"38. number of rings systems with 2 conjugated simple rings\"\"\"\n        simple_rings, _, ring_map = _get_ring_system(mol)\n        conj_rings_map = dict(\n            (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n        )\n        result = 0\n        for ring_set in ring_map:\n            n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n            result += n_conj == 2\n        return result\n\n    def n_ring_system_with_conj_non_conj_simple_ring(self, mol: dm.Mol):\n        \"\"\"39 number of ring system containing 2 simple rings, one conjugated and one nonconjugated\"\"\"\n        simple_rings, _, ring_map = _get_ring_system(mol)\n        conj_rings_map = dict(\n            (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n        )\n        result = 0\n        for ring_set in ring_map:\n            if len(ring_set) == 2:\n                n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n                result += n_conj == 1\n        return result\n\n    def n_ring_system_with_3_conj_simple_ring(self, mol: dm.Mol):\n        \"\"\"40. number of rings systems with 3 conjugated simple rings\"\"\"\n        simple_rings, _, ring_map = _get_ring_system(mol)\n        conj_rings_map = dict(\n            (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n        )\n        result = 0\n        for ring_set in ring_map:\n            n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n            result += n_conj == 3\n        return result\n\n    def n_ring_system_with_3_non_conj_simple_ring(self, mol: dm.Mol):\n        \"\"\"41. number of rings systems with 3 non-conjugated simple rings\"\"\"\n        simple_rings, _, ring_map = _get_ring_system(mol)\n        conj_rings_map = dict(\n            (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n        )\n        result = 0\n        for ring_set in ring_map:\n            n_not_conj = sum(not conj_rings_map[rnum] for rnum in ring_set)\n            result += n_not_conj == 3\n        return result\n\n    def n_ring_system_with_greater_one_conj_nonconj_simple_ring(self, mol: dm.Mol):\n        \"\"\"42. number of ring system containing 3 simple rings, at least one conjugated and one nonconjugated\"\"\"\n        simple_rings, _, ring_map = _get_ring_system(mol)\n        conj_rings_map = dict(\n            (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n        )\n        result = 0\n        for ring_set in ring_map:\n            if len(ring_set) == 3:\n                n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n                result += n_conj in [1, 2]\n        return result\n\n    @property\n    def columns(self):\n        \"\"\"Get the name of all the descriptors of this calculator\"\"\"\n        return list(self.DESCRIPTORS)\n\n    def __call__(self, mol: Union[dm.Mol, str]):\n        r\"\"\"\n        Compute the Fingerprint of a molecule\n\n        Args:\n            mol: the molecule of interest\n\n        Returns:\n            props (np.ndarray): list of computed rdkit molecular descriptors\n        \"\"\"\n        mol = dm.to_mol(mol)\n        if self.use_scaffold and mol is not None:\n            mol = MurckoScaffold.GetScaffoldForMol(mol)\n\n        props = []\n        for k in self.DESCRIPTORS:\n            try:\n                fn = getattr(self, k)\n                props.append(fn(mol))\n            except Exception as e:\n                if self.verbose:\n                    logger.error(e)\n                props.append(float(\"nan\"))\n        props = np.asarray(props)\n        if self.normalize:\n            return self.compute_normalization(props)\n        return props\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the name of all the descriptors of this calculator</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.__call__","title":"<code>__call__(mol)</code>","text":"<p>Compute the Fingerprint of a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <p>Returns:</p> Name Type Description <code>props</code> <code>ndarray</code> <p>list of computed rdkit molecular descriptors</p> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str]):\n    r\"\"\"\n    Compute the Fingerprint of a molecule\n\n    Args:\n        mol: the molecule of interest\n\n    Returns:\n        props (np.ndarray): list of computed rdkit molecular descriptors\n    \"\"\"\n    mol = dm.to_mol(mol)\n    if self.use_scaffold and mol is not None:\n        mol = MurckoScaffold.GetScaffoldForMol(mol)\n\n    props = []\n    for k in self.DESCRIPTORS:\n        try:\n            fn = getattr(self, k)\n            props.append(fn(mol))\n        except Exception as e:\n            if self.verbose:\n                logger.error(e)\n            props.append(float(\"nan\"))\n    props = np.asarray(props)\n    if self.normalize:\n        return self.compute_normalization(props)\n    return props\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Get state of the scaffold key function</p> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Get state of the scaffold key function\"\"\"\n    state = {}\n    state[\"normalize\"] = self.normalize\n    state[\"verbose\"] = self.verbose\n    state[\"use_scaffold\"] = self.use_scaffold\n    return state\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.__init__","title":"<code>__init__(normalize=False, verbose=False, use_scaffold=False, **kwargs)</code>","text":"<p>Init of the scaffold key function</p> <p>Parameters:</p> Name Type Description Default <code>normalize</code> <code>bool</code> <p>whether to normalize the value of the feature</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>whether to log errors</p> <code>False</code> <code>use_scaffold</code> <code>bool</code> <p>whether to convert the molecule into scaffold first</p> <code>False</code> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def __init__(\n    self, normalize: bool = False, verbose: bool = False, use_scaffold: bool = False, **kwargs\n):\n    \"\"\"\n    Init of the scaffold key function\n\n    Args:\n        normalize: whether to normalize the value of the feature\n        verbose: whether to log errors\n        use_scaffold: whether to convert the molecule into scaffold first\n    \"\"\"\n    self.normalize = normalize\n    self.verbose = verbose\n    self.use_scaffold = use_scaffold\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.abs_scaffold_format_charge","title":"<code>abs_scaffold_format_charge(mol)</code>","text":"<ol> <li>absolute value of the scaffold formal charge</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def abs_scaffold_format_charge(self, mol: dm.Mol):\n    \"\"\"17. absolute value of the scaffold formal charge\"\"\"\n    charge = GetFormalCharge(mol)\n    return abs(charge)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.compute_normalization","title":"<code>compute_normalization(features)</code>  <code>classmethod</code>","text":"<p>Normalize input features. The normalization parameters are computed by the scaffolds of 2.1M molecules from CHEMBL 29.</p> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>@classmethod\ndef compute_normalization(cls, features: np.ndarray):\n    \"\"\"Normalize input features. The normalization parameters are\n    computed by the scaffolds of 2.1M molecules from CHEMBL 29.\n    \"\"\"\n    return (features - cls.NORM_PARAMS[\"mean\"]) / cls.NORM_PARAMS[\"std\"]\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atom_at_least_2_nei_more_than_2_conn","title":"<code>n_atom_at_least_2_nei_more_than_2_conn(mol)</code>","text":"<ol> <li>Number of atoms where at least 2 connected atoms have more than 2 connections</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atom_at_least_2_nei_more_than_2_conn(self, mol: dm.Mol):\n    \"\"\"16. Number of atoms where at least 2 connected atoms have more than 2 connections\"\"\"\n    n_atoms = 0\n    for atom in mol.GetAtoms():\n        tmp = [x for x in atom.GetNeighbors() if len(x.GetNeighbors()) &gt; 2]\n        n_atoms += len(tmp) &gt; 2\n    return n_atoms\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atom_exocyclic","title":"<code>n_atom_exocyclic(mol)</code>","text":"<ol> <li>number of exocyclic atoms (connected by multiple bonds to a ring)</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atom_exocyclic(self, mol: dm.Mol):\n    \"\"\"5. number of exocyclic atoms (connected by multiple bonds to a ring)\"\"\"\n    sm = dm.from_smarts(\"[!r;!$(*-[r])&amp;$(*~[r])]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atom_in_chain","title":"<code>n_atom_in_chain(mol)</code>","text":"<ol> <li>number atoms in chains (not counting double-connected exo-chain atoms)</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atom_in_chain(self, mol: dm.Mol):\n    \"\"\"4. number atoms in chains (not counting double-connected exo-chain atoms)\"\"\"\n    sm = dm.from_smarts(\"[!r;!$(*=[r])]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atom_in_conjugated_ring","title":"<code>n_atom_in_conjugated_ring(mol)</code>","text":"<ol> <li>number of atoms in conjugated rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atom_in_conjugated_ring(self, mol: dm.Mol):\n    \"\"\"2. number of atoms in conjugated rings\"\"\"\n    ri = mol.GetRingInfo()\n    n = 0\n    for ring in ri.AtomRings():\n        if _is_ring_fully_conjugated(mol, ring):\n            n += len(ring)\n    return n\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atom_in_rings","title":"<code>n_atom_in_rings(mol)</code>","text":"<ol> <li>number of ring atoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atom_in_rings(self, mol: dm.Mol):\n    \"\"\"1. number of ring atoms\"\"\"\n    sm = dm.from_smarts(\"[r]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atom_spiro_atoms","title":"<code>n_atom_spiro_atoms(mol)</code>","text":"<ol> <li>number of spiro atoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atom_spiro_atoms(self, mol: dm.Mol):\n    \"\"\"13. number of spiro atoms\"\"\"\n    return Desc.CalcNumSpiroAtoms(mol)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_atoms_not_in_conjugated_ring","title":"<code>n_atoms_not_in_conjugated_ring(mol)</code>","text":"<ol> <li>number of atoms not in conjugated rings (i.e. atoms in aliphatic rings and non-ring atoms)</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_atoms_not_in_conjugated_ring(self, mol: dm.Mol):\n    \"\"\"\n    3. number of atoms not in conjugated rings\n    (i.e. atoms in aliphatic rings and non-ring atoms)\n    \"\"\"\n    # EN: replace conjugation by aromatic\n    ri = mol.GetRingInfo()\n    n = 0\n    for ring in ri.AtomRings():\n        if not _is_ring_fully_conjugated(mol, ring):\n            n += len(ring)\n    return n\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_bonds","title":"<code>n_bonds(mol)</code>","text":"<ol> <li>number of bonds</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_bonds(self, mol: dm.Mol):\n    \"\"\"18. number of bonds\"\"\"\n    return mol.GetNumBonds()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_bonds_2_heteroatoms","title":"<code>n_bonds_2_heteroatoms(mol)</code>","text":"<ol> <li>number of bonds connecting 2 heteroatoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_bonds_2_heteroatoms(self, mol: dm.Mol):\n    \"\"\"20. number of bonds connecting 2 heteroatoms\"\"\"\n    sm = dm.from_smarts(\"[!#1&amp;!#6]~[!#1&amp;!#6]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_bonds_at_least_3_conn","title":"<code>n_bonds_at_least_3_conn(mol)</code>","text":"<ol> <li>number of bonds with at least 3 connections on both its atoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_bonds_at_least_3_conn(self, mol: dm.Mol):\n    \"\"\"22. number of bonds with at least 3 connections on both its atoms\"\"\"\n    sm = dm.from_smarts(\"[$([!#1](~[!#1])(~[!#1])~[!#1])][$([!#1](~[!#1])(~[!#1])~[!#1])]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_bonds_atoms_with_at_least_one_nei_with_2_conn","title":"<code>n_bonds_atoms_with_at_least_one_nei_with_2_conn(mol)</code>","text":"<ol> <li>number of bonds where both atoms have at least one neighbor (not considering the bond atoms) with more than 2 connections</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_bonds_atoms_with_at_least_one_nei_with_2_conn(self, mol: dm.Mol):\n    \"\"\"\n    27. number of bonds where both atoms have at least one neighbor\n    (not considering the bond atoms) with more than 2 connections\n    \"\"\"\n    result = 0\n    huge_conn = list(\n        itertools.chain(*mol.GetSubstructMatches(dm.from_smarts(\"[*;!D0;!D1;!D2]\"), uniquify=1))\n    )\n    for bond in mol.GetBonds():\n        a_start, a_end = bond.GetBeginAtom(), bond.GetEndAtom()\n        # we need to exclud the bond atom themselves\n        allowed_conn_table = [\n            x for x in huge_conn if x not in [a_start.GetIdx(), a_end.GetIdx()]\n        ]\n        if any([x.GetIdx() in allowed_conn_table for x in a_start.GetNeighbors()]) and any(\n            [y.GetIdx() in allowed_conn_table for y in a_end.GetNeighbors()]\n        ):\n            result += 1\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_carbon_atleast_2_heteroatoms","title":"<code>n_carbon_atleast_2_heteroatoms(mol)</code>","text":"<ol> <li>number of carbon atoms connected to at least 2 heteroatoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_carbon_atleast_2_heteroatoms(self, mol: dm.Mol):\n    \"\"\"15. number of carbon atoms connected to at least 2 heteroatoms\"\"\"\n    n_atoms = 0\n    for atom in mol.GetAtoms():\n        tmp = [x for x in atom.GetNeighbors() if x.GetAtomicNum() not in [1, 6]]\n        n_atoms += len(tmp) &gt;= 2\n    return n_atoms\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_carbon_het_carbon_het_bonds","title":"<code>n_carbon_het_carbon_het_bonds(mol)</code>","text":"<ol> <li>number of bonds connecting 2 heteroatoms through 2 carbons</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_carbon_het_carbon_het_bonds(self, mol: dm.Mol):\n    \"\"\"21. number of bonds connecting 2 heteroatoms through 2 carbons\"\"\"\n    sm = dm.from_smarts(\"[!#1&amp;!#6]~[#6]~[#6]~[!#1&amp;!#6]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_exocyclic_single_bonds_carbon","title":"<code>n_exocyclic_single_bonds_carbon(mol)</code>","text":"<ol> <li>number of exocyclic single bonds where a ring atom is carbon</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_exocyclic_single_bonds_carbon(self, mol: dm.Mol):\n    \"\"\"23. number of exocyclic single bonds where a ring atom is carbon\"\"\"\n    sm = dm.from_smarts(\"[!R;!#1]-[#6;R]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_exocyclic_single_bonds_nitrogen","title":"<code>n_exocyclic_single_bonds_nitrogen(mol)</code>","text":"<ol> <li>number of exocyclic single bonds where a ring atom is nitrogen</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_exocyclic_single_bonds_nitrogen(self, mol: dm.Mol):\n    \"\"\"24. number of exocyclic single bonds where a ring atom is nitrogen\"\"\"\n    sm = dm.from_smarts(\"[!R;!#1]-[#7;R]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_heteroatom_more_than_2_conn","title":"<code>n_heteroatom_more_than_2_conn(mol)</code>","text":"<ol> <li>number of heteroatoms with more than 2 connections</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_heteroatom_more_than_2_conn(self, mol: dm.Mol):\n    \"\"\"14. number of heteroatoms with more than 2 connections\"\"\"\n    sm = dm.from_smarts(\"[!#1;!#6;!D1!D0;!D2]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_heteroatoms","title":"<code>n_heteroatoms(mol)</code>","text":"<ol> <li>number of heteroatoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_heteroatoms(self, mol: dm.Mol):\n    \"\"\"11. number of heteroatoms\"\"\"\n\n    sm = dm.from_smarts(\"[!#1&amp;!#6]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_heteroatoms_in_ring","title":"<code>n_heteroatoms_in_ring(mol)</code>","text":"<ol> <li>number of heteroatoms in rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_heteroatoms_in_ring(self, mol: dm.Mol):\n    \"\"\"12. number of heteroatoms in rings\"\"\"\n    sm = dm.from_smarts(\"[!#1&amp;!#6&amp;r]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_multiple_non_conj_ring_bonds","title":"<code>n_multiple_non_conj_ring_bonds(mol)</code>","text":"<ol> <li>number of multiple, nonconjugated ring bonds</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_multiple_non_conj_ring_bonds(self, mol: dm.Mol):\n    \"\"\"19. number of multiple, nonconjugated ring bonds\"\"\"\n    extracted_rings = []\n    nr_multiple_bonds_infcr = 0  # infcr: in not fully conjugated ring\n    rings = Chem.GetSymmSSSR(mol)\n    for i in range(len(rings)):\n        extracted_rings.append(list(rings[i]))\n    for ring in extracted_rings:\n        if not _is_ring_fully_conjugated(mol, ring):\n            nr_multiple_bonds_infcr += _n_multiple_bond_in_ring(mol, ring)\n    return nr_multiple_bonds_infcr\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_nitrogen","title":"<code>n_nitrogen(mol)</code>","text":"<ol> <li>number of nitrogen</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_nitrogen(self, mol: dm.Mol):\n    \"\"\"6. number of nitrogen\"\"\"\n    sm = dm.from_smarts(\"[#7]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_nitrogen_in_ring","title":"<code>n_nitrogen_in_ring(mol)</code>","text":"<ol> <li>number of nitrogen in rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_nitrogen_in_ring(self, mol: dm.Mol):\n    \"\"\"7. number of nitrogen in rings\"\"\"\n    sm = dm.from_smarts(\"[#7;r]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_non_ring_bonds_2_conj_rings","title":"<code>n_non_ring_bonds_2_conj_rings(mol)</code>","text":"<ol> <li>number of non-ring bonds connecting 2 nonconjugated rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_non_ring_bonds_2_conj_rings(self, mol: dm.Mol):\n    \"\"\"25. number of non-ring bonds connecting 2 nonconjugated rings\"\"\"\n    # EN: this is interpretated literally as bonds and not path\n    ring_atom_conj_state = _ring_atom_state(mol)\n    sm = dm.from_smarts(\"[R:1]!@[R:2]\")\n    bond_list = mol.GetSubstructMatches(sm, uniquify=True)\n    result = 0\n    for a_start, a_end in bond_list:\n        s_state = ring_atom_conj_state.get(a_start)\n        e_state = ring_atom_conj_state.get(a_end)\n        if False in s_state and False in e_state:\n            result += 1\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_non_ring_bonds_conj_nonconj_rings","title":"<code>n_non_ring_bonds_conj_nonconj_rings(mol)</code>","text":"<ol> <li>number of non-ring bonds connecting 2 rings, one of them conjugated and one non-conjugated</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_non_ring_bonds_conj_nonconj_rings(self, mol: dm.Mol):\n    \"\"\"\n    26. number of non-ring bonds connecting 2 rings,\n    one of them conjugated and one non-conjugated\n    \"\"\"\n    # EN: this is interpretated literally as bonds and not path\n\n    ring_atom_conj_state = _ring_atom_state(mol)\n    sm = dm.from_smarts(\"[R:1]!@[R:2]\")\n    bond_list = mol.GetSubstructMatches(sm, uniquify=True)\n    result = 0\n    for a_start, a_end in bond_list:\n        s_state = ring_atom_conj_state.get(a_start)\n        e_state = ring_atom_conj_state.get(a_end)\n        if (True in s_state and False in e_state) or (False in s_state and True in e_state):\n            result += 1\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_oxygen","title":"<code>n_oxygen(mol)</code>","text":"<ol> <li>number of oxygen</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_oxygen(self, mol: dm.Mol):\n    \"\"\"8. number of oxygen\"\"\"\n    sm = dm.from_smarts(\"[#8]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_oxygen_in_ring","title":"<code>n_oxygen_in_ring(mol)</code>","text":"<ol> <li>number of oxygen in rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_oxygen_in_ring(self, mol: dm.Mol):\n    \"\"\"9. number of oxygen in rings\"\"\"\n    sm = dm.from_smarts(\"[#8]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system","title":"<code>n_ring_system(mol)</code>","text":"<ol> <li>number of ring systems</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system(self, mol: dm.Mol):\n    \"\"\"36. number of ring systems\"\"\"\n    simple_rings, ring_system, _ = _get_ring_system(mol)\n    return len(ring_system)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system_with_2_conj_simple_ring","title":"<code>n_ring_system_with_2_conj_simple_ring(mol)</code>","text":"<ol> <li>number of rings systems with 2 conjugated simple rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system_with_2_conj_simple_ring(self, mol: dm.Mol):\n    \"\"\"38. number of rings systems with 2 conjugated simple rings\"\"\"\n    simple_rings, _, ring_map = _get_ring_system(mol)\n    conj_rings_map = dict(\n        (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n    )\n    result = 0\n    for ring_set in ring_map:\n        n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n        result += n_conj == 2\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system_with_2_non_conj_simple_ring","title":"<code>n_ring_system_with_2_non_conj_simple_ring(mol)</code>","text":"<ol> <li>number of rings systems with 2 non-conjugated simple rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system_with_2_non_conj_simple_ring(self, mol: dm.Mol):\n    \"\"\"37. number of rings systems with 2 non-conjugated simple rings\"\"\"\n    simple_rings, _, ring_map = _get_ring_system(mol)\n    conj_rings_map = dict(\n        (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n    )\n    result = 0\n    for ring_set in ring_map:\n        n_not_conj = sum(not conj_rings_map[rnum] for rnum in ring_set)\n        result += n_not_conj == 2\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system_with_3_conj_simple_ring","title":"<code>n_ring_system_with_3_conj_simple_ring(mol)</code>","text":"<ol> <li>number of rings systems with 3 conjugated simple rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system_with_3_conj_simple_ring(self, mol: dm.Mol):\n    \"\"\"40. number of rings systems with 3 conjugated simple rings\"\"\"\n    simple_rings, _, ring_map = _get_ring_system(mol)\n    conj_rings_map = dict(\n        (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n    )\n    result = 0\n    for ring_set in ring_map:\n        n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n        result += n_conj == 3\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system_with_3_non_conj_simple_ring","title":"<code>n_ring_system_with_3_non_conj_simple_ring(mol)</code>","text":"<ol> <li>number of rings systems with 3 non-conjugated simple rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system_with_3_non_conj_simple_ring(self, mol: dm.Mol):\n    \"\"\"41. number of rings systems with 3 non-conjugated simple rings\"\"\"\n    simple_rings, _, ring_map = _get_ring_system(mol)\n    conj_rings_map = dict(\n        (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n    )\n    result = 0\n    for ring_set in ring_map:\n        n_not_conj = sum(not conj_rings_map[rnum] for rnum in ring_set)\n        result += n_not_conj == 3\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system_with_conj_non_conj_simple_ring","title":"<code>n_ring_system_with_conj_non_conj_simple_ring(mol)</code>","text":"<p>39 number of ring system containing 2 simple rings, one conjugated and one nonconjugated</p> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system_with_conj_non_conj_simple_ring(self, mol: dm.Mol):\n    \"\"\"39 number of ring system containing 2 simple rings, one conjugated and one nonconjugated\"\"\"\n    simple_rings, _, ring_map = _get_ring_system(mol)\n    conj_rings_map = dict(\n        (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n    )\n    result = 0\n    for ring_set in ring_map:\n        if len(ring_set) == 2:\n            n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n            result += n_conj == 1\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_ring_system_with_greater_one_conj_nonconj_simple_ring","title":"<code>n_ring_system_with_greater_one_conj_nonconj_simple_ring(mol)</code>","text":"<ol> <li>number of ring system containing 3 simple rings, at least one conjugated and one nonconjugated</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_ring_system_with_greater_one_conj_nonconj_simple_ring(self, mol: dm.Mol):\n    \"\"\"42. number of ring system containing 3 simple rings, at least one conjugated and one nonconjugated\"\"\"\n    simple_rings, _, ring_map = _get_ring_system(mol)\n    conj_rings_map = dict(\n        (i, _is_ring_fully_conjugated(mol, x)) for i, x in enumerate(simple_rings)\n    )\n    result = 0\n    for ring_set in ring_map:\n        if len(ring_set) == 3:\n            n_conj = sum(conj_rings_map[rnum] for rnum in ring_set)\n            result += n_conj in [1, 2]\n    return result\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_non_conj_5_atoms_rings","title":"<code>n_simple_non_conj_5_atoms_rings(mol)</code>","text":"<ol> <li>number of simple non-conjugated rings with 5 atoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_non_conj_5_atoms_rings(self, mol: dm.Mol):\n    \"\"\"34. number of simple non-conjugated rings with 5 atoms\"\"\"\n    ri = mol.GetRingInfo()\n    n = 0\n    for ring in ri.AtomRings():\n        if not _is_ring_fully_conjugated(mol, ring) and len(ring) == 5:\n            n += 1\n    return n\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_non_conj_6_atoms_rings","title":"<code>n_simple_non_conj_6_atoms_rings(mol)</code>","text":"<ol> <li>number of simple non-conjugated rings with 6 atoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_non_conj_6_atoms_rings(self, mol: dm.Mol):\n    \"\"\"35. number of simple non-conjugated rings with 6 atoms\"\"\"\n    ri = mol.GetRingInfo()\n    n = 0\n    for ring in ri.AtomRings():\n        if not _is_ring_fully_conjugated(mol, ring) and len(ring) == 6:\n            n += 1\n    return n\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_rings","title":"<code>n_simple_rings(mol)</code>","text":"<ol> <li>number of simple rings</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_rings(self, mol: dm.Mol):\n    \"\"\"28. number of simple rings\"\"\"\n    ri = mol.GetRingInfo()\n    return ri.NumRings()\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_rings_1_heteroatoms","title":"<code>n_simple_rings_1_heteroatoms(mol)</code>","text":"<ol> <li>number of simple rings with 1 heteroatom</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_rings_1_heteroatoms(self, mol: dm.Mol):\n    \"\"\"31. number of simple rings with 1 heteroatom\"\"\"\n    ri = mol.GetRingInfo()\n    n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n    return sum(1 for x in n_heteros if x == 1)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_rings_2_heteroatoms","title":"<code>n_simple_rings_2_heteroatoms(mol)</code>","text":"<ol> <li>number of simple rings with 2 heteroatom</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_rings_2_heteroatoms(self, mol: dm.Mol):\n    \"\"\"32. number of simple rings with 2 heteroatom\"\"\"\n    ri = mol.GetRingInfo()\n    n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n    return sum(1 for x in n_heteros if x == 2)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_rings_at_least_3_heteroatoms","title":"<code>n_simple_rings_at_least_3_heteroatoms(mol)</code>","text":"<ol> <li>number of simple rings with 3 or more heteroatoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_rings_at_least_3_heteroatoms(self, mol: dm.Mol):\n    \"\"\"33. number of simple rings with 3 or more heteroatoms\"\"\"\n    ri = mol.GetRingInfo()\n    n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n    return sum(1 for x in n_heteros if x &gt;= 3)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_simple_rings_no_heteroatoms","title":"<code>n_simple_rings_no_heteroatoms(mol)</code>","text":"<ol> <li>number of simple rings with no heteroatoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_simple_rings_no_heteroatoms(self, mol: dm.Mol):\n    \"\"\"30. number of simple rings with no heteroatoms\"\"\"\n    ri = mol.GetRingInfo()\n    n_heteros = _count_heteroatom_per_ring(mol, ri.AtomRings())\n    return sum(1 for x in n_heteros if x == 0)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.n_sulfur","title":"<code>n_sulfur(mol)</code>","text":"<ol> <li>number of sulfur atoms</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def n_sulfur(self, mol: dm.Mol):\n    \"\"\"10. number of sulfur atoms\"\"\"\n    sm = dm.from_smarts(\"[#16]\")\n    return len(mol.GetSubstructMatches(sm, uniquify=True))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.ScaffoldKeyCalculator.size_largest_ring","title":"<code>size_largest_ring(mol)</code>","text":"<ol> <li>Size of the largest ring</li> </ol> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def size_largest_ring(self, mol: dm.Mol):\n    \"\"\"29. Size of the largest ring\"\"\"\n    ri = mol.GetRingInfo()\n    max_ring_size = max((len(r) for r in ri.AtomRings()), default=0)\n    return max_ring_size\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.skeys.skdistance","title":"<code>skdistance(sk1, sk2, weights=None, cdist=False)</code>","text":"<p>Compute the scaffold distance between two scaffold keys as described in https://pubs.acs.org/doi/abs/10.1021/ci5001983. The input features are expected to be normalized beforehand (see paper)</p> <p>Parameters:</p> Name Type Description Default <code>sk1</code> <code>ndarray</code> <p>scaffold key 1</p> required <code>sk2</code> <code>ndarray</code> <p>scaffold key 2</p> required <code>weights</code> <code>Optional[ndarray]</code> <p>how to weight each of the features. By default rank ordering is used.</p> <code>None</code> <code>cdist</code> <code>bool</code> <p>whether to compute the features on a batched of inputs (expected 2D)</p> <code>False</code> <p>Returns:</p> Name Type Description <code>dist</code> <code>float</code> <p>distance between two scaffold keys</p> Source code in <code>molfeat/calc/skeys.py</code> <pre><code>def skdistance(\n    sk1: np.ndarray,\n    sk2: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n    cdist: bool = False,\n):\n    \"\"\"Compute the scaffold distance between two scaffold keys\n    as described in https://pubs.acs.org/doi/abs/10.1021/ci5001983.\n    The input features are expected to be normalized beforehand (see paper)\n\n    Args:\n        sk1: scaffold key 1\n        sk2: scaffold key 2\n        weights: how to weight each of the features. By default rank ordering is used.\n        cdist: whether to compute the features on a batched of inputs (expected 2D)\n\n    Returns:\n        dist (float): distance between two scaffold keys\n    \"\"\"\n    if weights is None:\n        weights = 1 / (np.arange(sk1.shape[-1]) + 1)\n\n    if cdist:\n        sk1 = np.atleast_2d(sk1)\n        sk2 = np.atleast_2d(sk2)\n        val = np.abs(sk1[:, None] - sk2[:]) ** 1.5\n        dist = np.sum(val * weights, axis=-1)\n    else:\n        if any((sk.ndim &gt; 1 and sk.shape[0] != 1) for sk in [sk1, sk2]):\n            raise ValueError(\"`cdist` mode was not detected, you need to provide single vectors\")\n        val = np.abs(sk1 - sk2) ** 1.5\n        dist = np.sum(val * weights)\n    return dist\n</code></pre>"},{"location":"api/molfeat.calc.html#shape","title":"<code>Shape</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.shape.ElectroShapeDescriptors","title":"<code>ElectroShapeDescriptors</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>Compute Electroshape descriptors as described by</p> <p>Armstrong et al. ElectroShape: fast molecular similarity calculations incorporating shape, chirality and electrostatics. J Comput Aided Mol Des 24, 789-801 (2010). http://dx.doi.org/doi:10.1007/s10822-010-9374-0</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>class ElectroShapeDescriptors(SerializableCalculator):\n    \"\"\"Compute Electroshape descriptors as described by\n\n    Armstrong et al. ElectroShape: fast molecular similarity calculations incorporating shape, chirality and electrostatics.\n    J Comput Aided Mol Des 24, 789-801 (2010). http://dx.doi.org/doi:10.1007/s10822-010-9374-0\n    \"\"\"\n\n    SUPPORTED_CHARGE_MODELS = [\"gasteiger\", \"tripos\", \"mmff94\", \"formal\"]\n\n    def __init__(\n        self,\n        charge_model: str = \"gasteiger\",\n        replace_nan: bool = False,\n        electron_scaling: float = 25.0,\n        **kwargs,\n    ):\n        \"\"\"Constructor for ElectroShape descriptor\n\n        Args:\n            charge_model: charge model to use. One of ('gasteiger', 'tripos', 'mmff94', 'formal'). Defaults to \"gasteiger\".\n                Note that formal charges will be computed on the fly if not provided in the input molecules.\n                The `tripos` charge models comes from TRIPOS force field and are often parsed from mol2 files.\n            replace_nan: whether to replace NaN values. Defaults False\n            electron_scaling: scaling factor to convert electron charges to Angstroms. Defaults to 25.0.\n        \"\"\"\n\n        self.charge_model = charge_model\n        self.replace_nan = replace_nan\n        self.electron_scaling = electron_scaling\n        self._columns = None\n\n    @property\n    def columns(self):\n        \"\"\"\n        Get the name of all the descriptors of this calculator\n        \"\"\"\n        if self._columns is None:\n            self._columns = []\n            for i in range(1, 6):\n                self._columns.extend([f\"dist-{i}-mean\", f\"dist-{i}-std\", f\"dist-{i}-crb\"])\n\n        return self._columns\n\n    def __getstate__(self):\n        state = {}\n        state[\"charge_model\"] = self.charge_model\n        state[\"replace_nan\"] = self.replace_nan\n        state[\"electron_scaling\"] = self.electron_scaling\n        state[\"_columns\"] = self._columns\n        return state\n\n    def __len__(self):\n        \"\"\"Return the length of the calculator\"\"\"\n        return len(self.columns)\n\n    @staticmethod\n    def compute_charge(mol: Union[dm.Mol, str], charge_model: str = None):\n        \"\"\"\n        Get the molecular charge of the molecule.\n\n        Args:\n            charge_model: charge model to use. One of ('gasteiger', 'tripos', 'mmff94', 'formal'). Defaults to \"gasteiger\".\n        \"\"\"\n\n        if charge_model not in ElectroShapeDescriptors.SUPPORTED_CHARGE_MODELS:\n            raise ValueError(\n                f\"Unknown charge model {charge_model}. You should provide one of {ElectroShapeDescriptors.SUPPORTED_CHARGE_MODELS}\"\n            )\n        mol = dm.to_mol(mol)\n        atom_charge = []\n        atom_list = list(mol.GetAtoms())\n\n        # force compute the partial charges if not provided\n        if charge_model == \"gasteiger\" and not atom_list[0].HasProp(\"_GasteigerCharge\"):\n            rdPartialCharges.ComputeGasteigerCharges(mol)\n        elif charge_model == \"mmff94\" and not atom_list[0].HasProp(\"_MMFF94Charge\"):\n            ff_infos = rdForceFieldHelpers.MMFFGetMoleculeProperties(mol)\n            for i, atom in enumerate(atom_list):\n                atom.SetDoubleProp(\"_MMFF94Charge\", ff_infos.GetMMFFPartialCharge(i))\n\n        for atom in mol.GetAtoms():\n            if charge_model == \"formal\":\n                atom_charge.append(atom.GetFormalCharge())\n            elif charge_model == \"gasteiger\":\n                atom_charge.append(atom.GetDoubleProp(\"_GasteigerCharge\"))\n            elif charge_model == \"mmff94\":\n                atom_charge.append(atom.GetDoubleProp(\"_MMFF94Charge\"))\n            elif charge_model == \"tripos\":\n                atom_charge.append(atom.GetDoubleProp(\"_TriposPartialCharge\"))\n        return np.asarray(atom_charge)\n\n    @requires_conformer\n    def __call__(self, mol: Union[dm.Mol, str], conformer_id: Optional[int] = -1):\n        r\"\"\"\n        Get rdkit 3D descriptors for a molecule\n\n        Args:\n            mol: the molecule of interest\n            conformer_id (int, optional): Optional conformer id. Defaults to -1.\n\n        Returns:\n            shape_descriptor (np.ndarray): computed shape descriptor\n        \"\"\"\n\n        mol = dm.to_mol(mol)\n        coords = mol.GetConformer(conformer_id).GetPositions()\n        charge = self.compute_charge(mol, self.charge_model)\n        if self.replace_nan:\n            charge = np.nan_to_num(charge)\n\n        desc_4d = np.column_stack((coords, charge * self.electron_scaling))\n\n        c1 = desc_4d.mean(axis=0)\n        distances_c1 = norm(desc_4d - c1, axis=1)\n\n        c2 = desc_4d[distances_c1.argmax()]  # atom position furthest from c1\n        distances_c2 = norm(desc_4d - c2, axis=1)\n\n        c3 = desc_4d[distances_c2.argmax()]  # atom position furthest from c2\n        distances_c3 = norm(desc_4d - c3, axis=1)\n\n        vector_a = c2 - c1\n        vector_b = c3 - c1\n        vector_as = vector_a[:3]  # spatial parts of these vectors\n        vector_bs = vector_b[:3]  # spatial parts of these vectors\n        cross_ab = np.cross(vector_as, vector_bs)\n        vector_c = (norm(vector_a) / (2 * norm(cross_ab))) * cross_ab\n        vector_c1s = c1[:3]\n\n        max_charge = np.array(np.amax(charge) * self.electron_scaling)\n        min_charge = np.array(np.amin(charge) * self.electron_scaling)\n\n        c4 = np.append(vector_c1s + vector_c, max_charge)\n        c5 = np.append(vector_c1s + vector_c, min_charge)\n\n        distances_c4 = norm(desc_4d - c4, axis=1)\n        distances_c5 = norm(desc_4d - c5, axis=1)\n\n        distances_list = [\n            distances_c1,\n            distances_c2,\n            distances_c3,\n            distances_c4,\n            distances_c5,\n        ]\n\n        shape_descriptor = np.zeros(15)\n\n        i = 0\n        for distances in distances_list:\n            mean = np.mean(distances)\n            shape_descriptor[0 + i] = mean\n            shape_descriptor[1 + i] = np.std(distances)\n            shape_descriptor[2 + i] = cbrt(np.sum(((distances - mean) ** 3) / distances.size))\n            i += 3\n        if self.replace_nan:\n            return np.nan_to_num(shape_descriptor)\n        return shape_descriptor\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.ElectroShapeDescriptors.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the name of all the descriptors of this calculator</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.ElectroShapeDescriptors.__call__","title":"<code>__call__(mol, conformer_id=-1)</code>","text":"<p>Get rdkit 3D descriptors for a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>conformer_id</code> <code>int</code> <p>Optional conformer id. Defaults to -1.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>shape_descriptor</code> <code>ndarray</code> <p>computed shape descriptor</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>@requires_conformer\ndef __call__(self, mol: Union[dm.Mol, str], conformer_id: Optional[int] = -1):\n    r\"\"\"\n    Get rdkit 3D descriptors for a molecule\n\n    Args:\n        mol: the molecule of interest\n        conformer_id (int, optional): Optional conformer id. Defaults to -1.\n\n    Returns:\n        shape_descriptor (np.ndarray): computed shape descriptor\n    \"\"\"\n\n    mol = dm.to_mol(mol)\n    coords = mol.GetConformer(conformer_id).GetPositions()\n    charge = self.compute_charge(mol, self.charge_model)\n    if self.replace_nan:\n        charge = np.nan_to_num(charge)\n\n    desc_4d = np.column_stack((coords, charge * self.electron_scaling))\n\n    c1 = desc_4d.mean(axis=0)\n    distances_c1 = norm(desc_4d - c1, axis=1)\n\n    c2 = desc_4d[distances_c1.argmax()]  # atom position furthest from c1\n    distances_c2 = norm(desc_4d - c2, axis=1)\n\n    c3 = desc_4d[distances_c2.argmax()]  # atom position furthest from c2\n    distances_c3 = norm(desc_4d - c3, axis=1)\n\n    vector_a = c2 - c1\n    vector_b = c3 - c1\n    vector_as = vector_a[:3]  # spatial parts of these vectors\n    vector_bs = vector_b[:3]  # spatial parts of these vectors\n    cross_ab = np.cross(vector_as, vector_bs)\n    vector_c = (norm(vector_a) / (2 * norm(cross_ab))) * cross_ab\n    vector_c1s = c1[:3]\n\n    max_charge = np.array(np.amax(charge) * self.electron_scaling)\n    min_charge = np.array(np.amin(charge) * self.electron_scaling)\n\n    c4 = np.append(vector_c1s + vector_c, max_charge)\n    c5 = np.append(vector_c1s + vector_c, min_charge)\n\n    distances_c4 = norm(desc_4d - c4, axis=1)\n    distances_c5 = norm(desc_4d - c5, axis=1)\n\n    distances_list = [\n        distances_c1,\n        distances_c2,\n        distances_c3,\n        distances_c4,\n        distances_c5,\n    ]\n\n    shape_descriptor = np.zeros(15)\n\n    i = 0\n    for distances in distances_list:\n        mean = np.mean(distances)\n        shape_descriptor[0 + i] = mean\n        shape_descriptor[1 + i] = np.std(distances)\n        shape_descriptor[2 + i] = cbrt(np.sum(((distances - mean) ** 3) / distances.size))\n        i += 3\n    if self.replace_nan:\n        return np.nan_to_num(shape_descriptor)\n    return shape_descriptor\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.ElectroShapeDescriptors.__init__","title":"<code>__init__(charge_model='gasteiger', replace_nan=False, electron_scaling=25.0, **kwargs)</code>","text":"<p>Constructor for ElectroShape descriptor</p> <p>Parameters:</p> Name Type Description Default <code>charge_model</code> <code>str</code> <p>charge model to use. One of ('gasteiger', 'tripos', 'mmff94', 'formal'). Defaults to \"gasteiger\". Note that formal charges will be computed on the fly if not provided in the input molecules. The <code>tripos</code> charge models comes from TRIPOS force field and are often parsed from mol2 files.</p> <code>'gasteiger'</code> <code>replace_nan</code> <code>bool</code> <p>whether to replace NaN values. Defaults False</p> <code>False</code> <code>electron_scaling</code> <code>float</code> <p>scaling factor to convert electron charges to Angstroms. Defaults to 25.0.</p> <code>25.0</code> Source code in <code>molfeat/calc/shape.py</code> <pre><code>def __init__(\n    self,\n    charge_model: str = \"gasteiger\",\n    replace_nan: bool = False,\n    electron_scaling: float = 25.0,\n    **kwargs,\n):\n    \"\"\"Constructor for ElectroShape descriptor\n\n    Args:\n        charge_model: charge model to use. One of ('gasteiger', 'tripos', 'mmff94', 'formal'). Defaults to \"gasteiger\".\n            Note that formal charges will be computed on the fly if not provided in the input molecules.\n            The `tripos` charge models comes from TRIPOS force field and are often parsed from mol2 files.\n        replace_nan: whether to replace NaN values. Defaults False\n        electron_scaling: scaling factor to convert electron charges to Angstroms. Defaults to 25.0.\n    \"\"\"\n\n    self.charge_model = charge_model\n    self.replace_nan = replace_nan\n    self.electron_scaling = electron_scaling\n    self._columns = None\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.ElectroShapeDescriptors.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the calculator</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the length of the calculator\"\"\"\n    return len(self.columns)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.ElectroShapeDescriptors.compute_charge","title":"<code>compute_charge(mol, charge_model=None)</code>  <code>staticmethod</code>","text":"<p>Get the molecular charge of the molecule.</p> <p>Parameters:</p> Name Type Description Default <code>charge_model</code> <code>str</code> <p>charge model to use. One of ('gasteiger', 'tripos', 'mmff94', 'formal'). Defaults to \"gasteiger\".</p> <code>None</code> Source code in <code>molfeat/calc/shape.py</code> <pre><code>@staticmethod\ndef compute_charge(mol: Union[dm.Mol, str], charge_model: str = None):\n    \"\"\"\n    Get the molecular charge of the molecule.\n\n    Args:\n        charge_model: charge model to use. One of ('gasteiger', 'tripos', 'mmff94', 'formal'). Defaults to \"gasteiger\".\n    \"\"\"\n\n    if charge_model not in ElectroShapeDescriptors.SUPPORTED_CHARGE_MODELS:\n        raise ValueError(\n            f\"Unknown charge model {charge_model}. You should provide one of {ElectroShapeDescriptors.SUPPORTED_CHARGE_MODELS}\"\n        )\n    mol = dm.to_mol(mol)\n    atom_charge = []\n    atom_list = list(mol.GetAtoms())\n\n    # force compute the partial charges if not provided\n    if charge_model == \"gasteiger\" and not atom_list[0].HasProp(\"_GasteigerCharge\"):\n        rdPartialCharges.ComputeGasteigerCharges(mol)\n    elif charge_model == \"mmff94\" and not atom_list[0].HasProp(\"_MMFF94Charge\"):\n        ff_infos = rdForceFieldHelpers.MMFFGetMoleculeProperties(mol)\n        for i, atom in enumerate(atom_list):\n            atom.SetDoubleProp(\"_MMFF94Charge\", ff_infos.GetMMFFPartialCharge(i))\n\n    for atom in mol.GetAtoms():\n        if charge_model == \"formal\":\n            atom_charge.append(atom.GetFormalCharge())\n        elif charge_model == \"gasteiger\":\n            atom_charge.append(atom.GetDoubleProp(\"_GasteigerCharge\"))\n        elif charge_model == \"mmff94\":\n            atom_charge.append(atom.GetDoubleProp(\"_MMFF94Charge\"))\n        elif charge_model == \"tripos\":\n            atom_charge.append(atom.GetDoubleProp(\"_TriposPartialCharge\"))\n    return np.asarray(atom_charge)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.USRDescriptors","title":"<code>USRDescriptors</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>Descriptors for the shape of a molecule.</p> <p>!!! note:     The following shape descriptors are offered:         * USR: UltraFast Shape Recognition         * USRCAT: Ultrafast Shape Recognition with CREDO Atom Types</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>class USRDescriptors(SerializableCalculator):\n    \"\"\"Descriptors for the shape of a molecule.\n\n    !!! note:\n        The following shape descriptors are offered:\n            * USR: UltraFast Shape Recognition\n            * USRCAT: Ultrafast Shape Recognition with CREDO Atom Types\n    \"\"\"\n\n    def __init__(self, method: str = \"USR\", replace_nan: bool = False, **kwargs):\n        \"\"\"Constructor for ShapeDescriptors\n\n        Args:\n            method: Shape descriptor method to use. One of 'USR', 'USRCAT'. Default to 'USR'\n            replace_nan: Whether to replace nan or infinite values. Defaults to False.\n        \"\"\"\n        self.method = method.upper()\n        if self.method not in [\"USR\", \"USRCAT\"]:\n            raise ValueError(f\"Shape descriptor {self.method} is not supported\")\n        self.replace_nan = replace_nan\n        self._columns = None\n\n    def __getstate__(self):\n        state = {}\n        state[\"method\"] = self.method\n        state[\"replace_nan\"] = self.replace_nan\n        state[\"_columns\"] = self._columns\n        return state\n\n    @property\n    def columns(self):\n        \"\"\"\n        Get the name of all the descriptors of this calculator\n        \"\"\"\n        if self._columns is None:\n            if self.method == \"USR\":\n                self._columns = [f\"usr-{i}\" for i in range(1, 13)]\n            elif self.method == \"USRCAT\":\n                self._columns = [f\"usr-{i}\" for i in range(1, 61)]\n        return self._columns\n\n    def __len__(self):\n        \"\"\"Compute descriptors length\"\"\"\n        return len(self.columns)\n\n    @requires_conformer\n    def __call__(self, mol: Union[dm.Mol, str], conformer_id: Optional[int] = -1) -&gt; np.ndarray:\n        r\"\"\"\n        Get rdkit 3D descriptors for a molecule\n\n        Args:\n            mol: the molecule of interest\n            conformer_id: Optional conformer id. Defaults to -1.\n\n        Returns:\n            shape_descriptors: list of computed molecular descriptors\n        \"\"\"\n        if self.method == \"USR\":\n            shape_descr = rdMolDescriptors.GetUSR(mol, confId=conformer_id)\n        elif self.method == \"USRCAT\":\n            shape_descr = rdMolDescriptors.GetUSRCAT(mol, confId=conformer_id)\n        if self.replace_nan:\n            shape_descr = np.nan_to_num(shape_descr, self.replace_nan)\n        return np.asarray(shape_descr)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.USRDescriptors.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the name of all the descriptors of this calculator</p>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.USRDescriptors.__call__","title":"<code>__call__(mol, conformer_id=-1)</code>","text":"<p>Get rdkit 3D descriptors for a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>conformer_id</code> <code>Optional[int]</code> <p>Optional conformer id. Defaults to -1.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>shape_descriptors</code> <code>ndarray</code> <p>list of computed molecular descriptors</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>@requires_conformer\ndef __call__(self, mol: Union[dm.Mol, str], conformer_id: Optional[int] = -1) -&gt; np.ndarray:\n    r\"\"\"\n    Get rdkit 3D descriptors for a molecule\n\n    Args:\n        mol: the molecule of interest\n        conformer_id: Optional conformer id. Defaults to -1.\n\n    Returns:\n        shape_descriptors: list of computed molecular descriptors\n    \"\"\"\n    if self.method == \"USR\":\n        shape_descr = rdMolDescriptors.GetUSR(mol, confId=conformer_id)\n    elif self.method == \"USRCAT\":\n        shape_descr = rdMolDescriptors.GetUSRCAT(mol, confId=conformer_id)\n    if self.replace_nan:\n        shape_descr = np.nan_to_num(shape_descr, self.replace_nan)\n    return np.asarray(shape_descr)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.USRDescriptors.__init__","title":"<code>__init__(method='USR', replace_nan=False, **kwargs)</code>","text":"<p>Constructor for ShapeDescriptors</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Shape descriptor method to use. One of 'USR', 'USRCAT'. Default to 'USR'</p> <code>'USR'</code> <code>replace_nan</code> <code>bool</code> <p>Whether to replace nan or infinite values. Defaults to False.</p> <code>False</code> Source code in <code>molfeat/calc/shape.py</code> <pre><code>def __init__(self, method: str = \"USR\", replace_nan: bool = False, **kwargs):\n    \"\"\"Constructor for ShapeDescriptors\n\n    Args:\n        method: Shape descriptor method to use. One of 'USR', 'USRCAT'. Default to 'USR'\n        replace_nan: Whether to replace nan or infinite values. Defaults to False.\n    \"\"\"\n    self.method = method.upper()\n    if self.method not in [\"USR\", \"USRCAT\"]:\n        raise ValueError(f\"Shape descriptor {self.method} is not supported\")\n    self.replace_nan = replace_nan\n    self._columns = None\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.USRDescriptors.__len__","title":"<code>__len__()</code>","text":"<p>Compute descriptors length</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>def __len__(self):\n    \"\"\"Compute descriptors length\"\"\"\n    return len(self.columns)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.shape.usrdistance","title":"<code>usrdistance(shape_1, shape_2, weights=None)</code>","text":"<p>Computes similarity between molecules</p> <p>Parameters:</p> Name Type Description Default <code>shape_1</code> <p>USR shape descriptor of first molecule</p> required <code>shape_2</code> <p>USR shape descriptor</p> required <code>weights</code> <code>Optional[List[float]]</code> <p>List of scaling factor to use for</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dist</code> <p>Distance [0-1] between shapes of molecules, 0 indicates identical molecules</p> Source code in <code>molfeat/calc/shape.py</code> <pre><code>def usrdistance(\n    shape_1,\n    shape_2,\n    weights: Optional[List[float]] = None,\n):\n    \"\"\"Computes similarity between molecules\n\n    Args:\n        shape_1: USR shape descriptor of first molecule\n        shape_2: USR shape descriptor\n        weights: List of scaling factor to use for\n\n    Returns:\n        dist: Distance [0-1] between shapes of molecules, 0 indicates identical molecules\n    \"\"\"\n\n    # case for usr shape descriptors\n    if weights is None:\n        weights = []\n    if (\n        (shape_1.shape[-1] == shape_2.shape[-1] == 12)\n        or (shape_1.shape[-1] == shape_2.shape[-1] == 60)\n        or (shape_1.shape[-1] == shape_2.shape[-1] == 15)\n    ):\n        dist = rdMolDescriptors.GetUSRScore(shape_1, shape_2, weights=weights)\n        return dist\n\n    raise Exception(\n        \"Given vectors are not valid USR shape descriptors \"\n        \"or come from different methods. Correct vector lengths\"\n        \"are: 12 for USR, 60 for USRCAT, 15 for Electroshape\"\n    )\n</code></pre>"},{"location":"api/molfeat.calc.html#atoms-featurizer","title":"<code>Atoms Featurizer</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator","title":"<code>AtomCalculator</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>Base class for computing atom properties compatible with DGLLife</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>class AtomCalculator(SerializableCalculator):\n    \"\"\"\n    Base class for computing atom properties compatible with DGLLife\n    \"\"\"\n\n    DEFAULT_FEATURIZER = {\n        \"atom_one_hot\": atom_one_hot,\n        \"atom_degree_one_hot\": atom_degree_one_hot,\n        \"atom_implicit_valence_one_hot\": atom_implicit_valence_one_hot,\n        \"atom_hybridization_one_hot\": atom_hybridization_one_hot,\n        \"atom_is_aromatic\": atom_is_aromatic,\n        \"atom_formal_charge\": atom_formal_charge,\n        \"atom_num_radical_electrons\": atom_num_radical_electrons,\n        \"atom_is_in_ring\": atom_is_in_ring,\n        \"atom_total_num_H_one_hot\": atom_total_num_H_one_hot,\n        \"atom_chiral_tag_one_hot\": atom_chiral_tag_one_hot,\n        \"atom_is_chiral_center\": atom_is_chiral_center,\n    }\n\n    def __init__(\n        self,\n        featurizer_funcs: Dict[str, Callable] = None,\n        concat: bool = True,\n        name: str = \"hv\",\n    ):\n        \"\"\"\n        Init function of the atom property calculator\n\n        Args:\n            featurizer_funcs : Mapping of feature name to the featurization function.\n                For compatibility a list of callable/function is still accepted, and the corresponding\n                featurizer name will be automatically generated. Each function is of signature\n                ``func(dm.Atom) -&gt; list or 1D numpy array``.\n            concat: Whether to concat all the data into a single value in the output dict\n            name: Name of the key name of the concatenated features\n        \"\"\"\n        self._input_kwargs = locals().copy()\n        self._input_kwargs.pop(\"self\")\n        # we also remove the featurizer funcs\n        self._input_kwargs.pop(\"featurizer_funcs\", None)\n        self._toy_mol = dm.to_mol(\"CCO\")\n        self._feat_sizes = dict()\n        if featurizer_funcs is None:\n            featurizer_funcs = self.DEFAULT_FEATURIZER\n        if not isinstance(featurizer_funcs, dict):\n            get_name = lambda x: getattr(x, \"__name__\", repr(x))\n            featurizer_funcs = dict((get_name(x), x) for x in featurizer_funcs)\n        self.featurizer_funcs = featurizer_funcs\n        for k in self.featurizer_funcs.keys():\n            self.feat_size(feat_name=k)\n        self.concat = concat\n        self.name = name\n\n    def to_state_dict(self):\n        \"\"\"\n        Convert the Atom calculator to a state dict\n        Due to some constraints and cross-version compatibility,  the featurizer functions\n        need to be pickled and not just return a list\n        \"\"\"\n        state_dict = {}\n        state_dict[\"name\"] = self.__class__.__name__\n        state_dict[\"module\"] = self.__class__.__module__\n        state_dict[\"args\"] = self._input_kwargs\n        featurizer_fn_pickled = {}\n        for fname, ffunc in self.featurizer_funcs.items():\n            featurizer_fn_pickled[fname] = fn_to_hex(ffunc)\n        state_dict[\"args\"][\"featurizer_funcs\"] = featurizer_fn_pickled\n        state_dict[\"_molfeat_version\"] = MOLFEAT_VERSION\n\n        signature = inspect.signature(self.__init__)\n        val = {\n            k: v.default\n            for k, v in signature.parameters.items()\n            # if v.default is not inspect.Parameter.empty\n        }\n        to_remove = [k for k in state_dict[\"args\"] if k not in val.keys()]\n        for k in to_remove:\n            state_dict[\"args\"].pop(k)\n\n        return state_dict\n\n    @classmethod\n    def from_state_dict(cls, state_dict, override_args: Optional[dict] = None):\n        \"\"\"Create an instance of an atom calculator from a state dict\n\n        Args:\n            state_dict: state dictionary to use to create the atom calculator\n            override_args: optional dictionary of arguments to override the ones in the state dict\n                at construction of the new object\n        \"\"\"\n        # EN: at this moment, version compatibility is not enforced\n        cls_name = state_dict.get(\"name\", cls.__name__)\n        module_name = state_dict.get(\"module\", cls.__module__)\n        module = importlib.import_module(module_name)\n        klass = getattr(module, cls_name)\n        kwargs = state_dict[\"args\"].copy()\n        # now we need to unpickle the featurizer functions\n        featurizer_fn_pickled = kwargs.pop(\"featurizer_funcs\", None)\n        if featurizer_fn_pickled is not None:\n            featurizer_fn_loaded = {}\n            for k, v in featurizer_fn_pickled.items():\n                featurizer_fn_loaded[k] = hex_to_fn(v)\n            kwargs[\"featurizer_funcs\"] = featurizer_fn_loaded\n        kwargs.update(**(override_args or {}))\n        return klass(**kwargs)\n\n    def _concat(self, data_dict: Dict[str, Iterable]):\n        \"\"\"Concatenate the data into a single value\n\n        Args:\n            data_dict: mapping of feature names to tensor/arrays\n        Returns:\n            concatenated_dict: a dict with a single key where all array have been concatenated\n        \"\"\"\n        return concat_dict(data_dict, new_name=self.name)\n\n    def feat_size(self, feat_name=None):\n        \"\"\"Get the feature size for ``feat_name``.\n\n        When there is only one feature, users do not need to provide ``feat_name``.\n\n        Args:\n            feat_name: Feature for query.\n\n        Returns:\n            int: Feature size for the feature with name ``feat_name``. Default to None.\n        \"\"\"\n        if feat_name is None:\n            assert (\n                len(self.featurizer_funcs) == 1\n            ), \"feat_name should be provided if there are more than one features\"\n            feat_name = list(self.featurizer_funcs.keys())[0]\n\n        if feat_name not in self.featurizer_funcs:\n            raise ValueError(\n                \"Expect feat_name to be in {}, got {}\".format(\n                    list(self.featurizer_funcs.keys()), feat_name\n                )\n            )\n\n        if feat_name not in self._feat_sizes:\n            atom = self._toy_mol.GetAtomWithIdx(0)\n            self._feat_sizes[feat_name] = len(self.featurizer_funcs[feat_name](atom))\n        return self._feat_sizes[feat_name]\n\n    def __len__(self):\n        \"\"\"Get length of the property estimator\"\"\"\n        return sum(v for k, v in self._feat_sizes.items() if k != self.name)\n\n    def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None):\n        \"\"\"\n        Get rdkit basic descriptors for a molecule\n\n        Args:\n            mol: the molecule of interest\n            dtype: requested data type\n\n        Returns:\n            dict:  For each function in self.featurizer_funcs with the key ``k``, store the computed feature under the key ``k``.\n        \"\"\"\n        mol = dm.to_mol(mol)\n        num_atoms = mol.GetNumAtoms()\n        atom_features = defaultdict(list)\n\n        # Compute features for each atom\n        for i in range(num_atoms):\n            atom = mol.GetAtomWithIdx(i)\n            for feat_name, feat_func in self.featurizer_funcs.items():\n                atom_features[feat_name].append(feat_func(atom))\n\n        # Stack the features and convert them to float arrays\n        processed_features = dict()\n        for feat_name, feat_list in atom_features.items():\n            feat = np.stack(feat_list).astype(np.float32)\n            processed_features[feat_name] = feat\n\n        if self.concat:\n            processed_features = self._concat(processed_features)\n\n        if dtype is not None:\n            for feat_name, feat in processed_features.items():\n                feat = datatype.cast(feat, dtype=dtype)\n                processed_features[feat_name] = feat\n\n        return processed_features\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator.__call__","title":"<code>__call__(mol, dtype=None)</code>","text":"<p>Get rdkit basic descriptors for a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>dtype</code> <code>Callable</code> <p>requested data type</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>For each function in self.featurizer_funcs with the key <code>k</code>, store the computed feature under the key <code>k</code>.</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None):\n    \"\"\"\n    Get rdkit basic descriptors for a molecule\n\n    Args:\n        mol: the molecule of interest\n        dtype: requested data type\n\n    Returns:\n        dict:  For each function in self.featurizer_funcs with the key ``k``, store the computed feature under the key ``k``.\n    \"\"\"\n    mol = dm.to_mol(mol)\n    num_atoms = mol.GetNumAtoms()\n    atom_features = defaultdict(list)\n\n    # Compute features for each atom\n    for i in range(num_atoms):\n        atom = mol.GetAtomWithIdx(i)\n        for feat_name, feat_func in self.featurizer_funcs.items():\n            atom_features[feat_name].append(feat_func(atom))\n\n    # Stack the features and convert them to float arrays\n    processed_features = dict()\n    for feat_name, feat_list in atom_features.items():\n        feat = np.stack(feat_list).astype(np.float32)\n        processed_features[feat_name] = feat\n\n    if self.concat:\n        processed_features = self._concat(processed_features)\n\n    if dtype is not None:\n        for feat_name, feat in processed_features.items():\n            feat = datatype.cast(feat, dtype=dtype)\n            processed_features[feat_name] = feat\n\n    return processed_features\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator.__init__","title":"<code>__init__(featurizer_funcs=None, concat=True, name='hv')</code>","text":"<p>Init function of the atom property calculator</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_funcs</code> <p>Mapping of feature name to the featurization function. For compatibility a list of callable/function is still accepted, and the corresponding featurizer name will be automatically generated. Each function is of signature <code>func(dm.Atom) -&gt; list or 1D numpy array</code>.</p> <code>None</code> <code>concat</code> <code>bool</code> <p>Whether to concat all the data into a single value in the output dict</p> <code>True</code> <code>name</code> <code>str</code> <p>Name of the key name of the concatenated features</p> <code>'hv'</code> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def __init__(\n    self,\n    featurizer_funcs: Dict[str, Callable] = None,\n    concat: bool = True,\n    name: str = \"hv\",\n):\n    \"\"\"\n    Init function of the atom property calculator\n\n    Args:\n        featurizer_funcs : Mapping of feature name to the featurization function.\n            For compatibility a list of callable/function is still accepted, and the corresponding\n            featurizer name will be automatically generated. Each function is of signature\n            ``func(dm.Atom) -&gt; list or 1D numpy array``.\n        concat: Whether to concat all the data into a single value in the output dict\n        name: Name of the key name of the concatenated features\n    \"\"\"\n    self._input_kwargs = locals().copy()\n    self._input_kwargs.pop(\"self\")\n    # we also remove the featurizer funcs\n    self._input_kwargs.pop(\"featurizer_funcs\", None)\n    self._toy_mol = dm.to_mol(\"CCO\")\n    self._feat_sizes = dict()\n    if featurizer_funcs is None:\n        featurizer_funcs = self.DEFAULT_FEATURIZER\n    if not isinstance(featurizer_funcs, dict):\n        get_name = lambda x: getattr(x, \"__name__\", repr(x))\n        featurizer_funcs = dict((get_name(x), x) for x in featurizer_funcs)\n    self.featurizer_funcs = featurizer_funcs\n    for k in self.featurizer_funcs.keys():\n        self.feat_size(feat_name=k)\n    self.concat = concat\n    self.name = name\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator.__len__","title":"<code>__len__()</code>","text":"<p>Get length of the property estimator</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def __len__(self):\n    \"\"\"Get length of the property estimator\"\"\"\n    return sum(v for k, v in self._feat_sizes.items() if k != self.name)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator.feat_size","title":"<code>feat_size(feat_name=None)</code>","text":"<p>Get the feature size for <code>feat_name</code>.</p> <p>When there is only one feature, users do not need to provide <code>feat_name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feat_name</code> <p>Feature for query.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <p>Feature size for the feature with name <code>feat_name</code>. Default to None.</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def feat_size(self, feat_name=None):\n    \"\"\"Get the feature size for ``feat_name``.\n\n    When there is only one feature, users do not need to provide ``feat_name``.\n\n    Args:\n        feat_name: Feature for query.\n\n    Returns:\n        int: Feature size for the feature with name ``feat_name``. Default to None.\n    \"\"\"\n    if feat_name is None:\n        assert (\n            len(self.featurizer_funcs) == 1\n        ), \"feat_name should be provided if there are more than one features\"\n        feat_name = list(self.featurizer_funcs.keys())[0]\n\n    if feat_name not in self.featurizer_funcs:\n        raise ValueError(\n            \"Expect feat_name to be in {}, got {}\".format(\n                list(self.featurizer_funcs.keys()), feat_name\n            )\n        )\n\n    if feat_name not in self._feat_sizes:\n        atom = self._toy_mol.GetAtomWithIdx(0)\n        self._feat_sizes[feat_name] = len(self.featurizer_funcs[feat_name](atom))\n    return self._feat_sizes[feat_name]\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator.from_state_dict","title":"<code>from_state_dict(state_dict, override_args=None)</code>  <code>classmethod</code>","text":"<p>Create an instance of an atom calculator from a state dict</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <p>state dictionary to use to create the atom calculator</p> required <code>override_args</code> <code>Optional[dict]</code> <p>optional dictionary of arguments to override the ones in the state dict at construction of the new object</p> <code>None</code> Source code in <code>molfeat/calc/atom.py</code> <pre><code>@classmethod\ndef from_state_dict(cls, state_dict, override_args: Optional[dict] = None):\n    \"\"\"Create an instance of an atom calculator from a state dict\n\n    Args:\n        state_dict: state dictionary to use to create the atom calculator\n        override_args: optional dictionary of arguments to override the ones in the state dict\n            at construction of the new object\n    \"\"\"\n    # EN: at this moment, version compatibility is not enforced\n    cls_name = state_dict.get(\"name\", cls.__name__)\n    module_name = state_dict.get(\"module\", cls.__module__)\n    module = importlib.import_module(module_name)\n    klass = getattr(module, cls_name)\n    kwargs = state_dict[\"args\"].copy()\n    # now we need to unpickle the featurizer functions\n    featurizer_fn_pickled = kwargs.pop(\"featurizer_funcs\", None)\n    if featurizer_fn_pickled is not None:\n        featurizer_fn_loaded = {}\n        for k, v in featurizer_fn_pickled.items():\n            featurizer_fn_loaded[k] = hex_to_fn(v)\n        kwargs[\"featurizer_funcs\"] = featurizer_fn_loaded\n    kwargs.update(**(override_args or {}))\n    return klass(**kwargs)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomCalculator.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Convert the Atom calculator to a state dict Due to some constraints and cross-version compatibility,  the featurizer functions need to be pickled and not just return a list</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def to_state_dict(self):\n    \"\"\"\n    Convert the Atom calculator to a state dict\n    Due to some constraints and cross-version compatibility,  the featurizer functions\n    need to be pickled and not just return a list\n    \"\"\"\n    state_dict = {}\n    state_dict[\"name\"] = self.__class__.__name__\n    state_dict[\"module\"] = self.__class__.__module__\n    state_dict[\"args\"] = self._input_kwargs\n    featurizer_fn_pickled = {}\n    for fname, ffunc in self.featurizer_funcs.items():\n        featurizer_fn_pickled[fname] = fn_to_hex(ffunc)\n    state_dict[\"args\"][\"featurizer_funcs\"] = featurizer_fn_pickled\n    state_dict[\"_molfeat_version\"] = MOLFEAT_VERSION\n\n    signature = inspect.signature(self.__init__)\n    val = {\n        k: v.default\n        for k, v in signature.parameters.items()\n        # if v.default is not inspect.Parameter.empty\n    }\n    to_remove = [k for k in state_dict[\"args\"] if k not in val.keys()]\n    for k in to_remove:\n        state_dict[\"args\"].pop(k)\n\n    return state_dict\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.AtomMaterialCalculator","title":"<code>AtomMaterialCalculator</code>","text":"<p>               Bases: <code>AtomCalculator</code></p> <p>Atom calculator with the extend atomic property list which have been collected from various material science packages</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>class AtomMaterialCalculator(AtomCalculator):\n    \"\"\"Atom calculator with the extend atomic property list\n    which have been collected from various material science packages\n    \"\"\"\n\n    DEFAULT_FEATURIZER = {\n        \"atom_one_hot\": atom_one_hot,\n        \"atom_extended_properties\": atom_extended_properties,\n        \"atom_degree_one_hot\": atom_degree_one_hot,\n        \"atom_implicit_valence_one_hot\": atom_implicit_valence_one_hot,\n        \"atom_hybridization_one_hot\": atom_hybridization_one_hot,\n        \"atom_is_aromatic\": atom_is_aromatic,\n        \"atom_formal_charge\": atom_formal_charge,\n        \"atom_num_radical_electrons\": atom_num_radical_electrons,\n        \"atom_is_in_ring\": atom_is_in_ring,\n        \"atom_chiral_tag_one_hot\": atom_chiral_tag_one_hot,\n        \"atom_is_chiral_center\": atom_is_chiral_center,\n    }\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.DGLCanonicalAtomCalculator","title":"<code>DGLCanonicalAtomCalculator</code>","text":"<p>               Bases: <code>AtomCalculator</code></p> <p>Default canonical featurizer for atoms used by dgllife</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>class DGLCanonicalAtomCalculator(AtomCalculator):\n    \"\"\"Default canonical featurizer for atoms used by dgllife\"\"\"\n\n    DEFAULT_FEATURIZER = {\n        \"atom_one_hot\": atom_one_hot,\n        \"atom_degree_one_hot\": atom_degree_one_hot,\n        \"atom_implicit_valence_one_hot\": atom_implicit_valence_one_hot,\n        \"atom_formal_charge\": atom_formal_charge,\n        \"atom_num_radical_electrons\": atom_num_radical_electrons,\n        \"atom_hybridization_one_hot\": partial(\n            atom_hybridization_one_hot, allowable_set=DGLLIFE_HYBRIDIZATION_LIST\n        ),\n        \"atom_is_aromatic\": atom_is_aromatic,\n        \"atom_total_num_H_one_hot\": atom_total_num_H_one_hot,\n    }\n\n    def _concat(self, data_dict: Dict[str, Iterable]):\n        \"\"\"Concatenate the data into a single value\n\n        Args:\n            data_dict: mapping of feature names to tensor/arrays\n        Returns:\n            concatenated_dict: a dict with a single key where all array have been concatenated\n        \"\"\"\n        out = concat_dict(data_dict, new_name=self.name, order=list(self.featurizer_funcs.keys()))\n        return out\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.DGLWeaveAtomCalculator","title":"<code>DGLWeaveAtomCalculator</code>","text":"<p>               Bases: <code>DGLCanonicalAtomCalculator</code></p> <p>Default atom featurizer used by WeaveNet in DGLLife</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>class DGLWeaveAtomCalculator(DGLCanonicalAtomCalculator):\n    \"\"\"Default atom featurizer used by WeaveNet in DGLLife\"\"\"\n\n    DEFAULT_FEATURIZER = {\n        \"atom_one_hot\": partial(\n            atom_one_hot, allowable_set=DGLLIFE_WEAVE_ATOMS, encode_unknown=True\n        ),\n        \"atom_chiral_tag_one_hot\": partial(\n            atom_chiral_tag_one_hot, allowable_set=DGLLIFE_WEAVE_CHIRAL_TYPES\n        ),\n        \"atom_formal_charge\": atom_formal_charge,\n        \"atom_partial_charge\": atom_partial_charge,\n        \"atom_is_aromatic\": atom_is_aromatic,\n        \"atom_hybridization_one_hot\": partial(\n            atom_hybridization_one_hot, allowable_set=DGLLIFE_HYBRIDIZATION_LIST[:3]\n        ),\n    }\n\n    def __init__(self, concat: bool = True, name: str = \"hv\"):\n        featurizer_funcs = self.DEFAULT_FEATURIZER\n        featurizer_funcs[\"atom_weavenet_props\"] = self.atom_weave_props\n        super().__init__(concat=concat, name=name, featurizer_funcs=featurizer_funcs)\n\n    def _get_atom_state_info(self, feats):\n        \"\"\"Get atom Donor/Acceptor state information from chemical pharmacophore features\n\n        Args:\n            feats: computed chemical features\n        \"\"\"\n        is_donor = defaultdict(bool)\n        is_acceptor = defaultdict(bool)\n        # Get hydrogen bond donor/acceptor information\n        for feats in feats:\n            if feats.GetFamily() == \"Donor\":\n                nodes = feats.GetAtomIds()\n                for u in nodes:\n                    is_donor[u] = True\n            elif feats.GetFamily() == \"Acceptor\":\n                nodes = feats.GetAtomIds()\n                for u in nodes:\n                    is_acceptor[u] = True\n        return is_donor, is_acceptor\n\n    @staticmethod\n    @lru_cache(maxsize=None)\n    def _feat_factory_cache():\n        \"\"\"Build and cache chemical features caching for speed\"\"\"\n        fdef_name = os.path.join(RDConfig.RDDataDir, \"BaseFeatures.fdef\")\n        chem_feats = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n        return chem_feats\n\n    @lru_cache\n    def _compute_weave_net_properties(self, mol: dm.Mol):\n        # Get information for donor and acceptor\n        chem_feats = self._feat_factory_cache()\n        mol_feats = chem_feats.GetFeaturesForMol(mol)\n        is_donor, is_acceptor = self._get_atom_state_info(mol_feats)\n        sssr = GetSymmSSSR(mol)\n        num_atoms = mol.GetNumAtoms()\n        atom_features = []\n        for i in range(num_atoms):\n            cur_atom_props = [float(is_donor[i]), float(is_acceptor[i])]\n            # Count the number of rings the atom belongs to for ring size between 3 and 8\n            count = [0 for _ in range(3, 9)]\n            for ring in sssr:\n                ring_size = len(ring)\n                if i in ring and 3 &lt;= ring_size &lt;= 8:\n                    count[ring_size - 3] += 1\n            cur_atom_props.extend(count)\n            atom_features.append(cur_atom_props)\n        return atom_features\n\n    def atom_weave_props(self, atom: dm.Atom):\n        \"\"\"Get the WeaveNet properties for an atom\"\"\"\n        mol = atom.GetOwningMol()\n        feats = self._compute_weave_net_properties(mol)\n        return feats[atom.GetIdx()]\n\n    def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None):\n        \"\"\"\n        Get rdkit basic descriptors for a molecule\n\n        Args:\n            mol: the molecule of interest\n            dtype: requested data type\n\n        Returns:\n            dict:  For each function in self.featurizer_funcs with the key ``k``, store the computed feature under the key ``k``.\n        \"\"\"\n        AllChem.ComputeGasteigerCharges(mol)\n        return super().__call__(\n            mol,\n            dtype,\n        )\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.DGLWeaveAtomCalculator.__call__","title":"<code>__call__(mol, dtype=None)</code>","text":"<p>Get rdkit basic descriptors for a molecule</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>dtype</code> <code>Callable</code> <p>requested data type</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>For each function in self.featurizer_funcs with the key <code>k</code>, store the computed feature under the key <code>k</code>.</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None):\n    \"\"\"\n    Get rdkit basic descriptors for a molecule\n\n    Args:\n        mol: the molecule of interest\n        dtype: requested data type\n\n    Returns:\n        dict:  For each function in self.featurizer_funcs with the key ``k``, store the computed feature under the key ``k``.\n    \"\"\"\n    AllChem.ComputeGasteigerCharges(mol)\n    return super().__call__(\n        mol,\n        dtype,\n    )\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.atom.DGLWeaveAtomCalculator.atom_weave_props","title":"<code>atom_weave_props(atom)</code>","text":"<p>Get the WeaveNet properties for an atom</p> Source code in <code>molfeat/calc/atom.py</code> <pre><code>def atom_weave_props(self, atom: dm.Atom):\n    \"\"\"Get the WeaveNet properties for an atom\"\"\"\n    mol = atom.GetOwningMol()\n    feats = self._compute_weave_net_properties(mol)\n    return feats[atom.GetIdx()]\n</code></pre>"},{"location":"api/molfeat.calc.html#bonds-featurizer","title":"<code>Bonds Featurizer</code>","text":""},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator","title":"<code>BondCalculator</code>","text":"<p>               Bases: <code>SerializableCalculator</code></p> <p>A class for bond featurizer which loops over all bonds in a molecule and featurizes them with the <code>featurizer_funcs</code>. The constructed graph is assumed to be a bi-directed graph by default.</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>class BondCalculator(SerializableCalculator):\n    \"\"\"\n    A class for bond featurizer which loops over all bonds in a molecule and\n    featurizes them with the ``featurizer_funcs``. The constructed graph is assumed to be\n    a bi-directed graph by default.\n    \"\"\"\n\n    DEFAULT_FEATURIZER = {\n        \"bond_type_one_hot\": bond_type_one_hot,\n        \"bond_stereo_one_hot\": bond_stereo_one_hot,\n        \"bond_is_in_ring\": bond_is_in_ring,\n        \"bond_is_conjugated\": bond_is_conjugated,\n        \"bond_direction_one_hot\": bond_direction_one_hot,\n    }\n\n    def __init__(\n        self,\n        featurizer_funcs: Union[list, dict] = None,\n        self_loop: bool = False,\n        concat: bool = True,\n        name: str = \"he\",\n    ):\n        \"\"\"\n        Init function of the bond property calculator\n\n        Args:\n            featurizer_funcs: Mapping feature name to the featurization function.\n            self_loop: Whether self loops will be added. Default to False. If True, an additional\n                column of binary values to indicate the identity of self loops will be added.\n                The other features of the self loops will be zero.\n            concat: Whether to concat all the data into a single value in the output dict\n            name: Name of the key name of the concatenated features\n        \"\"\"\n        self._input_kwargs = locals().copy()\n        self._input_kwargs.pop(\"self\")\n        # remove featurizer_funcs too\n        self._input_kwargs.pop(\"featurizer_funcs\", None)\n        self._toy_mol = dm.to_mol(\"CO\")\n        self._feat_sizes = dict()\n        if featurizer_funcs is None:\n            featurizer_funcs = self.DEFAULT_FEATURIZER\n        if not isinstance(featurizer_funcs, dict):\n            get_name = lambda x: getattr(x, \"__name__\", repr(x))\n            featurizer_funcs = dict((get_name(x), x) for x in featurizer_funcs)\n        self.featurizer_funcs = featurizer_funcs\n        self._self_loop = self_loop\n        self.concat = concat\n        self.name = name\n        for k in self.featurizer_funcs.keys():\n            self.feat_size(feat_name=k)\n        if self._self_loop:\n            self._feat_sizes[\"self_loop\"] = 1\n\n    def to_state_dict(self):\n        \"\"\"Convert the Atom calculator to a state dict\n        Due to some constraints and cross-version compatibility,  the featurizer functions\n        need to be pickled and not just list\n        \"\"\"\n        state_dict = {}\n        state_dict[\"name\"] = self.__class__.__name__\n        state_dict[\"module\"] = self.__class__.__module__\n        state_dict[\"args\"] = self._input_kwargs\n\n        featurizer_fn_pickled = {}\n        for fname, ffunc in self.featurizer_funcs.items():\n            featurizer_fn_pickled[fname] = fn_to_hex(ffunc)\n        state_dict[\"args\"][\"featurizer_funcs\"] = featurizer_fn_pickled\n        state_dict[\"_molfeat_version\"] = MOLFEAT_VERSION\n        signature = inspect.signature(self.__init__)\n        val = {\n            k: v.default\n            for k, v in signature.parameters.items()\n            #    if v.default is not inspect.Parameter.empty\n        }\n        to_remove = [k for k in state_dict[\"args\"] if k not in val.keys()]\n        for k in to_remove:\n            state_dict[\"args\"].pop(k)\n        return state_dict\n\n    @classmethod\n    def from_state_dict(cls, state_dict, override_args: Optional[dict] = None):\n        \"\"\"Create an instance of an atom calculator from a state dict\n\n        Args:\n            state_dict: state dictionary to use to create the atom calculator\n            override_args: optional dictionary of arguments to override the ones in the state dict\n                at construction of the new object\n        \"\"\"\n        # EN: at this moment, version compatibility is not enforced\n        cls_name = state_dict.get(\"name\", cls.__name__)\n        module_name = state_dict.get(\"module\", cls.__module__)\n        module = importlib.import_module(module_name)\n        klass = getattr(module, cls_name)\n\n        kwargs = state_dict[\"args\"].copy()\n        # now we need to unpickle the featurizer functions\n        featurizer_fn_pickled = kwargs.pop(\"featurizer_funcs\", None)\n        if featurizer_fn_pickled is not None:\n            featurizer_fn_loaded = {}\n            for k, v in featurizer_fn_pickled.items():\n                featurizer_fn_loaded[k] = hex_to_fn(v)\n            kwargs[\"featurizer_funcs\"] = featurizer_fn_loaded\n        kwargs.update(**(override_args or {}))\n        return klass(**kwargs)\n\n    def _concat(self, data_dict: Dict[str, Iterable]):\n        \"\"\"Concatenate the data into a single value\n\n        Args:\n            data_dict: mapping of feature names to tensor/arrays\n        Returns:\n            concatenated_dict: a dict with a single key where all array have been concatenated\n        \"\"\"\n        return concat_dict(data_dict, new_name=self.name)\n\n    def feat_size(self, feat_name: Optional[str] = None):\n        \"\"\"Get the feature size for ``feat_name``.\n\n        When there is only one feature, ``feat_name`` can be None.\n\n        Args:\n            feat_name: Feature for query.\n\n        Returns:\n            int: Feature size for the feature with name ``feat_name``. Default to None.\n        \"\"\"\n        if feat_name is None:\n            assert (\n                len(self.featurizer_funcs) == 1\n            ), \"feat_name should be provided if there are more than one features\"\n            feat_name = list(self.featurizer_funcs.keys())[0]\n\n        if feat_name not in self.featurizer_funcs:\n            raise ValueError(\n                \"Expect feat_name to be in {}, got {}\".format(\n                    list(self.featurizer_funcs.keys()), feat_name\n                )\n            )\n        if feat_name not in self._feat_sizes:\n            bond = self._toy_mol.GetBondWithIdx(0)\n            self._feat_sizes[feat_name] = len(self.featurizer_funcs[feat_name](bond))\n        return self._feat_sizes[feat_name]\n\n    def __len__(self):\n        \"\"\"Get length of the property estimator\"\"\"\n        return sum(v for k, v in self._feat_sizes.items() if k != self.name)\n\n    def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None, **kwargs):\n        \"\"\"Featurize all bonds in a molecule.\n\n        Args:\n            mol: the molecule of interest\n            dtype: requested data type\n\n        Returns:\n            dict: For each function in self.featurizer_funcs with the key ``k``,\n                store the computed feature under the key ``k``.\n        \"\"\"\n        mol = dm.to_mol(mol)\n        num_bonds = mol.GetNumBonds()\n        bond_features = defaultdict(list)\n\n        # Compute features for each bond\n        for i in range(num_bonds):\n            bond = mol.GetBondWithIdx(i)\n            for feat_name, feat_func in self.featurizer_funcs.items():\n                feat = feat_func(bond)\n                bond_features[feat_name].extend([feat, feat.copy()])\n\n        # Stack the features and convert them to float arrays\n        processed_features = dict()\n        for feat_name, feat_list in bond_features.items():\n            feat = np.stack(feat_list)\n            processed_features[feat_name] = feat\n\n        if self._self_loop and num_bonds &gt; 0:\n            num_atoms = mol.GetNumAtoms()\n            for feat_name in processed_features:\n                feats = processed_features[feat_name]\n                # add a new label that says the feat are not self loop\n                # feats = np.concatenate([feats, np.zeros((feats.shape[0], 1))], axis=1)\n                # add a label at the last position that says it's a selfloop\n                add_edges = np.zeros((num_atoms, feats.shape[1]))\n                # self_loop_feats[:, -1] = 1\n                feats = np.concatenate([feats, add_edges], axis=0)\n                processed_features[feat_name] = feats\n            self_loop_feats = np.concatenate(\n                [np.zeros((num_bonds * 2, 1)), np.ones((num_atoms, 1))]\n            )\n\n            processed_features[\"self_loop\"] = self_loop_feats\n\n        if self._self_loop and num_bonds == 0:\n            num_atoms = mol.GetNumAtoms()\n            old_concat = self.concat\n            self.concat = False\n            processed_features = self(self._toy_mol)\n            self.concat = old_concat\n            for feat_name in processed_features:\n                feats = processed_features[feat_name]\n                feats = np.zeros((num_atoms, feats.shape[1]))\n                processed_features[feat_name] = feats\n        if self.concat and (num_bonds &gt; 0 or self._self_loop):\n            processed_features = self._concat(processed_features)\n        if dtype is not None:\n            for feat_name, feat in processed_features.items():\n                feat = datatype.cast(feat, dtype=dtype)\n                processed_features[feat_name] = feat\n\n        return processed_features\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator.__call__","title":"<code>__call__(mol, dtype=None, **kwargs)</code>","text":"<p>Featurize all bonds in a molecule.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>dtype</code> <code>Callable</code> <p>requested data type</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>For each function in self.featurizer_funcs with the key <code>k</code>, store the computed feature under the key <code>k</code>.</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None, **kwargs):\n    \"\"\"Featurize all bonds in a molecule.\n\n    Args:\n        mol: the molecule of interest\n        dtype: requested data type\n\n    Returns:\n        dict: For each function in self.featurizer_funcs with the key ``k``,\n            store the computed feature under the key ``k``.\n    \"\"\"\n    mol = dm.to_mol(mol)\n    num_bonds = mol.GetNumBonds()\n    bond_features = defaultdict(list)\n\n    # Compute features for each bond\n    for i in range(num_bonds):\n        bond = mol.GetBondWithIdx(i)\n        for feat_name, feat_func in self.featurizer_funcs.items():\n            feat = feat_func(bond)\n            bond_features[feat_name].extend([feat, feat.copy()])\n\n    # Stack the features and convert them to float arrays\n    processed_features = dict()\n    for feat_name, feat_list in bond_features.items():\n        feat = np.stack(feat_list)\n        processed_features[feat_name] = feat\n\n    if self._self_loop and num_bonds &gt; 0:\n        num_atoms = mol.GetNumAtoms()\n        for feat_name in processed_features:\n            feats = processed_features[feat_name]\n            # add a new label that says the feat are not self loop\n            # feats = np.concatenate([feats, np.zeros((feats.shape[0], 1))], axis=1)\n            # add a label at the last position that says it's a selfloop\n            add_edges = np.zeros((num_atoms, feats.shape[1]))\n            # self_loop_feats[:, -1] = 1\n            feats = np.concatenate([feats, add_edges], axis=0)\n            processed_features[feat_name] = feats\n        self_loop_feats = np.concatenate(\n            [np.zeros((num_bonds * 2, 1)), np.ones((num_atoms, 1))]\n        )\n\n        processed_features[\"self_loop\"] = self_loop_feats\n\n    if self._self_loop and num_bonds == 0:\n        num_atoms = mol.GetNumAtoms()\n        old_concat = self.concat\n        self.concat = False\n        processed_features = self(self._toy_mol)\n        self.concat = old_concat\n        for feat_name in processed_features:\n            feats = processed_features[feat_name]\n            feats = np.zeros((num_atoms, feats.shape[1]))\n            processed_features[feat_name] = feats\n    if self.concat and (num_bonds &gt; 0 or self._self_loop):\n        processed_features = self._concat(processed_features)\n    if dtype is not None:\n        for feat_name, feat in processed_features.items():\n            feat = datatype.cast(feat, dtype=dtype)\n            processed_features[feat_name] = feat\n\n    return processed_features\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator.__init__","title":"<code>__init__(featurizer_funcs=None, self_loop=False, concat=True, name='he')</code>","text":"<p>Init function of the bond property calculator</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_funcs</code> <code>Union[list, dict]</code> <p>Mapping feature name to the featurization function.</p> <code>None</code> <code>self_loop</code> <code>bool</code> <p>Whether self loops will be added. Default to False. If True, an additional column of binary values to indicate the identity of self loops will be added. The other features of the self loops will be zero.</p> <code>False</code> <code>concat</code> <code>bool</code> <p>Whether to concat all the data into a single value in the output dict</p> <code>True</code> <code>name</code> <code>str</code> <p>Name of the key name of the concatenated features</p> <code>'he'</code> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def __init__(\n    self,\n    featurizer_funcs: Union[list, dict] = None,\n    self_loop: bool = False,\n    concat: bool = True,\n    name: str = \"he\",\n):\n    \"\"\"\n    Init function of the bond property calculator\n\n    Args:\n        featurizer_funcs: Mapping feature name to the featurization function.\n        self_loop: Whether self loops will be added. Default to False. If True, an additional\n            column of binary values to indicate the identity of self loops will be added.\n            The other features of the self loops will be zero.\n        concat: Whether to concat all the data into a single value in the output dict\n        name: Name of the key name of the concatenated features\n    \"\"\"\n    self._input_kwargs = locals().copy()\n    self._input_kwargs.pop(\"self\")\n    # remove featurizer_funcs too\n    self._input_kwargs.pop(\"featurizer_funcs\", None)\n    self._toy_mol = dm.to_mol(\"CO\")\n    self._feat_sizes = dict()\n    if featurizer_funcs is None:\n        featurizer_funcs = self.DEFAULT_FEATURIZER\n    if not isinstance(featurizer_funcs, dict):\n        get_name = lambda x: getattr(x, \"__name__\", repr(x))\n        featurizer_funcs = dict((get_name(x), x) for x in featurizer_funcs)\n    self.featurizer_funcs = featurizer_funcs\n    self._self_loop = self_loop\n    self.concat = concat\n    self.name = name\n    for k in self.featurizer_funcs.keys():\n        self.feat_size(feat_name=k)\n    if self._self_loop:\n        self._feat_sizes[\"self_loop\"] = 1\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator.__len__","title":"<code>__len__()</code>","text":"<p>Get length of the property estimator</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def __len__(self):\n    \"\"\"Get length of the property estimator\"\"\"\n    return sum(v for k, v in self._feat_sizes.items() if k != self.name)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator.feat_size","title":"<code>feat_size(feat_name=None)</code>","text":"<p>Get the feature size for <code>feat_name</code>.</p> <p>When there is only one feature, <code>feat_name</code> can be None.</p> <p>Parameters:</p> Name Type Description Default <code>feat_name</code> <code>Optional[str]</code> <p>Feature for query.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <p>Feature size for the feature with name <code>feat_name</code>. Default to None.</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def feat_size(self, feat_name: Optional[str] = None):\n    \"\"\"Get the feature size for ``feat_name``.\n\n    When there is only one feature, ``feat_name`` can be None.\n\n    Args:\n        feat_name: Feature for query.\n\n    Returns:\n        int: Feature size for the feature with name ``feat_name``. Default to None.\n    \"\"\"\n    if feat_name is None:\n        assert (\n            len(self.featurizer_funcs) == 1\n        ), \"feat_name should be provided if there are more than one features\"\n        feat_name = list(self.featurizer_funcs.keys())[0]\n\n    if feat_name not in self.featurizer_funcs:\n        raise ValueError(\n            \"Expect feat_name to be in {}, got {}\".format(\n                list(self.featurizer_funcs.keys()), feat_name\n            )\n        )\n    if feat_name not in self._feat_sizes:\n        bond = self._toy_mol.GetBondWithIdx(0)\n        self._feat_sizes[feat_name] = len(self.featurizer_funcs[feat_name](bond))\n    return self._feat_sizes[feat_name]\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator.from_state_dict","title":"<code>from_state_dict(state_dict, override_args=None)</code>  <code>classmethod</code>","text":"<p>Create an instance of an atom calculator from a state dict</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <p>state dictionary to use to create the atom calculator</p> required <code>override_args</code> <code>Optional[dict]</code> <p>optional dictionary of arguments to override the ones in the state dict at construction of the new object</p> <code>None</code> Source code in <code>molfeat/calc/bond.py</code> <pre><code>@classmethod\ndef from_state_dict(cls, state_dict, override_args: Optional[dict] = None):\n    \"\"\"Create an instance of an atom calculator from a state dict\n\n    Args:\n        state_dict: state dictionary to use to create the atom calculator\n        override_args: optional dictionary of arguments to override the ones in the state dict\n            at construction of the new object\n    \"\"\"\n    # EN: at this moment, version compatibility is not enforced\n    cls_name = state_dict.get(\"name\", cls.__name__)\n    module_name = state_dict.get(\"module\", cls.__module__)\n    module = importlib.import_module(module_name)\n    klass = getattr(module, cls_name)\n\n    kwargs = state_dict[\"args\"].copy()\n    # now we need to unpickle the featurizer functions\n    featurizer_fn_pickled = kwargs.pop(\"featurizer_funcs\", None)\n    if featurizer_fn_pickled is not None:\n        featurizer_fn_loaded = {}\n        for k, v in featurizer_fn_pickled.items():\n            featurizer_fn_loaded[k] = hex_to_fn(v)\n        kwargs[\"featurizer_funcs\"] = featurizer_fn_loaded\n    kwargs.update(**(override_args or {}))\n    return klass(**kwargs)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.BondCalculator.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Convert the Atom calculator to a state dict Due to some constraints and cross-version compatibility,  the featurizer functions need to be pickled and not just list</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def to_state_dict(self):\n    \"\"\"Convert the Atom calculator to a state dict\n    Due to some constraints and cross-version compatibility,  the featurizer functions\n    need to be pickled and not just list\n    \"\"\"\n    state_dict = {}\n    state_dict[\"name\"] = self.__class__.__name__\n    state_dict[\"module\"] = self.__class__.__module__\n    state_dict[\"args\"] = self._input_kwargs\n\n    featurizer_fn_pickled = {}\n    for fname, ffunc in self.featurizer_funcs.items():\n        featurizer_fn_pickled[fname] = fn_to_hex(ffunc)\n    state_dict[\"args\"][\"featurizer_funcs\"] = featurizer_fn_pickled\n    state_dict[\"_molfeat_version\"] = MOLFEAT_VERSION\n    signature = inspect.signature(self.__init__)\n    val = {\n        k: v.default\n        for k, v in signature.parameters.items()\n        #    if v.default is not inspect.Parameter.empty\n    }\n    to_remove = [k for k in state_dict[\"args\"] if k not in val.keys()]\n    for k in to_remove:\n        state_dict[\"args\"].pop(k)\n    return state_dict\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.DGLCanonicalBondCalculator","title":"<code>DGLCanonicalBondCalculator</code>","text":"<p>               Bases: <code>BondCalculator</code></p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>class DGLCanonicalBondCalculator(BondCalculator):\n    DEFAULT_FEATURIZER = {\n        \"bond_type_one_hot\": bond_type_one_hot,\n        \"bond_is_conjugated\": bond_is_conjugated,\n        \"bond_is_in_ring\": bond_is_in_ring,\n        \"bond_stereo_one_hot\": bond_stereo_one_hot,\n    }\n\n    def _concat(self, data_dict: Dict[str, Iterable]):\n        \"\"\"Concatenate the data into a single value\n\n        Args:\n            data_dict: mapping of feature names to tensor/arrays\n        Returns:\n            concatenated_dict: a dict with a single key where all array have been concatenated\n        \"\"\"\n        return concat_dict(data_dict, new_name=self.name, order=list(self.featurizer_funcs.keys()))\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.DGLWeaveEdgeCalculator","title":"<code>DGLWeaveEdgeCalculator</code>","text":"<p>               Bases: <code>EdgeMatCalculator</code></p> <p>Edge featurizer used by WeaveNets</p> <p>The edge featurization is introduced in <code>Molecular Graph Convolutions: Moving Beyond Fingerprints &lt;https://arxiv.org/abs/1603.00856&gt;</code>__.</p> <p>This featurization is performed for a complete graph of atoms with self loops added, which considers the following default:</p> <ul> <li>Number of bonds between each pairs of atoms</li> <li>One-hot encoding of bond type if a bond exists between a pair of atoms</li> <li>Whether a pair of atoms belongs to a same ring</li> </ul> Source code in <code>molfeat/calc/bond.py</code> <pre><code>class DGLWeaveEdgeCalculator(EdgeMatCalculator):\n    \"\"\"Edge featurizer used by WeaveNets\n\n    The edge featurization is introduced in `Molecular Graph Convolutions:\n    Moving Beyond Fingerprints &lt;https://arxiv.org/abs/1603.00856&gt;`__.\n\n    This featurization is performed for a complete graph of atoms with self loops added,\n    which considers the following default:\n\n    * Number of bonds between each pairs of atoms\n    * One-hot encoding of bond type if a bond exists between a pair of atoms\n    * Whether a pair of atoms belongs to a same ring\n\n    \"\"\"\n\n    DEFAULT_FEATURIZER = {}\n    DEFAULT_PAIRWISE_FEATURIZER = {\n        \"pairwise_dist_indicator\": pairwise_dist_indicator,\n        \"pairwise_bond_indicator\": pairwise_bond_indicator,\n        \"pairwise_ring_membership\": pairwise_ring_membership,\n    }\n\n    def _concat(self, data_dict: Dict[str, Iterable]):\n        \"\"\"Concatenate the data into a single value\n\n        Args:\n            data_dict: mapping of feature names to tensor/arrays\n        Returns:\n            concatenated_dict: a dict with a single key where all array have been concatenated\n        \"\"\"\n\n        # To reproduce DGLDefault, we need to keep the order of dict insertion\n        return concat_dict(\n            data_dict, new_name=self.name, order=list(self.pairwise_atom_funcs.keys())\n        )\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.EdgeMatCalculator","title":"<code>EdgeMatCalculator</code>","text":"<p>               Bases: <code>BondCalculator</code></p> <p>Generate edge featurizer matrix</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>class EdgeMatCalculator(BondCalculator):\n    \"\"\"Generate edge featurizer matrix\"\"\"\n\n    DEFAULT_PAIRWISE_FEATURIZER = {\n        \"pairwise_2D_dist\": pairwise_2D_dist,\n        # \"pairwise_3D_dist\": pairwise_3D_dist,\n        \"pairwise_ring_membership\": pairwise_ring_membership,\n    }\n\n    def __init__(\n        self,\n        featurizer_funcs: Union[list, dict] = None,\n        pairwise_atom_funcs: Union[list, dict, str] = \"default\",\n        name: str = \"he\",\n    ):\n        \"\"\"\n        Init function of the edge matrix property calculator\n\n        Args:\n            featurizer_funcs: Mapping feature name to the featurization function.\n            pairwise_atom_funcs: Mapping feature name to pairwise featurization function.\n                Use the keywords \"default\" for the default values\n        \"\"\"\n        if pairwise_atom_funcs == \"default\":\n            pairwise_atom_funcs = self.DEFAULT_PAIRWISE_FEATURIZER\n        if not isinstance(pairwise_atom_funcs, dict):\n            get_name = lambda x: getattr(x, \"__name__\", repr(x))\n            pairwise_atom_funcs = dict((get_name(x), x) for x in pairwise_atom_funcs)\n        self.pairwise_atom_funcs = pairwise_atom_funcs\n        super().__init__(featurizer_funcs=featurizer_funcs, concat=True, name=name)\n        # add conf data to toy mol\n        self._toy_mol = dm.conformers.generate(self._toy_mol, n_confs=1, minimize_energy=False)\n        for k in self.pairwise_atom_funcs.keys():\n            self.feat_size(feat_name=k)\n\n    def to_state_dict(self):\n        \"\"\"Convert the Atom calculator to a state dict\n        Due to some constraints and cross-version compatibility,  the featurizer functions\n        need to be pickled and not just list\n        \"\"\"\n        state_dict = super().to_state_dict()\n        # repeat for the pairwise one\n        pairwise_atom_fn_pickled = {}\n        for fname, ffunc in self.pairwise_atom_funcs.items():\n            pairwise_atom_fn_pickled[fname] = fn_to_hex(ffunc)\n        state_dict[\"args\"][\"pairwise_atom_funcs\"] = pairwise_atom_fn_pickled\n        return state_dict\n\n    @classmethod\n    def from_state_dict(cls, state_dict, override_args: Optional[dict] = None):\n        \"\"\"Create an instance of an atom calculator from a state dict\n\n        Args:\n            state_dict: state dictionary to use to create the atom calculator\n            override_args: optional dictionary of arguments to override the ones in the state dict\n                at construction of the new object\n        \"\"\"\n        # EN: at this moment, version compatibility is not enforced\n        cls_name = state_dict.get(\"name\", cls.__name__)\n        module_name = state_dict.get(\"module\", cls.__module__)\n        module = importlib.import_module(module_name)\n        klass = getattr(module, cls_name)\n\n        kwargs = state_dict[\"args\"].copy()\n        # now we need to unpickle the featurizer functions\n        featurizer_fn_pickled = kwargs.pop(\"featurizer_funcs\", None)\n        if featurizer_fn_pickled is not None:\n            featurizer_fn_loaded = {}\n            for k, v in featurizer_fn_pickled.items():\n                featurizer_fn_loaded[k] = hex_to_fn(v)\n            kwargs[\"featurizer_funcs\"] = featurizer_fn_loaded\n\n        pairwise_atom_fn_pickled = kwargs.pop(\"pairwise_atom_funcs\", None)\n        if pairwise_atom_fn_pickled is not None:\n            pairwise_atom_fn_loaded = {}\n            for k, v in pairwise_atom_fn_pickled.items():\n                pairwise_atom_fn_loaded[k] = hex_to_fn(v)\n            kwargs[\"pairwise_atom_funcs\"] = pairwise_atom_fn_loaded\n        kwargs.update(**(override_args or {}))\n        return klass(**kwargs)\n\n    def feat_size(self, feat_name: Optional[str] = None):\n        \"\"\"Get the feature size for ``feat_name``.\n\n        Args:\n            feat_name: Feature for query.\n\n        Returns:\n            int: Feature size for the feature with name ``feat_name``. Default to None.\n        \"\"\"\n        if feat_name not in self.featurizer_funcs and feat_name not in self.pairwise_atom_funcs:\n            raise ValueError(\n                \"Expect feat_name to be in {}, got {}\".format(\n                    list(self.featurizer_funcs.keys()), feat_name\n                )\n            )\n        if feat_name not in self._feat_sizes:\n            if feat_name in self.featurizer_funcs:\n                bond = self._toy_mol.GetBondWithIdx(0)\n                self._feat_sizes[feat_name] = len(self.featurizer_funcs[feat_name](bond))\n            elif feat_name in self.pairwise_atom_funcs:\n                self._feat_sizes[feat_name] = self.pairwise_atom_funcs[feat_name](\n                    self._toy_mol\n                ).shape[-1]\n            else:\n                raise ValueError(f\"Feature name {feat_name} is not defined !\")\n        return self._feat_sizes[feat_name]\n\n    def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None, flat: bool = True):\n        \"\"\"Featurize all bonds in a molecule.\n\n        Args:\n            mol: the molecule of interest\n            dtype: requested data type\n            flat: whether to return a collapsed N^2, M or a N, N, M matrix\n\n        Returns:\n            dict: For each function in self.featurizer_funcs with the key ``k``,\n                store the computed feature under the key ``k``.\n        \"\"\"\n\n        mol = dm.to_mol(mol)\n        num_bonds = mol.GetNumBonds()\n        num_atoms = mol.GetNumAtoms()\n        feat_size = len(self)\n        edge_matrix = None\n\n        if self.pairwise_atom_funcs is not None:\n            feat_size -= sum(self._feat_sizes[x] for x in self.pairwise_atom_funcs.keys())\n        if self.featurizer_funcs is not None and len(self.featurizer_funcs) &gt; 0:\n            edge_matrix = np.zeros((num_atoms, num_atoms, feat_size))\n            # Compute features for each bond\n            for i in range(num_bonds):\n                bond = mol.GetBondWithIdx(i)\n                a_idx_1 = bond.GetBeginAtomIdx()\n                a_idx_2 = bond.GetEndAtomIdx()\n                bond_features = defaultdict(list)\n                for feat_name, feat_func in self.featurizer_funcs.items():\n                    feat = feat_func(bond)\n                    bond_features[feat_name].extend([feat])\n                bond_features = self._concat(bond_features)[self.name]\n                edge_matrix[a_idx_1, a_idx_2] = bond_features\n                edge_matrix[a_idx_2, a_idx_1] = bond_features\n\n            edge_matrix = edge_matrix.reshape(-1, feat_size)\n        if self.pairwise_atom_funcs is not None:\n            pwise_features = dict()\n            for pname, pfunc in self.pairwise_atom_funcs.items():\n                pwise_features[pname] = pfunc(mol)\n            pwise_features = self._concat(pwise_features)[self.name]\n            if edge_matrix is not None:\n                edge_matrix = np.concatenate([edge_matrix, pwise_features], axis=-1)\n            else:\n                edge_matrix = pwise_features\n        if not flat:\n            edge_matrix = edge_matrix.reshape(num_atoms, num_atoms, -1)\n        if dtype is not None:\n            edge_matrix = datatype.cast(edge_matrix, dtype=dtype)\n        return {self.name: edge_matrix}\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.EdgeMatCalculator.__call__","title":"<code>__call__(mol, dtype=None, flat=True)</code>","text":"<p>Featurize all bonds in a molecule.</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Union[Mol, str]</code> <p>the molecule of interest</p> required <code>dtype</code> <code>Callable</code> <p>requested data type</p> <code>None</code> <code>flat</code> <code>bool</code> <p>whether to return a collapsed N^2, M or a N, N, M matrix</p> <code>True</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>For each function in self.featurizer_funcs with the key <code>k</code>, store the computed feature under the key <code>k</code>.</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def __call__(self, mol: Union[dm.Mol, str], dtype: Callable = None, flat: bool = True):\n    \"\"\"Featurize all bonds in a molecule.\n\n    Args:\n        mol: the molecule of interest\n        dtype: requested data type\n        flat: whether to return a collapsed N^2, M or a N, N, M matrix\n\n    Returns:\n        dict: For each function in self.featurizer_funcs with the key ``k``,\n            store the computed feature under the key ``k``.\n    \"\"\"\n\n    mol = dm.to_mol(mol)\n    num_bonds = mol.GetNumBonds()\n    num_atoms = mol.GetNumAtoms()\n    feat_size = len(self)\n    edge_matrix = None\n\n    if self.pairwise_atom_funcs is not None:\n        feat_size -= sum(self._feat_sizes[x] for x in self.pairwise_atom_funcs.keys())\n    if self.featurizer_funcs is not None and len(self.featurizer_funcs) &gt; 0:\n        edge_matrix = np.zeros((num_atoms, num_atoms, feat_size))\n        # Compute features for each bond\n        for i in range(num_bonds):\n            bond = mol.GetBondWithIdx(i)\n            a_idx_1 = bond.GetBeginAtomIdx()\n            a_idx_2 = bond.GetEndAtomIdx()\n            bond_features = defaultdict(list)\n            for feat_name, feat_func in self.featurizer_funcs.items():\n                feat = feat_func(bond)\n                bond_features[feat_name].extend([feat])\n            bond_features = self._concat(bond_features)[self.name]\n            edge_matrix[a_idx_1, a_idx_2] = bond_features\n            edge_matrix[a_idx_2, a_idx_1] = bond_features\n\n        edge_matrix = edge_matrix.reshape(-1, feat_size)\n    if self.pairwise_atom_funcs is not None:\n        pwise_features = dict()\n        for pname, pfunc in self.pairwise_atom_funcs.items():\n            pwise_features[pname] = pfunc(mol)\n        pwise_features = self._concat(pwise_features)[self.name]\n        if edge_matrix is not None:\n            edge_matrix = np.concatenate([edge_matrix, pwise_features], axis=-1)\n        else:\n            edge_matrix = pwise_features\n    if not flat:\n        edge_matrix = edge_matrix.reshape(num_atoms, num_atoms, -1)\n    if dtype is not None:\n        edge_matrix = datatype.cast(edge_matrix, dtype=dtype)\n    return {self.name: edge_matrix}\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.EdgeMatCalculator.__init__","title":"<code>__init__(featurizer_funcs=None, pairwise_atom_funcs='default', name='he')</code>","text":"<p>Init function of the edge matrix property calculator</p> <p>Parameters:</p> Name Type Description Default <code>featurizer_funcs</code> <code>Union[list, dict]</code> <p>Mapping feature name to the featurization function.</p> <code>None</code> <code>pairwise_atom_funcs</code> <code>Union[list, dict, str]</code> <p>Mapping feature name to pairwise featurization function. Use the keywords \"default\" for the default values</p> <code>'default'</code> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def __init__(\n    self,\n    featurizer_funcs: Union[list, dict] = None,\n    pairwise_atom_funcs: Union[list, dict, str] = \"default\",\n    name: str = \"he\",\n):\n    \"\"\"\n    Init function of the edge matrix property calculator\n\n    Args:\n        featurizer_funcs: Mapping feature name to the featurization function.\n        pairwise_atom_funcs: Mapping feature name to pairwise featurization function.\n            Use the keywords \"default\" for the default values\n    \"\"\"\n    if pairwise_atom_funcs == \"default\":\n        pairwise_atom_funcs = self.DEFAULT_PAIRWISE_FEATURIZER\n    if not isinstance(pairwise_atom_funcs, dict):\n        get_name = lambda x: getattr(x, \"__name__\", repr(x))\n        pairwise_atom_funcs = dict((get_name(x), x) for x in pairwise_atom_funcs)\n    self.pairwise_atom_funcs = pairwise_atom_funcs\n    super().__init__(featurizer_funcs=featurizer_funcs, concat=True, name=name)\n    # add conf data to toy mol\n    self._toy_mol = dm.conformers.generate(self._toy_mol, n_confs=1, minimize_energy=False)\n    for k in self.pairwise_atom_funcs.keys():\n        self.feat_size(feat_name=k)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.EdgeMatCalculator.feat_size","title":"<code>feat_size(feat_name=None)</code>","text":"<p>Get the feature size for <code>feat_name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>feat_name</code> <code>Optional[str]</code> <p>Feature for query.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <p>Feature size for the feature with name <code>feat_name</code>. Default to None.</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def feat_size(self, feat_name: Optional[str] = None):\n    \"\"\"Get the feature size for ``feat_name``.\n\n    Args:\n        feat_name: Feature for query.\n\n    Returns:\n        int: Feature size for the feature with name ``feat_name``. Default to None.\n    \"\"\"\n    if feat_name not in self.featurizer_funcs and feat_name not in self.pairwise_atom_funcs:\n        raise ValueError(\n            \"Expect feat_name to be in {}, got {}\".format(\n                list(self.featurizer_funcs.keys()), feat_name\n            )\n        )\n    if feat_name not in self._feat_sizes:\n        if feat_name in self.featurizer_funcs:\n            bond = self._toy_mol.GetBondWithIdx(0)\n            self._feat_sizes[feat_name] = len(self.featurizer_funcs[feat_name](bond))\n        elif feat_name in self.pairwise_atom_funcs:\n            self._feat_sizes[feat_name] = self.pairwise_atom_funcs[feat_name](\n                self._toy_mol\n            ).shape[-1]\n        else:\n            raise ValueError(f\"Feature name {feat_name} is not defined !\")\n    return self._feat_sizes[feat_name]\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.EdgeMatCalculator.from_state_dict","title":"<code>from_state_dict(state_dict, override_args=None)</code>  <code>classmethod</code>","text":"<p>Create an instance of an atom calculator from a state dict</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <p>state dictionary to use to create the atom calculator</p> required <code>override_args</code> <code>Optional[dict]</code> <p>optional dictionary of arguments to override the ones in the state dict at construction of the new object</p> <code>None</code> Source code in <code>molfeat/calc/bond.py</code> <pre><code>@classmethod\ndef from_state_dict(cls, state_dict, override_args: Optional[dict] = None):\n    \"\"\"Create an instance of an atom calculator from a state dict\n\n    Args:\n        state_dict: state dictionary to use to create the atom calculator\n        override_args: optional dictionary of arguments to override the ones in the state dict\n            at construction of the new object\n    \"\"\"\n    # EN: at this moment, version compatibility is not enforced\n    cls_name = state_dict.get(\"name\", cls.__name__)\n    module_name = state_dict.get(\"module\", cls.__module__)\n    module = importlib.import_module(module_name)\n    klass = getattr(module, cls_name)\n\n    kwargs = state_dict[\"args\"].copy()\n    # now we need to unpickle the featurizer functions\n    featurizer_fn_pickled = kwargs.pop(\"featurizer_funcs\", None)\n    if featurizer_fn_pickled is not None:\n        featurizer_fn_loaded = {}\n        for k, v in featurizer_fn_pickled.items():\n            featurizer_fn_loaded[k] = hex_to_fn(v)\n        kwargs[\"featurizer_funcs\"] = featurizer_fn_loaded\n\n    pairwise_atom_fn_pickled = kwargs.pop(\"pairwise_atom_funcs\", None)\n    if pairwise_atom_fn_pickled is not None:\n        pairwise_atom_fn_loaded = {}\n        for k, v in pairwise_atom_fn_pickled.items():\n            pairwise_atom_fn_loaded[k] = hex_to_fn(v)\n        kwargs[\"pairwise_atom_funcs\"] = pairwise_atom_fn_loaded\n    kwargs.update(**(override_args or {}))\n    return klass(**kwargs)\n</code></pre>"},{"location":"api/molfeat.calc.html#molfeat.calc.bond.EdgeMatCalculator.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Convert the Atom calculator to a state dict Due to some constraints and cross-version compatibility,  the featurizer functions need to be pickled and not just list</p> Source code in <code>molfeat/calc/bond.py</code> <pre><code>def to_state_dict(self):\n    \"\"\"Convert the Atom calculator to a state dict\n    Due to some constraints and cross-version compatibility,  the featurizer functions\n    need to be pickled and not just list\n    \"\"\"\n    state_dict = super().to_state_dict()\n    # repeat for the pairwise one\n    pairwise_atom_fn_pickled = {}\n    for fname, ffunc in self.pairwise_atom_funcs.items():\n        pairwise_atom_fn_pickled[fname] = fn_to_hex(ffunc)\n    state_dict[\"args\"][\"pairwise_atom_funcs\"] = pairwise_atom_fn_pickled\n    return state_dict\n</code></pre>"},{"location":"api/molfeat.plugins.html","title":"<code>molfeat.plugins</code>","text":""},{"location":"api/molfeat.plugins.html#molfeat.plugins.factories.BaseFactory","title":"<code>BaseFactory(group, name, load=True)</code>","text":"<p>Return the plugin class registered under a given entry point group and name.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>entry point group</p> required <code>name</code> <code>str</code> <p>entry point name</p> required <code>load</code> <code>bool</code> <p>if True, load the matched entry point and return the loaded resource instead of the entry point itself.</p> <code>True</code> <p>Return:     the plugin class Raises:     MissingEntryPointError: entry point was not registered     MultipleEntryPointError: entry point could not be uniquely resolved     LoadingEntryPointError: entry point could not be loaded</p> Source code in <code>molfeat/plugins/factories.py</code> <pre><code>def BaseFactory(group: str, name: str, load: bool = True) -&gt; Union[EntryPoint, Any]:\n    \"\"\"Return the plugin class registered under a given entry point group and name.\n\n    Args:\n        group: entry point group\n        name: entry point name\n        load: if True, load the matched entry point and return the loaded resource instead of the entry point itself.\n    Return:\n        the plugin class\n    Raises:\n        MissingEntryPointError: entry point was not registered\n        MultipleEntryPointError: entry point could not be uniquely resolved\n        LoadingEntryPointError: entry point could not be loaded\n    \"\"\"\n    # circular import\n    from .entry_point import get_entry_point, load_entry_point\n\n    if load is True:\n        return load_entry_point(group, name)\n\n    return get_entry_point(group, name)\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.factories.CalculatorFactory","title":"<code>CalculatorFactory(entry_point_name, load=True, entry_point_group=None)</code>","text":"<pre><code>CalculatorFactory(\n    entry_point_name: str,\n    load: Literal[True] = True,\n    entry_point_group: Optional[str] = None,\n) -&gt; Union[Type[SerializableCalculator], Callable]\n</code></pre><pre><code>CalculatorFactory(\n    entry_point_name: str,\n    load: Literal[False],\n    entry_point_group: Optional[str] = None,\n) -&gt; EntryPoint\n</code></pre> <p>Return the <code>SerializableCalculator</code> sub class registered under the given entry point.</p> <p>Parameters:</p> Name Type Description Default <code>entry_point_name</code> <code>str</code> <p>the entry point name.</p> required <code>load</code> <code>bool</code> <p>if True, load the matched entry point and return the loaded resource instead of the entry point itself.</p> <code>True</code> <code>entry_point_group</code> <code>Optional[str]</code> <p>the optional entry point group to use</p> <code>None</code> Return <p>sub class of class:<code>~molfeat.calc.SerializableCalculator</code></p> Source code in <code>molfeat/plugins/factories.py</code> <pre><code>def CalculatorFactory(\n    entry_point_name: str,\n    load: bool = True,\n    entry_point_group: Optional[str] = None,\n) -&gt; Union[EntryPoint, Type[\"SerializableCalculator\"], Callable]:\n    \"\"\"Return the `SerializableCalculator` sub class registered under the given entry point.\n\n    Args:\n        entry_point_name: the entry point name.\n        load: if True, load the matched entry point and return the loaded resource instead of the entry point itself.\n        entry_point_group: the optional entry point group to use\n\n    Return:\n        sub class of :py:class:`~molfeat.calc.SerializableCalculator`\n    \"\"\"\n    from molfeat.calc import SerializableCalculator\n\n    if entry_point_group is None:\n        entry_point_group = \"molfeat.calc\"\n    entry_point = BaseFactory(entry_point_group, entry_point_name, load=load)\n    valid_classes = (SerializableCalculator,)\n\n    if not load:\n        return entry_point\n\n    # if the entry point is a module, nothing to do\n    if ismodule(entry_point):\n        return entry_point\n    if isclass(entry_point) and issubclass(entry_point, valid_classes):\n        return entry_point\n\n    raise_invalid_type_error(entry_point_name, entry_point_group, valid_classes)\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.factories.DefaultFactory","title":"<code>DefaultFactory(entry_point_name, load=True, entry_point_group=None)</code>","text":"<pre><code>DefaultFactory(\n    entry_point_name: str,\n    load: Literal[True] = True,\n    entry_point_group: str = None,\n) -&gt; Union[Type[PretrainedMolTransformer], Callable]\n</code></pre><pre><code>DefaultFactory(\n    entry_point_name: str,\n    load: Literal[False],\n    entry_point_group: str = None,\n) -&gt; EntryPoint\n</code></pre> <p>Return the Default factory for extending capabilities given a specific module.</p> <p>Parameters:</p> Name Type Description Default <code>entry_point_name</code> <code>str</code> <p>the entry point name.</p> required <code>load</code> <code>bool</code> <p>if True, load the matched entry point and return the loaded resource instead of the entry point itself.</p> <code>True</code> <code>entry_point_group</code> <code>str</code> <p>the optional entry point group to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[EntryPoint, Type[PretrainedMolTransformer], Callable]</code> <p>sub class or module of</p> Raise <p>InvalidEntryPointTypeError: if the type of the loaded entry point is invalid.</p> Source code in <code>molfeat/plugins/factories.py</code> <pre><code>def DefaultFactory(\n    entry_point_name: str,\n    load: bool = True,\n    entry_point_group: str = None,\n) -&gt; Union[EntryPoint, Type[\"PretrainedMolTransformer\"], Callable]:\n    \"\"\"Return the Default factory for extending capabilities given a specific module.\n\n    Args:\n        entry_point_name: the entry point name.\n        load: if True, load the matched entry point and return the loaded resource instead of the entry point itself.\n        entry_point_group: the optional entry point group to use\n\n    Returns:\n        sub class or module of\n\n    Raise:\n        InvalidEntryPointTypeError: if the type of the loaded entry point is invalid.\n    \"\"\"\n\n    if entry_point_group is None:\n        entry_point_group = \"molfeat\"\n    entry_point = BaseFactory(entry_point_group, entry_point_name, load=load)\n\n    if not load:\n        return entry_point\n    # if the entry point is a module, nothing to do\n    if ismodule(entry_point):\n        return entry_point\n    raise_invalid_type_error(entry_point_name, entry_point_group, ())\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.factories.PretrainedTransformerFactory","title":"<code>PretrainedTransformerFactory(entry_point_name, load=True, entry_point_group=None)</code>","text":"<pre><code>PretrainedTransformerFactory(\n    entry_point_name: str,\n    load: Literal[True] = True,\n    entry_point_group: Optional[str] = None,\n) -&gt; Union[Type[PretrainedMolTransformer], Callable]\n</code></pre><pre><code>PretrainedTransformerFactory(\n    entry_point_name: str, load: Literal[False]\n) -&gt; EntryPoint\n</code></pre> <p>Return the PretrainedMolTransformer sub class registered under the given entry point.</p> <p>Parameters:</p> Name Type Description Default <code>entry_point_name</code> <code>str</code> <p>the entry point name.</p> required <code>load</code> <code>bool</code> <p>if True, load the matched entry point and return the loaded resource instead of the entry point itself.</p> <code>True</code> <code>entry_point_group</code> <code>Optional[str]</code> <p>the optional entry point group to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[EntryPoint, Type[PretrainedMolTransformer], Callable]</code> <p>sub class of class:<code>~molfeat.trans.pretrained.PretrainedMolTransformer</code></p> Raise <p>InvalidEntryPointTypeError: if the type of the loaded entry point is invalid.</p> Source code in <code>molfeat/plugins/factories.py</code> <pre><code>def PretrainedTransformerFactory(\n    entry_point_name: str,\n    load: bool = True,\n    entry_point_group: Optional[str] = None,\n) -&gt; Union[EntryPoint, Type[\"PretrainedMolTransformer\"], Callable]:\n    \"\"\"Return the PretrainedMolTransformer sub class registered under the given entry point.\n\n    Args:\n        entry_point_name: the entry point name.\n        load: if True, load the matched entry point and return the loaded resource instead of the entry point itself.\n        entry_point_group: the optional entry point group to use\n\n    Returns:\n        sub class of :py:class:`~molfeat.trans.pretrained.PretrainedMolTransformer`\n\n    Raise:\n        InvalidEntryPointTypeError: if the type of the loaded entry point is invalid.\n    \"\"\"\n    from molfeat.trans import MoleculeTransformer\n    from molfeat.trans.pretrained import PretrainedMolTransformer\n\n    if entry_point_group is None:\n        entry_point_group = \"molfeat.trans.pretrained\"\n    entry_point = BaseFactory(entry_point_group, entry_point_name, load=load)\n    valid_classes = (PretrainedMolTransformer, MoleculeTransformer)\n\n    if not load:\n        return entry_point\n    # if the entry point is a module, nothing to do\n    if ismodule(entry_point):\n        return entry_point\n    if isclass(entry_point) and issubclass(entry_point, valid_classes):\n        return entry_point\n\n    raise_invalid_type_error(entry_point_name, entry_point_group, valid_classes)\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.factories.TransformerFactory","title":"<code>TransformerFactory(entry_point_name, load=True, entry_point_group=None)</code>","text":"<pre><code>TransformerFactory(\n    entry_point_name: str,\n    load: Literal[True] = True,\n    entry_point_group: Optional[str] = None,\n) -&gt; Union[Type[MoleculeTransformer], Callable]\n</code></pre><pre><code>TransformerFactory(\n    entry_point_name: str,\n    load: Literal[False],\n    entry_point_group: Optional[str] = None,\n) -&gt; EntryPoint\n</code></pre> <p>Return the <code>MoleculeTransformer</code> sub class registered under the given entry point.</p> <p>Parameters:</p> Name Type Description Default <code>entry_point_name</code> <code>str</code> <p>the entry point name.</p> required <code>load</code> <code>bool</code> <p>if True, load the matched entry point and return the loaded resource instead of the entry point itself.</p> <code>True</code> <code>entry_point_group</code> <code>Optional[str]</code> <p>the optional entry point group to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[EntryPoint, Type[MoleculeTransformer], Callable]</code> <p>sub class of class:<code>~molfeat.trans.MoleculeTransformer</code></p> Raise <p>InvalidEntryPointTypeError: if the type of the loaded entry point is invalid.</p> Source code in <code>molfeat/plugins/factories.py</code> <pre><code>def TransformerFactory(\n    entry_point_name: str,\n    load: bool = True,\n    entry_point_group: Optional[str] = None,\n) -&gt; Union[EntryPoint, Type[\"MoleculeTransformer\"], Callable]:\n    \"\"\"Return the `MoleculeTransformer` sub class registered under the given entry point.\n\n    Args:\n        entry_point_name: the entry point name.\n        load: if True, load the matched entry point and return the loaded resource instead of the entry point itself.\n        entry_point_group: the optional entry point group to use\n\n    Returns:\n        sub class of :py:class:`~molfeat.trans.MoleculeTransformer`\n\n    Raise:\n        InvalidEntryPointTypeError: if the type of the loaded entry point is invalid.\n    \"\"\"\n    from molfeat.trans import MoleculeTransformer\n    from molfeat.trans import BaseFeaturizer\n\n    if entry_point_group is None:\n        entry_point_group = \"molfeat.trans\"\n    entry_point = BaseFactory(entry_point_group, entry_point_name, load=load)\n    valid_classes = (MoleculeTransformer, BaseFeaturizer)\n\n    if not load:\n        return entry_point\n\n    # if the entry point is a module, nothing to do\n    if ismodule(entry_point):\n        return entry_point\n    if isclass(entry_point) and issubclass(entry_point, valid_classes):\n        return entry_point\n\n    raise_invalid_type_error(entry_point_name, entry_point_group, valid_classes)\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.factories.raise_invalid_type_error","title":"<code>raise_invalid_type_error(entry_point_name, entry_point_group, valid_classes)</code>","text":"<p>Raise an <code>InvalidEntryPointTypeError</code> with formatted message.</p> <p>Parameters:</p> Name Type Description Default <code>entry_point_name</code> <code>str</code> <p>name of the entry point</p> required <code>entry_point_group</code> <code>str</code> <p>name of the entry point group</p> required <code>valid_classes</code> <code>Tuple[Any, ...]</code> <p>tuple of valid classes for the given entry point group</p> required <p>Raises:</p> Type Description <code>InvalidEntryPointTypeError</code> <p>always</p> Source code in <code>molfeat/plugins/factories.py</code> <pre><code>def raise_invalid_type_error(\n    entry_point_name: str, entry_point_group: str, valid_classes: Tuple[Any, ...]\n) -&gt; NoReturn:\n    \"\"\"Raise an `InvalidEntryPointTypeError` with formatted message.\n\n    Args:\n        entry_point_name: name of the entry point\n        entry_point_group: name of the entry point group\n        valid_classes: tuple of valid classes for the given entry point group\n\n    Raises:\n        InvalidEntryPointTypeError: always\n    \"\"\"\n    template = \"entry point `{}` registered in group `{}` is invalid because its type is not one of the supported types ({})\"\n    args = (\n        entry_point_name,\n        entry_point_group,\n        \", \".join([e.__name__ for e in valid_classes]),\n    )\n    raise InvalidEntryPointTypeError(template.format(*args))\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.entry_point.get_entry_point","title":"<code>get_entry_point(group, name)</code>","text":"<p>Return an entry point with a given name within a specific group Args:     group: the entry point group     name: the name of the entry point</p> Source code in <code>molfeat/plugins/entry_point.py</code> <pre><code>def get_entry_point(group: str, name: str) -&gt; EntryPoint:\n    \"\"\"\n    Return an entry point with a given name within a specific group\n    Args:\n        group: the entry point group\n        name: the name of the entry point\n    \"\"\"\n    found = eps().select(group=group, name=name)\n    if name not in found.names:\n        raise MissingEntryPointError(f\"Entry point '{name}' not found in group '{group}'\")\n    # If multiple entry points are found and they have different values we raise, otherwise if they all\n    # correspond to the same value, we simply return one of them\n    if len(found) &gt; 1 and len(set(ep.value for ep in found)) != 1:\n        raise MultipleEntryPointError(\n            f\"Multiple entry points '{name}' found in group '{group}': {found}\"\n        )\n    return found[name]\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.entry_point.get_entry_points","title":"<code>get_entry_points(group)</code>","text":"<p>Return a list of all the entry points within a specific group</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>the entry point group</p> required <p>Returns:</p> Type Description <p>a list of entry points</p> Source code in <code>molfeat/plugins/entry_point.py</code> <pre><code>def get_entry_points(group: str):\n    \"\"\"\n    Return a list of all the entry points within a specific group\n\n    Args:\n        group: the entry point group\n\n    Returns:\n        a list of entry points\n    \"\"\"\n    return eps().select(group=group)\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.entry_point.is_registered_entry_point","title":"<code>is_registered_entry_point(class_module, class_name, groups=None)</code>  <code>cached</code>","text":"<p>Verify whether the class with the given module and class name is a registered entry point.</p> <p>Note</p> <p>This function only checks whether the class has a registered entry point. It does explicitly not verify if the corresponding class is also importable. Use <code>load_entry_point</code> for this purpose instead.</p> <p>Parameters:</p> Name Type Description Default <code>class_module</code> <code>str</code> <p>the module of the class</p> required <code>class_name</code> <code>str</code> <p>the name of the class</p> required <code>groups</code> <code>Optional[Sequence[str]]</code> <p>optionally consider only these entry point groups to look for the class</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the class is a registered entry point, False otherwise.</p> Source code in <code>molfeat/plugins/entry_point.py</code> <pre><code>@functools.lru_cache(maxsize=100)\ndef is_registered_entry_point(\n    class_module: str, class_name: str, groups: Optional[Sequence[str]] = None\n) -&gt; bool:\n    \"\"\"Verify whether the class with the given module and class name is a registered entry point.\n\n    !!! note\n        This function only checks whether the class has a registered entry point. It does explicitly not verify\n        if the corresponding class is also importable. Use `load_entry_point` for this purpose instead.\n\n    Args:\n        class_module: the module of the class\n        class_name: the name of the class\n        groups: optionally consider only these entry point groups to look for the class\n\n    Returns:\n        True if the class is a registered entry point, False otherwise.\n    \"\"\"\n    for group in eps().groups if groups is None else groups:\n        for entry_point in get_entry_points(group):\n            if class_module == entry_point.module and class_name == entry_point.attr:\n                return True\n    return False\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.entry_point.load_entry_point","title":"<code>load_entry_point(group, name)</code>","text":"<p>Load the class registered under the entry point for a given name and group</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str</code> <p>the entry point group</p> required <code>name</code> <code>str</code> <p>the name of the entry point</p> required <p>Returns:</p> Type Description <code>Any</code> <p>class registered at the given entry point</p> <p>Raises:</p> Type Description <code>MissingEntryPointError</code> <p>if the entry point was not registered</p> <code>MultipleEntryPointError</code> <p>if the entry point could not be uniquely resolved</p> <code>LoadingEntryPointError</code> <p>if the entry point could not be loaded</p> Source code in <code>molfeat/plugins/entry_point.py</code> <pre><code>def load_entry_point(group: str, name: str) -&gt; Any:\n    \"\"\"\n    Load the class registered under the entry point for a given name and group\n\n    Args:\n        group: the entry point group\n        name: the name of the entry point\n\n    Returns:\n        class registered at the given entry point\n\n    Raises:\n        MissingEntryPointError: if the entry point was not registered\n        MultipleEntryPointError: if the entry point could not be uniquely resolved\n        LoadingEntryPointError: if the entry point could not be loaded\n    \"\"\"\n    entry_point = get_entry_point(group, name)\n\n    try:\n        loaded_entry_point = entry_point.load()\n    except ImportError:\n        raise LoadingEntryPointError(\n            f\"Failed to load entry point '{name}':\\n{traceback.format_exc()}\"\n        )\n\n    return loaded_entry_point\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.entry_point.load_registered_plugins","title":"<code>load_registered_plugins(add_submodules=True, groups=None, plugins=None, verbose=True)</code>","text":"<p>Load all registered entry points by loading them with the corresponding factory and adding them to the corresponding module attribute.</p> <p>Parameters:</p> Name Type Description Default <code>add_submodules</code> <code>bool</code> <p>if True, add the loaded entry point to the corresponding module attribute.</p> <code>True</code> <code>groups</code> <code>Optional[List[str]]</code> <p>if provided, only load entry points from the given groups.</p> <code>None</code> <code>plugins</code> <code>Optional[List[str]]</code> <p>if provided, only load entry points or modules/classes that matches entry in the plugins list.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>if True, log a warning if an entry point cannot be loaded.</p> <code>True</code> <p>Raises:</p> Type Description <code>EntryPointError</code> <p>if any of the registered entry points cannot be loaded. This can happen if: * The entry point cannot uniquely be resolved * The resource registered at the entry point cannot be imported * The resource's type is incompatible with the entry point group that it is defined in.</p> Source code in <code>molfeat/plugins/entry_point.py</code> <pre><code>def load_registered_plugins(\n    add_submodules: bool = True,\n    groups: Optional[List[str]] = None,\n    plugins: Optional[List[str]] = None,\n    verbose: bool = True,\n):\n    \"\"\"Load all registered entry points by loading them with the corresponding factory and adding them to the corresponding module attribute.\n\n    Args:\n        add_submodules: if True, add the loaded entry point to the corresponding module attribute.\n        groups: if provided, only load entry points from the given groups.\n        plugins: if provided, only load entry points or modules/classes that matches entry in the plugins list.\n        verbose: if True, log a warning if an entry point cannot be loaded.\n\n    Raises:\n        EntryPointError: if any of the registered entry points cannot be loaded. This can happen if:\n            * The entry point cannot uniquely be resolved\n            * The resource registered at the entry point cannot be imported\n            * The resource's type is incompatible with the entry point group that it is defined in.\n    \"\"\"\n    for entry_point_group, factory in ENTRY_POINT_GROUP_FACTORYCLASS_MAPPING.items():\n        if groups is not None and entry_point_group not in groups:\n            continue\n        entry_points = get_entry_points(entry_point_group)\n        for entry_point in entry_points:\n            try:\n                loaded_module = factory(entry_point.name, entry_point_group=entry_point_group)\n                if _is_valid_plugin(loaded_module, plugins):\n                    setattr(\n                        sys.modules[entry_point.group],\n                        loaded_module.__name__,\n                        loaded_module,\n                    )\n                    if add_submodules:\n                        if not ismodule(loaded_module):\n                            module_to_add = loaded_module.__module__\n                        else:\n                            module_to_add = loaded_module\n                        sys.modules[f\"{entry_point.group}.{entry_point.name}\"] = module_to_add\n            except AttributeError as e:\n                if verbose:\n                    logger.warning(\n                        f\"Could not load entry point {entry_point.name} from group {entry_point.group}\"\n                    )\n                    logger.exception(e)\n</code></pre>"},{"location":"api/molfeat.plugins.html#molfeat.plugins.entry_point.validate_registered_entry_points","title":"<code>validate_registered_entry_points()</code>","text":"<p>Validate all registered entry points by loading them with the corresponding factory.</p> <p>Raises:</p> Type Description <code>EntryPointError</code> <p>if any of the registered entry points cannot be loaded. This can happen if: * The entry point cannot uniquely be resolved * The resource registered at the entry point cannot be imported * The resource's type is incompatible with the entry point group that it is defined in.</p> Source code in <code>molfeat/plugins/entry_point.py</code> <pre><code>def validate_registered_entry_points():\n    \"\"\"Validate all registered entry points by loading them with the corresponding factory.\n\n    Raises:\n        EntryPointError: if any of the registered entry points cannot be loaded. This can happen if:\n            * The entry point cannot uniquely be resolved\n            * The resource registered at the entry point cannot be imported\n            * The resource's type is incompatible with the entry point group that it is defined in.\n    \"\"\"\n    for entry_point_group, factory in ENTRY_POINT_GROUP_FACTORYCLASS_MAPPING.items():\n        entry_points = get_entry_points(entry_point_group)\n        for entry_point in entry_points:\n            factory(entry_point.name)\n</code></pre>"},{"location":"api/molfeat.store.html","title":"<code>molfeat.store</code>","text":""},{"location":"api/molfeat.store.html#molfeat.store.modelcard.ModelInfo","title":"<code>ModelInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>molfeat/store/modelcard.py</code> <pre><code>class ModelInfo(BaseModel):\n    model_config = ConfigDict(\n        protected_namespaces=(\n            \"protected_\",\n        )  # Prevents warning from usage of model_ prefix in fields\n    )\n\n    name: str\n    inputs: str = \"smiles\"\n    type: Literal[\"pretrained\", \"hand-crafted\", \"hashed\", \"count\"]\n    version: int = 0\n    group: Optional[str] = \"all\"\n    submitter: str\n    description: str\n    representation: Literal[\"graph\", \"line-notation\", \"vector\", \"tensor\", \"other\"]\n    require_3D: Optional[bool] = False\n    tags: Optional[List[str]] = []\n    authors: Optional[List[str]]\n    reference: Optional[str] = None\n    created_at: datetime = Field(default_factory=datetime.now)\n    sha256sum: Optional[str] = None\n    model_usage: Optional[str] = None\n\n    def path(self, root_path: str):\n        \"\"\"Generate the folder path where to save this model\n\n        Args:\n            root_path: path to the root folder\n        \"\"\"\n        version = str(self.version or 0)\n        return dm.fs.join(root_path, self.group, self.name, version)\n\n    def match(self, new_card: Union[\"ModelInfo\", dict], match_only: Optional[List[str]] = None):\n        \"\"\"Compare two model card information and returns True if they are the same\n\n        Args:\n            new_card: card to search for in the modelstore\n            match_only: list of minimum attribute that should match between the two model information\n        \"\"\"\n\n        self_content = self.model_dump().copy()\n        if not isinstance(new_card, dict):\n            new_card = new_card.model_dump()\n        new_content = new_card.copy()\n        # we always remove the datetime field\n        self_content.pop(\"created_at\", None)\n        new_content.pop(\"created_at\", None)\n        if match_only is not None:\n            self_content = {k: self_content.get(k) for k in match_only}\n            new_content = {k: new_content.get(k) for k in match_only}\n        return self_content == new_content\n\n    def set_usage(self, usage: str):\n        \"\"\"Set the usage of the model\n\n        Args:\n            usage: usage of the model\n        \"\"\"\n        self.model_usage = usage\n\n    def usage(self):\n        \"\"\"Return the usage of the model\"\"\"\n        if self.model_usage is not None and self.model_usage:\n            return self.model_usage\n        import_statement, loader_statement = get_model_init(self)\n        comment = \"# sanitize and standardize your molecules if needed\"\n        if self.require_3D:\n            comment += \"\\n# &lt;generate 3D coordinates here&gt; \"\n        usage = f\"\"\"\n        import datamol as dm\n        {import_statement}\n        smiles = dm.freesolv().iloc[:100].smiles\n        {comment}\n        transformer = {loader_statement}\n        features = transformer(smiles)\n        \"\"\"\n        usage = \"\\n\".join([x.strip() for x in usage.split(\"\\n\")])\n        return usage\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelcard.ModelInfo.match","title":"<code>match(new_card, match_only=None)</code>","text":"<p>Compare two model card information and returns True if they are the same</p> <p>Parameters:</p> Name Type Description Default <code>new_card</code> <code>Union[ModelInfo, dict]</code> <p>card to search for in the modelstore</p> required <code>match_only</code> <code>Optional[List[str]]</code> <p>list of minimum attribute that should match between the two model information</p> <code>None</code> Source code in <code>molfeat/store/modelcard.py</code> <pre><code>def match(self, new_card: Union[\"ModelInfo\", dict], match_only: Optional[List[str]] = None):\n    \"\"\"Compare two model card information and returns True if they are the same\n\n    Args:\n        new_card: card to search for in the modelstore\n        match_only: list of minimum attribute that should match between the two model information\n    \"\"\"\n\n    self_content = self.model_dump().copy()\n    if not isinstance(new_card, dict):\n        new_card = new_card.model_dump()\n    new_content = new_card.copy()\n    # we always remove the datetime field\n    self_content.pop(\"created_at\", None)\n    new_content.pop(\"created_at\", None)\n    if match_only is not None:\n        self_content = {k: self_content.get(k) for k in match_only}\n        new_content = {k: new_content.get(k) for k in match_only}\n    return self_content == new_content\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelcard.ModelInfo.path","title":"<code>path(root_path)</code>","text":"<p>Generate the folder path where to save this model</p> <p>Parameters:</p> Name Type Description Default <code>root_path</code> <code>str</code> <p>path to the root folder</p> required Source code in <code>molfeat/store/modelcard.py</code> <pre><code>def path(self, root_path: str):\n    \"\"\"Generate the folder path where to save this model\n\n    Args:\n        root_path: path to the root folder\n    \"\"\"\n    version = str(self.version or 0)\n    return dm.fs.join(root_path, self.group, self.name, version)\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelcard.ModelInfo.set_usage","title":"<code>set_usage(usage)</code>","text":"<p>Set the usage of the model</p> <p>Parameters:</p> Name Type Description Default <code>usage</code> <code>str</code> <p>usage of the model</p> required Source code in <code>molfeat/store/modelcard.py</code> <pre><code>def set_usage(self, usage: str):\n    \"\"\"Set the usage of the model\n\n    Args:\n        usage: usage of the model\n    \"\"\"\n    self.model_usage = usage\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelcard.ModelInfo.usage","title":"<code>usage()</code>","text":"<p>Return the usage of the model</p> Source code in <code>molfeat/store/modelcard.py</code> <pre><code>def usage(self):\n    \"\"\"Return the usage of the model\"\"\"\n    if self.model_usage is not None and self.model_usage:\n        return self.model_usage\n    import_statement, loader_statement = get_model_init(self)\n    comment = \"# sanitize and standardize your molecules if needed\"\n    if self.require_3D:\n        comment += \"\\n# &lt;generate 3D coordinates here&gt; \"\n    usage = f\"\"\"\n    import datamol as dm\n    {import_statement}\n    smiles = dm.freesolv().iloc[:100].smiles\n    {comment}\n    transformer = {loader_statement}\n    features = transformer(smiles)\n    \"\"\"\n    usage = \"\\n\".join([x.strip() for x in usage.split(\"\\n\")])\n    return usage\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelcard.get_model_init","title":"<code>get_model_init(card)</code>","text":"<p>Get the model initialization code</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <p>model card to use</p> required Source code in <code>molfeat/store/modelcard.py</code> <pre><code>def get_model_init(card):\n    \"\"\"Get the model initialization code\n\n    Args:\n        card: model card to use\n    \"\"\"\n    if card.group == \"all\" and card.type != \"pretrained\":\n        import_statement = \"from molfeat.trans import MoleculeTransformer\"\n        loader_statement = f\"MoleculeTransformer(featurizer='{card.name}', dtype=float)\"\n    elif card.group in [\"rdkit\", \"fp\", \"shape\"]:\n        import_statement = \"from molfeat.trans.fp import FPVecTransformer\"\n        loader_statement = f\"FPVecTransformer(kind='{card.name}', dtype=float)\"\n    elif card.group == \"dgllife\":\n        import_statement = \"from molfeat.trans.pretrained import PretrainedDGLTransformer\"\n        loader_statement = f\"PretrainedDGLTransformer(kind='{card.name}', dtype=float)\"\n    elif card.group == \"graphormer\":\n        import_statement = \"from molfeat.trans.pretrained import GraphormerTransformer\"\n        loader_statement = f\"GraphormerTransformer(kind='{card.name}', dtype=float)\"\n    elif card.group == \"fcd\":\n        import_statement = \"from molfeat.trans.pretrained import FCDTransformer\"\n        loader_statement = \"FCDTransformer()\"\n    elif card.group == \"pharmacophore\":\n        name = card.name.split(\"-\")[-1]\n        if card.require_3D:\n            import_class = \"Pharmacophore3D\"\n        else:\n            import_class = \"Pharmacophore2D\"\n        import_statement = f\"from molfeat.trans.base import MoleculeTransformer\\nfrom molfeat.calc.pharmacophore import {import_class}\"\n        loader_statement = (\n            f\"MoleculeTransformer(featurizer={import_class}(factory='{name}'), dtype=float)\"\n        )\n    elif card.group == \"huggingface\":\n        import_statement = (\n            \"from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\"\n        )\n        loader_statement = (\n            f\"PretrainedHFTransformer(kind='{card.name}', notation='{card.inputs}', dtype=float)\"\n        )\n    else:\n        raise ValueError(f\"Unknown model group {card.group}\")\n    return import_statement, loader_statement\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.InMemoryModelStore","title":"<code>InMemoryModelStore</code>","text":"<p>               Bases: <code>ModelStore</code></p> <p>A class for loading models directly into memory from ModelStore</p> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>class InMemoryModelStore(ModelStore):\n    \"\"\"A class for loading models directly into memory from ModelStore\"\"\"\n\n    def download(\n        self,\n        modelcard: ModelInfo,\n    ) -&gt; Dict[str, io.BytesIO]:\n        \"\"\"Download an artifact into memory\n\n        Args:\n            modelcard: information on the model to download\n\n        Returns:\n            A dictionary with file names as keys and file-like objects as values.\n        \"\"\"\n        remote_dir = modelcard.path(self.model_store_bucket)\n        model_name = modelcard.name\n        if not self.exists(modelcard, check_remote=True):\n            raise ModelStoreError(f\"Model {model_name} does not exist in the model store!\")\n\n        model_remote_path = dm.fs.join(remote_dir, self.MODEL_PATH_NAME)\n        metadata_remote_path = dm.fs.join(remote_dir, self.METADATA_PATH_NAME)\n\n        model_data = {}\n\n        # Download metadata\n        with fsspec.open(metadata_remote_path, \"rb\") as IN:\n            model_data[self.METADATA_PATH_NAME] = io.BytesIO(IN.read())\n\n        # Download model\n        with fsspec.open(model_remote_path, \"rb\") as IN:\n            model_data[self.MODEL_PATH_NAME] = io.BytesIO(IN.read())\n\n        return model_data\n\n    def load(\n        self,\n        model_name: Union[str, dict, ModelInfo],\n        load_fn: Optional[Callable] = None,\n        load_fn_kwargs: Optional[dict] = None,\n    ):\n        \"\"\"\n        Load a model by its name\n\n        Args:\n            model_name: name of the model to load\n            load_fn: Custom loading function to load the model\n            load_fn_kwargs: Optional dict of additional kwargs to provide to the loading function\n\n        Returns:\n            model: Optional model, if the model requires download or loading weights\n            model_info: model information card\n        \"\"\"\n        if isinstance(model_name, str):\n            modelcard = self.search(name=model_name)[0]\n        else:\n            modelcard = model_name\n\n        model_data = self.download(\n            modelcard=modelcard,\n        )\n        if load_fn is None:\n            load_fn = joblib.load\n        model = None\n        load_fn_kwargs = load_fn_kwargs or {}\n        if self.MODEL_PATH_NAME in model_data:\n            model = load_fn(model_data[self.MODEL_PATH_NAME], **load_fn_kwargs)\n        model_info_dict = yaml.safe_load(model_data[self.METADATA_PATH_NAME])\n        model_info = ModelInfo(**model_info_dict)\n        return model, model_info\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.InMemoryModelStore.download","title":"<code>download(modelcard)</code>","text":"<p>Download an artifact into memory</p> <p>Parameters:</p> Name Type Description Default <code>modelcard</code> <code>ModelInfo</code> <p>information on the model to download</p> required <p>Returns:</p> Type Description <code>Dict[str, BytesIO]</code> <p>A dictionary with file names as keys and file-like objects as values.</p> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def download(\n    self,\n    modelcard: ModelInfo,\n) -&gt; Dict[str, io.BytesIO]:\n    \"\"\"Download an artifact into memory\n\n    Args:\n        modelcard: information on the model to download\n\n    Returns:\n        A dictionary with file names as keys and file-like objects as values.\n    \"\"\"\n    remote_dir = modelcard.path(self.model_store_bucket)\n    model_name = modelcard.name\n    if not self.exists(modelcard, check_remote=True):\n        raise ModelStoreError(f\"Model {model_name} does not exist in the model store!\")\n\n    model_remote_path = dm.fs.join(remote_dir, self.MODEL_PATH_NAME)\n    metadata_remote_path = dm.fs.join(remote_dir, self.METADATA_PATH_NAME)\n\n    model_data = {}\n\n    # Download metadata\n    with fsspec.open(metadata_remote_path, \"rb\") as IN:\n        model_data[self.METADATA_PATH_NAME] = io.BytesIO(IN.read())\n\n    # Download model\n    with fsspec.open(model_remote_path, \"rb\") as IN:\n        model_data[self.MODEL_PATH_NAME] = io.BytesIO(IN.read())\n\n    return model_data\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.InMemoryModelStore.load","title":"<code>load(model_name, load_fn=None, load_fn_kwargs=None)</code>","text":"<p>Load a model by its name</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>Union[str, dict, ModelInfo]</code> <p>name of the model to load</p> required <code>load_fn</code> <code>Optional[Callable]</code> <p>Custom loading function to load the model</p> <code>None</code> <code>load_fn_kwargs</code> <code>Optional[dict]</code> <p>Optional dict of additional kwargs to provide to the loading function</p> <code>None</code> <p>Returns:</p> Name Type Description <code>model</code> <p>Optional model, if the model requires download or loading weights</p> <code>model_info</code> <p>model information card</p> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def load(\n    self,\n    model_name: Union[str, dict, ModelInfo],\n    load_fn: Optional[Callable] = None,\n    load_fn_kwargs: Optional[dict] = None,\n):\n    \"\"\"\n    Load a model by its name\n\n    Args:\n        model_name: name of the model to load\n        load_fn: Custom loading function to load the model\n        load_fn_kwargs: Optional dict of additional kwargs to provide to the loading function\n\n    Returns:\n        model: Optional model, if the model requires download or loading weights\n        model_info: model information card\n    \"\"\"\n    if isinstance(model_name, str):\n        modelcard = self.search(name=model_name)[0]\n    else:\n        modelcard = model_name\n\n    model_data = self.download(\n        modelcard=modelcard,\n    )\n    if load_fn is None:\n        load_fn = joblib.load\n    model = None\n    load_fn_kwargs = load_fn_kwargs or {}\n    if self.MODEL_PATH_NAME in model_data:\n        model = load_fn(model_data[self.MODEL_PATH_NAME], **load_fn_kwargs)\n    model_info_dict = yaml.safe_load(model_data[self.METADATA_PATH_NAME])\n    model_info = ModelInfo(**model_info_dict)\n    return model, model_info\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore","title":"<code>ModelStore</code>","text":"<p>A class for artefact serializing from any url</p> <p>This class not only allow pretrained model serializing and loading, but also help in listing model availability and registering models.</p> <p>For simplicity.     * There is no versioning.     * Only one model should match a given name     * Model deletion is not allowed (on the read-only default store)     * Only a single store is supported per model store instance</p> <p>Building a New Model Store</p> <p>To create a new model store, you will mainly need a model store bucket path. The default model store bucket, located at <code>gs://molfeat-store-prod/artifacts/</code>, is read-only.</p> <p>To build your own model store bucket, follow the instructions below:</p> <ol> <li>Create a local or remote cloud directory that can be accessed by fsspec (and the corresponding filesystem).</li> <li>[Optional] Sync the default model store bucket to your new path if you want to access the default models.</li> <li>Set the environment variable <code>MOLFEAT_MODEL_STORE_BUCKET</code> to your new path. This variable will be used as the default model store bucket when creating a new model store instance without specifying a path.     Note that setting up this path is necessary if you want to access models directly by their names, without manually loading them from your custom model store.</li> </ol> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>class ModelStore:\n    \"\"\"A class for artefact serializing from any url\n\n    This class not only allow pretrained model serializing and loading,\n    but also help in listing model availability and registering models.\n\n    For simplicity.\n        * There is no versioning.\n        * Only one model should match a given name\n        * Model deletion is not allowed (on the read-only default store)\n        * Only a single store is supported per model store instance\n\n    !!! note \"Building a New Model Store\"\n        To create a new model store, you will mainly need a model store bucket path. The default model store bucket, located at `gs://molfeat-store-prod/artifacts/`, is **read-only**.\n\n        To build your own model store bucket, follow the instructions below:\n\n        1. Create a local or remote cloud directory that can be accessed by fsspec (and the corresponding filesystem).\n        2. [Optional] Sync the default model store bucket to your new path if you want to access the default models.\n        3. Set the environment variable `MOLFEAT_MODEL_STORE_BUCKET` to your new path. This variable will be used as the default model store bucket when creating a new model store instance without specifying a path.\n            Note that setting up this path is necessary if you want to access models directly by their names, without manually loading them from your custom model store.\n\n\n    \"\"\"\n\n    # EN: be careful not to recreate ada\n    # EN: should we just use modelstore ?\n    MODEL_STORE_BUCKET = \"gs://molfeat-store-prod/artifacts/\"\n    MODEL_PATH_NAME = \"model.save\"\n    METADATA_PATH_NAME = \"metadata.json\"\n\n    def __init__(self, model_store_bucket: Optional[str] = None):\n        if model_store_bucket is None:\n            model_store_bucket = os.getenv(\"MOLFEAT_MODEL_STORE_BUCKET\", self.MODEL_STORE_BUCKET)\n        self.model_store_bucket = model_store_bucket\n        self._available_models = []\n        self._update_store()\n\n    def _update_store(self):\n        \"\"\"Initialize the store with all available models\"\"\"\n        all_metadata = dm.fs.glob(dm.fs.join(self.model_store_bucket, \"**/metadata.json\"))\n        self._available_models = []\n        for mtd_file in all_metadata:\n            with fsspec.open(mtd_file, \"r\") as IN:\n                mtd_content = yaml.safe_load(IN)\n                model_info = ModelInfo(**mtd_content)\n                self._available_models.append(model_info)\n\n    @property\n    def available_models(self):\n        \"\"\"Return a list of all models that have been serialized in molfeat\"\"\"\n        return self._available_models\n\n    def __len__(self):\n        \"\"\"Return the length of the model store\"\"\"\n        return len(self.available_models)\n\n    def register(\n        self,\n        modelcard: Union[ModelInfo, dict],\n        model: Optional[Any] = None,\n        chunk_size: int = 2048,\n        save_fn: Optional[Callable] = None,\n        save_fn_kwargs: Optional[dict] = None,\n        force: bool = True,\n    ):\n        \"\"\"\n        Register a new model to the store\n\n        !!! note `save_fn`\n            You can pass additional kwargs for your `save_fn` through the `save_fn_kwargs` argument.\n            It's expected that `save_fn` will be called as : `save_fn(model, &lt;model_upload_path&gt;, **save_fn_wargs)`,\n            with `&lt;model_upload_path&gt;` being provided by the model store, and that it will return the path to the serialized model.\n            If not provided, `joblib.dump` is used by default.\n\n        Args:\n            modelcard: Model information\n            model: A path to the model artifact or any object that needs to be saved\n            chunk_size: the chunk size for the upload\n            save_fn: any custom function for serializing the model, that takes the model, the upload path and parameters `save_fn_kwargs` as inputs.\n            save_fn_kwargs: any additional kwargs to pass to save_fn\n            force: whether to force upload to the bucket\n\n        \"\"\"\n        if not isinstance(modelcard, ModelInfo):\n            modelcard = ModelInfo(**modelcard)\n        # we save the model first\n        if self.exists(card=modelcard):\n            logger.warning(f\"Model {modelcard.name} exists already ...\")\n            if not force:\n                return\n\n        model_root_dir = modelcard.path(self.model_store_bucket)\n        model_path = model\n        model_upload_path = dm.fs.join(model_root_dir, self.MODEL_PATH_NAME)\n        model_metadata_upload_path = dm.fs.join(model_root_dir, self.METADATA_PATH_NAME)\n\n        save_fn_kwargs = save_fn_kwargs or {}\n        if save_fn is None:\n            if not isinstance(model, (pathlib.Path, os.PathLike)):\n                local_model_path = tempfile.NamedTemporaryFile(delete=False)\n                with local_model_path:\n                    joblib.dump(model, local_model_path)\n                model_path = local_model_path.name\n            # Upload the artifact to the bucket\n            dm.fs.copy_file(\n                model_path,\n                model_upload_path,\n                progress=True,\n                leave_progress=False,\n                chunk_size=chunk_size,\n                force=force,\n            )\n        else:\n            model_path = save_fn(model, model_upload_path, **save_fn_kwargs)\n            # we reset to None if the save_fn has not returned anything\n            model_path = model_path or model_upload_path\n        modelcard.sha256sum = commons.sha256sum(model_path)\n        # then we save the metadata as json\n        with fsspec.open(model_metadata_upload_path, \"w\") as OUT:\n            OUT.write(modelcard.json())\n        self._update_store()\n        logger.info(f\"Successfuly registered model {modelcard.name} !\")\n\n    def _filelock(self, lock_name: str):\n        \"\"\"Create an empty lock file into `cache_dir_path/locks/lock_name`\"\"\"\n\n        lock_path = dm.fs.join(\n            str(platformdirs.user_cache_dir(\"molfeat\")), \"_lock_files\", lock_name\n        )\n        dm.fs.get_mapper(lock_path)\n        # ensure file is created\n        # out = mapper.fs.touch(lock_path) # does not work  -_-\n        with fsspec.open(lock_path, \"w\", auto_mkdir=True):\n            pass\n\n        return filelock.FileLock(lock_path)\n\n    def download(\n        self,\n        modelcard: ModelInfo,\n        output_dir: Optional[Union[os.PathLike, pathlib.Path]] = None,\n        chunk_size: int = 2048,\n        force: bool = False,\n    ):\n        \"\"\"Download an artifact locally\n\n        Args:\n            modelcard: information on the model to download\n            output_dir: path where to save the downloaded artifact\n            chunk_size: chunk size to use for download\n            force: whether to force download even if the file exists already\n        \"\"\"\n\n        remote_dir = modelcard.path(self.model_store_bucket)\n        model_name = modelcard.name\n        if not self.exists(modelcard, check_remote=True):\n            raise ModelStoreError(f\"Model {model_name} does not exist in the model store !\")\n\n        if output_dir is None:\n            output_dir = dm.fs.join(platformdirs.user_cache_dir(\"molfeat\"), model_name)\n\n        dm.fs.mkdir(output_dir, exist_ok=True)\n\n        model_remote_path = dm.fs.join(remote_dir, self.MODEL_PATH_NAME)\n        model_dest_path = dm.fs.join(output_dir, self.MODEL_PATH_NAME)\n        metadata_remote_path = dm.fs.join(remote_dir, self.METADATA_PATH_NAME)\n        metadata_dest_path = dm.fs.join(output_dir, self.METADATA_PATH_NAME)\n\n        # avoid downloading if the file exists already\n        if (\n            not (\n                dm.fs.exists(metadata_dest_path)\n                and (dm.fs.exists(model_dest_path) == dm.fs.exists(model_remote_path))\n            )\n            or force\n        ):\n            # metadata should exists if the model exists\n            with self._filelock(f\"{model_name}.metadata.json.lock\"):\n                dm.fs.copy_file(\n                    metadata_remote_path,\n                    metadata_dest_path,\n                    progress=True,\n                    leave_progress=False,\n                    force=True,\n                )\n\n            if dm.fs.exists(model_remote_path):\n                with self._filelock(f\"{model_name}.lock\"):\n                    if dm.fs.is_dir(model_remote_path):\n                        # we copy the model dir\n                        dm.fs.copy_dir(\n                            model_remote_path,\n                            model_dest_path,\n                            progress=True,\n                            leave_progress=False,\n                            chunk_size=chunk_size,\n                            force=force,\n                        )\n                    else:\n                        # we copy the model dir\n                        dm.fs.copy_file(\n                            model_remote_path,\n                            model_dest_path,\n                            progress=True,\n                            leave_progress=False,\n                            chunk_size=chunk_size,\n                            force=force,\n                        )\n\n        cache_sha256sum = commons.sha256sum(model_dest_path)\n        if modelcard.sha256sum is not None and cache_sha256sum != modelcard.sha256sum:\n            mapper = dm.fs.get_mapper(output_dir)\n            mapper.fs.delete(output_dir, recursive=True)\n            raise ModelStoreError(\n                f\"\"\"The destination artifact at {model_dest_path} has a different sha256sum ({cache_sha256sum}) \"\"\"\n                f\"\"\"than the Remote artifact sha256sum ({modelcard.sha256sum}). The destination artifact has been removed !\"\"\"\n            )\n\n        return output_dir\n\n    def load(\n        self,\n        model_name: Union[str, dict, ModelInfo],\n        load_fn: Optional[Callable] = None,\n        load_fn_kwargs: Optional[dict] = None,\n        download_output_dir: Optional[Union[os.PathLike, pathlib.Path]] = None,\n        chunk_size: int = 2048,\n        force: bool = False,\n    ):\n        \"\"\"\n        Load a model by its name\n\n        Args:\n            model_name: name of the model to load\n            load_fn: Custom loading function to load the model\n            load_fn_kwargs: Optional dict of additional kwargs to provide to the loading function\n            download_output_dir: Argument for download function to specify the download folder\n            chunk_size: chunk size for download\n            force: whether to reforce the download of the file\n\n        Returns:\n            model: Optional model, if the model requires download or loading weights\n            model_info: model information card\n        \"\"\"\n        if isinstance(model_name, str):\n            # find the model with the same name\n            modelcard = self.search(name=model_name)[0]\n        else:\n            modelcard = model_name\n        output_dir = self.download(\n            modelcard=modelcard,\n            output_dir=download_output_dir,\n            chunk_size=chunk_size,\n            force=force,\n        )\n        if load_fn is None:\n            load_fn = joblib.load\n        model_path = dm.fs.join(output_dir, self.MODEL_PATH_NAME)\n        metadata_path = dm.fs.join(output_dir, self.METADATA_PATH_NAME)\n\n        # deal with non-pretrained models that might not have a serialized file\n        model = None\n        load_fn_kwargs = load_fn_kwargs or {}\n        if dm.fs.exists(model_path):\n            model = load_fn(model_path, **load_fn_kwargs)\n        with fsspec.open(metadata_path, \"r\") as IN:\n            model_info_dict = yaml.safe_load(IN)\n        model_info = ModelInfo(**model_info_dict)\n        return model, model_info\n\n    def __contains__(self, card: Optional[ModelInfo] = None):\n        return self.exists(card)\n\n    def exists(\n        self,\n        card: Optional[ModelInfo] = None,\n        check_remote: bool = False,\n        **match_params,\n    ) -&gt; bool:\n        \"\"\"Returns True if a model is registered in the store\n\n        Args:\n            card: card of the model to check\n            check_remote: whether to check if the remote path of the model exists\n            match_params: parameters for matching as expected by `ModelInfo.match`\n        \"\"\"\n\n        found = False\n        for model_info in self.available_models:\n            if model_info.match(card, **match_params):\n                found = True\n                break\n        return found and (not check_remote or dm.fs.exists(card.path(self.model_store_bucket)))\n\n    def search(self, modelcard: Optional[ModelInfo] = None, **search_kwargs):\n        \"\"\" \"Return all model card that match the required search parameters\n\n        Args:\n            modelcard: model card to search for\n            search_kwargs: search parameters to use\n        \"\"\"\n        search_infos = {}\n        found = []\n        if modelcard is not None:\n            search_infos = modelcard.dict().copy()\n        search_infos.update(search_kwargs)\n        for model in self.available_models:\n            if model.match(search_infos, match_only=list(search_infos.keys())):\n                found.append(model)\n        return found\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.available_models","title":"<code>available_models</code>  <code>property</code>","text":"<p>Return a list of all models that have been serialized in molfeat</p>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the model store</p> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the length of the model store\"\"\"\n    return len(self.available_models)\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.download","title":"<code>download(modelcard, output_dir=None, chunk_size=2048, force=False)</code>","text":"<p>Download an artifact locally</p> <p>Parameters:</p> Name Type Description Default <code>modelcard</code> <code>ModelInfo</code> <p>information on the model to download</p> required <code>output_dir</code> <code>Optional[Union[PathLike, Path]]</code> <p>path where to save the downloaded artifact</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>chunk size to use for download</p> <code>2048</code> <code>force</code> <code>bool</code> <p>whether to force download even if the file exists already</p> <code>False</code> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def download(\n    self,\n    modelcard: ModelInfo,\n    output_dir: Optional[Union[os.PathLike, pathlib.Path]] = None,\n    chunk_size: int = 2048,\n    force: bool = False,\n):\n    \"\"\"Download an artifact locally\n\n    Args:\n        modelcard: information on the model to download\n        output_dir: path where to save the downloaded artifact\n        chunk_size: chunk size to use for download\n        force: whether to force download even if the file exists already\n    \"\"\"\n\n    remote_dir = modelcard.path(self.model_store_bucket)\n    model_name = modelcard.name\n    if not self.exists(modelcard, check_remote=True):\n        raise ModelStoreError(f\"Model {model_name} does not exist in the model store !\")\n\n    if output_dir is None:\n        output_dir = dm.fs.join(platformdirs.user_cache_dir(\"molfeat\"), model_name)\n\n    dm.fs.mkdir(output_dir, exist_ok=True)\n\n    model_remote_path = dm.fs.join(remote_dir, self.MODEL_PATH_NAME)\n    model_dest_path = dm.fs.join(output_dir, self.MODEL_PATH_NAME)\n    metadata_remote_path = dm.fs.join(remote_dir, self.METADATA_PATH_NAME)\n    metadata_dest_path = dm.fs.join(output_dir, self.METADATA_PATH_NAME)\n\n    # avoid downloading if the file exists already\n    if (\n        not (\n            dm.fs.exists(metadata_dest_path)\n            and (dm.fs.exists(model_dest_path) == dm.fs.exists(model_remote_path))\n        )\n        or force\n    ):\n        # metadata should exists if the model exists\n        with self._filelock(f\"{model_name}.metadata.json.lock\"):\n            dm.fs.copy_file(\n                metadata_remote_path,\n                metadata_dest_path,\n                progress=True,\n                leave_progress=False,\n                force=True,\n            )\n\n        if dm.fs.exists(model_remote_path):\n            with self._filelock(f\"{model_name}.lock\"):\n                if dm.fs.is_dir(model_remote_path):\n                    # we copy the model dir\n                    dm.fs.copy_dir(\n                        model_remote_path,\n                        model_dest_path,\n                        progress=True,\n                        leave_progress=False,\n                        chunk_size=chunk_size,\n                        force=force,\n                    )\n                else:\n                    # we copy the model dir\n                    dm.fs.copy_file(\n                        model_remote_path,\n                        model_dest_path,\n                        progress=True,\n                        leave_progress=False,\n                        chunk_size=chunk_size,\n                        force=force,\n                    )\n\n    cache_sha256sum = commons.sha256sum(model_dest_path)\n    if modelcard.sha256sum is not None and cache_sha256sum != modelcard.sha256sum:\n        mapper = dm.fs.get_mapper(output_dir)\n        mapper.fs.delete(output_dir, recursive=True)\n        raise ModelStoreError(\n            f\"\"\"The destination artifact at {model_dest_path} has a different sha256sum ({cache_sha256sum}) \"\"\"\n            f\"\"\"than the Remote artifact sha256sum ({modelcard.sha256sum}). The destination artifact has been removed !\"\"\"\n        )\n\n    return output_dir\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.exists","title":"<code>exists(card=None, check_remote=False, **match_params)</code>","text":"<p>Returns True if a model is registered in the store</p> <p>Parameters:</p> Name Type Description Default <code>card</code> <code>Optional[ModelInfo]</code> <p>card of the model to check</p> <code>None</code> <code>check_remote</code> <code>bool</code> <p>whether to check if the remote path of the model exists</p> <code>False</code> <code>match_params</code> <p>parameters for matching as expected by <code>ModelInfo.match</code></p> <code>{}</code> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def exists(\n    self,\n    card: Optional[ModelInfo] = None,\n    check_remote: bool = False,\n    **match_params,\n) -&gt; bool:\n    \"\"\"Returns True if a model is registered in the store\n\n    Args:\n        card: card of the model to check\n        check_remote: whether to check if the remote path of the model exists\n        match_params: parameters for matching as expected by `ModelInfo.match`\n    \"\"\"\n\n    found = False\n    for model_info in self.available_models:\n        if model_info.match(card, **match_params):\n            found = True\n            break\n    return found and (not check_remote or dm.fs.exists(card.path(self.model_store_bucket)))\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.load","title":"<code>load(model_name, load_fn=None, load_fn_kwargs=None, download_output_dir=None, chunk_size=2048, force=False)</code>","text":"<p>Load a model by its name</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>Union[str, dict, ModelInfo]</code> <p>name of the model to load</p> required <code>load_fn</code> <code>Optional[Callable]</code> <p>Custom loading function to load the model</p> <code>None</code> <code>load_fn_kwargs</code> <code>Optional[dict]</code> <p>Optional dict of additional kwargs to provide to the loading function</p> <code>None</code> <code>download_output_dir</code> <code>Optional[Union[PathLike, Path]]</code> <p>Argument for download function to specify the download folder</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>chunk size for download</p> <code>2048</code> <code>force</code> <code>bool</code> <p>whether to reforce the download of the file</p> <code>False</code> <p>Returns:</p> Name Type Description <code>model</code> <p>Optional model, if the model requires download or loading weights</p> <code>model_info</code> <p>model information card</p> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def load(\n    self,\n    model_name: Union[str, dict, ModelInfo],\n    load_fn: Optional[Callable] = None,\n    load_fn_kwargs: Optional[dict] = None,\n    download_output_dir: Optional[Union[os.PathLike, pathlib.Path]] = None,\n    chunk_size: int = 2048,\n    force: bool = False,\n):\n    \"\"\"\n    Load a model by its name\n\n    Args:\n        model_name: name of the model to load\n        load_fn: Custom loading function to load the model\n        load_fn_kwargs: Optional dict of additional kwargs to provide to the loading function\n        download_output_dir: Argument for download function to specify the download folder\n        chunk_size: chunk size for download\n        force: whether to reforce the download of the file\n\n    Returns:\n        model: Optional model, if the model requires download or loading weights\n        model_info: model information card\n    \"\"\"\n    if isinstance(model_name, str):\n        # find the model with the same name\n        modelcard = self.search(name=model_name)[0]\n    else:\n        modelcard = model_name\n    output_dir = self.download(\n        modelcard=modelcard,\n        output_dir=download_output_dir,\n        chunk_size=chunk_size,\n        force=force,\n    )\n    if load_fn is None:\n        load_fn = joblib.load\n    model_path = dm.fs.join(output_dir, self.MODEL_PATH_NAME)\n    metadata_path = dm.fs.join(output_dir, self.METADATA_PATH_NAME)\n\n    # deal with non-pretrained models that might not have a serialized file\n    model = None\n    load_fn_kwargs = load_fn_kwargs or {}\n    if dm.fs.exists(model_path):\n        model = load_fn(model_path, **load_fn_kwargs)\n    with fsspec.open(metadata_path, \"r\") as IN:\n        model_info_dict = yaml.safe_load(IN)\n    model_info = ModelInfo(**model_info_dict)\n    return model, model_info\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.register","title":"<code>register(modelcard, model=None, chunk_size=2048, save_fn=None, save_fn_kwargs=None, force=True)</code>","text":"<p>Register a new model to the store</p> <p>!!! note <code>save_fn</code>     You can pass additional kwargs for your <code>save_fn</code> through the <code>save_fn_kwargs</code> argument.     It's expected that <code>save_fn</code> will be called as : <code>save_fn(model, &lt;model_upload_path&gt;, **save_fn_wargs)</code>,     with <code>&lt;model_upload_path&gt;</code> being provided by the model store, and that it will return the path to the serialized model.     If not provided, <code>joblib.dump</code> is used by default.</p> <p>Parameters:</p> Name Type Description Default <code>modelcard</code> <code>Union[ModelInfo, dict]</code> <p>Model information</p> required <code>model</code> <code>Optional[Any]</code> <p>A path to the model artifact or any object that needs to be saved</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>the chunk size for the upload</p> <code>2048</code> <code>save_fn</code> <code>Optional[Callable]</code> <p>any custom function for serializing the model, that takes the model, the upload path and parameters <code>save_fn_kwargs</code> as inputs.</p> <code>None</code> <code>save_fn_kwargs</code> <code>Optional[dict]</code> <p>any additional kwargs to pass to save_fn</p> <code>None</code> <code>force</code> <code>bool</code> <p>whether to force upload to the bucket</p> <code>True</code> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def register(\n    self,\n    modelcard: Union[ModelInfo, dict],\n    model: Optional[Any] = None,\n    chunk_size: int = 2048,\n    save_fn: Optional[Callable] = None,\n    save_fn_kwargs: Optional[dict] = None,\n    force: bool = True,\n):\n    \"\"\"\n    Register a new model to the store\n\n    !!! note `save_fn`\n        You can pass additional kwargs for your `save_fn` through the `save_fn_kwargs` argument.\n        It's expected that `save_fn` will be called as : `save_fn(model, &lt;model_upload_path&gt;, **save_fn_wargs)`,\n        with `&lt;model_upload_path&gt;` being provided by the model store, and that it will return the path to the serialized model.\n        If not provided, `joblib.dump` is used by default.\n\n    Args:\n        modelcard: Model information\n        model: A path to the model artifact or any object that needs to be saved\n        chunk_size: the chunk size for the upload\n        save_fn: any custom function for serializing the model, that takes the model, the upload path and parameters `save_fn_kwargs` as inputs.\n        save_fn_kwargs: any additional kwargs to pass to save_fn\n        force: whether to force upload to the bucket\n\n    \"\"\"\n    if not isinstance(modelcard, ModelInfo):\n        modelcard = ModelInfo(**modelcard)\n    # we save the model first\n    if self.exists(card=modelcard):\n        logger.warning(f\"Model {modelcard.name} exists already ...\")\n        if not force:\n            return\n\n    model_root_dir = modelcard.path(self.model_store_bucket)\n    model_path = model\n    model_upload_path = dm.fs.join(model_root_dir, self.MODEL_PATH_NAME)\n    model_metadata_upload_path = dm.fs.join(model_root_dir, self.METADATA_PATH_NAME)\n\n    save_fn_kwargs = save_fn_kwargs or {}\n    if save_fn is None:\n        if not isinstance(model, (pathlib.Path, os.PathLike)):\n            local_model_path = tempfile.NamedTemporaryFile(delete=False)\n            with local_model_path:\n                joblib.dump(model, local_model_path)\n            model_path = local_model_path.name\n        # Upload the artifact to the bucket\n        dm.fs.copy_file(\n            model_path,\n            model_upload_path,\n            progress=True,\n            leave_progress=False,\n            chunk_size=chunk_size,\n            force=force,\n        )\n    else:\n        model_path = save_fn(model, model_upload_path, **save_fn_kwargs)\n        # we reset to None if the save_fn has not returned anything\n        model_path = model_path or model_upload_path\n    modelcard.sha256sum = commons.sha256sum(model_path)\n    # then we save the metadata as json\n    with fsspec.open(model_metadata_upload_path, \"w\") as OUT:\n        OUT.write(modelcard.json())\n    self._update_store()\n    logger.info(f\"Successfuly registered model {modelcard.name} !\")\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.modelstore.ModelStore.search","title":"<code>search(modelcard=None, **search_kwargs)</code>","text":"<p>\"Return all model card that match the required search parameters</p> <p>Parameters:</p> Name Type Description Default <code>modelcard</code> <code>Optional[ModelInfo]</code> <p>model card to search for</p> <code>None</code> <code>search_kwargs</code> <p>search parameters to use</p> <code>{}</code> Source code in <code>molfeat/store/modelstore.py</code> <pre><code>def search(self, modelcard: Optional[ModelInfo] = None, **search_kwargs):\n    \"\"\" \"Return all model card that match the required search parameters\n\n    Args:\n        modelcard: model card to search for\n        search_kwargs: search parameters to use\n    \"\"\"\n    search_infos = {}\n    found = []\n    if modelcard is not None:\n        search_infos = modelcard.dict().copy()\n    search_infos.update(search_kwargs)\n    for model in self.available_models:\n        if model.match(search_infos, match_only=list(search_infos.keys())):\n            found.append(model)\n    return found\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.loader.PretrainedModel","title":"<code>PretrainedModel</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for loading pretrained models</p> Source code in <code>molfeat/store/loader.py</code> <pre><code>class PretrainedModel(abc.ABC):\n    \"\"\"Base class for loading pretrained models\"\"\"\n\n    @classmethod\n    def _artifact_load(cls, name: str, download_path: Optional[os.PathLike] = None, **kwargs):\n        \"\"\"Load an artifact based on its name\n\n        Args:\n            name: name of the model to load\n            download_path: path to a directory where to save the downloaded files\n        \"\"\"\n        ...\n\n    @classmethod\n    def _load_or_raise(\n        cls,\n        name: str,\n        download_path: Optional[os.PathLike] = None,\n        **kwargs,\n    ):\n        \"\"\"Load model or raise an exception\n\n        Args:\n            name: name of the model to load\n            download_path: local download path of the model\n\n        \"\"\"\n        ...\n\n    @abc.abstractmethod\n    def load(self):\n        \"\"\"Load the model\"\"\"\n        ...\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.loader.PretrainedModel.load","title":"<code>load()</code>  <code>abstractmethod</code>","text":"<p>Load the model</p> Source code in <code>molfeat/store/loader.py</code> <pre><code>@abc.abstractmethod\ndef load(self):\n    \"\"\"Load the model\"\"\"\n    ...\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.loader.PretrainedStoreModel","title":"<code>PretrainedStoreModel</code>","text":"<p>               Bases: <code>PretrainedModel</code></p> <p>Class for loading pretrained models from the model zoo</p> Source code in <code>molfeat/store/loader.py</code> <pre><code>class PretrainedStoreModel(PretrainedModel):\n    r\"\"\"\n    Class for loading pretrained models from the model zoo\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        cache_path: Optional[os.PathLike] = None,\n        store: Optional[ModelStore] = None,\n    ):\n        \"\"\"Interface for pretrained model from the default modelstore\n\n        Args:\n            name: name of the pretrained transformer in the model store\n            cache_path: optional local cache path.\n            store: ModelStore to use for loading the pretrained model\n        \"\"\"\n        self.name = name\n        self.cache_path = cache_path\n        if store is None:\n            store = ModelStore()\n        self.store = store\n\n    @classmethod\n    def _artifact_load(cls, name: str, download_path: Optional[os.PathLike] = None, **kwargs):\n        \"\"\"Load internal artefact from the model store\n\n        Args:\n            name: name of the model to load\n            download_path: path to a directory where to save the downloaded files\n        \"\"\"\n\n        if not dm.fs.exists(download_path):\n            cls._load_or_raise.cache_clear()\n        return cls._load_or_raise(name, download_path, **kwargs)\n\n    @classmethod\n    @lru_cache(maxsize=100)\n    def _load_or_raise(\n        cls,\n        name: str,\n        download_path: Optional[os.PathLike] = None,\n        store: Optional[ModelStore] = None,\n        **kwargs,\n    ):\n        \"\"\"Load when from ada or raise exception\n        Args:\n            name: name\n        \"\"\"\n        if store is None:\n            store = ModelStore()\n        try:\n            modelcard = store.search(name=name)[0]\n            artifact_dir = store.download(modelcard, download_path, **kwargs)\n        except Exception:\n            mess = f\"Can't retrieve model {name} from the store !\"\n            raise ModelStoreError(mess)\n        return artifact_dir\n\n    def load(self):\n        \"\"\"Load the model\"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.loader.PretrainedStoreModel.__init__","title":"<code>__init__(name, cache_path=None, store=None)</code>","text":"<p>Interface for pretrained model from the default modelstore</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the pretrained transformer in the model store</p> required <code>cache_path</code> <code>Optional[PathLike]</code> <p>optional local cache path.</p> <code>None</code> <code>store</code> <code>Optional[ModelStore]</code> <p>ModelStore to use for loading the pretrained model</p> <code>None</code> Source code in <code>molfeat/store/loader.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    cache_path: Optional[os.PathLike] = None,\n    store: Optional[ModelStore] = None,\n):\n    \"\"\"Interface for pretrained model from the default modelstore\n\n    Args:\n        name: name of the pretrained transformer in the model store\n        cache_path: optional local cache path.\n        store: ModelStore to use for loading the pretrained model\n    \"\"\"\n    self.name = name\n    self.cache_path = cache_path\n    if store is None:\n        store = ModelStore()\n    self.store = store\n</code></pre>"},{"location":"api/molfeat.store.html#molfeat.store.loader.PretrainedStoreModel.load","title":"<code>load()</code>","text":"<p>Load the model</p> Source code in <code>molfeat/store/loader.py</code> <pre><code>def load(self):\n    \"\"\"Load the model\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/molfeat.trans.base.html","title":"molfeat.trans.base","text":""},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.BaseFeaturizer","title":"<code>BaseFeaturizer</code>","text":"<p>               Bases: <code>BaseEstimator</code></p> <p>Molecule featurizer base class that needs to be implemented by all featurizers. This featurizer is compatible with scikit-learn estimators and thus can be plugged into a pipeline</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>class BaseFeaturizer(BaseEstimator):\n    \"\"\"\n    Molecule featurizer base class that needs to be implemented by all featurizers.\n    This featurizer is compatible with scikit-learn estimators and thus can be plugged into a pipeline\n    \"\"\"\n\n    def __init__(\n        self,\n        n_jobs: int = 1,\n        verbose: bool = True,\n        dtype: Optional[Union[str, Callable]] = None,\n        parallel_kwargs: Optional[Dict[str, Any]] = None,\n        **params,\n    ):\n        self._n_jobs = n_jobs\n        self.dtype = dtype\n        self.verbose = verbose\n        self.parallel_kwargs = parallel_kwargs or {}\n        for k, v in params.items():\n            setattr(self, k, v)\n        self._input_params = dict(n_jobs=n_jobs, dtype=dtype, verbose=verbose, **params)\n\n    @property\n    def n_jobs(self):\n        \"\"\"Get the number of concurrent jobs to run with this featurizer\"\"\"\n        return self._n_jobs\n\n    @n_jobs.setter\n    def n_jobs(self, val):\n        if val &gt;= 1:\n            self._n_jobs = val\n        elif val == -1:\n            self._n_jobs = joblib.cpu_count()\n\n    def _get_param_names(self):\n        \"\"\"Get parameter names for the estimator\"\"\"\n        return self._input_params.keys()\n\n    def _update_params(self):\n        \"\"\"Update parameters of the current estimator\"\"\"\n        ...\n\n    def set_params(self, **params):\n        \"\"\"Set the parameters of this estimator.\n\n        Returns:\n            self: estimator instance\n        \"\"\"\n        super().set_params(**params)\n        for k, v in params.items():\n            if k in self._input_params:\n                self._input_params[k] = v\n        self._update_params()\n        return self\n\n    def copy(self):\n        \"\"\"Return a copy of this object.\"\"\"\n        copy_obj = self.__class__(**self._input_params)\n        for k, v in self.__dict__.items():\n            if not hasattr(copy_obj, k):\n                setattr(copy_obj, k, copy.deepcopy(v))\n        return copy_obj\n\n    def preprocess(self, inputs: list, labels: Optional[list] = None):\n        \"\"\"Preprocess input\n\n        Args:\n            inputs: inputs to preprocess\n            labels: labels to preprocess (optional)\n\n        Returns:\n            processed: pre-processed input list\n        \"\"\"\n        return inputs, labels\n\n    def get_collate_fn(self, *args, **kwargs):\n        \"\"\"\n        Get collate function of this featurizer. In the implementation of this function\n        you should set the relevant attributes or argument of the underlying collate function\n        (e.g via functools.partial) and return the function itself\n\n        Returns:\n            fn: Collate function for pytorch or None\n        \"\"\"\n        return None\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.BaseFeaturizer.n_jobs","title":"<code>n_jobs</code>  <code>property</code> <code>writable</code>","text":"<p>Get the number of concurrent jobs to run with this featurizer</p>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.BaseFeaturizer.copy","title":"<code>copy()</code>","text":"<p>Return a copy of this object.</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def copy(self):\n    \"\"\"Return a copy of this object.\"\"\"\n    copy_obj = self.__class__(**self._input_params)\n    for k, v in self.__dict__.items():\n        if not hasattr(copy_obj, k):\n            setattr(copy_obj, k, copy.deepcopy(v))\n    return copy_obj\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.BaseFeaturizer.get_collate_fn","title":"<code>get_collate_fn(*args, **kwargs)</code>","text":"<p>Get collate function of this featurizer. In the implementation of this function you should set the relevant attributes or argument of the underlying collate function (e.g via functools.partial) and return the function itself</p> <p>Returns:</p> Name Type Description <code>fn</code> <p>Collate function for pytorch or None</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def get_collate_fn(self, *args, **kwargs):\n    \"\"\"\n    Get collate function of this featurizer. In the implementation of this function\n    you should set the relevant attributes or argument of the underlying collate function\n    (e.g via functools.partial) and return the function itself\n\n    Returns:\n        fn: Collate function for pytorch or None\n    \"\"\"\n    return None\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.BaseFeaturizer.preprocess","title":"<code>preprocess(inputs, labels=None)</code>","text":"<p>Preprocess input</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>list</code> <p>inputs to preprocess</p> required <code>labels</code> <code>Optional[list]</code> <p>labels to preprocess (optional)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>processed</code> <p>pre-processed input list</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def preprocess(self, inputs: list, labels: Optional[list] = None):\n    \"\"\"Preprocess input\n\n    Args:\n        inputs: inputs to preprocess\n        labels: labels to preprocess (optional)\n\n    Returns:\n        processed: pre-processed input list\n    \"\"\"\n    return inputs, labels\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.BaseFeaturizer.set_params","title":"<code>set_params(**params)</code>","text":"<p>Set the parameters of this estimator.</p> <p>Returns:</p> Name Type Description <code>self</code> <p>estimator instance</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def set_params(self, **params):\n    \"\"\"Set the parameters of this estimator.\n\n    Returns:\n        self: estimator instance\n    \"\"\"\n    super().set_params(**params)\n    for k, v in params.items():\n        if k in self._input_params:\n            self._input_params[k] = v\n    self._update_params()\n    return self\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer","title":"<code>MoleculeTransformer</code>","text":"<p>               Bases: <code>TransformerMixin</code>, <code>BaseFeaturizer</code></p> <p>Base class for molecular data transformer such as Fingerprinter etc. If you create a subclass of this featurizer, you will need to make sure that the input argument of the init are kept as is in the object attributes.</p> <p>Note</p> <p>The transformer supports a variety of datatype, they are only enforced when passing the <code>enforce_dtype=True</code> attributes in <code>__call__</code>. For pandas dataframes, use <code>'pandas'|'df'|'dataframe'|pd.DataFrame</code></p> Using a custom Calculator <p>You can use your own calculator for featurization. It's recommended to subclass <code>molfeat.calc.base.SerializableCalculator</code> If you calculator also implements a <code>batch_compute</code> method, it will be used for batch featurization and parallelization options will be passed to it.</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>class MoleculeTransformer(TransformerMixin, BaseFeaturizer, metaclass=_TransformerMeta):\n    \"\"\"\n    Base class for molecular data transformer such as Fingerprinter etc.\n    If you create a subclass of this featurizer, you will need to make sure that the\n    input argument of the init are kept as is in the object attributes.\n\n    !!! note\n        The transformer supports a variety of datatype, they are only enforced when passing the\n        `enforce_dtype=True` attributes in `__call__`. For pandas dataframes, use `'pandas'|'df'|'dataframe'|pd.DataFrame`\n\n    ???+ tip \"Using a custom Calculator\"\n        You can use your own calculator for featurization. It's recommended to subclass `molfeat.calc.base.SerializableCalculator`\n        If you calculator also implements a `batch_compute` method, it will be used for batch featurization and parallelization options will be passed to it.\n    \"\"\"\n\n    def __init__(\n        self,\n        featurizer: Union[str, Callable],\n        n_jobs: int = 1,\n        verbose: bool = False,\n        dtype: Optional[Union[str, Callable]] = None,\n        parallel_kwargs: Optional[Dict[str, Any]] = None,\n        **params,\n    ):\n        \"\"\"Mol transformer base class\n\n        Args:\n            featurizer: featurizer to use\n            n_jobs (int, optional): Number of job to run in parallel. Defaults to 1.\n            verbose (bool, optional): Verbosity level. Defaults to True.\n            dtype (callable, optional): Output data type. Defaults to None, where numpy arrays are returned.\n            parallel_kwargs (dict, optional): Optional kwargs to pass to the dm.parallelized function. Defaults to None.\n\n        \"\"\"\n        super().__init__(\n            n_jobs=n_jobs,\n            verbose=verbose,\n            dtype=dtype,\n            featurizer=featurizer,\n            parallel_kwargs=parallel_kwargs,\n            **params,\n        )\n        if callable(featurizer):\n            self.featurizer = featurizer\n        else:\n            self.featurizer = get_calculator(featurizer, **params)\n\n        self.cols_to_keep = None\n        self._fitted = False\n\n        self._save_input_args()\n        if self.featurizer and not (\n            isinstance(self.featurizer, str) or is_callable(self.featurizer)\n        ):\n            raise AttributeError(f\"Featurizer {self.featurizer} must be a callable or a string\")\n\n    def _save_input_args(self):\n        \"\"\"Save the input arguments of a transformer to the attribute\n        `_input_args` of the object.\n        \"\"\"\n\n        # NOTE(hadim): don't override existing _input_args so\n        # it's possible to use MoleculeTransformer as a featurizer\n        # instead of simply a base class.\n        if not hasattr(self, \"_input_args\"):\n            self._input_args = get_input_args()\n\n    def _update_params(self):\n        if not callable(self.featurizer):\n            params = copy.deepcopy(self._input_params)\n            params.pop(\"featurizer\")\n            self.featurizer = get_calculator(self.featurizer, **params)\n        self._fitted = False\n\n    def __setstate__(self, state):\n        state.pop(\"callbacks\", None)\n        self.__dict__.update(state)\n        self.__dict__[\"parallel_kwargs\"] = state.get(\"parallel_kwargs\", {})\n        self._update_params()\n\n    def fit(self, X: List[Union[dm.Mol, str]], y: Optional[list] = None, **fit_params):\n        \"\"\"Fit the current transformer on given dataset.\n\n        The goal of fitting is for example to identify nan columns values\n        that needs to be removed from the dataset\n\n        Args:\n            X: input list of molecules\n            y (list, optional): Optional list of molecular properties. Defaults to None.\n\n        Returns:\n            self: MolTransformer instance after fitting\n        \"\"\"\n        feats = self.transform(X, ignore_errors=True)\n        lengths = [len(x) for x in feats if not datatype.is_null(x)]\n        if lengths:\n            # we will ignore all nan\n            feats = datatype.to_numpy([f for f in feats if not datatype.is_null(f)])\n            self.cols_to_keep = (~np.any(np.isnan(feats), axis=0)).nonzero()[0]\n        self._fitted = True\n        return self\n\n    def _transform(self, mol: dm.Mol):\n        r\"\"\"\n        Compute features for a single molecule.\n        This method would potentially need to be reimplemented by child classes\n\n        Args:\n            mol (dm.Mol): molecule to transform into features\n\n        Returns\n            feat: featurized input molecule\n\n        \"\"\"\n        feat = None\n        try:\n            feat = datatype.to_numpy(self.featurizer(mol))\n            if self.cols_to_keep is not None:\n                feat = feat[self.cols_to_keep]\n        except Exception as e:\n            if self.verbose:\n                logger.error(e)\n        return feat\n\n    def transform(\n        self,\n        mols: List[Union[dm.Mol, str]],\n        ignore_errors: bool = False,\n        **kwargs,\n    ):\n        r\"\"\"\n        Compute the features for a set of molecules.\n\n        !!! note\n            Note that depending on the `ignore_errors` argument, all failed\n            featurization (caused whether by invalid smiles or error during\n            data transformation) will be substitued by None features for the\n            corresponding molecule. This is done, so you can find the positions\n            of these molecules and filter them out according to your own logic.\n\n        Args:\n            mols: a list containing smiles or mol objects\n            ignore_errors (bool, optional): Whether to silently ignore errors\n\n\n        Returns:\n            features: a list of features for each molecule in the input set\n        \"\"\"\n        # Convert single mol to iterable format\n        if isinstance(mols, pd.DataFrame):\n            mols = mols[mols.columns[0]]\n        if isinstance(mols, (str, dm.Mol)) or not isinstance(mols, Iterable):\n            mols = [mols]\n\n        def _to_mol(x):\n            return dm.to_mol(x) if x else None\n\n        parallel_kwargs = getattr(self, \"parallel_kwargs\", {})\n\n        if hasattr(self.featurizer, \"batch_compute\") and callable(self.featurizer.batch_compute):\n            # this calculator can be batched which will be faster\n            features = self.featurizer.batch_compute(mols, n_jobs=self.n_jobs, **parallel_kwargs)\n        else:\n            mols = dm.parallelized(_to_mol, mols, n_jobs=self.n_jobs, **parallel_kwargs)\n            if self.n_jobs not in [0, 1]:\n                # use a proxy model to run in parallel\n                cpy = self.copy()\n                features = dm.parallelized(\n                    cpy._transform,\n                    mols,\n                    n_jobs=self.n_jobs,\n                    **cpy.parallel_kwargs,\n                )\n            else:\n                features = [self._transform(mol) for mol in mols]\n        if not ignore_errors:\n            for ind, feat in enumerate(features):\n                if feat is None:\n                    raise ValueError(\n                        f\"Cannot transform molecule at index {ind}. Please check logs (set verbose to True) to see errors!\"\n                    )\n\n        # sklearn feature validation for sklearn pipeline\n        return datatype.as_numpy_array_if_possible(features, self.dtype)\n\n    def __len__(self):\n        \"\"\"Compute featurizer length\"\"\"\n\n        # check length and _length attribute\n        cols_to_keep = getattr(self, \"cols_to_keep\", None)\n        cur_length = None\n\n        if cols_to_keep is not None:\n            cur_length = len(cols_to_keep)\n        else:\n            cur_length = getattr(self, \"length\", getattr(self, \"_length\", None))\n            # then check the featurizer length if it's a callable and not a string/None\n            if (\n                cur_length is None\n                and callable(self.featurizer)\n                and hasattr(self.featurizer, \"__len__\")\n            ):\n                cur_length = len(self.featurizer)\n\n        if cur_length is None:\n            raise ValueError(\n                f\"Cannot auto-determine length of this MolTransformer: {self.__class__.__name__}\"\n            )\n\n        return cur_length\n\n    def __call__(\n        self,\n        mols: List[Union[dm.Mol, str]],\n        enforce_dtype: bool = True,\n        ignore_errors: bool = False,\n        **kwargs,\n    ):\n        r\"\"\"\n        Calculate features for molecules. Using __call__, instead of transform.\n        If ignore_error is True, a list of features and valid ids are returned.\n        Note that most Transfomers allow you to specify\n        a return datatype.\n\n        Args:\n            mols:  Mol or SMILES of the molecules to be transformed\n            enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n            ignore_errors: Whether to ignore errors during featurization or raise an error.\n            kwargs: Named parameters for the transform method\n\n        Returns:\n            feats: list of valid features\n            ids: all valid molecule positions that did not failed during featurization.\n                Only returned when ignore_errors is True.\n\n        \"\"\"\n        features = self.transform(mols, ignore_errors=ignore_errors, enforce_dtype=False, **kwargs)\n        ids = np.arange(len(features))\n        if ignore_errors:\n            features, ids = self._filter_none(features)\n        if self.dtype is not None and enforce_dtype:\n            features = datatype.cast(features, dtype=self.dtype, columns=self.columns)\n        if not ignore_errors:\n            return features\n        return features, ids\n\n    @staticmethod\n    def _filter_none(features):\n        ids_bad = []\n        # If the features are a list, filter the None ids\n        if isinstance(features, (tuple, list, np.ndarray)):\n            for f_id, feat in enumerate(features):\n                if datatype.is_null(feat):\n                    ids_bad.append(f_id)\n            ids_to_keep = [\n                this_id for this_id in np.arange(0, len(features)) if this_id not in ids_bad\n            ]\n            features = [features[ii] for ii in ids_to_keep]\n\n        # If the features are a dict or DataFrame, filter the ids when any key id is None\n        elif isinstance(features, (dict, pd.DataFrame)):\n            if isinstance(features, dict):\n                features = pd.DataFrame(features)\n            for feat_col in features.columns:\n                for f_id, feat in enumerate(features[feat_col].values.flatten()):\n                    if feat is None:\n                        ids_bad.append(f_id)\n            ids_bad = np.unique(ids_bad).tolist()\n            all_ids = np.arange(0, features.shape[0])\n            ids_to_keep = [this_id for this_id in all_ids if this_id not in ids_bad]\n            features = features.iloc[ids_to_keep, :]\n\n        else:\n            ids_to_keep = np.arange(0, features.shape[0])\n        return features, list(ids_to_keep)\n\n    @property\n    def columns(self):\n        \"\"\"Get the list of columns for this molecular descriptor\n\n        Returns:\n            columns (list): Name of the columns of the descriptor\n        \"\"\"\n        columns = getattr(self.featurizer, \"columns\", None)\n        cols_to_keep = getattr(self, \"cols_to_keep\", None)\n        if columns is not None and cols_to_keep is not None and len(cols_to_keep) &gt; 0:\n            columns = [columns[i] for i in cols_to_keep]\n        return columns\n\n    @staticmethod\n    def batch_transform(\n        transformer: Callable,\n        mols: List[Union[dm.Mol, str]],\n        batch_size: int = 256,\n        n_jobs: Optional[int] = None,\n        concatenate: bool = True,\n        progress: bool = True,\n        leave_progress: bool = False,\n        **parallel_kwargs,\n    ):\n        \"\"\"\n        Batched computation of featurization of a list of molecules\n\n        Args:\n            transformer: Fingerprint transformer\n            mols: List of molecules to featurize\n            batch_size: Batch size\n            n_jobs: number of jobs to run in parallel\n            concatenate: Whether to concatenate the results or return the list of batched results\n            progress: whether to show progress bar\n            leave_progress: whether to leave progress bar after completion\n            parallel_kwargs: additional arguments to pass to dm.parallelized\n\n        Returns:\n            List of batches\n        \"\"\"\n\n        step_size = int(np.ceil(len(mols) / batch_size))\n        batched_mols = np.array_split(mols, step_size)\n\n        tqdm_kwargs = parallel_kwargs.setdefault(\"tqdm_kwargs\", {})\n        tqdm_kwargs.update(leave=leave_progress, desc=\"Batch compute:\")\n        parallel_kwargs[\"tqdm_kwargs\"] = tqdm_kwargs\n\n        # it's recommended to use a precomputed molecule transformer\n        # instead of the internal cache for pretrained models\n        cache_attr = \"cache\"\n        existing_cache = getattr(transformer, cache_attr, None)\n        if existing_cache is None:\n            cache_attr = \"precompute_cache\"\n            existing_cache = getattr(transformer, cache_attr, None)\n\n        use_mp_cache = (\n            existing_cache is not None\n            and not isinstance(existing_cache, MPDataCache)\n            and n_jobs not in [None, 0, 1]  # this is based on datamol sequential vs parallel\n        )\n        if use_mp_cache:\n            # we need to change the cache system to one that works with multiprocessing\n            # to have a shared memory\n            new_cache = MPDataCache()\n            new_cache.update(existing_cache)\n            setattr(transformer, cache_attr, new_cache)\n\n        transformed = dm.parallelized(\n            transformer,\n            batched_mols,\n            n_jobs=n_jobs,\n            progress=progress,\n            **parallel_kwargs,\n        )\n        if use_mp_cache:\n            # we set back the original transformation while updating it with\n            # all the missing values\n            existing_cache.update(getattr(transformer, cache_attr, {}))\n            setattr(transformer, cache_attr, existing_cache)\n\n        if concatenate:\n            # if we ask for concatenation, then we would need to fix None values ideally\n            fixed_transformations = []\n            for computed_trans in transformed:\n                if computed_trans is None:\n                    computed_trans = np.full(len(computed_trans), len(transformer), np.nan)\n                else:\n                    for i, x in enumerate(computed_trans):\n                        if x is None:\n                            computed_trans[i] = np.full(len(transformer), np.nan)\n                fixed_transformations.append(computed_trans)\n            return np.concatenate(fixed_transformations)\n        return transformed\n\n    # Featurizer to state methods\n\n    def to_state_dict(self) -&gt; dict:\n        \"\"\"Serialize the featurizer to a state dict.\"\"\"\n\n        if getattr(self, \"_input_args\") is None:\n            raise ValueError(f\"Cannot save state for this transformer '{self.__class__.__name__}'\")\n\n        # Process the input arguments before building the state\n        args = copy.deepcopy(self._input_args)\n\n        # Deal with dtype\n        if \"dtype\" in args and not isinstance(args[\"dtype\"], str):\n            args[\"dtype\"] = map_dtype(args[\"dtype\"])\n\n        ## Deal with graph atom/bond featurizers\n        # NOTE(hadim): it's important to highlight that atom/bond featurizers can't be\n        # customized with this logic.\n        if args.get(\"atom_featurizer\") is not None:\n            if hasattr(args.get(\"atom_featurizer\"), \"to_state_dict\"):\n                args[\"atom_featurizer\"] = args[\"atom_featurizer\"].to_state_dict()\n                args[\"_atom_featurizer_is_pickled\"] = False\n            else:\n                logger.warning\n                (\n                    \"You are attempting to pickle an atom featurizer without a `to_state_dict` function into a hex string\"\n                )\n                args[\"atom_featurizer\"] = fn_to_hex(args[\"atom_featurizer\"])\n                args[\"_atom_featurizer_is_pickled\"] = True\n\n        # deal with bond featurizer\n        if args.get(\"bond_featurizer\") is not None:\n            if hasattr(args.get(\"bond_featurizer\"), \"to_state_dict\"):\n                args[\"bond_featurizer\"] = args[\"bond_featurizer\"].to_state_dict()\n                args[\"_bond_featurizer_is_pickled\"] = False\n            else:\n                logger.warning(\n                    \"You are attempting to pickle a bond featurizer without a `to_state_dict` function into a hex string\"\n                )\n                args[\"bond_featurizer\"] = fn_to_hex(args[\"bond_featurizer\"])\n                args[\"_bond_featurizer_is_pickled\"] = True\n\n        ## Deal with custom featurizer\n        if \"featurizer\" in args and isinstance(args[\"featurizer\"], Callable):\n            if hasattr(args[\"featurizer\"], \"to_state_dict\"):\n                args[\"featurizer\"] = args[\"featurizer\"].to_state_dict()\n                args[\"_featurizer_is_pickled\"] = False\n            else:\n                logger.warning(\n                    \"You are attempting to pickle a callable without a `to_state_dict` function into a hex string\"\n                )\n                args[\"featurizer\"] = fn_to_hex(args[\"featurizer\"])\n                args[\"_featurizer_is_pickled\"] = True\n\n        # Build the state\n        state = {}\n        state[\"name\"] = self.__class__.__name__\n        state[\"args\"] = args\n        state[\"_molfeat_version\"] = MOLFEAT_VERSION\n        return state\n\n    def to_state_json(self) -&gt; str:\n        return json.dumps(self.to_state_dict())\n\n    def to_state_yaml(self) -&gt; str:\n        return yaml.dump(self.to_state_dict(), Dumper=yaml.SafeDumper)\n\n    def to_state_json_file(self, filepath: Union[str, Path]):\n        with fsspec.open(filepath, \"w\") as f:\n            f.write(self.to_state_json())  # type: ignore\n\n    def to_state_yaml_file(self, filepath: Union[str, Path]):\n        with fsspec.open(filepath, \"w\") as f:\n            f.write(self.to_state_yaml())  # type: ignore\n\n    # State to featurizer methods\n\n    @staticmethod\n    def from_state_dict(state: dict, override_args: Optional[dict] = None) -&gt; \"MoleculeTransformer\":\n        \"\"\"Reload a featurizer from a state dict.\"\"\"\n\n        # Don't alter the original state dict\n        state = copy.deepcopy(state)\n\n        # MoleculeTransformer is a special case that has his own logic\n        if state[\"name\"] == \"PrecomputedMolTransformer\":\n            return PrecomputedMolTransformer.from_state_dict(\n                state=state,\n                override_args=override_args,\n            )\n\n        # Get the name\n        transformer_class = _TRANSFORMERS.get(state[\"name\"])\n        if transformer_class is None:\n            raise ValueError(f\"The featurizer '{state['name']}' is not supported.\")\n        if isinstance(transformer_class, str):\n            # Get the transformer class from its path\n            transformer_class = import_from_string(transformer_class)\n\n        # Process the state as needed\n        args = state.get(\"args\", {})\n\n        # Deal with dtype\n        if \"dtype\" in args and isinstance(args[\"dtype\"], str):\n            args[\"dtype\"] = map_dtype(args[\"dtype\"])\n\n        ## Deal with graph atom/bond featurizers\n        if args.get(\"atom_featurizer\") is not None:\n            if not args.get(\"_atom_featurizer_is_pickled\"):\n                klass_name = args[\"atom_featurizer\"].get(\"name\")\n                args[\"atom_featurizer\"] = ATOM_FEATURIZER_MAPPING_REVERSE[\n                    klass_name\n                ].from_state_dict(args[\"atom_featurizer\"])\n            else:\n                # buffer = io.BytesIO(bytes.fromhex(args[\"atom_featurizer\"]))\n                # args[\"atom_featurizer\"] = joblib.load(buffer)\n                args[\"atom_featurizer\"] = hex_to_fn(args[\"atom_featurizer\"])\n            args.pop(\"_atom_featurizer_is_pickled\", None)\n        if args.get(\"bond_featurizer\") is not None:\n            if not args.get(\"_bond_featurizer_is_pickled\"):\n                klass_name = args[\"bond_featurizer\"].get(\"name\")\n                args[\"bond_featurizer\"] = BOND_FEATURIZER_MAPPING_REVERSE[\n                    klass_name\n                ].from_state_dict(args[\"bond_featurizer\"])\n            else:\n                args[\"bond_featurizer\"] = hex_to_fn(args[\"bond_featurizer\"])\n            args.pop(\"_bond_featurizer_is_pickled\", None)\n        ## Deal with custom featurizer\n        if \"featurizer\" in args:\n            if args.get(\"_featurizer_is_pickled\") is True:\n                args[\"featurizer\"] = hex_to_fn(args[\"featurizer\"])\n                args.pop(\"_featurizer_is_pickled\")\n            elif (\n                isinstance(args[\"featurizer\"], Mapping)\n                and args[\"featurizer\"].get(\"name\") in _CALCULATORS\n            ):\n                # we have found a known calculator\n                klass_name = args[\"featurizer\"].get(\"name\")\n                args[\"featurizer\"] = _CALCULATORS[klass_name].from_state_dict(args[\"featurizer\"])\n                args.pop(\"_featurizer_is_pickled\")\n\n        if override_args is not None:\n            args.update(override_args)\n\n        # Create the transformer\n        featurizer = transformer_class(**args)\n        return featurizer\n\n    @staticmethod\n    def from_state_json(\n        state_json: str,\n        override_args: Optional[dict] = None,\n    ) -&gt; \"MoleculeTransformer\":\n        state_dict = json.loads(state_json)\n        return MoleculeTransformer.from_state_dict(state_dict, override_args=override_args)\n\n    @staticmethod\n    def from_state_yaml(\n        state_yaml: str,\n        override_args: Optional[dict] = None,\n    ) -&gt; \"MoleculeTransformer\":\n        state_dict = yaml.load(state_yaml, Loader=yaml.SafeLoader)\n        return MoleculeTransformer.from_state_dict(state_dict, override_args=override_args)\n\n    @staticmethod\n    def from_state_json_file(\n        filepath: Union[str, Path],\n        override_args: Optional[dict] = None,\n    ) -&gt; \"MoleculeTransformer\":\n        with fsspec.open(filepath, \"r\") as f:\n            featurizer = MoleculeTransformer.from_state_json(f.read(), override_args=override_args)  # type: ignore\n        return featurizer\n\n    @staticmethod\n    def from_state_yaml_file(\n        filepath: Union[str, Path],\n        override_args: Optional[dict] = None,\n    ) -&gt; \"MoleculeTransformer\":\n        with fsspec.open(filepath, \"r\") as f:\n            featurizer = MoleculeTransformer.from_state_yaml(f.read(), override_args=override_args)  # type: ignore\n        return featurizer\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the list of columns for this molecular descriptor</p> <p>Returns:</p> Name Type Description <code>columns</code> <code>list</code> <p>Name of the columns of the descriptor</p>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.__call__","title":"<code>__call__(mols, enforce_dtype=True, ignore_errors=False, **kwargs)</code>","text":"<p>Calculate features for molecules. Using call, instead of transform. If ignore_error is True, a list of features and valid ids are returned. Note that most Transfomers allow you to specify a return datatype.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>Mol or SMILES of the molecules to be transformed</p> required <code>enforce_dtype</code> <code>bool</code> <p>whether to enforce the instance dtype in the generated fingerprint</p> <code>True</code> <code>ignore_errors</code> <code>bool</code> <p>Whether to ignore errors during featurization or raise an error.</p> <code>False</code> <code>kwargs</code> <p>Named parameters for the transform method</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>feats</code> <p>list of valid features</p> <code>ids</code> <p>all valid molecule positions that did not failed during featurization. Only returned when ignore_errors is True.</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def __call__(\n    self,\n    mols: List[Union[dm.Mol, str]],\n    enforce_dtype: bool = True,\n    ignore_errors: bool = False,\n    **kwargs,\n):\n    r\"\"\"\n    Calculate features for molecules. Using __call__, instead of transform.\n    If ignore_error is True, a list of features and valid ids are returned.\n    Note that most Transfomers allow you to specify\n    a return datatype.\n\n    Args:\n        mols:  Mol or SMILES of the molecules to be transformed\n        enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n        ignore_errors: Whether to ignore errors during featurization or raise an error.\n        kwargs: Named parameters for the transform method\n\n    Returns:\n        feats: list of valid features\n        ids: all valid molecule positions that did not failed during featurization.\n            Only returned when ignore_errors is True.\n\n    \"\"\"\n    features = self.transform(mols, ignore_errors=ignore_errors, enforce_dtype=False, **kwargs)\n    ids = np.arange(len(features))\n    if ignore_errors:\n        features, ids = self._filter_none(features)\n    if self.dtype is not None and enforce_dtype:\n        features = datatype.cast(features, dtype=self.dtype, columns=self.columns)\n    if not ignore_errors:\n        return features\n    return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.__init__","title":"<code>__init__(featurizer, n_jobs=1, verbose=False, dtype=None, parallel_kwargs=None, **params)</code>","text":"<p>Mol transformer base class</p> <p>Parameters:</p> Name Type Description Default <code>featurizer</code> <code>Union[str, Callable]</code> <p>featurizer to use</p> required <code>n_jobs</code> <code>int</code> <p>Number of job to run in parallel. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Verbosity level. Defaults to True.</p> <code>False</code> <code>dtype</code> <code>callable</code> <p>Output data type. Defaults to None, where numpy arrays are returned.</p> <code>None</code> <code>parallel_kwargs</code> <code>dict</code> <p>Optional kwargs to pass to the dm.parallelized function. Defaults to None.</p> <code>None</code> Source code in <code>molfeat/trans/base.py</code> <pre><code>def __init__(\n    self,\n    featurizer: Union[str, Callable],\n    n_jobs: int = 1,\n    verbose: bool = False,\n    dtype: Optional[Union[str, Callable]] = None,\n    parallel_kwargs: Optional[Dict[str, Any]] = None,\n    **params,\n):\n    \"\"\"Mol transformer base class\n\n    Args:\n        featurizer: featurizer to use\n        n_jobs (int, optional): Number of job to run in parallel. Defaults to 1.\n        verbose (bool, optional): Verbosity level. Defaults to True.\n        dtype (callable, optional): Output data type. Defaults to None, where numpy arrays are returned.\n        parallel_kwargs (dict, optional): Optional kwargs to pass to the dm.parallelized function. Defaults to None.\n\n    \"\"\"\n    super().__init__(\n        n_jobs=n_jobs,\n        verbose=verbose,\n        dtype=dtype,\n        featurizer=featurizer,\n        parallel_kwargs=parallel_kwargs,\n        **params,\n    )\n    if callable(featurizer):\n        self.featurizer = featurizer\n    else:\n        self.featurizer = get_calculator(featurizer, **params)\n\n    self.cols_to_keep = None\n    self._fitted = False\n\n    self._save_input_args()\n    if self.featurizer and not (\n        isinstance(self.featurizer, str) or is_callable(self.featurizer)\n    ):\n        raise AttributeError(f\"Featurizer {self.featurizer} must be a callable or a string\")\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.__len__","title":"<code>__len__()</code>","text":"<p>Compute featurizer length</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def __len__(self):\n    \"\"\"Compute featurizer length\"\"\"\n\n    # check length and _length attribute\n    cols_to_keep = getattr(self, \"cols_to_keep\", None)\n    cur_length = None\n\n    if cols_to_keep is not None:\n        cur_length = len(cols_to_keep)\n    else:\n        cur_length = getattr(self, \"length\", getattr(self, \"_length\", None))\n        # then check the featurizer length if it's a callable and not a string/None\n        if (\n            cur_length is None\n            and callable(self.featurizer)\n            and hasattr(self.featurizer, \"__len__\")\n        ):\n            cur_length = len(self.featurizer)\n\n    if cur_length is None:\n        raise ValueError(\n            f\"Cannot auto-determine length of this MolTransformer: {self.__class__.__name__}\"\n        )\n\n    return cur_length\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.batch_transform","title":"<code>batch_transform(transformer, mols, batch_size=256, n_jobs=None, concatenate=True, progress=True, leave_progress=False, **parallel_kwargs)</code>  <code>staticmethod</code>","text":"<p>Batched computation of featurization of a list of molecules</p> <p>Parameters:</p> Name Type Description Default <code>transformer</code> <code>Callable</code> <p>Fingerprint transformer</p> required <code>mols</code> <code>List[Union[Mol, str]]</code> <p>List of molecules to featurize</p> required <code>batch_size</code> <code>int</code> <p>Batch size</p> <code>256</code> <code>n_jobs</code> <code>Optional[int]</code> <p>number of jobs to run in parallel</p> <code>None</code> <code>concatenate</code> <code>bool</code> <p>Whether to concatenate the results or return the list of batched results</p> <code>True</code> <code>progress</code> <code>bool</code> <p>whether to show progress bar</p> <code>True</code> <code>leave_progress</code> <code>bool</code> <p>whether to leave progress bar after completion</p> <code>False</code> <code>parallel_kwargs</code> <p>additional arguments to pass to dm.parallelized</p> <code>{}</code> <p>Returns:</p> Type Description <p>List of batches</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>@staticmethod\ndef batch_transform(\n    transformer: Callable,\n    mols: List[Union[dm.Mol, str]],\n    batch_size: int = 256,\n    n_jobs: Optional[int] = None,\n    concatenate: bool = True,\n    progress: bool = True,\n    leave_progress: bool = False,\n    **parallel_kwargs,\n):\n    \"\"\"\n    Batched computation of featurization of a list of molecules\n\n    Args:\n        transformer: Fingerprint transformer\n        mols: List of molecules to featurize\n        batch_size: Batch size\n        n_jobs: number of jobs to run in parallel\n        concatenate: Whether to concatenate the results or return the list of batched results\n        progress: whether to show progress bar\n        leave_progress: whether to leave progress bar after completion\n        parallel_kwargs: additional arguments to pass to dm.parallelized\n\n    Returns:\n        List of batches\n    \"\"\"\n\n    step_size = int(np.ceil(len(mols) / batch_size))\n    batched_mols = np.array_split(mols, step_size)\n\n    tqdm_kwargs = parallel_kwargs.setdefault(\"tqdm_kwargs\", {})\n    tqdm_kwargs.update(leave=leave_progress, desc=\"Batch compute:\")\n    parallel_kwargs[\"tqdm_kwargs\"] = tqdm_kwargs\n\n    # it's recommended to use a precomputed molecule transformer\n    # instead of the internal cache for pretrained models\n    cache_attr = \"cache\"\n    existing_cache = getattr(transformer, cache_attr, None)\n    if existing_cache is None:\n        cache_attr = \"precompute_cache\"\n        existing_cache = getattr(transformer, cache_attr, None)\n\n    use_mp_cache = (\n        existing_cache is not None\n        and not isinstance(existing_cache, MPDataCache)\n        and n_jobs not in [None, 0, 1]  # this is based on datamol sequential vs parallel\n    )\n    if use_mp_cache:\n        # we need to change the cache system to one that works with multiprocessing\n        # to have a shared memory\n        new_cache = MPDataCache()\n        new_cache.update(existing_cache)\n        setattr(transformer, cache_attr, new_cache)\n\n    transformed = dm.parallelized(\n        transformer,\n        batched_mols,\n        n_jobs=n_jobs,\n        progress=progress,\n        **parallel_kwargs,\n    )\n    if use_mp_cache:\n        # we set back the original transformation while updating it with\n        # all the missing values\n        existing_cache.update(getattr(transformer, cache_attr, {}))\n        setattr(transformer, cache_attr, existing_cache)\n\n    if concatenate:\n        # if we ask for concatenation, then we would need to fix None values ideally\n        fixed_transformations = []\n        for computed_trans in transformed:\n            if computed_trans is None:\n                computed_trans = np.full(len(computed_trans), len(transformer), np.nan)\n            else:\n                for i, x in enumerate(computed_trans):\n                    if x is None:\n                        computed_trans[i] = np.full(len(transformer), np.nan)\n            fixed_transformations.append(computed_trans)\n        return np.concatenate(fixed_transformations)\n    return transformed\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.fit","title":"<code>fit(X, y=None, **fit_params)</code>","text":"<p>Fit the current transformer on given dataset.</p> <p>The goal of fitting is for example to identify nan columns values that needs to be removed from the dataset</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>List[Union[Mol, str]]</code> <p>input list of molecules</p> required <code>y</code> <code>list</code> <p>Optional list of molecular properties. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <p>MolTransformer instance after fitting</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def fit(self, X: List[Union[dm.Mol, str]], y: Optional[list] = None, **fit_params):\n    \"\"\"Fit the current transformer on given dataset.\n\n    The goal of fitting is for example to identify nan columns values\n    that needs to be removed from the dataset\n\n    Args:\n        X: input list of molecules\n        y (list, optional): Optional list of molecular properties. Defaults to None.\n\n    Returns:\n        self: MolTransformer instance after fitting\n    \"\"\"\n    feats = self.transform(X, ignore_errors=True)\n    lengths = [len(x) for x in feats if not datatype.is_null(x)]\n    if lengths:\n        # we will ignore all nan\n        feats = datatype.to_numpy([f for f in feats if not datatype.is_null(f)])\n        self.cols_to_keep = (~np.any(np.isnan(feats), axis=0)).nonzero()[0]\n    self._fitted = True\n    return self\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.from_state_dict","title":"<code>from_state_dict(state, override_args=None)</code>  <code>staticmethod</code>","text":"<p>Reload a featurizer from a state dict.</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>@staticmethod\ndef from_state_dict(state: dict, override_args: Optional[dict] = None) -&gt; \"MoleculeTransformer\":\n    \"\"\"Reload a featurizer from a state dict.\"\"\"\n\n    # Don't alter the original state dict\n    state = copy.deepcopy(state)\n\n    # MoleculeTransformer is a special case that has his own logic\n    if state[\"name\"] == \"PrecomputedMolTransformer\":\n        return PrecomputedMolTransformer.from_state_dict(\n            state=state,\n            override_args=override_args,\n        )\n\n    # Get the name\n    transformer_class = _TRANSFORMERS.get(state[\"name\"])\n    if transformer_class is None:\n        raise ValueError(f\"The featurizer '{state['name']}' is not supported.\")\n    if isinstance(transformer_class, str):\n        # Get the transformer class from its path\n        transformer_class = import_from_string(transformer_class)\n\n    # Process the state as needed\n    args = state.get(\"args\", {})\n\n    # Deal with dtype\n    if \"dtype\" in args and isinstance(args[\"dtype\"], str):\n        args[\"dtype\"] = map_dtype(args[\"dtype\"])\n\n    ## Deal with graph atom/bond featurizers\n    if args.get(\"atom_featurizer\") is not None:\n        if not args.get(\"_atom_featurizer_is_pickled\"):\n            klass_name = args[\"atom_featurizer\"].get(\"name\")\n            args[\"atom_featurizer\"] = ATOM_FEATURIZER_MAPPING_REVERSE[\n                klass_name\n            ].from_state_dict(args[\"atom_featurizer\"])\n        else:\n            # buffer = io.BytesIO(bytes.fromhex(args[\"atom_featurizer\"]))\n            # args[\"atom_featurizer\"] = joblib.load(buffer)\n            args[\"atom_featurizer\"] = hex_to_fn(args[\"atom_featurizer\"])\n        args.pop(\"_atom_featurizer_is_pickled\", None)\n    if args.get(\"bond_featurizer\") is not None:\n        if not args.get(\"_bond_featurizer_is_pickled\"):\n            klass_name = args[\"bond_featurizer\"].get(\"name\")\n            args[\"bond_featurizer\"] = BOND_FEATURIZER_MAPPING_REVERSE[\n                klass_name\n            ].from_state_dict(args[\"bond_featurizer\"])\n        else:\n            args[\"bond_featurizer\"] = hex_to_fn(args[\"bond_featurizer\"])\n        args.pop(\"_bond_featurizer_is_pickled\", None)\n    ## Deal with custom featurizer\n    if \"featurizer\" in args:\n        if args.get(\"_featurizer_is_pickled\") is True:\n            args[\"featurizer\"] = hex_to_fn(args[\"featurizer\"])\n            args.pop(\"_featurizer_is_pickled\")\n        elif (\n            isinstance(args[\"featurizer\"], Mapping)\n            and args[\"featurizer\"].get(\"name\") in _CALCULATORS\n        ):\n            # we have found a known calculator\n            klass_name = args[\"featurizer\"].get(\"name\")\n            args[\"featurizer\"] = _CALCULATORS[klass_name].from_state_dict(args[\"featurizer\"])\n            args.pop(\"_featurizer_is_pickled\")\n\n    if override_args is not None:\n        args.update(override_args)\n\n    # Create the transformer\n    featurizer = transformer_class(**args)\n    return featurizer\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Serialize the featurizer to a state dict.</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def to_state_dict(self) -&gt; dict:\n    \"\"\"Serialize the featurizer to a state dict.\"\"\"\n\n    if getattr(self, \"_input_args\") is None:\n        raise ValueError(f\"Cannot save state for this transformer '{self.__class__.__name__}'\")\n\n    # Process the input arguments before building the state\n    args = copy.deepcopy(self._input_args)\n\n    # Deal with dtype\n    if \"dtype\" in args and not isinstance(args[\"dtype\"], str):\n        args[\"dtype\"] = map_dtype(args[\"dtype\"])\n\n    ## Deal with graph atom/bond featurizers\n    # NOTE(hadim): it's important to highlight that atom/bond featurizers can't be\n    # customized with this logic.\n    if args.get(\"atom_featurizer\") is not None:\n        if hasattr(args.get(\"atom_featurizer\"), \"to_state_dict\"):\n            args[\"atom_featurizer\"] = args[\"atom_featurizer\"].to_state_dict()\n            args[\"_atom_featurizer_is_pickled\"] = False\n        else:\n            logger.warning\n            (\n                \"You are attempting to pickle an atom featurizer without a `to_state_dict` function into a hex string\"\n            )\n            args[\"atom_featurizer\"] = fn_to_hex(args[\"atom_featurizer\"])\n            args[\"_atom_featurizer_is_pickled\"] = True\n\n    # deal with bond featurizer\n    if args.get(\"bond_featurizer\") is not None:\n        if hasattr(args.get(\"bond_featurizer\"), \"to_state_dict\"):\n            args[\"bond_featurizer\"] = args[\"bond_featurizer\"].to_state_dict()\n            args[\"_bond_featurizer_is_pickled\"] = False\n        else:\n            logger.warning(\n                \"You are attempting to pickle a bond featurizer without a `to_state_dict` function into a hex string\"\n            )\n            args[\"bond_featurizer\"] = fn_to_hex(args[\"bond_featurizer\"])\n            args[\"_bond_featurizer_is_pickled\"] = True\n\n    ## Deal with custom featurizer\n    if \"featurizer\" in args and isinstance(args[\"featurizer\"], Callable):\n        if hasattr(args[\"featurizer\"], \"to_state_dict\"):\n            args[\"featurizer\"] = args[\"featurizer\"].to_state_dict()\n            args[\"_featurizer_is_pickled\"] = False\n        else:\n            logger.warning(\n                \"You are attempting to pickle a callable without a `to_state_dict` function into a hex string\"\n            )\n            args[\"featurizer\"] = fn_to_hex(args[\"featurizer\"])\n            args[\"_featurizer_is_pickled\"] = True\n\n    # Build the state\n    state = {}\n    state[\"name\"] = self.__class__.__name__\n    state[\"args\"] = args\n    state[\"_molfeat_version\"] = MOLFEAT_VERSION\n    return state\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.MoleculeTransformer.transform","title":"<code>transform(mols, ignore_errors=False, **kwargs)</code>","text":"<p>Compute the features for a set of molecules.</p> <p>Note</p> <p>Note that depending on the <code>ignore_errors</code> argument, all failed featurization (caused whether by invalid smiles or error during data transformation) will be substitued by None features for the corresponding molecule. This is done, so you can find the positions of these molecules and filter them out according to your own logic.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>a list containing smiles or mol objects</p> required <code>ignore_errors</code> <code>bool</code> <p>Whether to silently ignore errors</p> <code>False</code> <p>Returns:</p> Name Type Description <code>features</code> <p>a list of features for each molecule in the input set</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def transform(\n    self,\n    mols: List[Union[dm.Mol, str]],\n    ignore_errors: bool = False,\n    **kwargs,\n):\n    r\"\"\"\n    Compute the features for a set of molecules.\n\n    !!! note\n        Note that depending on the `ignore_errors` argument, all failed\n        featurization (caused whether by invalid smiles or error during\n        data transformation) will be substitued by None features for the\n        corresponding molecule. This is done, so you can find the positions\n        of these molecules and filter them out according to your own logic.\n\n    Args:\n        mols: a list containing smiles or mol objects\n        ignore_errors (bool, optional): Whether to silently ignore errors\n\n\n    Returns:\n        features: a list of features for each molecule in the input set\n    \"\"\"\n    # Convert single mol to iterable format\n    if isinstance(mols, pd.DataFrame):\n        mols = mols[mols.columns[0]]\n    if isinstance(mols, (str, dm.Mol)) or not isinstance(mols, Iterable):\n        mols = [mols]\n\n    def _to_mol(x):\n        return dm.to_mol(x) if x else None\n\n    parallel_kwargs = getattr(self, \"parallel_kwargs\", {})\n\n    if hasattr(self.featurizer, \"batch_compute\") and callable(self.featurizer.batch_compute):\n        # this calculator can be batched which will be faster\n        features = self.featurizer.batch_compute(mols, n_jobs=self.n_jobs, **parallel_kwargs)\n    else:\n        mols = dm.parallelized(_to_mol, mols, n_jobs=self.n_jobs, **parallel_kwargs)\n        if self.n_jobs not in [0, 1]:\n            # use a proxy model to run in parallel\n            cpy = self.copy()\n            features = dm.parallelized(\n                cpy._transform,\n                mols,\n                n_jobs=self.n_jobs,\n                **cpy.parallel_kwargs,\n            )\n        else:\n            features = [self._transform(mol) for mol in mols]\n    if not ignore_errors:\n        for ind, feat in enumerate(features):\n            if feat is None:\n                raise ValueError(\n                    f\"Cannot transform molecule at index {ind}. Please check logs (set verbose to True) to see errors!\"\n                )\n\n    # sklearn feature validation for sklearn pipeline\n    return datatype.as_numpy_array_if_possible(features, self.dtype)\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.PrecomputedMolTransformer","title":"<code>PrecomputedMolTransformer</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>Convenience class for storing precomputed features.</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>class PrecomputedMolTransformer(MoleculeTransformer):\n    \"\"\"Convenience class for storing precomputed features.\"\"\"\n\n    def __init__(\n        self,\n        cache: Optional[Union[_Cache, Mapping[Any, Any], CacheList]] = None,\n        cache_dict: Optional[Dict[str, Union[_Cache, Mapping[Any, Any], CacheList]]] = None,\n        cache_key: Optional[str] = None,\n        *args,\n        featurizer: Optional[Union[MoleculeTransformer, str]] = None,\n        state_path: Optional[str] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Transformer that supports precomputation of features. You can either pass an empty cache or a pre-populated cache\n\n        Args:\n            cache: a datastructure of type mapping that maps each molecule to the precomputed features\n            cache_dict: A dictionary of cache objects. This is a convenient structure when use multiple\n                datacache for model selection.\n            cache_key: The key of cache object to use.\n            featurizer: optional featurizer used to compute the features of values not in the cache.\n                Either the featurizer object or a string.\n            state_path: optional state file path used to initiate the transformer object at the initialization\n        \"\"\"\n        if (state_path is not None) and (\n            (cache is not None) or (cache_dict is not None and cache_key is not None)\n        ):\n            raise ValueError(\n                \"`PrecomputedMolTransformer` can only be initiated by either `state_path` or\"\n                \" the rest of parameters for cache and featurizer. But both are given.\"\n            )\n\n        super().__init__(*args, featurizer=\"none\", **kwargs)\n\n        if state_path is not None:\n            self.__dict__ = self.from_state_file(state_path=state_path).__dict__.copy()\n        else:\n            if cache_dict is not None and cache_key is not None:\n                self.cache_key = cache_key\n                self.cache = cache_dict[self.cache_key]\n            elif cache is not None:\n                self.cache = cache\n            else:\n                raise AttributeError(\"The cache is not specified.\")\n\n            if isinstance(featurizer, str):\n                self.base_featurizer = MoleculeTransformer(featurizer, *args, **kwargs)\n            else:\n                self.base_featurizer = featurizer\n\n        # Set the length of the featurizer\n        if len(self.cache) &gt; 0:\n            self.length = len(list(self.cache.values())[0])\n        elif self.base_featurizer is not None:\n            self.length = len(self.base_featurizer)\n        else:\n            raise AttributeError(\n                \"The cache is empty and the base featurizer is not specified. It's impossible\"\n                \" to determine the length of the featurizer.\"\n            )\n\n    def _transform(self, mol: dm.Mol):\n        r\"\"\"\n        Return precomputed feature for a single molecule\n\n        Args:\n            mol (dm.Mol): molecule to transform into features\n\n        Returns\n            feat: featurized input molecule\n\n        \"\"\"\n        feat = self.cache.get(mol)\n        # if feat is None and we have an existing featurizer, we can update the cache\n        if feat is None and self.base_featurizer is not None:\n            feat = self.base_featurizer._transform(mol)\n            self.cache[mol] = feat\n\n        try:\n            feat = datatype.to_numpy(feat)\n            if self.cols_to_keep is not None:\n                feat = feat[self.cols_to_keep]\n        except Exception as e:\n            if self.verbose:\n                logger.error(e)\n        return feat\n\n    def update(self, feat_dict: Mapping[Any, Any]):\n        r\"\"\"\n        Fill the cache with new set of features for the molecules in mols.\n\n        Args:\n            feat_dict: A dictionary of molecules to features.\n        \"\"\"\n        self.cache.update(feat_dict)\n\n    def __getstate__(self):\n        \"\"\"Get the state for pickling\"\"\"\n        state = {k: copy.deepcopy(v) for k, v in self.__dict__.items() if k not in [\"cache\"]}\n        if isinstance(self.cache, FileCache):\n            state[\"file_cache_args\"] = dict(\n                cache_file=self.cache.cache_file,\n                name=self.cache.name,\n                mol_hasher=self.cache.mol_hasher,\n                n_jobs=self.cache.n_jobs,\n                verbose=self.cache.verbose,\n                file_type=self.cache.file_type,\n                parquet_kwargs=self.cache.parquet_kwargs,\n            )\n        else:\n            # EN: we do not copy the cache\n            state[\"cache\"] = self.cache\n        return state\n\n    def __setstate__(self, state):\n        if \"file_cache_args\" in state:\n            cache = FileCache(**state.pop(\"file_cache_args\"))\n            state[\"cache\"] = cache\n        return super().__setstate__(state)\n\n    def to_state_dict(self, save_to_file: bool = True) -&gt; dict:\n        \"\"\"Serialize a PrecomputedMolTransformer object to a state dict.\n\n        Notes:\n            - The base_featurizer must be set or a ValueError will be raised.\n            - The cache must be a FileCache object or a ValueError will be raised.\n\n        Args:\n            save_to_file: whether to save the cache to file.\n        \"\"\"\n\n        if self.base_featurizer is None:\n            raise ValueError(\n                \"You can't serialize a PrecomputedMolTransformer that does not contain a\"\n                \" featurizer.\"\n            )\n\n        if not isinstance(self.cache, FileCache):\n            raise ValueError(\"The cache must be a FileCache object.\")\n\n        state = {}\n        state[\"name\"] = \"PrecomputedMolTransformer\"\n        state[\"base_featurizer\"] = self.base_featurizer.to_state_dict()\n        state[\"cache\"] = self.cache.to_state_dict(save_to_file=save_to_file)\n        state[\"_molfeat_version\"] = MOLFEAT_VERSION\n\n        return state\n\n    @staticmethod\n    def from_state_dict(\n        state: dict,\n        override_args: Optional[dict] = None,\n    ) -&gt; \"PrecomputedMolTransformer\":\n        # Don't alter the original state dict\n        state = copy.deepcopy(state)\n\n        args = {}\n\n        # Load the FileCache object\n        args[\"cache\"] = FileCache.from_state_dict(state[\"cache\"])\n\n        # Load the base featurizer\n        args[\"featurizer\"] = MoleculeTransformer.from_state_dict(state[\"base_featurizer\"])\n\n        if override_args is not None:\n            args.update(override_args)\n\n        # Doesn't allow state_path in the initiation args\n        args.pop(\"state_path\", None)\n        return PrecomputedMolTransformer(**args)\n\n    def from_state_file(\n        self,\n        state_path: str,\n        override_args: Optional[dict] = None,\n    ) -&gt; \"PrecomputedMolTransformer\":\n        if state_path.endswith(\"yaml\") or state_path.endswith(\"yml\"):\n            return self.from_state_yaml_file(filepath=state_path, override_args=override_args)\n        elif state_path.endswith(\"json\"):\n            return self.from_state_json_file(filepath=state_path, override_args=override_args)\n        else:\n            raise ValueError(\n                \"Only files with 'yaml' or 'json' format are allowed. \"\n                \"The filename must be ending with `yaml`, 'yml' or 'json'.\"\n            )\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.PrecomputedMolTransformer.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Get the state for pickling</p> Source code in <code>molfeat/trans/base.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Get the state for pickling\"\"\"\n    state = {k: copy.deepcopy(v) for k, v in self.__dict__.items() if k not in [\"cache\"]}\n    if isinstance(self.cache, FileCache):\n        state[\"file_cache_args\"] = dict(\n            cache_file=self.cache.cache_file,\n            name=self.cache.name,\n            mol_hasher=self.cache.mol_hasher,\n            n_jobs=self.cache.n_jobs,\n            verbose=self.cache.verbose,\n            file_type=self.cache.file_type,\n            parquet_kwargs=self.cache.parquet_kwargs,\n        )\n    else:\n        # EN: we do not copy the cache\n        state[\"cache\"] = self.cache\n    return state\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.PrecomputedMolTransformer.__init__","title":"<code>__init__(cache=None, cache_dict=None, cache_key=None, *args, featurizer=None, state_path=None, **kwargs)</code>","text":"<p>Transformer that supports precomputation of features. You can either pass an empty cache or a pre-populated cache</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Optional[Union[_Cache, Mapping[Any, Any], CacheList]]</code> <p>a datastructure of type mapping that maps each molecule to the precomputed features</p> <code>None</code> <code>cache_dict</code> <code>Optional[Dict[str, Union[_Cache, Mapping[Any, Any], CacheList]]]</code> <p>A dictionary of cache objects. This is a convenient structure when use multiple datacache for model selection.</p> <code>None</code> <code>cache_key</code> <code>Optional[str]</code> <p>The key of cache object to use.</p> <code>None</code> <code>featurizer</code> <code>Optional[Union[MoleculeTransformer, str]]</code> <p>optional featurizer used to compute the features of values not in the cache. Either the featurizer object or a string.</p> <code>None</code> <code>state_path</code> <code>Optional[str]</code> <p>optional state file path used to initiate the transformer object at the initialization</p> <code>None</code> Source code in <code>molfeat/trans/base.py</code> <pre><code>def __init__(\n    self,\n    cache: Optional[Union[_Cache, Mapping[Any, Any], CacheList]] = None,\n    cache_dict: Optional[Dict[str, Union[_Cache, Mapping[Any, Any], CacheList]]] = None,\n    cache_key: Optional[str] = None,\n    *args,\n    featurizer: Optional[Union[MoleculeTransformer, str]] = None,\n    state_path: Optional[str] = None,\n    **kwargs,\n):\n    \"\"\"\n    Transformer that supports precomputation of features. You can either pass an empty cache or a pre-populated cache\n\n    Args:\n        cache: a datastructure of type mapping that maps each molecule to the precomputed features\n        cache_dict: A dictionary of cache objects. This is a convenient structure when use multiple\n            datacache for model selection.\n        cache_key: The key of cache object to use.\n        featurizer: optional featurizer used to compute the features of values not in the cache.\n            Either the featurizer object or a string.\n        state_path: optional state file path used to initiate the transformer object at the initialization\n    \"\"\"\n    if (state_path is not None) and (\n        (cache is not None) or (cache_dict is not None and cache_key is not None)\n    ):\n        raise ValueError(\n            \"`PrecomputedMolTransformer` can only be initiated by either `state_path` or\"\n            \" the rest of parameters for cache and featurizer. But both are given.\"\n        )\n\n    super().__init__(*args, featurizer=\"none\", **kwargs)\n\n    if state_path is not None:\n        self.__dict__ = self.from_state_file(state_path=state_path).__dict__.copy()\n    else:\n        if cache_dict is not None and cache_key is not None:\n            self.cache_key = cache_key\n            self.cache = cache_dict[self.cache_key]\n        elif cache is not None:\n            self.cache = cache\n        else:\n            raise AttributeError(\"The cache is not specified.\")\n\n        if isinstance(featurizer, str):\n            self.base_featurizer = MoleculeTransformer(featurizer, *args, **kwargs)\n        else:\n            self.base_featurizer = featurizer\n\n    # Set the length of the featurizer\n    if len(self.cache) &gt; 0:\n        self.length = len(list(self.cache.values())[0])\n    elif self.base_featurizer is not None:\n        self.length = len(self.base_featurizer)\n    else:\n        raise AttributeError(\n            \"The cache is empty and the base featurizer is not specified. It's impossible\"\n            \" to determine the length of the featurizer.\"\n        )\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.PrecomputedMolTransformer.to_state_dict","title":"<code>to_state_dict(save_to_file=True)</code>","text":"<p>Serialize a PrecomputedMolTransformer object to a state dict.</p> Notes <ul> <li>The base_featurizer must be set or a ValueError will be raised.</li> <li>The cache must be a FileCache object or a ValueError will be raised.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>save_to_file</code> <code>bool</code> <p>whether to save the cache to file.</p> <code>True</code> Source code in <code>molfeat/trans/base.py</code> <pre><code>def to_state_dict(self, save_to_file: bool = True) -&gt; dict:\n    \"\"\"Serialize a PrecomputedMolTransformer object to a state dict.\n\n    Notes:\n        - The base_featurizer must be set or a ValueError will be raised.\n        - The cache must be a FileCache object or a ValueError will be raised.\n\n    Args:\n        save_to_file: whether to save the cache to file.\n    \"\"\"\n\n    if self.base_featurizer is None:\n        raise ValueError(\n            \"You can't serialize a PrecomputedMolTransformer that does not contain a\"\n            \" featurizer.\"\n        )\n\n    if not isinstance(self.cache, FileCache):\n        raise ValueError(\"The cache must be a FileCache object.\")\n\n    state = {}\n    state[\"name\"] = \"PrecomputedMolTransformer\"\n    state[\"base_featurizer\"] = self.base_featurizer.to_state_dict()\n    state[\"cache\"] = self.cache.to_state_dict(save_to_file=save_to_file)\n    state[\"_molfeat_version\"] = MOLFEAT_VERSION\n\n    return state\n</code></pre>"},{"location":"api/molfeat.trans.base.html#molfeat.trans.base.PrecomputedMolTransformer.update","title":"<code>update(feat_dict)</code>","text":"<p>Fill the cache with new set of features for the molecules in mols.</p> <p>Parameters:</p> Name Type Description Default <code>feat_dict</code> <code>Mapping[Any, Any]</code> <p>A dictionary of molecules to features.</p> required Source code in <code>molfeat/trans/base.py</code> <pre><code>def update(self, feat_dict: Mapping[Any, Any]):\n    r\"\"\"\n    Fill the cache with new set of features for the molecules in mols.\n\n    Args:\n        feat_dict: A dictionary of molecules to features.\n    \"\"\"\n    self.cache.update(feat_dict)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html","title":"molfeat.trans.concat","text":""},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat","title":"<code>FeatConcat</code>","text":"<p>               Bases: <code>list</code>, <code>BaseEstimator</code></p> <p>Concatenation container for <code>FPVecTransformer</code>. This class allows merging multiple fingerprints into a single one. It gives the ability to call the following methods     - <code>fit</code>     - <code>transform</code>     - <code>fit_transform</code> on a list of transformers and concatenate the results.</p> <p>Note</p> <p>The featurization length of this featurizer is accessible via the <code>length</code> property. <code>len()</code> will return the number of base featurizer.</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>class FeatConcat(list, BaseEstimator):\n    r\"\"\"\n    Concatenation container for `FPVecTransformer`. This class allows\n    merging multiple fingerprints into a single one.\n    It gives the ability to call the following methods\n        - `fit`\n        - `transform`\n        - `fit_transform`\n    on a list of transformers and concatenate the results.\n\n    !!! note\n        The featurization length of this featurizer is accessible via the `length` property.\n        `len()` will return the number of base featurizer.\n    \"\"\"\n\n    _STR_DELIMITER = \"||\"\n\n    def __init__(\n        self,\n        iterable: Optional[Union[Iterable, str]] = None,\n        dtype: Optional[Callable] = None,\n        params: Optional[Dict[str, Any]] = None,\n        collate_fn: Optional[Callable] = None,\n    ):\n        \"\"\"Featurizer concatenator\n\n        Args:\n            iterable: List of featurizer to concatenate.\n            dtype: Datatype of the computed fingerprint\n            params: Optional dictionary of parameters for the featurizers when there is a need for initializing them\n            collate_fn: optional function to provide for custom collating.\n                By default the collate function will be None, which will use the torch default\n        \"\"\"\n        super().__init__()\n        self.params = params or {}\n        if isinstance(iterable, str):\n            iterable = [x.strip() for x in iterable.split(self._STR_DELIMITER)]\n        if iterable is not None:\n            for item in iterable:\n                if isinstance(item, str):\n                    item = FPVecTransformer(kind=item, **self.params.get(item, {}))\n                self.append(item)\n        self.dtype = dtype\n        self._length = None\n        self.collate_fn = collate_fn\n\n    def append(self, item):\n        r\"\"\"Override the ``append`` to accept only ``FPVecTransformer``\"\"\"\n        self._check_supported(item)\n        super().append(item)\n\n    def insert(self, index, item):\n        r\"\"\"Override the ``insert`` to accept only ``BaseFeaturizer``\"\"\"\n        self._check_suported(item)\n        super().insert(index, item)\n\n    def __add__(self, item):\n        \"\"\"Override the `__add__` method\"\"\"\n        self._check_supported(item)\n        super().__add__(item)\n\n    def __setitem__(self, index, value):\n        \"\"\"Override the `__setitem__`  method\"\"\"\n        self._check_supported(value)\n        super().__setitem__(index, value)\n\n    @property\n    def length(self):\n        \"\"\"\n        Length property for Feat concatenation.  This is the sum of the length of each transformer.\n        Note that __len__ returns the number of base featurizer here instead.\n        \"\"\"\n        if self._length is None:\n            full_length = 0\n            for feat in self:\n                if isinstance(feat, FeatConcat):\n                    full_length += feat.length\n                else:\n                    full_length += len(feat)\n            self._length = full_length\n        return self._length\n\n    def _check_supported(self, item):\n        r\"\"\"Check if the item is the right type\"\"\"\n        if not isinstance(item, FPVecTransformer):\n            raise ValueError(\"FPVecTransformer allowed only, provided {}\".format(type(item)))\n\n    def get_collate_fn(self, *args, **kwargs):\n        \"\"\"\n        Get collate function of this featurizer. The FeatConcat featurizer use the default\n        collate function which does not do anything.\n\n        Returns:\n            fn: Collate function for pytorch or None\n        \"\"\"\n        return getattr(self, \"collate_fn\", None)\n\n    def iter_index(self, indexes: Union[int, Iterator[int]]):\n        r\"\"\"\n        Allow the `FeatConcat` to be indexed using a list, or any other iterable.\n\n        Args:\n            indexes: The indexes to index the ``FeatConcat``.\n\n        Returns\n            indexed_fpconcat: A new FeatConcat object with the indexed element\n        \"\"\"\n        if not isinstance(indexes, (list, tuple)):\n            try:\n                indexes = list(indexes)\n            except TypeError:\n                indexes = [indexes]\n        return FeatConcat([self[ii] for ii in indexes])\n\n    @property\n    def columns(self):\n        \"\"\"Get the list of columns for the concatenated molecules\n\n        Returns:\n            columns (list): Name of the columns of the descriptor\n        \"\"\"\n        tmp_mol = dm.to_mol(\"CC(C)O\")\n        columns = []\n        for fp in self:\n            fp_columns = getattr(fp, \"columns\", None)\n            fp_name = str(fp)\n            if fp_columns is None:\n                fp_out, _ = fp([tmp_mol])\n                fp_out = np.asarray(fp_out)\n                fp_columns = [f\"{fp_name}:{ind}\" for ind in range(fp_out.shape[-1])]\n            columns.extend(fp_columns)\n        return columns\n\n    def transform(self, mols: List[Union[dm.Mol, str]], **kwargs):\n        r\"\"\"\n        Calls the ``FPVecTransformer.transform`` for each transformer in\n        the current list, and concatenates the resulting fingerprints.\n\n        Args:\n            mols: List of SMILES or molecules\n            kwargs: named parameters for transform (see below)\n\n        Returns:\n            fps: Computed fingerprints of size NxD, where D is the\n                sum of the length of each transformer and N is the number of input\n                molecules that have been successfully featurized.\n        \"\"\"\n\n        fps = []\n        for _, fp_trans in enumerate(self):\n            out = fp_trans.transform(mols, enforce_dtype=False, **kwargs)\n            out = datatype.cast(out, dtype=\"pandas\")\n            fps.append(out)\n        fps = pd.concat(fps, axis=1)\n        fps.columns = self.columns\n        return fps.values\n\n    def __call__(\n        self,\n        mols: List[Union[dm.Mol, str]],\n        enforce_dtype: bool = False,\n        ignore_errors: bool = False,\n        **kwargs,\n    ):\n        r\"\"\"\n        Calls each of the internal transformer and concatenate results only on valid indices.\n\n        Args:\n            mols:  Mol or SMILES of the molecules to be transformed\n            enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n            ignore_errors: Whether to ignore errors during featurization or raise an error.\n            kwargs: Named parameters for the transform method\n\n        Returns:\n\n            fp: array\n                computed fingerprints of size NxD, where D is the\n                sum of the length of each transformer and N is the number of input\n                molecules that have been successfully featurized.\n            idx: array\n                Indices of successful featurization given the original molecule input.\n        \"\"\"\n\n        fps = []\n        valid_idx = np.zeros(len(mols))\n        for _, transf in enumerate(self):\n            fp = transf.transform(mols, ignore_errors=ignore_errors, **kwargs)\n            fp, idx = transf._filter_none(fp)\n            fps.append(fp)\n            valid_idx[idx] += 1  # increase counter of valids\n        valid_idx = np.nonzero(valid_idx == len(self))[0]\n        fps = np.concatenate(fps, axis=1)\n        if self.dtype is not None and enforce_dtype:\n            fps = datatype.cast(fps, dtype=self.dtype, columns=self.columns)\n        if not ignore_errors:\n            return fps\n        return fps, list(valid_idx)\n\n    def fit_transform(\n        self,\n        mols: List[Union[str, dm.Mol]],\n        y: Optional[Iterable] = None,\n        fit_kwargs: Dict = None,\n        trans_kwargs: Dict = None,\n    ):\n        r\"\"\"\n        Calls the ``self.fit`` followed by the ``fit.transform`` for each transfomer in\n        the current list, and concatenates the resulting fingerprints.\n\n        Args:\n            mols: List of SMILES or molecules\n            y: target for the fitting. Usually ignored for FPVecTransformer\n            fit_kwargs:  named parameters for fit\n            fit_kwargs:named parameters for transform\n\n        Returns:\n\n            fp: computed fingerprints of size NxD, where D is the\n                sum of the length of each transformer and N is the number of input\n                molecules that have been successfully featurized.\n        \"\"\"\n        fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n        trans_kwargs = {} if trans_kwargs is None else trans_kwargs\n        self.fit(mols, y=y, **fit_kwargs)\n        return self.transform(mols, **trans_kwargs)\n\n    def fit(self, X: List[Union[dm.Mol, str]], y=None, **kwargs):\n        r\"\"\"\n        Calls the ``FPVecTransformer.fit`` for each transformer in the current list.\n\n        Args:\n            X: input list of molecules\n            y (list, optional): Optional list of molecular properties. Defaults to None.\n\n        Returns:\n            self: FeatConcat instance after fitting\n        \"\"\"\n\n        for _, fp_trans in enumerate(self):\n            fp_trans.fit(X, y=y, **kwargs)\n        return self\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get the list of columns for the concatenated molecules</p> <p>Returns:</p> Name Type Description <code>columns</code> <code>list</code> <p>Name of the columns of the descriptor</p>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.length","title":"<code>length</code>  <code>property</code>","text":"<p>Length property for Feat concatenation.  This is the sum of the length of each transformer. Note that len returns the number of base featurizer here instead.</p>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.__add__","title":"<code>__add__(item)</code>","text":"<p>Override the <code>__add__</code> method</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def __add__(self, item):\n    \"\"\"Override the `__add__` method\"\"\"\n    self._check_supported(item)\n    super().__add__(item)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.__call__","title":"<code>__call__(mols, enforce_dtype=False, ignore_errors=False, **kwargs)</code>","text":"<p>Calls each of the internal transformer and concatenate results only on valid indices.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>Mol or SMILES of the molecules to be transformed</p> required <code>enforce_dtype</code> <code>bool</code> <p>whether to enforce the instance dtype in the generated fingerprint</p> <code>False</code> <code>ignore_errors</code> <code>bool</code> <p>Whether to ignore errors during featurization or raise an error.</p> <code>False</code> <code>kwargs</code> <p>Named parameters for the transform method</p> <code>{}</code> <p>Returns:</p> <pre><code>fp: array\n    computed fingerprints of size NxD, where D is the\n    sum of the length of each transformer and N is the number of input\n    molecules that have been successfully featurized.\nidx: array\n    Indices of successful featurization given the original molecule input.\n</code></pre> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def __call__(\n    self,\n    mols: List[Union[dm.Mol, str]],\n    enforce_dtype: bool = False,\n    ignore_errors: bool = False,\n    **kwargs,\n):\n    r\"\"\"\n    Calls each of the internal transformer and concatenate results only on valid indices.\n\n    Args:\n        mols:  Mol or SMILES of the molecules to be transformed\n        enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n        ignore_errors: Whether to ignore errors during featurization or raise an error.\n        kwargs: Named parameters for the transform method\n\n    Returns:\n\n        fp: array\n            computed fingerprints of size NxD, where D is the\n            sum of the length of each transformer and N is the number of input\n            molecules that have been successfully featurized.\n        idx: array\n            Indices of successful featurization given the original molecule input.\n    \"\"\"\n\n    fps = []\n    valid_idx = np.zeros(len(mols))\n    for _, transf in enumerate(self):\n        fp = transf.transform(mols, ignore_errors=ignore_errors, **kwargs)\n        fp, idx = transf._filter_none(fp)\n        fps.append(fp)\n        valid_idx[idx] += 1  # increase counter of valids\n    valid_idx = np.nonzero(valid_idx == len(self))[0]\n    fps = np.concatenate(fps, axis=1)\n    if self.dtype is not None and enforce_dtype:\n        fps = datatype.cast(fps, dtype=self.dtype, columns=self.columns)\n    if not ignore_errors:\n        return fps\n    return fps, list(valid_idx)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.__init__","title":"<code>__init__(iterable=None, dtype=None, params=None, collate_fn=None)</code>","text":"<p>Featurizer concatenator</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Optional[Union[Iterable, str]]</code> <p>List of featurizer to concatenate.</p> <code>None</code> <code>dtype</code> <code>Optional[Callable]</code> <p>Datatype of the computed fingerprint</p> <code>None</code> <code>params</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dictionary of parameters for the featurizers when there is a need for initializing them</p> <code>None</code> <code>collate_fn</code> <code>Optional[Callable]</code> <p>optional function to provide for custom collating. By default the collate function will be None, which will use the torch default</p> <code>None</code> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def __init__(\n    self,\n    iterable: Optional[Union[Iterable, str]] = None,\n    dtype: Optional[Callable] = None,\n    params: Optional[Dict[str, Any]] = None,\n    collate_fn: Optional[Callable] = None,\n):\n    \"\"\"Featurizer concatenator\n\n    Args:\n        iterable: List of featurizer to concatenate.\n        dtype: Datatype of the computed fingerprint\n        params: Optional dictionary of parameters for the featurizers when there is a need for initializing them\n        collate_fn: optional function to provide for custom collating.\n            By default the collate function will be None, which will use the torch default\n    \"\"\"\n    super().__init__()\n    self.params = params or {}\n    if isinstance(iterable, str):\n        iterable = [x.strip() for x in iterable.split(self._STR_DELIMITER)]\n    if iterable is not None:\n        for item in iterable:\n            if isinstance(item, str):\n                item = FPVecTransformer(kind=item, **self.params.get(item, {}))\n            self.append(item)\n    self.dtype = dtype\n    self._length = None\n    self.collate_fn = collate_fn\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.__setitem__","title":"<code>__setitem__(index, value)</code>","text":"<p>Override the <code>__setitem__</code>  method</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def __setitem__(self, index, value):\n    \"\"\"Override the `__setitem__`  method\"\"\"\n    self._check_supported(value)\n    super().__setitem__(index, value)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.append","title":"<code>append(item)</code>","text":"<p>Override the <code>append</code> to accept only <code>FPVecTransformer</code></p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def append(self, item):\n    r\"\"\"Override the ``append`` to accept only ``FPVecTransformer``\"\"\"\n    self._check_supported(item)\n    super().append(item)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.fit","title":"<code>fit(X, y=None, **kwargs)</code>","text":"<p>Calls the <code>FPVecTransformer.fit</code> for each transformer in the current list.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>List[Union[Mol, str]]</code> <p>input list of molecules</p> required <code>y</code> <code>list</code> <p>Optional list of molecular properties. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <p>FeatConcat instance after fitting</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def fit(self, X: List[Union[dm.Mol, str]], y=None, **kwargs):\n    r\"\"\"\n    Calls the ``FPVecTransformer.fit`` for each transformer in the current list.\n\n    Args:\n        X: input list of molecules\n        y (list, optional): Optional list of molecular properties. Defaults to None.\n\n    Returns:\n        self: FeatConcat instance after fitting\n    \"\"\"\n\n    for _, fp_trans in enumerate(self):\n        fp_trans.fit(X, y=y, **kwargs)\n    return self\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.fit_transform","title":"<code>fit_transform(mols, y=None, fit_kwargs=None, trans_kwargs=None)</code>","text":"<p>Calls the <code>self.fit</code> followed by the <code>fit.transform</code> for each transfomer in the current list, and concatenates the resulting fingerprints.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[str, Mol]]</code> <p>List of SMILES or molecules</p> required <code>y</code> <code>Optional[Iterable]</code> <p>target for the fitting. Usually ignored for FPVecTransformer</p> <code>None</code> <code>fit_kwargs</code> <code>Dict</code> <p>named parameters for fit</p> <code>None</code> <code>fit_kwargs</code> <code>Dict</code> <p>named parameters for transform</p> <code>None</code> <p>Returns:</p> <pre><code>fp: computed fingerprints of size NxD, where D is the\n    sum of the length of each transformer and N is the number of input\n    molecules that have been successfully featurized.\n</code></pre> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def fit_transform(\n    self,\n    mols: List[Union[str, dm.Mol]],\n    y: Optional[Iterable] = None,\n    fit_kwargs: Dict = None,\n    trans_kwargs: Dict = None,\n):\n    r\"\"\"\n    Calls the ``self.fit`` followed by the ``fit.transform`` for each transfomer in\n    the current list, and concatenates the resulting fingerprints.\n\n    Args:\n        mols: List of SMILES or molecules\n        y: target for the fitting. Usually ignored for FPVecTransformer\n        fit_kwargs:  named parameters for fit\n        fit_kwargs:named parameters for transform\n\n    Returns:\n\n        fp: computed fingerprints of size NxD, where D is the\n            sum of the length of each transformer and N is the number of input\n            molecules that have been successfully featurized.\n    \"\"\"\n    fit_kwargs = {} if fit_kwargs is None else fit_kwargs\n    trans_kwargs = {} if trans_kwargs is None else trans_kwargs\n    self.fit(mols, y=y, **fit_kwargs)\n    return self.transform(mols, **trans_kwargs)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.get_collate_fn","title":"<code>get_collate_fn(*args, **kwargs)</code>","text":"<p>Get collate function of this featurizer. The FeatConcat featurizer use the default collate function which does not do anything.</p> <p>Returns:</p> Name Type Description <code>fn</code> <p>Collate function for pytorch or None</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def get_collate_fn(self, *args, **kwargs):\n    \"\"\"\n    Get collate function of this featurizer. The FeatConcat featurizer use the default\n    collate function which does not do anything.\n\n    Returns:\n        fn: Collate function for pytorch or None\n    \"\"\"\n    return getattr(self, \"collate_fn\", None)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.insert","title":"<code>insert(index, item)</code>","text":"<p>Override the <code>insert</code> to accept only <code>BaseFeaturizer</code></p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def insert(self, index, item):\n    r\"\"\"Override the ``insert`` to accept only ``BaseFeaturizer``\"\"\"\n    self._check_suported(item)\n    super().insert(index, item)\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.iter_index","title":"<code>iter_index(indexes)</code>","text":"<p>Allow the <code>FeatConcat</code> to be indexed using a list, or any other iterable.</p> <p>Parameters:</p> Name Type Description Default <code>indexes</code> <code>Union[int, Iterator[int]]</code> <p>The indexes to index the <code>FeatConcat</code>.</p> required <p>Returns     indexed_fpconcat: A new FeatConcat object with the indexed element</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def iter_index(self, indexes: Union[int, Iterator[int]]):\n    r\"\"\"\n    Allow the `FeatConcat` to be indexed using a list, or any other iterable.\n\n    Args:\n        indexes: The indexes to index the ``FeatConcat``.\n\n    Returns\n        indexed_fpconcat: A new FeatConcat object with the indexed element\n    \"\"\"\n    if not isinstance(indexes, (list, tuple)):\n        try:\n            indexes = list(indexes)\n        except TypeError:\n            indexes = [indexes]\n    return FeatConcat([self[ii] for ii in indexes])\n</code></pre>"},{"location":"api/molfeat.trans.concat.html#molfeat.trans.concat.FeatConcat.transform","title":"<code>transform(mols, **kwargs)</code>","text":"<p>Calls the <code>FPVecTransformer.transform</code> for each transformer in the current list, and concatenates the resulting fingerprints.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>List of SMILES or molecules</p> required <code>kwargs</code> <p>named parameters for transform (see below)</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>fps</code> <p>Computed fingerprints of size NxD, where D is the sum of the length of each transformer and N is the number of input molecules that have been successfully featurized.</p> Source code in <code>molfeat/trans/concat.py</code> <pre><code>def transform(self, mols: List[Union[dm.Mol, str]], **kwargs):\n    r\"\"\"\n    Calls the ``FPVecTransformer.transform`` for each transformer in\n    the current list, and concatenates the resulting fingerprints.\n\n    Args:\n        mols: List of SMILES or molecules\n        kwargs: named parameters for transform (see below)\n\n    Returns:\n        fps: Computed fingerprints of size NxD, where D is the\n            sum of the length of each transformer and N is the number of input\n            molecules that have been successfully featurized.\n    \"\"\"\n\n    fps = []\n    for _, fp_trans in enumerate(self):\n        out = fp_trans.transform(mols, enforce_dtype=False, **kwargs)\n        out = datatype.cast(out, dtype=\"pandas\")\n        fps.append(out)\n    fps = pd.concat(fps, axis=1)\n    fps.columns = self.columns\n    return fps.values\n</code></pre>"},{"location":"api/molfeat.trans.fp.html","title":"molfeat.trans.fp","text":""},{"location":"api/molfeat.trans.fp.html#molfeat.trans.fp.FPVecFilteredTransformer","title":"<code>FPVecFilteredTransformer</code>","text":"<p>               Bases: <code>FPVecTransformer</code></p> <p>Fingerprint molecule transformer with columns filters applying to the featurized vector when <code>fit</code> is called</p> Source code in <code>molfeat/trans/fp.py</code> <pre><code>class FPVecFilteredTransformer(FPVecTransformer):\n    r\"\"\"\n    Fingerprint molecule transformer with columns filters applying to the featurized vector when `fit` is called\n    \"\"\"\n\n    def __init__(\n        self,\n        kind: str = \"ecfp:4\",\n        length: int = 2000,\n        occ_threshold: float = 0,\n        del_invariant: bool = False,\n        n_jobs: int = 1,\n        verbose: bool = False,\n        dtype: Callable = np.float32,\n        **params,\n    ):\n        \"\"\"Molecular to vector featurization with filtering applied\n\n        Args:\n            kind (str, optional): Name of the fingerprints (one supported fingerprints: see self.AVAILABLE_FPS). Defaults to \"ecfp4\".\n            length (int, optional): Length of the fingerprint. Defaults to 2000.\n            occ_threshold (float, optional): Minimum proportion a columns need to be non null to be kept.\n            del_invariant (bool, optional): Whether to delete columns that are invariant.\n            n_jobs (int, optional): Number of jobs. Defaults to 1.\n            verbose (bool, optional): Verbosity level. Defaults to False.\n            dtype (Callable, optional): Data type. Defaults to np.float32.\n            params (dict, optional): Any additional parameters to the fingerprint function\n        \"\"\"\n\n        super().__init__(\n            kind=kind,\n            length=length,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            dtype=dtype,\n            **params,\n        )\n        self.occ_threshold = occ_threshold\n        self.del_invariant = del_invariant\n        self._input_params.update(occ_threshold=occ_threshold, del_invariant=del_invariant)\n\n    def _update_params(self):\n        params = copy.deepcopy(self._input_params)\n        params.pop(\"featurizer\", None)\n        params.pop(\"length\", None)\n        params.pop(\"kind\", None)\n        params.pop(\"verbose\", None)\n        params.pop(\"dtype\", None)\n        params.pop(\"n_jobs\", None)\n        params.pop(\"occ_threshold\", None)\n        params.pop(\"del_invariant\", None)\n        self.featurizer = self._prepare_featurizer(self.kind, self.length, **params)\n\n    def __repr__(self):\n        return \"{} (kind={}, length={}, occ_threshold={}, del_invariant={}, dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self.kind),\n            _parse_to_evaluable_str(self.length),\n            _parse_to_evaluable_str(self.occ_threshold),\n            _parse_to_evaluable_str(self.del_invariant),\n            _parse_to_evaluable_str(self.dtype),\n        )\n\n    def fit(self, X: List[Union[dm.Mol, str]], y: Optional[list] = None, **fit_params):\n        \"\"\"Fit the current transformer on given dataset.\n\n        The goal of fitting is for example to identify nan columns values\n        that needs to be removed from the dataset\n\n        Args:\n            X: input list of molecules\n            y (list, optional): Optional list of molecular properties. Defaults to None.\n\n        Returns:\n            self: MolTransformer instance after fitting\n        \"\"\"\n\n        feats = self.transform(X, ignore_errors=True)\n        lengths = [len(x) for x in feats if not datatype.is_null(x)]\n\n        if lengths:\n            # we will ignore all nan\n            feats = datatype.to_numpy([f for f in feats if not datatype.is_null(f)])\n            # all nan columns\n            unwanted_columns = []\n            # let's adjsut occ to float\n            occ_threshold = self.occ_threshold\n            if occ_threshold &gt; 1:\n                occ_threshold = occ_threshold / feats.shape[0]\n            # not nan\n            unwanted_columns.append(~np.any(np.isnan(feats), axis=0))\n            # not enough set bits\n            unwanted_columns.append(\n                (np.count_nonzero(feats, axis=0) / feats.shape[0]) &gt; occ_threshold\n            )\n            if self.del_invariant:\n                unwanted_columns.append(~np.all(feats == feats[0, :], axis=0))\n            self.cols_to_keep = (np.logical_and.reduce(unwanted_columns)).nonzero()[0]\n        self._fitted = True\n        return self\n</code></pre>"},{"location":"api/molfeat.trans.fp.html#molfeat.trans.fp.FPVecFilteredTransformer.__init__","title":"<code>__init__(kind='ecfp:4', length=2000, occ_threshold=0, del_invariant=False, n_jobs=1, verbose=False, dtype=np.float32, **params)</code>","text":"<p>Molecular to vector featurization with filtering applied</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Name of the fingerprints (one supported fingerprints: see self.AVAILABLE_FPS). Defaults to \"ecfp4\".</p> <code>'ecfp:4'</code> <code>length</code> <code>int</code> <p>Length of the fingerprint. Defaults to 2000.</p> <code>2000</code> <code>occ_threshold</code> <code>float</code> <p>Minimum proportion a columns need to be non null to be kept.</p> <code>0</code> <code>del_invariant</code> <code>bool</code> <p>Whether to delete columns that are invariant.</p> <code>False</code> <code>n_jobs</code> <code>int</code> <p>Number of jobs. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Verbosity level. Defaults to False.</p> <code>False</code> <code>dtype</code> <code>Callable</code> <p>Data type. Defaults to np.float32.</p> <code>float32</code> <code>params</code> <code>dict</code> <p>Any additional parameters to the fingerprint function</p> <code>{}</code> Source code in <code>molfeat/trans/fp.py</code> <pre><code>def __init__(\n    self,\n    kind: str = \"ecfp:4\",\n    length: int = 2000,\n    occ_threshold: float = 0,\n    del_invariant: bool = False,\n    n_jobs: int = 1,\n    verbose: bool = False,\n    dtype: Callable = np.float32,\n    **params,\n):\n    \"\"\"Molecular to vector featurization with filtering applied\n\n    Args:\n        kind (str, optional): Name of the fingerprints (one supported fingerprints: see self.AVAILABLE_FPS). Defaults to \"ecfp4\".\n        length (int, optional): Length of the fingerprint. Defaults to 2000.\n        occ_threshold (float, optional): Minimum proportion a columns need to be non null to be kept.\n        del_invariant (bool, optional): Whether to delete columns that are invariant.\n        n_jobs (int, optional): Number of jobs. Defaults to 1.\n        verbose (bool, optional): Verbosity level. Defaults to False.\n        dtype (Callable, optional): Data type. Defaults to np.float32.\n        params (dict, optional): Any additional parameters to the fingerprint function\n    \"\"\"\n\n    super().__init__(\n        kind=kind,\n        length=length,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        dtype=dtype,\n        **params,\n    )\n    self.occ_threshold = occ_threshold\n    self.del_invariant = del_invariant\n    self._input_params.update(occ_threshold=occ_threshold, del_invariant=del_invariant)\n</code></pre>"},{"location":"api/molfeat.trans.fp.html#molfeat.trans.fp.FPVecFilteredTransformer.fit","title":"<code>fit(X, y=None, **fit_params)</code>","text":"<p>Fit the current transformer on given dataset.</p> <p>The goal of fitting is for example to identify nan columns values that needs to be removed from the dataset</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>List[Union[Mol, str]]</code> <p>input list of molecules</p> required <code>y</code> <code>list</code> <p>Optional list of molecular properties. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <p>MolTransformer instance after fitting</p> Source code in <code>molfeat/trans/fp.py</code> <pre><code>def fit(self, X: List[Union[dm.Mol, str]], y: Optional[list] = None, **fit_params):\n    \"\"\"Fit the current transformer on given dataset.\n\n    The goal of fitting is for example to identify nan columns values\n    that needs to be removed from the dataset\n\n    Args:\n        X: input list of molecules\n        y (list, optional): Optional list of molecular properties. Defaults to None.\n\n    Returns:\n        self: MolTransformer instance after fitting\n    \"\"\"\n\n    feats = self.transform(X, ignore_errors=True)\n    lengths = [len(x) for x in feats if not datatype.is_null(x)]\n\n    if lengths:\n        # we will ignore all nan\n        feats = datatype.to_numpy([f for f in feats if not datatype.is_null(f)])\n        # all nan columns\n        unwanted_columns = []\n        # let's adjsut occ to float\n        occ_threshold = self.occ_threshold\n        if occ_threshold &gt; 1:\n            occ_threshold = occ_threshold / feats.shape[0]\n        # not nan\n        unwanted_columns.append(~np.any(np.isnan(feats), axis=0))\n        # not enough set bits\n        unwanted_columns.append(\n            (np.count_nonzero(feats, axis=0) / feats.shape[0]) &gt; occ_threshold\n        )\n        if self.del_invariant:\n            unwanted_columns.append(~np.all(feats == feats[0, :], axis=0))\n        self.cols_to_keep = (np.logical_and.reduce(unwanted_columns)).nonzero()[0]\n    self._fitted = True\n    return self\n</code></pre>"},{"location":"api/molfeat.trans.fp.html#molfeat.trans.fp.FPVecTransformer","title":"<code>FPVecTransformer</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>Molecular fingerprinter that computes various fingerprints and descriptors regularly used in QSAR modeling.</p> <p>Note</p> <p>For fingerprints with a radius parameter, you can provide the radius using the notation \"fp:radius\". For example \"Morgan Circular 2\" can be written as \"morgan:2\". Under the hood, morgan and ecfp fingerprints are equated with the proper radius/diameter adjustment.</p> <p>For counting fingerprints, you just need to add the '-count' suffix to the name of the fingerprint. For example: \"morgan-count:2\"</p> Source code in <code>molfeat/trans/fp.py</code> <pre><code>class FPVecTransformer(MoleculeTransformer):\n    r\"\"\"\n    Molecular fingerprinter that computes various fingerprints and descriptors regularly used in QSAR modeling.\n\n    !!! note\n        For fingerprints with a radius parameter, you can provide the radius using the notation \"fp:radius\".\n        For example \"Morgan Circular 2\" can be written as \"morgan:2\". Under the hood, morgan and ecfp fingerprints\n        are equated with the proper radius/diameter adjustment.\n\n        For counting fingerprints, you just need to add the '-count' suffix to the name of the fingerprint. For example:\n        \"morgan-count:2\"\n    \"\"\"\n\n    AVAILABLE_FPS = list(FP_FUNCS.keys()) + [\n        \"desc3D\",\n        \"desc2D\",\n        \"mordred\",\n        \"cats2D\",\n        \"cats3D\",\n        \"pharm2D\",\n        \"pharm3D\",\n        \"scaffoldkeys\",\n        \"skeys\",\n        \"electroshape\",\n        \"usr\",\n        \"usrcat\",\n    ]\n\n    def __init__(\n        self,\n        kind: str = \"ecfp:4\",\n        length: int = 2000,\n        n_jobs: int = 1,\n        verbose: bool = False,\n        dtype: Callable = np.float32,\n        parallel_kwargs: Optional[dict] = None,\n        **params,\n    ):\n        \"\"\"Molecular to vector fingerprinter\n\n        Args:\n            kind (str, optional): Name of the fingerprints (one supported fingerprints: see self.AVAILABLE_FPS). Defaults to \"ecfp4\".\n            length (int, optional): Length of the fingerprint. Defaults to 2000.\n            n_jobs (int, optional): Number of jobs. Defaults to 1.\n            verbose (bool, optional): Verbosity level. Defaults to False.\n            dtype (Callable, optional): Data type. Defaults to np.float32.\n            parallel_kwargs (dict, optional): Optional arguments to pass to dm.parallelized when required. Defaults to None.\n            params (dict, optional): Any additional parameters to the fingerprint function\n        \"\"\"\n        self._save_input_args()\n\n        # remove any featurizer that was passed as argument\n        params.pop(\"featurizer\", None)\n        self._feat_params = params\n        featurizer = self._prepare_featurizer(kind, length, **params)\n        super().__init__(\n            featurizer=featurizer,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            dtype=dtype,\n            parallel_kwargs=parallel_kwargs,\n            **params,\n        )\n        self.kind = kind\n        self.length = length\n        self._length = None\n        # update length for featurizer that have they fixed length\n        # EN: setting up a protected _length function helps to bypass\n        # the absurd \"is\" comparison done by sklearn in clone\n        # note that the featurizer length would likely be ignored by featurizer\n        # that do not support a variable length\n        if hasattr(self.featurizer, \"__len__\"):\n            self._length = len(featurizer)\n        self._input_params.update(kind=kind, length=length)\n        if self.kind.lower() in _UNSERIALIZABLE_FPS:\n            self.parallel_kwargs.update(scheduler=\"threads\")\n\n    def __len__(self):\n        \"\"\"Compute featurizer length\"\"\"\n        if getattr(self, \"cols_to_keep\", None) is None and self._length is not None:\n            return self._length\n        return super().__len__()\n\n    def _get_param_names(self):\n        \"\"\"Get parameter names for the estimator\"\"\"\n        out = self._input_params.keys()\n        return [x for x in out if x != \"featurizer\"]\n\n    @classmethod\n    def _prepare_featurizer(cls, kind: str, length: int, **params):\n        \"\"\"Prepare featurizer from its name and parameters\n\n        Args:\n            kind: Name of the featurizer\n            length: Length of the featurizer\n        Returns:\n            calculator (Callable): fingerprint calculator\n        \"\"\"\n        match = re.search(r\":(\\d+)$\", kind)\n        radius = None\n        if match is not None:\n            radius = match.group(1)\n        if radius is not None:\n            kind = kind.replace(radius, \"\").strip(\":\").lower()\n            radius = int(radius)\n            if any(x in kind for x in [\"ecfp\", \"fcfp\"]):\n                radius = max(radius // 2, 1)\n            params[\"radius\"] = radius\n        if any(x in kind for x in [\"morgan\", \"morgan_circular\", \"morgan-circular\"]):\n            kind = kind.replace(\"_circular\", \"\").replace(\"-circular\", \"\").replace(\"morgan\", \"ecfp\")\n        if kind not in cls.AVAILABLE_FPS:\n            raise ValueError(f\"{kind} is not a valid featurizer\")\n        params[\"length\"] = length\n\n        return get_calculator(kind, **params)\n\n    def _update_params(self):\n        params = copy.deepcopy(self._input_params)\n        params.pop(\"featurizer\", None)\n        params.pop(\"length\", None)\n        params.pop(\"kind\", None)\n        params.pop(\"verbose\", None)\n        params.pop(\"dtype\", None)\n        params.pop(\"n_jobs\", None)\n        self._fitted = False\n        self.featurizer = self._prepare_featurizer(self.kind, self.length, **params)\n\n    def __repr__(self):\n        return \"{}(kind={}, length={}, dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self.kind),\n            _parse_to_evaluable_str(self.length),\n            _parse_to_evaluable_str(self.dtype),\n        )\n\n    def __str__(self):\n        # The output for the print function\n        return self.__repr__()\n\n    def __eq__(self, other):\n        same_type = isinstance(self, type(other))\n        return same_type and all(\n            [getattr(other, k) == v for k, v in self.get_params() if not callable(v)]\n        )\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __hash__(self):\n        return hash(repr(self))\n</code></pre>"},{"location":"api/molfeat.trans.fp.html#molfeat.trans.fp.FPVecTransformer.__init__","title":"<code>__init__(kind='ecfp:4', length=2000, n_jobs=1, verbose=False, dtype=np.float32, parallel_kwargs=None, **params)</code>","text":"<p>Molecular to vector fingerprinter</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>Name of the fingerprints (one supported fingerprints: see self.AVAILABLE_FPS). Defaults to \"ecfp4\".</p> <code>'ecfp:4'</code> <code>length</code> <code>int</code> <p>Length of the fingerprint. Defaults to 2000.</p> <code>2000</code> <code>n_jobs</code> <code>int</code> <p>Number of jobs. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Verbosity level. Defaults to False.</p> <code>False</code> <code>dtype</code> <code>Callable</code> <p>Data type. Defaults to np.float32.</p> <code>float32</code> <code>parallel_kwargs</code> <code>dict</code> <p>Optional arguments to pass to dm.parallelized when required. Defaults to None.</p> <code>None</code> <code>params</code> <code>dict</code> <p>Any additional parameters to the fingerprint function</p> <code>{}</code> Source code in <code>molfeat/trans/fp.py</code> <pre><code>def __init__(\n    self,\n    kind: str = \"ecfp:4\",\n    length: int = 2000,\n    n_jobs: int = 1,\n    verbose: bool = False,\n    dtype: Callable = np.float32,\n    parallel_kwargs: Optional[dict] = None,\n    **params,\n):\n    \"\"\"Molecular to vector fingerprinter\n\n    Args:\n        kind (str, optional): Name of the fingerprints (one supported fingerprints: see self.AVAILABLE_FPS). Defaults to \"ecfp4\".\n        length (int, optional): Length of the fingerprint. Defaults to 2000.\n        n_jobs (int, optional): Number of jobs. Defaults to 1.\n        verbose (bool, optional): Verbosity level. Defaults to False.\n        dtype (Callable, optional): Data type. Defaults to np.float32.\n        parallel_kwargs (dict, optional): Optional arguments to pass to dm.parallelized when required. Defaults to None.\n        params (dict, optional): Any additional parameters to the fingerprint function\n    \"\"\"\n    self._save_input_args()\n\n    # remove any featurizer that was passed as argument\n    params.pop(\"featurizer\", None)\n    self._feat_params = params\n    featurizer = self._prepare_featurizer(kind, length, **params)\n    super().__init__(\n        featurizer=featurizer,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        dtype=dtype,\n        parallel_kwargs=parallel_kwargs,\n        **params,\n    )\n    self.kind = kind\n    self.length = length\n    self._length = None\n    # update length for featurizer that have they fixed length\n    # EN: setting up a protected _length function helps to bypass\n    # the absurd \"is\" comparison done by sklearn in clone\n    # note that the featurizer length would likely be ignored by featurizer\n    # that do not support a variable length\n    if hasattr(self.featurizer, \"__len__\"):\n        self._length = len(featurizer)\n    self._input_params.update(kind=kind, length=length)\n    if self.kind.lower() in _UNSERIALIZABLE_FPS:\n        self.parallel_kwargs.update(scheduler=\"threads\")\n</code></pre>"},{"location":"api/molfeat.trans.fp.html#molfeat.trans.fp.FPVecTransformer.__len__","title":"<code>__len__()</code>","text":"<p>Compute featurizer length</p> Source code in <code>molfeat/trans/fp.py</code> <pre><code>def __len__(self):\n    \"\"\"Compute featurizer length\"\"\"\n    if getattr(self, \"cols_to_keep\", None) is None and self._length is not None:\n        return self._length\n    return super().__len__()\n</code></pre>"},{"location":"api/molfeat.trans.graph.html","title":"molfeat.trans.graph","text":""},{"location":"api/molfeat.trans.graph.html#graphs","title":"Graphs","text":""},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.AdjGraphTransformer","title":"<code>AdjGraphTransformer</code>","text":"<p>               Bases: <code>GraphTransformer</code></p> <p>Transforms a molecule into a molecular graph representation formed by an adjacency matrix of atoms and a set of features for each atom (and potentially bond).</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class AdjGraphTransformer(GraphTransformer):\n    r\"\"\"\n    Transforms a molecule into a molecular graph representation formed by an\n    adjacency matrix of atoms and a set of features for each atom (and potentially bond).\n    \"\"\"\n\n    def __init__(\n        self,\n        atom_featurizer: Optional[Callable] = None,\n        bond_featurizer: Optional[Callable] = None,\n        self_loop: bool = False,\n        explicit_hydrogens: bool = False,\n        canonical_atom_order: bool = True,\n        max_n_atoms: Optional[int] = None,\n        n_jobs: int = 1,\n        verbose: bool = False,\n        dtype: Optional[Callable] = None,\n        **params,\n    ):\n        \"\"\"\n        Adjacency graph transformer\n\n        Args:\n            atom_featurizer: atom featurizer to use\n            bond_featurizer: bond featurizer to use\n            self_loop: whether to add self loops to the adjacency matrix. Your bond featurizer needs to supports this.\n            explicit_hydrogens: Whether to use explicit hydrogen in preprocessing of the input molecule\n            canonical_atom_order: Whether to use a canonical ordering of the atoms\n            max_n_atoms: Maximum number of atom to set the size of the graph\n            n_jobs: Number of job to run in parallel. Defaults to 1.\n            verbose: Verbosity level. Defaults to True.\n            dtype: Output data type. Defaults to None, where numpy arrays are returned.\n        \"\"\"\n        super().__init__(\n            atom_featurizer=atom_featurizer,\n            bond_featurizer=bond_featurizer,\n            max_n_atoms=max_n_atoms,\n            self_loop=self_loop,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            dtype=dtype,\n            canonical_atom_order=canonical_atom_order,\n            explicit_hydrogens=explicit_hydrogens,\n            **params,\n        )\n\n    def _graph_featurizer(self, mol: dm.Mol):\n        \"\"\"Internal adjacency graph featurizer\n\n        Returns:\n            mat : N,N matrix representing the graph\n        \"\"\"\n        adj_mat = GetAdjacencyMatrix(mol)\n        if self.self_loop:\n            np.fill_diagonal(adj_mat, 1)\n        return adj_mat\n\n    @staticmethod\n    def _collate_batch(batch, max_n_atoms=None, pack=False):\n        \"\"\"\n        Collate a batch of samples. Expected format is either single graphs, e.g. a list of tuples of the form (adj, feats),\n        or graphs together with their labels, where each sample is of the form ((adj, feats), label).\n\n        Args:\n             batch: list\n                Batch of samples.\n             max_n_atoms: Max num atoms in graphs.\n             pack: Whether the graph should be packed or not into a supergraph.\n\n        Returns:\n            Collated samples.\n\n        \"\"\"\n        if isinstance(batch[0], (list, tuple)) and len(batch[0]) &gt; 2:\n            graphs, feats, labels = map(list, zip(*batch))\n            batched_graph = AdjGraphTransformer._collate_graphs(\n                zip(graphs, feats), max_n_atoms=max_n_atoms, pack=pack\n            )\n\n            if torch.is_tensor(labels[0]):\n                return batched_graph, torch.stack(labels)\n            else:\n                return batched_graph, labels\n\n        # Otherwise we assume the batch is composed of single graphs.\n        return AdjGraphTransformer._collate_graphs(batch, max_n_atoms=max_n_atoms, pack=pack)\n\n    @staticmethod\n    def _collate_graphs(batch, max_n_atoms, pack):\n        if not all([len(b) == 2 for b in batch]):\n            raise ValueError(\"Default collate function only supports pair of (Graph, AtomFeats) \")\n\n        graphs, feats = zip(*batch)\n        # in case someone does not convert to tensor and wants to use collate\n        # who would do that ?\n        graphs = [datatype.to_tensor(g) for g in graphs]\n        feats = [datatype.to_tensor(f) for f in feats]\n        if pack:\n            return pack_graph(graphs, feats)\n        else:\n            if max_n_atoms is None:\n                cur_max_atoms = max([x.shape[0] for x in feats])\n            else:\n                cur_max_atoms = max_n_atoms\n\n            graphs = torch.stack(\n                [\n                    F.pad(\n                        g,\n                        (0, cur_max_atoms - g.shape[0], 0, cur_max_atoms - g.shape[1]),\n                    )\n                    for g in graphs\n                ]\n            )\n            feats = torch.stack([F.pad(f, (0, 0, 0, cur_max_atoms - f.shape[0])) for f in feats])\n        return graphs, feats\n\n    def get_collate_fn(self, pack: bool = False, max_n_atoms: Optional[int] = None):\n        \"\"\"Get collate function. Adj Graph are collated either through batching\n        or diagonally packing the graph into a super graph. Either a format of (batch, labels) or graph is supported.\n\n        !!! note\n            Edge features are not supported yet in the default collate because\n            there is no straightforward and universal way to collate them\n\n        Args:\n            pack : Whether to pack or batch the graphs.\n            max_n_atoms: Maximum number of node per graph when packing is False.\n                If the graph needs to be packed and it is not set, instance attributes will be used\n        \"\"\"\n        if self.bond_featurizer is not None:\n            raise ValueError(\n                \"Default collate function is not supported for transformer with bond featurizer\"\n            )\n        max_n_atoms = max_n_atoms or self.max_n_atoms\n\n        return partial(self._collate_batch, pack=pack, max_n_atoms=max_n_atoms)\n\n    def transform(self, mols: List[Union[dm.Mol, str]], keep_dict: bool = False, **kwargs):\n        r\"\"\"\n        Compute the graph featurization for a set of molecules.\n\n        Args:\n            mols: a list containing smiles or mol objects\n            keep_dict: whether to keep atom and bond featurizer as dict or get the underlying data\n            kwargs: arguments to pass to the `super().transform`\n\n         Returns:\n             features: a list of features for each molecule in the input set\n        \"\"\"\n        features = super().transform(mols, **kwargs)\n        if not keep_dict:\n            out = []\n            for i, feat in enumerate(features):\n                if feat is not None:\n                    graph, nodes, *bonds = feat\n                    if isinstance(nodes, dict):\n                        nodes = nodes[self.atom_featurizer.name]\n                    if len(bonds) &gt; 0 and isinstance(bonds[0], dict):\n                        try:\n                            bonds = bonds[0][self.bond_featurizer.name]\n                            feat = (graph, nodes, bonds)\n                        except KeyError as e:\n                            # more information on failure\n                            logger.error(\"Encountered Molecule without bonds\")\n                            raise e\n                    else:\n                        feat = (graph, nodes)\n                out.append(feat)\n            features = out\n        return features\n\n    def _transform(self, mol: dm.Mol):\n        r\"\"\"\n        Transforms a molecule into an Adjacency graph with a set of atom and optional bond features\n\n        Args:\n            mol: molecule to transform into features\n\n        Returns\n            feat: featurized input molecule (adj_mat, node_feat) or (adj_mat, node_feat, edge_feat)\n\n        \"\"\"\n        if mol is None:\n            return None\n\n        try:\n            adj_matrix = datatype.cast(self._graph_featurizer(mol), dtype=self.dtype)\n            atom_data = self.atom_featurizer(mol, dtype=self.dtype)\n            feats = (adj_matrix, atom_data)\n            bond_data = None\n            if self.bond_featurizer is not None:\n                bond_data = self.bond_featurizer(mol, flat=False, dtype=self.dtype)\n                feats = (\n                    adj_matrix,\n                    atom_data,\n                    bond_data,\n                )\n        except Exception as e:\n            if self.verbose:\n                logger.error(e)\n            feats = None\n        return feats\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.AdjGraphTransformer.__init__","title":"<code>__init__(atom_featurizer=None, bond_featurizer=None, self_loop=False, explicit_hydrogens=False, canonical_atom_order=True, max_n_atoms=None, n_jobs=1, verbose=False, dtype=None, **params)</code>","text":"<p>Adjacency graph transformer</p> <p>Parameters:</p> Name Type Description Default <code>atom_featurizer</code> <code>Optional[Callable]</code> <p>atom featurizer to use</p> <code>None</code> <code>bond_featurizer</code> <code>Optional[Callable]</code> <p>bond featurizer to use</p> <code>None</code> <code>self_loop</code> <code>bool</code> <p>whether to add self loops to the adjacency matrix. Your bond featurizer needs to supports this.</p> <code>False</code> <code>explicit_hydrogens</code> <code>bool</code> <p>Whether to use explicit hydrogen in preprocessing of the input molecule</p> <code>False</code> <code>canonical_atom_order</code> <code>bool</code> <p>Whether to use a canonical ordering of the atoms</p> <code>True</code> <code>max_n_atoms</code> <code>Optional[int]</code> <p>Maximum number of atom to set the size of the graph</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of job to run in parallel. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Verbosity level. Defaults to True.</p> <code>False</code> <code>dtype</code> <code>Optional[Callable]</code> <p>Output data type. Defaults to None, where numpy arrays are returned.</p> <code>None</code> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def __init__(\n    self,\n    atom_featurizer: Optional[Callable] = None,\n    bond_featurizer: Optional[Callable] = None,\n    self_loop: bool = False,\n    explicit_hydrogens: bool = False,\n    canonical_atom_order: bool = True,\n    max_n_atoms: Optional[int] = None,\n    n_jobs: int = 1,\n    verbose: bool = False,\n    dtype: Optional[Callable] = None,\n    **params,\n):\n    \"\"\"\n    Adjacency graph transformer\n\n    Args:\n        atom_featurizer: atom featurizer to use\n        bond_featurizer: bond featurizer to use\n        self_loop: whether to add self loops to the adjacency matrix. Your bond featurizer needs to supports this.\n        explicit_hydrogens: Whether to use explicit hydrogen in preprocessing of the input molecule\n        canonical_atom_order: Whether to use a canonical ordering of the atoms\n        max_n_atoms: Maximum number of atom to set the size of the graph\n        n_jobs: Number of job to run in parallel. Defaults to 1.\n        verbose: Verbosity level. Defaults to True.\n        dtype: Output data type. Defaults to None, where numpy arrays are returned.\n    \"\"\"\n    super().__init__(\n        atom_featurizer=atom_featurizer,\n        bond_featurizer=bond_featurizer,\n        max_n_atoms=max_n_atoms,\n        self_loop=self_loop,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        dtype=dtype,\n        canonical_atom_order=canonical_atom_order,\n        explicit_hydrogens=explicit_hydrogens,\n        **params,\n    )\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.AdjGraphTransformer.get_collate_fn","title":"<code>get_collate_fn(pack=False, max_n_atoms=None)</code>","text":"<p>Get collate function. Adj Graph are collated either through batching or diagonally packing the graph into a super graph. Either a format of (batch, labels) or graph is supported.</p> <p>Note</p> <p>Edge features are not supported yet in the default collate because there is no straightforward and universal way to collate them</p> <p>Parameters:</p> Name Type Description Default <code>pack</code> <p>Whether to pack or batch the graphs.</p> <code>False</code> <code>max_n_atoms</code> <code>Optional[int]</code> <p>Maximum number of node per graph when packing is False. If the graph needs to be packed and it is not set, instance attributes will be used</p> <code>None</code> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def get_collate_fn(self, pack: bool = False, max_n_atoms: Optional[int] = None):\n    \"\"\"Get collate function. Adj Graph are collated either through batching\n    or diagonally packing the graph into a super graph. Either a format of (batch, labels) or graph is supported.\n\n    !!! note\n        Edge features are not supported yet in the default collate because\n        there is no straightforward and universal way to collate them\n\n    Args:\n        pack : Whether to pack or batch the graphs.\n        max_n_atoms: Maximum number of node per graph when packing is False.\n            If the graph needs to be packed and it is not set, instance attributes will be used\n    \"\"\"\n    if self.bond_featurizer is not None:\n        raise ValueError(\n            \"Default collate function is not supported for transformer with bond featurizer\"\n        )\n    max_n_atoms = max_n_atoms or self.max_n_atoms\n\n    return partial(self._collate_batch, pack=pack, max_n_atoms=max_n_atoms)\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.AdjGraphTransformer.transform","title":"<code>transform(mols, keep_dict=False, **kwargs)</code>","text":"<p>Compute the graph featurization for a set of molecules.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>a list containing smiles or mol objects</p> required <code>keep_dict</code> <code>bool</code> <p>whether to keep atom and bond featurizer as dict or get the underlying data</p> <code>False</code> <code>kwargs</code> <p>arguments to pass to the <code>super().transform</code></p> <code>{}</code> <p>Returns:      features: a list of features for each molecule in the input set</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def transform(self, mols: List[Union[dm.Mol, str]], keep_dict: bool = False, **kwargs):\n    r\"\"\"\n    Compute the graph featurization for a set of molecules.\n\n    Args:\n        mols: a list containing smiles or mol objects\n        keep_dict: whether to keep atom and bond featurizer as dict or get the underlying data\n        kwargs: arguments to pass to the `super().transform`\n\n     Returns:\n         features: a list of features for each molecule in the input set\n    \"\"\"\n    features = super().transform(mols, **kwargs)\n    if not keep_dict:\n        out = []\n        for i, feat in enumerate(features):\n            if feat is not None:\n                graph, nodes, *bonds = feat\n                if isinstance(nodes, dict):\n                    nodes = nodes[self.atom_featurizer.name]\n                if len(bonds) &gt; 0 and isinstance(bonds[0], dict):\n                    try:\n                        bonds = bonds[0][self.bond_featurizer.name]\n                        feat = (graph, nodes, bonds)\n                    except KeyError as e:\n                        # more information on failure\n                        logger.error(\"Encountered Molecule without bonds\")\n                        raise e\n                else:\n                    feat = (graph, nodes)\n            out.append(feat)\n        features = out\n    return features\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.CompleteGraphTransformer","title":"<code>CompleteGraphTransformer</code>","text":"<p>               Bases: <code>GraphTransformer</code></p> <p>Transforms a molecule into a complete graph</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class CompleteGraphTransformer(GraphTransformer):\n    \"\"\"Transforms a molecule into a complete graph\"\"\"\n\n    def _graph_featurizer(self, mol: dm.Mol):\n        \"\"\"Complete grah featurizer\n\n        Args:\n            mol: molecule to transform into a graph\n\n        Returns:\n            mat : N,N matrix representing the graph\n        \"\"\"\n        n_atoms = mol.GetNumAtoms()\n        adj_mat = np.ones((n_atoms, n_atoms))\n        if not self.self_loop:\n            np.fill_diagonal(adj_mat, 0)\n        return adj_mat\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.DGLGraphTransformer","title":"<code>DGLGraphTransformer</code>","text":"<p>               Bases: <code>GraphTransformer</code></p> <p>Transforms a molecule into a molecular graph representation formed by an adjacency matrix of atoms and a set of features for each atom (and potentially bond).</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class DGLGraphTransformer(GraphTransformer):\n    r\"\"\"\n    Transforms a molecule into a molecular graph representation formed by an\n    adjacency matrix of atoms and a set of features for each atom (and potentially bond).\n    \"\"\"\n\n    def __init__(\n        self,\n        atom_featurizer: Optional[Callable] = None,\n        bond_featurizer: Optional[Callable] = None,\n        self_loop: bool = False,\n        explicit_hydrogens: bool = False,\n        canonical_atom_order: bool = True,\n        complete_graph: bool = False,\n        num_virtual_nodes: int = 0,\n        n_jobs: int = 1,\n        verbose: bool = False,\n        dtype: Optional[Callable] = None,\n        **params,\n    ):\n        \"\"\"\n        Adjacency graph transformer\n\n        Args:\n           atom_featurizer: atom featurizer to use\n           bond_featurizer: atom featurizer to use\n           self_loop: whether to use self loop or not\n           explicit_hydrogens: Whether to use explicit hydrogen in preprocessing of the input molecule\n           canonical_atom_order: Whether to use a canonical ordering of the atoms\n           complete_graph: Whether to use a complete graph constructor or not\n           num_virtual_nodes: number of virtual nodes to add\n           n_jobs: Number of job to run in parallel. Defaults to 1.\n           verbose: Verbosity level. Defaults to True.\n           dtype: Output data type. Defaults to None, where numpy arrays are returned.\n        \"\"\"\n\n        super().__init__(\n            atom_featurizer=atom_featurizer,\n            bond_featurizer=bond_featurizer,\n            n_jobs=n_jobs,\n            self_loop=self_loop,\n            num_virtual_nodes=num_virtual_nodes,\n            complete_graph=complete_graph,\n            verbose=verbose,\n            dtype=dtype,\n            canonical_atom_order=canonical_atom_order,\n            explicit_hydrogens=explicit_hydrogens,\n            **params,\n        )\n\n        if not requires.check(\"dgllife\"):\n            logger.error(\n                \"Cannot find dgllife. It's required for some features. Please install it first !\"\n            )\n        if not requires.check(\"dgl\"):\n            raise ValueError(\"Cannot find dgl, please install it first !\")\n        if self.dtype is not None and not datatype.is_dtype_tensor(self.dtype):\n            raise ValueError(\"DGL featurizer only supports torch tensors currently\")\n\n    def auto_self_loop(self):\n        \"\"\"Patch the featurizer to auto support self loop based on the bond featurizer characteristics\"\"\"\n        super().auto_self_loop()\n        if isinstance(self.bond_featurizer, EdgeMatCalculator):\n            self.self_loop = True\n\n    def get_collate_fn(self, *args, **kwargs):\n        \"\"\"Return DGL collate function for a batch of molecular graph\"\"\"\n        return self._dgl_collate\n\n    @staticmethod\n    def _dgl_collate(batch):\n        \"\"\"\n        Batch of samples to be used with the featurizer. A sample of the batch is expected to\n        be of the form (graph, label) or simply a graph.\n\n        Args:\n         batch: list\n            batch of samples.\n\n        returns:\n            Batched lists of graphs and labels\n        \"\"\"\n        if isinstance(batch[0], (list, tuple)):\n            graphs, labels = map(list, zip(*batch))\n            batched_graph = dgl.batch(graphs)\n\n            if torch.is_tensor(labels[0]):\n                return batched_graph, torch.stack(labels)\n            else:\n                return batched_graph, labels\n\n        # Otherwise we assume the batch is composed of single graphs.\n        return dgl.batch(batch)\n\n    def _graph_featurizer(self, mol: dm.Mol):\n        \"\"\"Convert a molecule to a DGL graph.\n\n        This only supports the bigraph and not any virtual nodes or complete graph.\n\n        Args:\n            mol (dm.Mol): molecule to transform into features\n\n        Returns:\n            graph (dgl.DGLGraph): graph built with dgl\n        \"\"\"\n\n        n_atoms = mol.GetNumAtoms()\n        num_bonds = mol.GetNumBonds()\n        graph = dgl.graph()\n        graph.add_nodes(n_atoms)\n        bond_src = []\n        bond_dst = []\n        for i in range(num_bonds):\n            bond = mol.GetBondWithIdx(i)\n            begin_idx = bond.GetBeginAtom().GetIdx()\n            end_idx = bond.GetEndAtom().GetIdx()\n            bond_src.append(begin_idx)\n            bond_dst.append(end_idx)\n            # set up the reverse direction\n            bond_src.append(end_idx)\n            bond_dst.append(begin_idx)\n\n        if self.self_loop:\n            nodes = graph.nodes().tolist()\n            bond_src.extend(nodes)\n            bond_dst.extend(nodes)\n\n        graph.add_edges(bond_src, bond_dst)\n        return graph\n\n    @property\n    def atom_dim(self):\n        return super(DGLGraphTransformer, self).atom_dim + int(self.num_virtual_nodes &gt; 0)\n\n    @property\n    def bond_dim(self):\n        return super(DGLGraphTransformer, self).bond_dim + int(self.num_virtual_nodes &gt; 0)\n\n    def _transform(self, mol: dm.Mol):\n        r\"\"\"\n        Transforms a molecule into an Adjacency graph with a set of atom and bond features\n\n        Args:\n            mol (dm.Mol): molecule to transform into features\n\n        Returns\n            graph (dgl.DGLGraph): a dgl graph containing atoms and bond data\n\n        \"\"\"\n        if mol is None:\n            return None\n\n        graph = None\n        if requires.check(\"dgllife\"):\n            graph_featurizer = dgllife_utils.mol_to_bigraph\n\n            if self.complete_graph:\n                graph_featurizer = dgllife_utils.mol_to_complete_graph\n            try:\n                graph = graph_featurizer(\n                    mol,\n                    add_self_loop=self.self_loop,\n                    node_featurizer=self.__recast(self.atom_featurizer),\n                    edge_featurizer=self.__recast(self.bond_featurizer),\n                    canonical_atom_order=self.canonical_atom_order,\n                    explicit_hydrogens=self.explicit_hydrogens,\n                    num_virtual_nodes=self.num_virtual_nodes,\n                )\n            except Exception as e:\n                if self.verbose:\n                    logger.error(e)\n                graph = None\n\n        elif requires.check(\"dgl\") and not self.complete_graph:\n            # we need to build the graph ourselves.\n            graph = self._graph_featurizer(mol)\n            if self.atom_featurizer is not None:\n                graph.ndata.update(self.atom_featurizer(mol, dtype=self.dtype))\n\n            if self.bond_featurizer is not None:\n                graph.edata.update(self.bond_featurizer(mol, dtype=self.dtype))\n\n        else:\n            raise ValueError(\n                \"Incorrect setup, please install missing packages (dgl, dgllife) for more features\"\n            )\n        return graph\n\n    def __recast(self, featurizer: Callable):\n        \"\"\"Recast the output of a featurizer to the transformer underlying type\n\n        Args:\n            featurizer: featurizer to patch\n        \"\"\"\n        if featurizer is None:\n            return None\n        dtype = self.dtype or torch.float\n\n        def patch_feats(*args, **kwargs):\n            out_dict = featurizer(*args, **kwargs)\n            out_dict = {k: datatype.cast(val, dtype=dtype) for k, val in out_dict.items()}\n            return out_dict\n\n        return patch_feats\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.DGLGraphTransformer.__init__","title":"<code>__init__(atom_featurizer=None, bond_featurizer=None, self_loop=False, explicit_hydrogens=False, canonical_atom_order=True, complete_graph=False, num_virtual_nodes=0, n_jobs=1, verbose=False, dtype=None, **params)</code>","text":"<p>Adjacency graph transformer</p> <p>Parameters:</p> Name Type Description Default <code>atom_featurizer</code> <code>Optional[Callable]</code> <p>atom featurizer to use</p> <code>None</code> <code>bond_featurizer</code> <code>Optional[Callable]</code> <p>atom featurizer to use</p> <code>None</code> <code>self_loop</code> <code>bool</code> <p>whether to use self loop or not</p> <code>False</code> <code>explicit_hydrogens</code> <code>bool</code> <p>Whether to use explicit hydrogen in preprocessing of the input molecule</p> <code>False</code> <code>canonical_atom_order</code> <code>bool</code> <p>Whether to use a canonical ordering of the atoms</p> <code>True</code> <code>complete_graph</code> <code>bool</code> <p>Whether to use a complete graph constructor or not</p> <code>False</code> <code>num_virtual_nodes</code> <code>int</code> <p>number of virtual nodes to add</p> <code>0</code> <code>n_jobs</code> <code>int</code> <p>Number of job to run in parallel. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Verbosity level. Defaults to True.</p> <code>False</code> <code>dtype</code> <code>Optional[Callable]</code> <p>Output data type. Defaults to None, where numpy arrays are returned.</p> <code>None</code> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def __init__(\n    self,\n    atom_featurizer: Optional[Callable] = None,\n    bond_featurizer: Optional[Callable] = None,\n    self_loop: bool = False,\n    explicit_hydrogens: bool = False,\n    canonical_atom_order: bool = True,\n    complete_graph: bool = False,\n    num_virtual_nodes: int = 0,\n    n_jobs: int = 1,\n    verbose: bool = False,\n    dtype: Optional[Callable] = None,\n    **params,\n):\n    \"\"\"\n    Adjacency graph transformer\n\n    Args:\n       atom_featurizer: atom featurizer to use\n       bond_featurizer: atom featurizer to use\n       self_loop: whether to use self loop or not\n       explicit_hydrogens: Whether to use explicit hydrogen in preprocessing of the input molecule\n       canonical_atom_order: Whether to use a canonical ordering of the atoms\n       complete_graph: Whether to use a complete graph constructor or not\n       num_virtual_nodes: number of virtual nodes to add\n       n_jobs: Number of job to run in parallel. Defaults to 1.\n       verbose: Verbosity level. Defaults to True.\n       dtype: Output data type. Defaults to None, where numpy arrays are returned.\n    \"\"\"\n\n    super().__init__(\n        atom_featurizer=atom_featurizer,\n        bond_featurizer=bond_featurizer,\n        n_jobs=n_jobs,\n        self_loop=self_loop,\n        num_virtual_nodes=num_virtual_nodes,\n        complete_graph=complete_graph,\n        verbose=verbose,\n        dtype=dtype,\n        canonical_atom_order=canonical_atom_order,\n        explicit_hydrogens=explicit_hydrogens,\n        **params,\n    )\n\n    if not requires.check(\"dgllife\"):\n        logger.error(\n            \"Cannot find dgllife. It's required for some features. Please install it first !\"\n        )\n    if not requires.check(\"dgl\"):\n        raise ValueError(\"Cannot find dgl, please install it first !\")\n    if self.dtype is not None and not datatype.is_dtype_tensor(self.dtype):\n        raise ValueError(\"DGL featurizer only supports torch tensors currently\")\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.DGLGraphTransformer.__recast","title":"<code>__recast(featurizer)</code>","text":"<p>Recast the output of a featurizer to the transformer underlying type</p> <p>Parameters:</p> Name Type Description Default <code>featurizer</code> <code>Callable</code> <p>featurizer to patch</p> required Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def __recast(self, featurizer: Callable):\n    \"\"\"Recast the output of a featurizer to the transformer underlying type\n\n    Args:\n        featurizer: featurizer to patch\n    \"\"\"\n    if featurizer is None:\n        return None\n    dtype = self.dtype or torch.float\n\n    def patch_feats(*args, **kwargs):\n        out_dict = featurizer(*args, **kwargs)\n        out_dict = {k: datatype.cast(val, dtype=dtype) for k, val in out_dict.items()}\n        return out_dict\n\n    return patch_feats\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.DGLGraphTransformer.auto_self_loop","title":"<code>auto_self_loop()</code>","text":"<p>Patch the featurizer to auto support self loop based on the bond featurizer characteristics</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def auto_self_loop(self):\n    \"\"\"Patch the featurizer to auto support self loop based on the bond featurizer characteristics\"\"\"\n    super().auto_self_loop()\n    if isinstance(self.bond_featurizer, EdgeMatCalculator):\n        self.self_loop = True\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.DGLGraphTransformer.get_collate_fn","title":"<code>get_collate_fn(*args, **kwargs)</code>","text":"<p>Return DGL collate function for a batch of molecular graph</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def get_collate_fn(self, *args, **kwargs):\n    \"\"\"Return DGL collate function for a batch of molecular graph\"\"\"\n    return self._dgl_collate\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.DistGraphTransformer3D","title":"<code>DistGraphTransformer3D</code>","text":"<p>               Bases: <code>AdjGraphTransformer</code></p> <p>Graph featurizer using the 3D distance between pair of atoms for the adjacency matrix The <code>self_loop</code> attribute is ignored here as the distance between an atom and itself is 0.</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class DistGraphTransformer3D(AdjGraphTransformer):\n    \"\"\"\n    Graph featurizer using the 3D distance between pair of atoms for the adjacency matrix\n    The `self_loop` attribute is ignored here as the distance between an atom and itself is 0.\n\n    \"\"\"\n\n    @requires_conformer\n    def _graph_featurizer(self, mol: dm.Mol):\n        \"\"\"Graph topological distance featurizer\n\n        Args:\n            mol: molecule to transform into a graph\n\n        Returns:\n            mat : N,N matrix representing the graph\n        \"\"\"\n        return Get3DDistanceMatrix(mol)\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer","title":"<code>GraphTransformer</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>Base class for all graph transformers including DGL</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class GraphTransformer(MoleculeTransformer):\n    \"\"\"\n    Base class for all graph transformers including DGL\n    \"\"\"\n\n    def __init__(\n        self,\n        atom_featurizer: Optional[Callable] = None,\n        bond_featurizer: Optional[Callable] = None,\n        explicit_hydrogens: bool = False,\n        canonical_atom_order: bool = True,\n        self_loop: bool = False,\n        n_jobs: int = 1,\n        verbose: bool = False,\n        dtype: Optional[Callable] = None,\n        **params,\n    ):\n        \"\"\"Mol to Graph transformer base class\n\n        Args:\n            atom_featurizer: atom featurizer to use\n            bond_featurizer: atom featurizer to use\n            explicit_hydrogens: Whether to use explicit hydrogen in preprocessing of the input molecule\n            canonical_atom_order: Whether to use a canonical ordering of the atoms\n            self_loop: Whether to add self loops or not\n            n_jobs: Number of job to run in parallel. Defaults to 1.\n            verbose: Verbosity level. Defaults to True.\n            dtype: Output data type. Defaults to None\n        \"\"\"\n\n        self._save_input_args()\n\n        super().__init__(\n            n_jobs=n_jobs,\n            verbose=verbose,\n            dtype=dtype,\n            featurizer=\"none\",\n            self_loop=self_loop,\n            canonical_atom_order=canonical_atom_order,\n            explicit_hydrogens=explicit_hydrogens,\n            **params,\n        )\n        if atom_featurizer is None:\n            atom_featurizer = AtomCalculator()\n        self.atom_featurizer = atom_featurizer\n        self.bond_featurizer = bond_featurizer\n        self._atom_dim = None\n        self._bond_dim = None\n\n    def auto_self_loop(self):\n        \"\"\"Patch the featurizer to auto support self loop based on the bond featurizer characteristics\"\"\"\n        bf_self_loop = None\n        if self.bond_featurizer is not None:\n            bf_self_loop = getattr(self.bond_featurizer, \"self_loop\", None)\n            bf_self_loop = bf_self_loop or getattr(self.bond_featurizer, \"_self_loop\", None)\n        if bf_self_loop is not None:\n            self.self_loop = bf_self_loop\n\n    def preprocess(self, inputs, labels=None):\n        \"\"\"Preprocess list of input molecules\n        Args:\n            labels: For compatibility\n        \"\"\"\n        inputs, labels = super().preprocess(inputs, labels)\n        new_inputs = []\n        for m in inputs:\n            try:\n                mol = dm.to_mol(\n                    m, add_hs=self.explicit_hydrogens, ordered=self.canonical_atom_order\n                )\n            except Exception:\n                mol = None\n            new_inputs.append(mol)\n\n        return new_inputs, labels\n\n    def fit(self, **fit_params):\n        \"\"\"Fit the current transformer on given dataset.\"\"\"\n        if self.verbose:\n            logger.error(\"GraphTransformer featurizers cannot be fitted !\")\n        return self\n\n    @property\n    def atom_dim(self):\n        r\"\"\"\n        Get the number of features per atom\n\n        Returns:\n            atom_dim (int): Number of atom features\n        \"\"\"\n        if self._atom_dim is None:\n            try:\n                self._atom_dim = len(self.atom_featurizer)\n            except Exception:\n                _toy_mol = dm.to_mol(\"C\")\n                out = self.atom_featurizer(_toy_mol)\n                self._atom_dim = sum([x.shape[-1] for x in out.values()])\n        return self._atom_dim\n\n    @property\n    def bond_dim(self):\n        r\"\"\"\n        Get the number of features for a bond\n\n        Returns:\n            bond_dim (int): Number of bond features\n        \"\"\"\n        if self.bond_featurizer is None:\n            self._bond_dim = 0\n        if self._bond_dim is None:\n            try:\n                self._bond_dim = len(self.bond_featurizer)\n            except Exception:\n                _toy_mol = dm.to_mol(\"CO\")\n                out = self.bond_featurizer(_toy_mol)\n                self._bond_dim = sum([x.shape[-1] for x in out.values()])\n        return self._bond_dim\n\n    def _transform(self, mol: dm.Mol):\n        r\"\"\"\n        Compute features for a single molecule.\n        This method would potentially need to be reimplemented by child classes\n\n        Args:\n            mol: molecule to transform into features\n\n        Returns\n            feat: featurized input molecule\n\n        \"\"\"\n        raise NotImplementedError\n\n    def __call__(self, mols: List[Union[dm.Mol, str]], ignore_errors: bool = False, **kwargs):\n        r\"\"\"\n        Calculate features for molecules. Using __call__, instead of transform.\n        Note that most Transfomers allow you to specify\n        a return datatype.\n\n        Args:\n            mols:  Mol or SMILES of the molecules to be transformed\n            ignore_errors: Whether to ignore errors during featurization or raise an error.\n            kwargs: Named parameters for the transform method\n\n        Returns:\n            feats: list of valid features\n            ids: all valid molecule positions that did not failed during featurization\n                Only returned when ignore_errors is True.\n\n        \"\"\"\n        features = self.transform(mols, ignore_errors=ignore_errors, **kwargs)\n        if not ignore_errors:\n            return features\n        features, ids = self._filter_none(features)\n        return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.atom_dim","title":"<code>atom_dim</code>  <code>property</code>","text":"<p>Get the number of features per atom</p> <p>Returns:</p> Name Type Description <code>atom_dim</code> <code>int</code> <p>Number of atom features</p>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.bond_dim","title":"<code>bond_dim</code>  <code>property</code>","text":"<p>Get the number of features for a bond</p> <p>Returns:</p> Name Type Description <code>bond_dim</code> <code>int</code> <p>Number of bond features</p>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.__call__","title":"<code>__call__(mols, ignore_errors=False, **kwargs)</code>","text":"<p>Calculate features for molecules. Using call, instead of transform. Note that most Transfomers allow you to specify a return datatype.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>Mol or SMILES of the molecules to be transformed</p> required <code>ignore_errors</code> <code>bool</code> <p>Whether to ignore errors during featurization or raise an error.</p> <code>False</code> <code>kwargs</code> <p>Named parameters for the transform method</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>feats</code> <p>list of valid features</p> <code>ids</code> <p>all valid molecule positions that did not failed during featurization Only returned when ignore_errors is True.</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def __call__(self, mols: List[Union[dm.Mol, str]], ignore_errors: bool = False, **kwargs):\n    r\"\"\"\n    Calculate features for molecules. Using __call__, instead of transform.\n    Note that most Transfomers allow you to specify\n    a return datatype.\n\n    Args:\n        mols:  Mol or SMILES of the molecules to be transformed\n        ignore_errors: Whether to ignore errors during featurization or raise an error.\n        kwargs: Named parameters for the transform method\n\n    Returns:\n        feats: list of valid features\n        ids: all valid molecule positions that did not failed during featurization\n            Only returned when ignore_errors is True.\n\n    \"\"\"\n    features = self.transform(mols, ignore_errors=ignore_errors, **kwargs)\n    if not ignore_errors:\n        return features\n    features, ids = self._filter_none(features)\n    return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.__init__","title":"<code>__init__(atom_featurizer=None, bond_featurizer=None, explicit_hydrogens=False, canonical_atom_order=True, self_loop=False, n_jobs=1, verbose=False, dtype=None, **params)</code>","text":"<p>Mol to Graph transformer base class</p> <p>Parameters:</p> Name Type Description Default <code>atom_featurizer</code> <code>Optional[Callable]</code> <p>atom featurizer to use</p> <code>None</code> <code>bond_featurizer</code> <code>Optional[Callable]</code> <p>atom featurizer to use</p> <code>None</code> <code>explicit_hydrogens</code> <code>bool</code> <p>Whether to use explicit hydrogen in preprocessing of the input molecule</p> <code>False</code> <code>canonical_atom_order</code> <code>bool</code> <p>Whether to use a canonical ordering of the atoms</p> <code>True</code> <code>self_loop</code> <code>bool</code> <p>Whether to add self loops or not</p> <code>False</code> <code>n_jobs</code> <code>int</code> <p>Number of job to run in parallel. Defaults to 1.</p> <code>1</code> <code>verbose</code> <code>bool</code> <p>Verbosity level. Defaults to True.</p> <code>False</code> <code>dtype</code> <code>Optional[Callable]</code> <p>Output data type. Defaults to None</p> <code>None</code> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def __init__(\n    self,\n    atom_featurizer: Optional[Callable] = None,\n    bond_featurizer: Optional[Callable] = None,\n    explicit_hydrogens: bool = False,\n    canonical_atom_order: bool = True,\n    self_loop: bool = False,\n    n_jobs: int = 1,\n    verbose: bool = False,\n    dtype: Optional[Callable] = None,\n    **params,\n):\n    \"\"\"Mol to Graph transformer base class\n\n    Args:\n        atom_featurizer: atom featurizer to use\n        bond_featurizer: atom featurizer to use\n        explicit_hydrogens: Whether to use explicit hydrogen in preprocessing of the input molecule\n        canonical_atom_order: Whether to use a canonical ordering of the atoms\n        self_loop: Whether to add self loops or not\n        n_jobs: Number of job to run in parallel. Defaults to 1.\n        verbose: Verbosity level. Defaults to True.\n        dtype: Output data type. Defaults to None\n    \"\"\"\n\n    self._save_input_args()\n\n    super().__init__(\n        n_jobs=n_jobs,\n        verbose=verbose,\n        dtype=dtype,\n        featurizer=\"none\",\n        self_loop=self_loop,\n        canonical_atom_order=canonical_atom_order,\n        explicit_hydrogens=explicit_hydrogens,\n        **params,\n    )\n    if atom_featurizer is None:\n        atom_featurizer = AtomCalculator()\n    self.atom_featurizer = atom_featurizer\n    self.bond_featurizer = bond_featurizer\n    self._atom_dim = None\n    self._bond_dim = None\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.auto_self_loop","title":"<code>auto_self_loop()</code>","text":"<p>Patch the featurizer to auto support self loop based on the bond featurizer characteristics</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def auto_self_loop(self):\n    \"\"\"Patch the featurizer to auto support self loop based on the bond featurizer characteristics\"\"\"\n    bf_self_loop = None\n    if self.bond_featurizer is not None:\n        bf_self_loop = getattr(self.bond_featurizer, \"self_loop\", None)\n        bf_self_loop = bf_self_loop or getattr(self.bond_featurizer, \"_self_loop\", None)\n    if bf_self_loop is not None:\n        self.self_loop = bf_self_loop\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.fit","title":"<code>fit(**fit_params)</code>","text":"<p>Fit the current transformer on given dataset.</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def fit(self, **fit_params):\n    \"\"\"Fit the current transformer on given dataset.\"\"\"\n    if self.verbose:\n        logger.error(\"GraphTransformer featurizers cannot be fitted !\")\n    return self\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.GraphTransformer.preprocess","title":"<code>preprocess(inputs, labels=None)</code>","text":"<p>Preprocess list of input molecules Args:     labels: For compatibility</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def preprocess(self, inputs, labels=None):\n    \"\"\"Preprocess list of input molecules\n    Args:\n        labels: For compatibility\n    \"\"\"\n    inputs, labels = super().preprocess(inputs, labels)\n    new_inputs = []\n    for m in inputs:\n        try:\n            mol = dm.to_mol(\n                m, add_hs=self.explicit_hydrogens, ordered=self.canonical_atom_order\n            )\n        except Exception:\n            mol = None\n        new_inputs.append(mol)\n\n    return new_inputs, labels\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.PYGGraphTransformer","title":"<code>PYGGraphTransformer</code>","text":"<p>               Bases: <code>AdjGraphTransformer</code></p> <p>Graph transformer for the PYG models</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class PYGGraphTransformer(AdjGraphTransformer):\n    \"\"\"\n    Graph transformer for the PYG models\n    \"\"\"\n\n    def _graph_featurizer(self, mol: dm.Mol):\n        # we have used bond_calculator, therefore we need to\n        # go over the molecules and fetch the proper bond info from the atom idx\n        if self.bond_featurizer is None or (\n            isinstance(self.bond_featurizer, EdgeMatCalculator)\n            or hasattr(self.bond_featurizer, \"pairwise_atom_funcs\")\n        ):\n            graph = super()._graph_featurizer(mol)\n            (rows, cols) = np.nonzero(graph)\n            return np.vstack((rows, cols))\n\n        # we have a regular bond calculator here instead of all pairwise atoms\n        graph = []\n        for i in range(mol.GetNumBonds()):\n            bond = mol.GetBondWithIdx(i)\n            a_idx_1 = bond.GetBeginAtomIdx()\n            a_idx_2 = bond.GetEndAtomIdx()\n            graph += [[a_idx_1, a_idx_2], [a_idx_2, a_idx_1]]\n        if getattr(self.bond_featurizer, \"_self_loop\", False):\n            graph.extend([[atom_ind, atom_ind] for atom_ind in range(mol.GetNumAtoms())])\n        graph = np.asarray(graph).T\n        return graph\n\n    def _convert_feat_to_data_point(\n        self,\n        graph: np.ndarray,\n        node_feat: np.ndarray,\n        bond_feat: Optional[np.ndarray] = None,\n    ):\n        \"\"\"Convert extracted graph features to a pyg Data object\n        Args:\n            graph: graph adjacency matrix\n            node_feat: node features\n            bond_feat: bond features\n\n        Returns:\n            datapoint: a pyg Data object\n        \"\"\"\n        node_feat = torch.tensor(node_feat, dtype=torch.float32)\n        # construct edge index array E of shape (2, n_edges)\n        graph = torch.LongTensor(graph).view(2, -1)\n\n        if bond_feat is not None:\n            bond_feat = torch.tensor(bond_feat, dtype=torch.float32)\n            if bond_feat.ndim == 3:\n                bond_feat = bond_feat[graph[0, :], graph[1, :]]\n\n        d = Data(x=node_feat, edge_index=graph, edge_attr=bond_feat)\n        return d\n\n    def transform(self, mols: List[Union[dm.Mol, str]], **kwargs):\n        r\"\"\"\n        Compute the graph featurization for a set of molecules.\n\n        Args:\n            mols: a list containing smiles or mol objects\n            kwargs: arguments to pass to the `super().transform`\n\n         Returns:\n             features: a list of Data point for each molecule in the input set\n        \"\"\"\n        features = super().transform(mols, keep_dict=False, **kwargs)\n        return [self._convert_feat_to_data_point(*feat) for feat in features]\n\n    def get_collate_fn(\n        self,\n        dataset: Optional[Union[PygDataset, Sequence[BaseData], DatasetAdapter]] = None,\n        follow_batch: Optional[List[str]] = None,\n        exclude_keys: Optional[List[str]] = None,\n        return_pair: Optional[bool] = True,\n        **kwargs,\n    ):\n        \"\"\"\n        Get collate function for pyg graphs.\n        Note: The `collate_fn` is not required when using `torch_geometric.loader.dataloader.DataLoader`.\n\n        Args:\n            dataset: The dataset from which to load the data and apply the collate function.\n                This is required if the dataset is &lt;torch_geometric.data.on_disk_dataset.OnDiskDataset&gt;.\n            follow_batch: Creates assignment batch vectors for each key in the list. (default: :obj:`None`)\n            exclude_keys: Will exclude each key in the list. (default: :obj:`None`)\n            return_pair: whether to return a pair of X,y or a databatch (default: :obj:`True`)\n\n        Returns:\n            Collated samples.\n\n        See Also:\n            &lt;torch_geometric.loader.dataloader.Collator&gt;\n            &lt;torch_geometric.loader.dataloader.DataLoader&gt;\n        \"\"\"\n        collator = Collater(dataset=dataset, follow_batch=follow_batch, exclude_keys=exclude_keys)\n        return partial(self._collate_batch, collator=collator, return_pair=return_pair)\n\n    @staticmethod\n    def _collate_batch(batch, collator: Callable, return_pair: bool = False, **kwargs):\n        \"\"\"\n        Collate a batch of samples.\n\n        Args:\n            batch: Batch of samples.\n            collator: collator function\n            return_pair: whether to return a pair of (X,y) a databatch\n        Returns:\n            Collated samples.\n        \"\"\"\n        if isinstance(batch[0], (list, tuple)) and len(batch[0]) &gt; 1:\n            graphs, labels = map(list, zip(*batch))\n            for graph, label in zip(graphs, labels):\n                graph.y = label\n            batch = graphs\n        batch = collator(batch)\n        if return_pair:\n            return (batch, batch.y)\n        return batch\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.PYGGraphTransformer.get_collate_fn","title":"<code>get_collate_fn(dataset=None, follow_batch=None, exclude_keys=None, return_pair=True, **kwargs)</code>","text":"<p>Get collate function for pyg graphs. Note: The <code>collate_fn</code> is not required when using <code>torch_geometric.loader.dataloader.DataLoader</code>.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Optional[Union[Dataset, Sequence[BaseData], DatasetAdapter]]</code> <p>The dataset from which to load the data and apply the collate function. This is required if the dataset is . <code>None</code> <code>follow_batch</code> <code>Optional[List[str]]</code> <p>Creates assignment batch vectors for each key in the list. (default: :obj:<code>None</code>)</p> <code>None</code> <code>exclude_keys</code> <code>Optional[List[str]]</code> <p>Will exclude each key in the list. (default: :obj:<code>None</code>)</p> <code>None</code> <code>return_pair</code> <code>Optional[bool]</code> <p>whether to return a pair of X,y or a databatch (default: :obj:<code>True</code>)</p> <code>True</code> <p>Returns:</p> Type Description <p>Collated samples.</p> See Also <p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def get_collate_fn(\n    self,\n    dataset: Optional[Union[PygDataset, Sequence[BaseData], DatasetAdapter]] = None,\n    follow_batch: Optional[List[str]] = None,\n    exclude_keys: Optional[List[str]] = None,\n    return_pair: Optional[bool] = True,\n    **kwargs,\n):\n    \"\"\"\n    Get collate function for pyg graphs.\n    Note: The `collate_fn` is not required when using `torch_geometric.loader.dataloader.DataLoader`.\n\n    Args:\n        dataset: The dataset from which to load the data and apply the collate function.\n            This is required if the dataset is &lt;torch_geometric.data.on_disk_dataset.OnDiskDataset&gt;.\n        follow_batch: Creates assignment batch vectors for each key in the list. (default: :obj:`None`)\n        exclude_keys: Will exclude each key in the list. (default: :obj:`None`)\n        return_pair: whether to return a pair of X,y or a databatch (default: :obj:`True`)\n\n    Returns:\n        Collated samples.\n\n    See Also:\n        &lt;torch_geometric.loader.dataloader.Collator&gt;\n        &lt;torch_geometric.loader.dataloader.DataLoader&gt;\n    \"\"\"\n    collator = Collater(dataset=dataset, follow_batch=follow_batch, exclude_keys=exclude_keys)\n    return partial(self._collate_batch, collator=collator, return_pair=return_pair)\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.PYGGraphTransformer.transform","title":"<code>transform(mols, **kwargs)</code>","text":"<p>Compute the graph featurization for a set of molecules.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>a list containing smiles or mol objects</p> required <code>kwargs</code> <p>arguments to pass to the <code>super().transform</code></p> <code>{}</code> <p>Returns:      features: a list of Data point for each molecule in the input set</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>def transform(self, mols: List[Union[dm.Mol, str]], **kwargs):\n    r\"\"\"\n    Compute the graph featurization for a set of molecules.\n\n    Args:\n        mols: a list containing smiles or mol objects\n        kwargs: arguments to pass to the `super().transform`\n\n     Returns:\n         features: a list of Data point for each molecule in the input set\n    \"\"\"\n    features = super().transform(mols, keep_dict=False, **kwargs)\n    return [self._convert_feat_to_data_point(*feat) for feat in features]\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.adj.TopoDistGraphTransformer","title":"<code>TopoDistGraphTransformer</code>","text":"<p>               Bases: <code>AdjGraphTransformer</code></p> <p>Graph featurizer using the topological distance between each pair of nodes instead of the adjacency matrix.</p> <p>The <code>self_loop</code> attribute is ignored here as the distance between an atom and itself is 0.</p> Source code in <code>molfeat/trans/graph/adj.py</code> <pre><code>class TopoDistGraphTransformer(AdjGraphTransformer):\n    \"\"\"\n    Graph featurizer using the topological distance between each pair\n    of nodes instead of the adjacency matrix.\n\n    The `self_loop` attribute is ignored here as the distance between an atom and itself is 0.\n    \"\"\"\n\n    def _graph_featurizer(self, mol: dm.Mol):\n        \"\"\"Graph topological distance featurizer\n\n        Args:\n            mol: molecule to transform into a graph\n\n        Returns:\n            mat : N,N matrix representing the graph\n        \"\"\"\n        return GetDistanceMatrix(mol)\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#tree","title":"Tree","text":""},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.tree.MolTreeDecompositionTransformer","title":"<code>MolTreeDecompositionTransformer</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>Transforms a molecule into a tree structure whose nodes correspond to different functional groups.</p> Source code in <code>molfeat/trans/graph/tree.py</code> <pre><code>class MolTreeDecompositionTransformer(MoleculeTransformer):\n    r\"\"\"\n    Transforms a molecule into a tree structure whose nodes correspond to different functional groups.\n    \"\"\"\n\n    def __init__(\n        self,\n        vocab: Optional[Iterable] = None,\n        one_hot: bool = False,\n        dtype: Optional[Callable] = None,\n        cache: bool = True,\n        **params,\n    ):\n        \"\"\"MolTree featurizer\n\n        Args:\n            vocab: List of the smiles of the functional groups or clusters.\n                If None, the transformer should be fiited before any usage.\n            one_hot (bool, optional): Whether or not for a tree a 1d array or a 2d array is returned as features\n                If 1d array, vocabulary elements are mapped into integers,\n                otherwise, vocabulary elements  ar mapped into one-hot vectors\n            cache: Whether to cache the tree decomposition to avoid recomputing for seen molecules\n            dtype: Output data type. Defaults to None\n\n        Attributes:\n            vocab: Mapping from clusters to integers\n            vocab_size: The number of clusters + 1\n            one_hot: Whether or not for a sequence a 1d array or a 2d array is returned as features\n        \"\"\"\n\n        self._save_input_args()\n\n        super().__init__(\n            dtype=dtype,\n            one_hot=one_hot,\n            cache=cache,\n            featurizer=TreeDecomposer(cache=cache),\n            **params,\n        )\n        if vocab is not None:\n            self.vocab = vocab\n            self._vocab_size = len(self.vocab) + 1\n            self._fitted = True\n        else:\n            self.vocab = None\n            self._vocab_size = None\n            self._fitted = False\n\n        if not requires.check(\"dgl\"):\n            raise ValueError(\"dgl is required for this featurizer, please install it first\")\n\n        if self.dtype is not None and not datatype.is_dtype_tensor(self.dtype):\n            raise ValueError(\"DGL featurizer only supports torch tensors currently\")\n\n    @property\n    def vocab_size(self):\n        \"\"\"Compute vocab size of this featurizer\n\n        Returns:\n            size: vocab size\n        \"\"\"\n        return self._vocab_size\n\n    def fit(\n        self,\n        X: List[Union[dm.Mol, str]],\n        y: Optional[list] = None,\n        output_file: Optional[os.PathLike] = None,\n        **fit_params,\n    ):\n        \"\"\"Fit the current transformer on given dataset.\n\n        The goal of fitting is for example to identify nan columns values\n        that needs to be removed from the dataset\n\n        Args:\n            X: input list of molecules\n            y (list, optional): Optional list of molecular properties. Defaults to None.\n            output_file: path to a file that will be used to store the generated set of fragments.\n            fit_params: key val of additional fit parameters\n\n\n        Returns:\n            self: MolTransformer instance after fitting\n        \"\"\"\n        if self.vocab is not None:\n            logger.warning(\"The previous vocabulary of fragments will be erased.\")\n        self.vocab = self.featurizer.get_vocab(X, output_file=output_file, log=self.verbose)\n        self._vocab_size = len(self.vocab) + 1\n        self._fitted = True\n\n        # save the vocab in the state\n        self._input_args[\"vocab\"] = self.vocab\n\n        return self\n\n    def _transform(self, mol: dm.Mol):\n        r\"\"\"\n        Compute features for a single molecule.\n        This method would potentially need to be reimplemented by child classes\n\n        Args:\n            mol (dm.Mol): molecule to transform into features\n\n        Returns\n            feat: featurized input molecule\n\n        \"\"\"\n        if not self._fitted:\n            raise ValueError(\n                \"Need to call the fit function before any transformation. \\\n                Or provide the fragments vocabulary at the object construction\"\n            )\n\n        try:\n            _, edges, fragments = self.featurizer(mol)\n            n_nodes = len(fragments)\n            enc = [self.vocab.index(f) + 1 if f in self.vocab else 0 for f in fragments]\n            enc = datatype.cast(enc, (self.dtype or torch.long))\n            graph = dgl.graph(([], []))\n            graph.add_nodes(n_nodes)\n            for edge in edges:\n                graph.add_edges(*edge)\n                graph.add_edges(*edge[::-1])\n\n            if self.one_hot:\n                enc = [one_hot_encoding(f, self.vocab, encode_unknown=True) for f in fragments]\n                enc = np.asarray(enc)\n                enc = datatype.cast(enc, (self.dtype or torch.float))\n\n            graph.ndata[\"hv\"] = enc\n        except Exception as e:\n            raise e\n            if self.verbose:\n                logger.error(e)\n            graph = None\n        return graph\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.tree.MolTreeDecompositionTransformer.vocab_size","title":"<code>vocab_size</code>  <code>property</code>","text":"<p>Compute vocab size of this featurizer</p> <p>Returns:</p> Name Type Description <code>size</code> <p>vocab size</p>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.tree.MolTreeDecompositionTransformer.__init__","title":"<code>__init__(vocab=None, one_hot=False, dtype=None, cache=True, **params)</code>","text":"<p>MolTree featurizer</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Optional[Iterable]</code> <p>List of the smiles of the functional groups or clusters. If None, the transformer should be fiited before any usage.</p> <code>None</code> <code>one_hot</code> <code>bool</code> <p>Whether or not for a tree a 1d array or a 2d array is returned as features If 1d array, vocabulary elements are mapped into integers, otherwise, vocabulary elements  ar mapped into one-hot vectors</p> <code>False</code> <code>cache</code> <code>bool</code> <p>Whether to cache the tree decomposition to avoid recomputing for seen molecules</p> <code>True</code> <code>dtype</code> <code>Optional[Callable]</code> <p>Output data type. Defaults to None</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>vocab</code> <p>Mapping from clusters to integers</p> <code>vocab_size</code> <p>The number of clusters + 1</p> <code>one_hot</code> <p>Whether or not for a sequence a 1d array or a 2d array is returned as features</p> Source code in <code>molfeat/trans/graph/tree.py</code> <pre><code>def __init__(\n    self,\n    vocab: Optional[Iterable] = None,\n    one_hot: bool = False,\n    dtype: Optional[Callable] = None,\n    cache: bool = True,\n    **params,\n):\n    \"\"\"MolTree featurizer\n\n    Args:\n        vocab: List of the smiles of the functional groups or clusters.\n            If None, the transformer should be fiited before any usage.\n        one_hot (bool, optional): Whether or not for a tree a 1d array or a 2d array is returned as features\n            If 1d array, vocabulary elements are mapped into integers,\n            otherwise, vocabulary elements  ar mapped into one-hot vectors\n        cache: Whether to cache the tree decomposition to avoid recomputing for seen molecules\n        dtype: Output data type. Defaults to None\n\n    Attributes:\n        vocab: Mapping from clusters to integers\n        vocab_size: The number of clusters + 1\n        one_hot: Whether or not for a sequence a 1d array or a 2d array is returned as features\n    \"\"\"\n\n    self._save_input_args()\n\n    super().__init__(\n        dtype=dtype,\n        one_hot=one_hot,\n        cache=cache,\n        featurizer=TreeDecomposer(cache=cache),\n        **params,\n    )\n    if vocab is not None:\n        self.vocab = vocab\n        self._vocab_size = len(self.vocab) + 1\n        self._fitted = True\n    else:\n        self.vocab = None\n        self._vocab_size = None\n        self._fitted = False\n\n    if not requires.check(\"dgl\"):\n        raise ValueError(\"dgl is required for this featurizer, please install it first\")\n\n    if self.dtype is not None and not datatype.is_dtype_tensor(self.dtype):\n        raise ValueError(\"DGL featurizer only supports torch tensors currently\")\n</code></pre>"},{"location":"api/molfeat.trans.graph.html#molfeat.trans.graph.tree.MolTreeDecompositionTransformer.fit","title":"<code>fit(X, y=None, output_file=None, **fit_params)</code>","text":"<p>Fit the current transformer on given dataset.</p> <p>The goal of fitting is for example to identify nan columns values that needs to be removed from the dataset</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>List[Union[Mol, str]]</code> <p>input list of molecules</p> required <code>y</code> <code>list</code> <p>Optional list of molecular properties. Defaults to None.</p> <code>None</code> <code>output_file</code> <code>Optional[PathLike]</code> <p>path to a file that will be used to store the generated set of fragments.</p> <code>None</code> <code>fit_params</code> <p>key val of additional fit parameters</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>self</code> <p>MolTransformer instance after fitting</p> Source code in <code>molfeat/trans/graph/tree.py</code> <pre><code>def fit(\n    self,\n    X: List[Union[dm.Mol, str]],\n    y: Optional[list] = None,\n    output_file: Optional[os.PathLike] = None,\n    **fit_params,\n):\n    \"\"\"Fit the current transformer on given dataset.\n\n    The goal of fitting is for example to identify nan columns values\n    that needs to be removed from the dataset\n\n    Args:\n        X: input list of molecules\n        y (list, optional): Optional list of molecular properties. Defaults to None.\n        output_file: path to a file that will be used to store the generated set of fragments.\n        fit_params: key val of additional fit parameters\n\n\n    Returns:\n        self: MolTransformer instance after fitting\n    \"\"\"\n    if self.vocab is not None:\n        logger.warning(\"The previous vocabulary of fragments will be erased.\")\n    self.vocab = self.featurizer.get_vocab(X, output_file=output_file, log=self.verbose)\n    self._vocab_size = len(self.vocab) + 1\n    self._fitted = True\n\n    # save the vocab in the state\n    self._input_args[\"vocab\"] = self.vocab\n\n    return self\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.base.html","title":"Base Pretrained Models","text":""},{"location":"api/molfeat.trans.pretrained.base.html#pretrained-model","title":"Pretrained Model","text":""},{"location":"api/molfeat.trans.pretrained.base.html#molfeat.trans.pretrained.base.PretrainedMolTransformer","title":"<code>PretrainedMolTransformer</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>Transformer based on pretrained featurizer</p> <p>Note</p> <ul> <li>When implementing a subclass of this class, you need to define the <code>_embed</code> and optionally the <code>_convert</code> methods.</li> <li>If your model is an instance of PretrainedModel that handles loading of the model from a store or through a complex mechanism   then you can decide whether you want to preload the true underlying model. You will be in charge of handling the logic of when you need to call preload, and when you don't.   Note however that by default preloading is only attempted when the featurizer is still an instance of PretrainedModel.</li> </ul> <p>Attributes     featurizer (object): featurizer object     dtype (type, optional): Data type. Use call instead     precompute_cache: (bool, optional): Whether to precompute the features into a local cache. Defaults to False.         Note that due to molecular hashing, some pretrained featurizers might be better off just not using any cache as they can be faster.         Furthermore, the cache is not saved when pickling the object. If you want to save the cache, you need to save the object separately.     _require_mols (bool): Whether the embedding takes mols or smiles as input     preload: whether to preload the pretrained model from the store (if available) during initialization.</p> Source code in <code>molfeat/trans/pretrained/base.py</code> <pre><code>class PretrainedMolTransformer(MoleculeTransformer):\n    r\"\"\"\n    Transformer based on pretrained featurizer\n\n    !!! note\n        * When implementing a subclass of this class, you need to define the `_embed` and optionally the `_convert` methods.\n        * If your model is an instance of PretrainedModel that handles loading of the model from a store or through a complex mechanism\n          then you can decide whether you want to preload the true underlying model. You will be in charge of handling the logic of when you need to call preload, and when you don't.\n          Note however that by default preloading is only attempted when the featurizer is still an instance of PretrainedModel.\n\n\n    Attributes\n        featurizer (object): featurizer object\n        dtype (type, optional): Data type. Use call instead\n        precompute_cache: (bool, optional): Whether to precompute the features into a local cache. Defaults to False.\n            Note that due to molecular hashing, some pretrained featurizers might be better off just not using any cache as they can be faster.\n            Furthermore, the cache is not saved when pickling the object. If you want to save the cache, you need to save the object separately.\n        _require_mols (bool): Whether the embedding takes mols or smiles as input\n        preload: whether to preload the pretrained model from the store (if available) during initialization.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        dtype: Optional[Callable] = None,\n        precompute_cache: Optional[Union[bool, DataCache]] = None,\n        preload: bool = False,\n        **params,\n    ):\n        self._save_input_args()\n\n        featurizer = params.pop(\"featurizer\", None)\n        super().__init__(dtype=dtype, featurizer=\"none\", **params)\n        self.featurizer = featurizer\n        self._require_mols = False\n        self.preload = preload\n        self._feat_length = None\n        if precompute_cache is False:\n            precompute_cache = None\n        if precompute_cache is True:\n            name = str(self.__class__.__name__)\n            precompute_cache = DataCache(name=name)\n        self.precompute_cache = precompute_cache\n\n    def set_cache(self, cache: DataCache):\n        \"\"\"Set the cache for the transformer\n\n        Args:\n            cache: cache object\n        \"\"\"\n        self.precompute_cache = cache\n\n    def _get_param_names(self):\n        \"\"\"Get parameter names for the estimator\"\"\"\n        out = self._input_params.keys()\n        out = [x for x in out if x != \"featurizer\"]\n        return out\n\n    def _embed(self, smiles: str, **kwargs):\n        \"\"\"Compute molecular embeddings for input list of smiles\n        This functiom takes a list of smiles or molecules and return the featurization\n        corresponding to the inputs.  In `transform` and `_transform`, this function is\n        called after calling `_convert`\n\n        Args:\n            smiles: input smiles\n        \"\"\"\n        raise NotImplementedError\n\n    def _preload(self):\n        \"\"\"Preload the pretrained model for later queries\"\"\"\n        if self.featurizer is not None and isinstance(self.featurizer, PretrainedModel):\n            self.featurizer = self.featurizer.load()\n            self.preload = True\n\n    def __getstate__(self):\n        \"\"\"Getting state to allow pickling\"\"\"\n        d = copy.deepcopy(self.__dict__)\n        d[\"precompute_cache\"] = None\n        if isinstance(getattr(self, \"featurizer\", None), PretrainedModel) or self.preload:\n            d.pop(\"featurizer\", None)\n        return d\n\n    def __setstate__(self, d):\n        \"\"\"Setting state during reloading pickling\"\"\"\n        self.__dict__.update(d)\n        self._update_params()\n\n    def fit(self, *args, **kwargs):\n        return self\n\n    def _convert(self, inputs: list, **kwargs):\n        \"\"\"Convert molecules to the right format\n\n        In `transform` and `_transform`, this function is called before calling `_embed`\n\n        Args:\n            inputs: inputs to preprocess\n\n        Returns:\n            processed: pre-processed input list\n        \"\"\"\n        if not self._require_mols:\n            inputs = [dm.to_smiles(m) for m in inputs]\n        return inputs\n\n    def preprocess(self, inputs: list, labels: Optional[list] = None):\n        \"\"\"Run preprocessing on the input data\n        Args:\n            inputs: list of input molecules\n            labels: list of labels\n        \"\"\"\n        out = super().preprocess(inputs, labels)\n        if self.precompute_cache not in [False, None]:\n            try:\n                self.transform(inputs)\n            except Exception:\n                pass\n        return out\n\n    def _transform(self, mol: dm.Mol, **kwargs):\n        r\"\"\"\n        Compute features for a single molecule.\n        This method would potentially need to be reimplemented by any child class\n\n        Args:\n            mol (dm.Mol): molecule to transform into features\n\n        Returns\n            feat: featurized input molecule\n\n        \"\"\"\n        feat = None\n        if self.precompute_cache is not None:\n            feat = self.precompute_cache.get(mol)\n        if feat is None:\n            try:\n                mols = [dm.to_mol(mol)]\n                mols = self._convert(mols, **kwargs)\n                feat = self._embed(mols, **kwargs)\n                feat = feat[0]\n            except Exception as e:\n                if self.verbose:\n                    logger.error(e)\n\n            if self.precompute_cache is not None:\n                self.precompute_cache[mol] = feat\n        return feat\n\n    def transform(self, smiles: List[str], **kwargs):\n        \"\"\"Perform featurization of the input molecules\n\n        The featurization process is as follow:\n        1. convert the input molecules into the right format, expected by the pre-trained model using `_convert`\n        2. compute embedding of the molecule using `_embed`\n        3. perform any model-specific postprocessing and cache update\n\n        The dtype returned is the native datatype of the transformer.\n        Use `__call__` to get the dtype in the `dtype` attribute format\n\n        Args:\n            mols: a list containing smiles or mol objects\n\n        Returns:\n            out: featurized molecules\n        \"\"\"\n        if isinstance(smiles, str) or not isinstance(smiles, Iterable):\n            smiles = [smiles]\n\n        n_mols = len(smiles)\n        ind_to_compute = dict(zip(range(n_mols), range(n_mols)))\n        pre_computed = [None] * n_mols\n\n        if self.precompute_cache not in [False, None]:\n            ind_to_compute = {}\n            pre_computed = self.precompute_cache.fetch(smiles)\n            ind = 0\n            for i, v in enumerate(pre_computed):\n                if v is None:\n                    ind_to_compute[i] = ind\n                    ind += 1\n\n        parallel_kwargs = getattr(self, \"parallel_kwargs\", {})\n        mols = dm.parallelized(\n            dm.to_mol, smiles, n_jobs=getattr(self, \"n_jobs\", 1), **parallel_kwargs\n        )\n        mols = [mols[i] for i in ind_to_compute]\n\n        if len(mols) &gt; 0:\n            converted_mols = self._convert(mols, **kwargs)\n            out = self._embed(converted_mols, **kwargs)\n\n            if not isinstance(out, list):\n                out = list(out)\n\n            if self.precompute_cache is not None:\n                # cache value now\n                self.precompute_cache.update(dict(zip(mols, out)))\n        out = [\n            out[ind_to_compute[i]] if i in ind_to_compute else pre_computed[i]\n            for i in range(n_mols)\n        ]\n        return datatype.as_numpy_array_if_possible(out, self.dtype)\n\n    def __eq__(self, other):\n        if isinstance(other, self.__class__):\n            return str(self) == str(other)\n        return False\n\n    def _update_params(self):\n        self._fitted = False\n\n    def __len__(self):\n        if self._feat_length is None:\n            self._preload()\n            tmp_mol = dm.to_mol(\"CCC\")\n            embs = self._transform(tmp_mol)\n            self._feat_length = len(embs)\n        return self._feat_length\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __hash__(self):\n        return hash(repr(self))\n\n    def __repr__(self):\n        return \"{}(dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self.dtype),\n        )\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.base.html#molfeat.trans.pretrained.base.PretrainedMolTransformer.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Getting state to allow pickling</p> Source code in <code>molfeat/trans/pretrained/base.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Getting state to allow pickling\"\"\"\n    d = copy.deepcopy(self.__dict__)\n    d[\"precompute_cache\"] = None\n    if isinstance(getattr(self, \"featurizer\", None), PretrainedModel) or self.preload:\n        d.pop(\"featurizer\", None)\n    return d\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.base.html#molfeat.trans.pretrained.base.PretrainedMolTransformer.__setstate__","title":"<code>__setstate__(d)</code>","text":"<p>Setting state during reloading pickling</p> Source code in <code>molfeat/trans/pretrained/base.py</code> <pre><code>def __setstate__(self, d):\n    \"\"\"Setting state during reloading pickling\"\"\"\n    self.__dict__.update(d)\n    self._update_params()\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.base.html#molfeat.trans.pretrained.base.PretrainedMolTransformer.preprocess","title":"<code>preprocess(inputs, labels=None)</code>","text":"<p>Run preprocessing on the input data Args:     inputs: list of input molecules     labels: list of labels</p> Source code in <code>molfeat/trans/pretrained/base.py</code> <pre><code>def preprocess(self, inputs: list, labels: Optional[list] = None):\n    \"\"\"Run preprocessing on the input data\n    Args:\n        inputs: list of input molecules\n        labels: list of labels\n    \"\"\"\n    out = super().preprocess(inputs, labels)\n    if self.precompute_cache not in [False, None]:\n        try:\n            self.transform(inputs)\n        except Exception:\n            pass\n    return out\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.base.html#molfeat.trans.pretrained.base.PretrainedMolTransformer.set_cache","title":"<code>set_cache(cache)</code>","text":"<p>Set the cache for the transformer</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>DataCache</code> <p>cache object</p> required Source code in <code>molfeat/trans/pretrained/base.py</code> <pre><code>def set_cache(self, cache: DataCache):\n    \"\"\"Set the cache for the transformer\n\n    Args:\n        cache: cache object\n    \"\"\"\n    self.precompute_cache = cache\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.base.html#molfeat.trans.pretrained.base.PretrainedMolTransformer.transform","title":"<code>transform(smiles, **kwargs)</code>","text":"<p>Perform featurization of the input molecules</p> <p>The featurization process is as follow: 1. convert the input molecules into the right format, expected by the pre-trained model using <code>_convert</code> 2. compute embedding of the molecule using <code>_embed</code> 3. perform any model-specific postprocessing and cache update</p> <p>The dtype returned is the native datatype of the transformer. Use <code>__call__</code> to get the dtype in the <code>dtype</code> attribute format</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <p>a list containing smiles or mol objects</p> required <p>Returns:</p> Name Type Description <code>out</code> <p>featurized molecules</p> Source code in <code>molfeat/trans/pretrained/base.py</code> <pre><code>def transform(self, smiles: List[str], **kwargs):\n    \"\"\"Perform featurization of the input molecules\n\n    The featurization process is as follow:\n    1. convert the input molecules into the right format, expected by the pre-trained model using `_convert`\n    2. compute embedding of the molecule using `_embed`\n    3. perform any model-specific postprocessing and cache update\n\n    The dtype returned is the native datatype of the transformer.\n    Use `__call__` to get the dtype in the `dtype` attribute format\n\n    Args:\n        mols: a list containing smiles or mol objects\n\n    Returns:\n        out: featurized molecules\n    \"\"\"\n    if isinstance(smiles, str) or not isinstance(smiles, Iterable):\n        smiles = [smiles]\n\n    n_mols = len(smiles)\n    ind_to_compute = dict(zip(range(n_mols), range(n_mols)))\n    pre_computed = [None] * n_mols\n\n    if self.precompute_cache not in [False, None]:\n        ind_to_compute = {}\n        pre_computed = self.precompute_cache.fetch(smiles)\n        ind = 0\n        for i, v in enumerate(pre_computed):\n            if v is None:\n                ind_to_compute[i] = ind\n                ind += 1\n\n    parallel_kwargs = getattr(self, \"parallel_kwargs\", {})\n    mols = dm.parallelized(\n        dm.to_mol, smiles, n_jobs=getattr(self, \"n_jobs\", 1), **parallel_kwargs\n    )\n    mols = [mols[i] for i in ind_to_compute]\n\n    if len(mols) &gt; 0:\n        converted_mols = self._convert(mols, **kwargs)\n        out = self._embed(converted_mols, **kwargs)\n\n        if not isinstance(out, list):\n            out = list(out)\n\n        if self.precompute_cache is not None:\n            # cache value now\n            self.precompute_cache.update(dict(zip(mols, out)))\n    out = [\n        out[ind_to_compute[i]] if i in ind_to_compute else pre_computed[i]\n        for i in range(n_mols)\n    ]\n    return datatype.as_numpy_array_if_possible(out, self.dtype)\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html","title":"DGL","text":""},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#dgllife-pretrained-models","title":"DGLLife pretrained models","text":""},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.DGLModel","title":"<code>DGLModel</code>","text":"<p>               Bases: <code>PretrainedStoreModel</code></p> <p>Load one of the pretrained DGL models for molecular embedding:</p> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>class DGLModel(PretrainedStoreModel):\n    r\"\"\"\n    Load one of the pretrained DGL models for molecular embedding:\n    \"\"\"\n\n    AVAILABLE_MODELS = [\n        \"gin_supervised_contextpred\",\n        \"gin_supervised_infomax\",\n        \"gin_supervised_edgepred\",\n        \"gin_supervised_masking\",\n        \"jtvae_zinc_no_kl\",\n    ]\n\n    def __init__(\n        self,\n        name: str,\n        cache_path: Optional[os.PathLike] = None,\n        store: Optional[ModelStore] = None,\n    ):\n        super().__init__(name, cache_path=cache_path, store=store)\n        self._model = None\n\n    @classmethod\n    def available_models(cls, query: Optional[str] = None):\n        \"\"\"List available models\n        Args:\n            query (str, optional): Query to filter the list of available models. Defaults to None.\n        \"\"\"\n        if query is None:\n            return cls.AVAILABLE_MODELS\n        else:\n            return [x for x in cls.AVAILABLE_MODELS if re.search(query, x, re.IGNORECASE)]\n\n    @classmethod\n    def from_pretrained(cls, model_name: str):\n        \"\"\"Load pretrained model using the dgllife API and not the store\"\"\"\n        if not requires.check(\"dgllife\"):\n            raise ValueError(\"dgllife is not installed\")\n        import dgllife\n\n        base_model = dgllife.model.load_pretrained(model_name)\n        base_model.eval()\n        model = DGLModel(name=model_name)\n        model._model = base_model\n        return model\n\n    def load(self):\n        \"\"\"Load GIN model\"\"\"\n        if self._model is not None:\n            return self._model\n        download_output_dir = self._artifact_load(\n            name=self.name, download_path=self.cache_path, store=self.store\n        )\n        model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)\n        with fsspec.open(model_path, \"rb\") as f:\n            model = joblib.load(f)\n        model.eval()\n        return model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.DGLModel.available_models","title":"<code>available_models(query=None)</code>  <code>classmethod</code>","text":"<p>List available models Args:     query (str, optional): Query to filter the list of available models. Defaults to None.</p> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>@classmethod\ndef available_models(cls, query: Optional[str] = None):\n    \"\"\"List available models\n    Args:\n        query (str, optional): Query to filter the list of available models. Defaults to None.\n    \"\"\"\n    if query is None:\n        return cls.AVAILABLE_MODELS\n    else:\n        return [x for x in cls.AVAILABLE_MODELS if re.search(query, x, re.IGNORECASE)]\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.DGLModel.from_pretrained","title":"<code>from_pretrained(model_name)</code>  <code>classmethod</code>","text":"<p>Load pretrained model using the dgllife API and not the store</p> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>@classmethod\ndef from_pretrained(cls, model_name: str):\n    \"\"\"Load pretrained model using the dgllife API and not the store\"\"\"\n    if not requires.check(\"dgllife\"):\n        raise ValueError(\"dgllife is not installed\")\n    import dgllife\n\n    base_model = dgllife.model.load_pretrained(model_name)\n    base_model.eval()\n    model = DGLModel(name=model_name)\n    model._model = base_model\n    return model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.DGLModel.load","title":"<code>load()</code>","text":"<p>Load GIN model</p> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>def load(self):\n    \"\"\"Load GIN model\"\"\"\n    if self._model is not None:\n        return self._model\n    download_output_dir = self._artifact_load(\n        name=self.name, download_path=self.cache_path, store=self.store\n    )\n    model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)\n    with fsspec.open(model_path, \"rb\") as f:\n        model = joblib.load(f)\n    model.eval()\n    return model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.PretrainedDGLTransformer","title":"<code>PretrainedDGLTransformer</code>","text":"<p>               Bases: <code>PretrainedMolTransformer</code></p> <p>DGL Pretrained transformer</p> <p>Attributes:</p> Name Type Description <code>featurizer</code> <code>DGLModel</code> <p>DGL featurizer object</p> <code>dtype</code> <code>type</code> <p>Data type.</p> <code>pooling</code> <code>str</code> <p>Pooling method for GIN's embedding layer (Default: mean)</p> <code>batch_size</code> <code>int</code> <p>Batch size to consider for model</p> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>class PretrainedDGLTransformer(PretrainedMolTransformer):\n    r\"\"\"\n    DGL Pretrained transformer\n\n    Attributes:\n        featurizer (DGLModel): DGL featurizer object\n        dtype (type, optional): Data type.\n        pooling (str, optional): Pooling method for GIN's embedding layer (Default: mean)\n        batch_size (int, optional): Batch size to consider for model\n    \"\"\"\n\n    def __init__(\n        self,\n        kind: Union[str, DGLModel] = \"gin_supervised_contextpred\",\n        dtype: Callable = np.float32,\n        pooling: str = \"mean\",\n        batch_size: int = 32,\n        preload: bool = False,\n        **params,\n    ):\n        \"\"\"DGL pretrained featurizer\n\n        Args:\n            kind (str, optional): name of the pretrained gin. Defaults to \"gin_supervised_contextpred\".\n            dtype: datatype. Defaults to np.float32.\n            pooling: global pooling to perform. Defaults to \"mean\".\n            batch_size: batch size for featurizing the molecules. Defaults to 32.\n            preload: whether to preload the internal pretrained featurizer or not\n\n        \"\"\"\n        if not requires.check(\"dgllife\"):\n            raise ValueError(\"Cannot find dgl|dgllife. It's required for this featurizer !\")\n        super().__init__(\n            dtype=dtype,\n            pooling=pooling,\n            batch_size=batch_size,\n            preload=preload,\n            kind=kind,\n            **params,\n        )\n        self.pooling = pooling\n        self.preload = preload\n        self._pooling_obj = self.get_pooling(pooling)\n        if isinstance(kind, DGLModel):\n            self.kind = kind.name\n            self.featurizer = kind\n        else:\n            self.kind = kind\n            self.featurizer = DGLModel(name=self.kind)\n        self.batch_size = int(batch_size)\n        if self.preload:\n            self._preload()\n\n    def __repr__(self):\n        return \"{}(kind={}, pooling={}, dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self.kind),\n            _parse_to_evaluable_str(self.pooling),\n            _parse_to_evaluable_str(self.dtype),\n        )\n\n    def _update_params(self):\n        super()._update_params()\n        self._pooling_obj = self.get_pooling(self.pooling)\n        featurizer = DGLModel(name=self.kind)\n        self.featurizer = featurizer.load()\n\n    @staticmethod\n    def get_pooling(pooling: str):\n        \"\"\"Get pooling method from name\n\n        Args:\n            pooling: name of the pooling method\n        \"\"\"\n        pooling = pooling.lower()\n        if pooling in [\"mean\", \"avg\", \"average\"]:\n            return AvgPooling()\n        elif pooling == \"sum\":\n            return SumPooling()\n        elif pooling == \"max\":\n            return MaxPooling()\n        else:\n            raise ValueError(f\"Pooling: {pooling} not supported !\")\n\n    def _embed_gin(self, dataset):\n        \"\"\"Embed molecules using GIN\"\"\"\n        data_loader = DataLoader(\n            dataset,\n            batch_size=self.batch_size,\n            collate_fn=dgl.batch,\n            shuffle=False,\n            drop_last=False,\n        )\n\n        mol_emb = []\n        for batch_id, bg in enumerate(data_loader):\n            if self.verbose:\n                logger.debug(\"Processing batch {:d}/{:d}\".format(batch_id + 1, len(data_loader)))\n            nfeats = [\n                bg.ndata.pop(\"atomic_number\").to(torch.device(\"cpu\")),\n                bg.ndata.pop(\"chirality_type\").to(torch.device(\"cpu\")),\n            ]\n            efeats = [\n                bg.edata.pop(\"bond_type\").to(torch.device(\"cpu\")),\n                bg.edata.pop(\"bond_direction_type\").to(torch.device(\"cpu\")),\n            ]\n            with torch.no_grad():\n                node_repr = self.featurizer(bg, nfeats, efeats)\n            mol_emb.append(self._pooling_obj(bg, node_repr))\n        mol_emb = torch.cat(mol_emb, dim=0).detach().cpu().numpy()\n        return mol_emb\n\n    def _embed_jtvae(self, dataset):\n        \"\"\"Embed molecules using JTVAE\"\"\"\n        dataloader = DataLoader(dataset, batch_size=1, collate_fn=JTVAECollator(training=False))\n\n        mol_emb = []\n        for tree, tree_graph, mol_graph in dataloader:\n            _, tree_vec, mol_vec = self.featurizer.encode(tree_graph, mol_graph)\n            enc = torch.cat([tree_vec, mol_vec], dim=1).detach()\n            mol_emb.append(enc)\n        mol_emb = torch.cat(mol_emb, dim=0).cpu().numpy()\n        return mol_emb\n\n    def _embed(self, smiles: List[str], **kwargs):\n        \"\"\"Embed molecules into a latent space\"\"\"\n        self._preload()\n        dataset, successes = self.graph_featurizer(smiles, kind=self.kind)\n        if self.kind in DGLModel.available_models(query=\"^jtvae\"):\n            mol_emb = self._embed_jtvae(dataset)\n        else:\n            mol_emb = self._embed_gin(dataset)\n\n        mol_emb = list(mol_emb)\n        out = []\n        k = 0\n        for success in successes:\n            if success:\n                out.append(mol_emb[k])\n                k += 1\n            else:\n                out.append(None)\n        return out\n\n    @staticmethod\n    def graph_featurizer(smiles: List[str], kind: Optional[str] = None):\n        \"\"\"\n        Construct graphs from SMILES and featurize them\n\n        Args:\n            smiles: SMILES of molecules for embedding computation\n\n        Returns:\n            dataset: List of graphs constructed and featurized\n            list of bool: Indicators for whether the SMILES string can be parsed by RDKit\n        \"\"\"\n        if kind in DGLModel.available_models(query=\"^jtvae\"):\n            vocab = JTVAEVocab()\n\n            tmp_file = tempfile.NamedTemporaryFile(delete=False)\n            with fsspec.open(tmp_file.name, \"w\") as f:\n                f.write(\"\\n\".join(smiles))\n            dataset = JTVAEDataset(tmp_file.name, vocab, training=False)\n            os.unlink(tmp_file.name)\n            # JTVAE does not support failure\n            success = [True] * len(smiles)\n            if len(dataset) != len(smiles):\n                raise ValueError(\"JTVAE failed to featurize some molecules !\")\n            return dataset, success\n\n        else:\n            graphs = []\n            success = []\n            for smi in smiles:\n                try:\n                    mol = dm.to_mol(smi)\n                    if mol is None:\n                        success.append(False)\n                        continue\n                    g = mol_to_bigraph(\n                        mol,\n                        add_self_loop=True,\n                        node_featurizer=PretrainAtomFeaturizer(),\n                        edge_featurizer=PretrainBondFeaturizer(),\n                        canonical_atom_order=False,\n                    )\n                    graphs.append(g)\n                    success.append(True)\n                except Exception as e:\n                    logger.error(e)\n                    success.append(False)\n            return graphs, success\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.PretrainedDGLTransformer.__init__","title":"<code>__init__(kind='gin_supervised_contextpred', dtype=np.float32, pooling='mean', batch_size=32, preload=False, **params)</code>","text":"<p>DGL pretrained featurizer</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>name of the pretrained gin. Defaults to \"gin_supervised_contextpred\".</p> <code>'gin_supervised_contextpred'</code> <code>dtype</code> <code>Callable</code> <p>datatype. Defaults to np.float32.</p> <code>float32</code> <code>pooling</code> <code>str</code> <p>global pooling to perform. Defaults to \"mean\".</p> <code>'mean'</code> <code>batch_size</code> <code>int</code> <p>batch size for featurizing the molecules. Defaults to 32.</p> <code>32</code> <code>preload</code> <code>bool</code> <p>whether to preload the internal pretrained featurizer or not</p> <code>False</code> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>def __init__(\n    self,\n    kind: Union[str, DGLModel] = \"gin_supervised_contextpred\",\n    dtype: Callable = np.float32,\n    pooling: str = \"mean\",\n    batch_size: int = 32,\n    preload: bool = False,\n    **params,\n):\n    \"\"\"DGL pretrained featurizer\n\n    Args:\n        kind (str, optional): name of the pretrained gin. Defaults to \"gin_supervised_contextpred\".\n        dtype: datatype. Defaults to np.float32.\n        pooling: global pooling to perform. Defaults to \"mean\".\n        batch_size: batch size for featurizing the molecules. Defaults to 32.\n        preload: whether to preload the internal pretrained featurizer or not\n\n    \"\"\"\n    if not requires.check(\"dgllife\"):\n        raise ValueError(\"Cannot find dgl|dgllife. It's required for this featurizer !\")\n    super().__init__(\n        dtype=dtype,\n        pooling=pooling,\n        batch_size=batch_size,\n        preload=preload,\n        kind=kind,\n        **params,\n    )\n    self.pooling = pooling\n    self.preload = preload\n    self._pooling_obj = self.get_pooling(pooling)\n    if isinstance(kind, DGLModel):\n        self.kind = kind.name\n        self.featurizer = kind\n    else:\n        self.kind = kind\n        self.featurizer = DGLModel(name=self.kind)\n    self.batch_size = int(batch_size)\n    if self.preload:\n        self._preload()\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.PretrainedDGLTransformer.get_pooling","title":"<code>get_pooling(pooling)</code>  <code>staticmethod</code>","text":"<p>Get pooling method from name</p> <p>Parameters:</p> Name Type Description Default <code>pooling</code> <code>str</code> <p>name of the pooling method</p> required Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>@staticmethod\ndef get_pooling(pooling: str):\n    \"\"\"Get pooling method from name\n\n    Args:\n        pooling: name of the pooling method\n    \"\"\"\n    pooling = pooling.lower()\n    if pooling in [\"mean\", \"avg\", \"average\"]:\n        return AvgPooling()\n    elif pooling == \"sum\":\n        return SumPooling()\n    elif pooling == \"max\":\n        return MaxPooling()\n    else:\n        raise ValueError(f\"Pooling: {pooling} not supported !\")\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.dgl_pretrained.html#molfeat.trans.pretrained.dgl_pretrained.PretrainedDGLTransformer.graph_featurizer","title":"<code>graph_featurizer(smiles, kind=None)</code>  <code>staticmethod</code>","text":"<p>Construct graphs from SMILES and featurize them</p> <p>Parameters:</p> Name Type Description Default <code>smiles</code> <code>List[str]</code> <p>SMILES of molecules for embedding computation</p> required <p>Returns:</p> Name Type Description <code>dataset</code> <p>List of graphs constructed and featurized</p> <p>list of bool: Indicators for whether the SMILES string can be parsed by RDKit</p> Source code in <code>molfeat/trans/pretrained/dgl_pretrained.py</code> <pre><code>@staticmethod\ndef graph_featurizer(smiles: List[str], kind: Optional[str] = None):\n    \"\"\"\n    Construct graphs from SMILES and featurize them\n\n    Args:\n        smiles: SMILES of molecules for embedding computation\n\n    Returns:\n        dataset: List of graphs constructed and featurized\n        list of bool: Indicators for whether the SMILES string can be parsed by RDKit\n    \"\"\"\n    if kind in DGLModel.available_models(query=\"^jtvae\"):\n        vocab = JTVAEVocab()\n\n        tmp_file = tempfile.NamedTemporaryFile(delete=False)\n        with fsspec.open(tmp_file.name, \"w\") as f:\n            f.write(\"\\n\".join(smiles))\n        dataset = JTVAEDataset(tmp_file.name, vocab, training=False)\n        os.unlink(tmp_file.name)\n        # JTVAE does not support failure\n        success = [True] * len(smiles)\n        if len(dataset) != len(smiles):\n            raise ValueError(\"JTVAE failed to featurize some molecules !\")\n        return dataset, success\n\n    else:\n        graphs = []\n        success = []\n        for smi in smiles:\n            try:\n                mol = dm.to_mol(smi)\n                if mol is None:\n                    success.append(False)\n                    continue\n                g = mol_to_bigraph(\n                    mol,\n                    add_self_loop=True,\n                    node_featurizer=PretrainAtomFeaturizer(),\n                    edge_featurizer=PretrainBondFeaturizer(),\n                    canonical_atom_order=False,\n                )\n                graphs.append(g)\n                success.append(True)\n            except Exception as e:\n                logger.error(e)\n                success.append(False)\n        return graphs, success\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.fcd.html","title":"FCD","text":""},{"location":"api/molfeat.trans.pretrained.fcd.html#fcd-model","title":"FCD model","text":""},{"location":"api/molfeat.trans.pretrained.fcd.html#molfeat.trans.pretrained.fcd.FCDTransformer","title":"<code>FCDTransformer</code>","text":"<p>               Bases: <code>PretrainedMolTransformer</code></p> <p>FCD transformer based on the ChemNet pretrained model</p> <p>Attributes:</p> Name Type Description <code>featurizer</code> <code>FCD</code> <p>FCD featurizer object</p> <code>dtype</code> <code>type</code> <p>Data type. Use call instead</p> Source code in <code>molfeat/trans/pretrained/fcd.py</code> <pre><code>class FCDTransformer(PretrainedMolTransformer):\n    r\"\"\"\n    FCD transformer based on the ChemNet pretrained model\n\n    Attributes:\n        featurizer (FCD): FCD featurizer object\n        dtype (type, optional): Data type. Use call instead\n    \"\"\"\n\n    def __init__(self, n_jobs=1, dtype=np.float32, **params):\n        super().__init__(dtype=dtype, **params)\n        if not requires.check(\"fcd_torch\"):\n            raise ImportError(\n                \"`fcd_torch` is not available, please install it `conda install -c conda-forge fcd_torch'`\"\n            )\n\n        self.n_jobs = n_jobs\n        self.featurizer = FCD(n_jobs=n_jobs)\n\n    def _embed(self, smiles, **kwargs):\n        \"\"\"Compute embedding\"\"\"\n        return self.featurizer.get_predictions(smiles)\n\n    def _update_params(self):\n        super()._update_params()\n        self.featurizer = FCD(n_jobs=self.n_jobs)\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html","title":"Graphormer","text":""},{"location":"api/molfeat.trans.pretrained.graphormer.html#graphormer-pretrained-models","title":"Graphormer pretrained models","text":""},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer","title":"<code>GraphormerTransformer</code>","text":"<p>               Bases: <code>PretrainedMolTransformer</code></p> <p>Graphormer transformer from microsoft, pretrained on PCQM4Mv2 quantum chemistry dataset for the prediction of homo-lumo gap.</p> <p>Attributes:</p> Name Type Description <code>featurizer</code> <p>Graphormer embedding object</p> <code>dtype</code> <p>Data type. Use call instead</p> <code>pooling</code> <p>Pooling method for Graphormer's embedding layer</p> Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>class GraphormerTransformer(PretrainedMolTransformer):\n    r\"\"\"\n    Graphormer transformer from microsoft, pretrained on PCQM4Mv2 quantum chemistry dataset\n    for the prediction of homo-lumo gap.\n\n    Attributes:\n        featurizer: Graphormer embedding object\n        dtype: Data type. Use call instead\n        pooling: Pooling method for Graphormer's embedding layer\n    \"\"\"\n\n    def __init__(\n        self,\n        kind: str = \"pcqm4mv2_graphormer_base\",\n        dtype: Callable = np.float32,\n        pooling: str = \"mean\",\n        max_length: Optional[int] = None,\n        concat_layers: Union[List[int], int] = -1,\n        ignore_padding: bool = True,\n        version=None,\n        **params,\n    ):\n        \"\"\"\n        Pretrained graphormer featurizer.\n\n        !!! note\n            The default behaviour of this feature extractor is to return the last hidden state of the encoder,\n            averaged across all nodes (including the virtual node connected to all other nodes).\n\n            For a different behaviour, please change the pooling method:\n            * `graph` or `virtual`: use the virtual node embedding in the last layer to get the graph representation\n            * `mean`, `max`, `sum`, etc or any other supported pooling of `molfeat.utils.pooler.Pooling`\n                will take the operation defined by the pooling layer across all nodes of each graph\n\n        Args:\n            kind: name of the featurizer as available in the model store\n            dtype: Data type to output\n            pooling: type of pooling to use. One of ['graph', 'virtual', 'mean', 'max', 'sum']. The value \"graph\" corresponds to the virtual node representation\n            max_length: Maximum length of the input sequence to consider. Please update this for large sequences\n            concat_layers: Layer to concat to get the representation. By default the last hidden layer is returned.\n            ignore_padding: Whether to ignore padding in the representation (default: True) to avoid effect of batching\n            params: any other parameter to pass to PretrainedMolTransformer\n        \"\"\"\n\n        super().__init__(dtype=dtype, pooling=pooling, **params)\n        if not requires.check(\"graphormer_pretrained\"):\n            raise ValueError(\"`graphormer` is required to use this featurizer.\")\n\n        if concat_layers is None:\n            concat_layers = -1\n        if not isinstance(concat_layers, list):\n            concat_layers = [concat_layers]\n        self.concat_layers = concat_layers\n        self.preload = True\n        self.name = kind\n        self._require_mols = False\n        self.max_length = max_length\n        self.ignore_padding = ignore_padding\n        if isinstance(pooling, str):\n            if pooling in Pooling.SUPPORTED_POOLING:\n                pooling = Pooling(dim=1, name=pooling)\n            else:\n                pooling = None\n        self.pooling = pooling\n        self.featurizer = GraphormerEmbeddingsExtractor(\n            pretrained_name=self.name, max_nodes=self.max_length, concat_layers=self.concat_layers\n        )\n        self.featurizer.config.max_nodes = self.max_length\n        self.version = version\n\n    def __repr__(self):\n        return \"{}(name={}, pooling={}, dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self.name),\n            _parse_to_evaluable_str(self.pooling.name),\n            _parse_to_evaluable_str(self.dtype),\n        )\n\n    @staticmethod\n    def list_available_models():\n        \"\"\"List available graphormer model to use\"\"\"\n        return [\n            \"pcqm4mv1_graphormer_base\",  # PCQM4Mv1\n            \"pcqm4mv2_graphormer_base\",  # PCQM4Mv2\n            \"pcqm4mv1_graphormer_base_for_molhiv\",  # ogbg-molhiv\n            \"oc20is2re_graphormer3d_base\",  # Open Catalyst Challenge\n        ]\n\n    def _embed(self, inputs: List[str], **kwargs):\n        \"\"\"Internal molecular embedding\n\n        Args:\n            smiles: input smiles\n        \"\"\"\n        with torch.no_grad():\n            layer_reprs, graph_reprs, padding_mask = self.featurizer(inputs)\n            if self.pooling is None:\n                x = graph_reprs\n            else:\n                x = self.pooling(layer_reprs, mask=(padding_mask if self.ignore_padding else None))\n        return x.numpy()\n\n    def __getstate__(self):\n        \"\"\"Getting state to allow pickling\"\"\"\n        d = copy.deepcopy(self.__dict__)\n        d[\"precompute_cache\"] = None\n        d.pop(\"featurizer\", None)\n        return d\n\n    def __setstate__(self, d):\n        \"\"\"Setting state during reloading pickling\"\"\"\n        self.__dict__.update(d)\n        self._update_params()\n\n    def compute_max_length(self, inputs: list):\n        \"\"\"Compute maximum node number for the input list of molecules\n\n        Args:\n            inputs: input list of molecules\n        \"\"\"\n        dataset = GraphormerInferenceDataset(\n            inputs,\n            multi_hop_max_dist=self.featurizer.config.multi_hop_max_dist,\n            spatial_pos_max=self.featurizer.config.spatial_pos_max,\n        )\n        xs = [item.x.size(0) for item in dataset]\n        return max(xs)\n\n    def set_max_length(self, max_length: int):\n        \"\"\"Set the maximum length for this featurizer\"\"\"\n        self.max_length = max_length\n        self._update_params()\n        self._preload()\n\n    def _convert(self, inputs: list, **kwargs):\n        \"\"\"Convert molecules to the right format\n\n        Args:\n            inputs: inputs to preprocess\n\n        Returns:\n            processed: pre-processed input list\n        \"\"\"\n        inputs = super()._convert(inputs, **kwargs)\n        batch = self.featurizer._convert(inputs)\n        return batch\n\n    def _update_params(self):\n        super()._update_params()\n        self.featurizer = GraphormerEmbeddingsExtractor(\n            pretrained_name=self.name, max_nodes=self.max_length\n        )\n        self.featurizer.config.max_nodes = self.max_length\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Getting state to allow pickling</p> Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>def __getstate__(self):\n    \"\"\"Getting state to allow pickling\"\"\"\n    d = copy.deepcopy(self.__dict__)\n    d[\"precompute_cache\"] = None\n    d.pop(\"featurizer\", None)\n    return d\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer.__init__","title":"<code>__init__(kind='pcqm4mv2_graphormer_base', dtype=np.float32, pooling='mean', max_length=None, concat_layers=-1, ignore_padding=True, version=None, **params)</code>","text":"<p>Pretrained graphormer featurizer.</p> <p>Note</p> <p>The default behaviour of this feature extractor is to return the last hidden state of the encoder, averaged across all nodes (including the virtual node connected to all other nodes).</p> <p>For a different behaviour, please change the pooling method: * <code>graph</code> or <code>virtual</code>: use the virtual node embedding in the last layer to get the graph representation * <code>mean</code>, <code>max</code>, <code>sum</code>, etc or any other supported pooling of <code>molfeat.utils.pooler.Pooling</code>     will take the operation defined by the pooling layer across all nodes of each graph</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>str</code> <p>name of the featurizer as available in the model store</p> <code>'pcqm4mv2_graphormer_base'</code> <code>dtype</code> <code>Callable</code> <p>Data type to output</p> <code>float32</code> <code>pooling</code> <code>str</code> <p>type of pooling to use. One of ['graph', 'virtual', 'mean', 'max', 'sum']. The value \"graph\" corresponds to the virtual node representation</p> <code>'mean'</code> <code>max_length</code> <code>Optional[int]</code> <p>Maximum length of the input sequence to consider. Please update this for large sequences</p> <code>None</code> <code>concat_layers</code> <code>Union[List[int], int]</code> <p>Layer to concat to get the representation. By default the last hidden layer is returned.</p> <code>-1</code> <code>ignore_padding</code> <code>bool</code> <p>Whether to ignore padding in the representation (default: True) to avoid effect of batching</p> <code>True</code> <code>params</code> <p>any other parameter to pass to PretrainedMolTransformer</p> <code>{}</code> Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>def __init__(\n    self,\n    kind: str = \"pcqm4mv2_graphormer_base\",\n    dtype: Callable = np.float32,\n    pooling: str = \"mean\",\n    max_length: Optional[int] = None,\n    concat_layers: Union[List[int], int] = -1,\n    ignore_padding: bool = True,\n    version=None,\n    **params,\n):\n    \"\"\"\n    Pretrained graphormer featurizer.\n\n    !!! note\n        The default behaviour of this feature extractor is to return the last hidden state of the encoder,\n        averaged across all nodes (including the virtual node connected to all other nodes).\n\n        For a different behaviour, please change the pooling method:\n        * `graph` or `virtual`: use the virtual node embedding in the last layer to get the graph representation\n        * `mean`, `max`, `sum`, etc or any other supported pooling of `molfeat.utils.pooler.Pooling`\n            will take the operation defined by the pooling layer across all nodes of each graph\n\n    Args:\n        kind: name of the featurizer as available in the model store\n        dtype: Data type to output\n        pooling: type of pooling to use. One of ['graph', 'virtual', 'mean', 'max', 'sum']. The value \"graph\" corresponds to the virtual node representation\n        max_length: Maximum length of the input sequence to consider. Please update this for large sequences\n        concat_layers: Layer to concat to get the representation. By default the last hidden layer is returned.\n        ignore_padding: Whether to ignore padding in the representation (default: True) to avoid effect of batching\n        params: any other parameter to pass to PretrainedMolTransformer\n    \"\"\"\n\n    super().__init__(dtype=dtype, pooling=pooling, **params)\n    if not requires.check(\"graphormer_pretrained\"):\n        raise ValueError(\"`graphormer` is required to use this featurizer.\")\n\n    if concat_layers is None:\n        concat_layers = -1\n    if not isinstance(concat_layers, list):\n        concat_layers = [concat_layers]\n    self.concat_layers = concat_layers\n    self.preload = True\n    self.name = kind\n    self._require_mols = False\n    self.max_length = max_length\n    self.ignore_padding = ignore_padding\n    if isinstance(pooling, str):\n        if pooling in Pooling.SUPPORTED_POOLING:\n            pooling = Pooling(dim=1, name=pooling)\n        else:\n            pooling = None\n    self.pooling = pooling\n    self.featurizer = GraphormerEmbeddingsExtractor(\n        pretrained_name=self.name, max_nodes=self.max_length, concat_layers=self.concat_layers\n    )\n    self.featurizer.config.max_nodes = self.max_length\n    self.version = version\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer.__setstate__","title":"<code>__setstate__(d)</code>","text":"<p>Setting state during reloading pickling</p> Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>def __setstate__(self, d):\n    \"\"\"Setting state during reloading pickling\"\"\"\n    self.__dict__.update(d)\n    self._update_params()\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer.compute_max_length","title":"<code>compute_max_length(inputs)</code>","text":"<p>Compute maximum node number for the input list of molecules</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>list</code> <p>input list of molecules</p> required Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>def compute_max_length(self, inputs: list):\n    \"\"\"Compute maximum node number for the input list of molecules\n\n    Args:\n        inputs: input list of molecules\n    \"\"\"\n    dataset = GraphormerInferenceDataset(\n        inputs,\n        multi_hop_max_dist=self.featurizer.config.multi_hop_max_dist,\n        spatial_pos_max=self.featurizer.config.spatial_pos_max,\n    )\n    xs = [item.x.size(0) for item in dataset]\n    return max(xs)\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer.list_available_models","title":"<code>list_available_models()</code>  <code>staticmethod</code>","text":"<p>List available graphormer model to use</p> Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>@staticmethod\ndef list_available_models():\n    \"\"\"List available graphormer model to use\"\"\"\n    return [\n        \"pcqm4mv1_graphormer_base\",  # PCQM4Mv1\n        \"pcqm4mv2_graphormer_base\",  # PCQM4Mv2\n        \"pcqm4mv1_graphormer_base_for_molhiv\",  # ogbg-molhiv\n        \"oc20is2re_graphormer3d_base\",  # Open Catalyst Challenge\n    ]\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.graphormer.html#molfeat.trans.pretrained.graphormer.GraphormerTransformer.set_max_length","title":"<code>set_max_length(max_length)</code>","text":"<p>Set the maximum length for this featurizer</p> Source code in <code>molfeat/trans/pretrained/graphormer.py</code> <pre><code>def set_max_length(self, max_length: int):\n    \"\"\"Set the maximum length for this featurizer\"\"\"\n    self.max_length = max_length\n    self._update_params()\n    self._preload()\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html","title":"HuggingFace","text":""},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#transformer-pretrained-models","title":"Transformer pretrained models","text":""},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#huggingface-transformers","title":"HuggingFace Transformers","text":""},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFExperiment","title":"<code>HFExperiment</code>  <code>dataclass</code>","text":"Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>@dataclass\nclass HFExperiment:\n    model: PreTrainedModel\n    tokenizer: Union[PreTrainedTokenizer, PreTrainedTokenizerFast]\n    notation: str = \"smiles\"\n\n    @classmethod\n    def save(cls, model: HFExperiment, path: str, clean_up: bool = False):\n        \"\"\"Save a hugging face model to a specific path\n\n        Args:\n            model: model to save\n            path: path to the folder root where to save the model\n            clean_up: whether to clean up the local path after saving\n        \"\"\"\n        local_path = tempfile.mkdtemp()\n        # we can save both the tokenizer and the model to the same path\n        model.model.save_pretrained(local_path)\n        model.tokenizer.save_pretrained(local_path)\n\n        # With transformers&gt;=4.35.0, models are by default saved as safetensors.\n        # For backwards compatibility, we also save the model as the older pickle-based format.\n        model.model.save_pretrained(local_path, safe_serialization=False)\n\n        dm.fs.copy_dir(local_path, path, force=True, progress=True, leave_progress=False)\n        logger.info(f\"Model saved to {path}\")\n        # clean up now\n        if clean_up:\n            mapper = dm.fs.get_mapper(local_path)\n            mapper.fs.delete(local_path, recursive=True)\n        return path\n\n    @classmethod\n    def load(cls, path: str, model_class=None, device: str = \"cpu\"):\n        \"\"\"Load a model from the given path\n        Args:\n            path: Path to the model to load\n            model_class: optional model class to provide if the model should be loaded with a specific class\n            device: the device to load the model on (\"cpu\" or \"cuda\")\n        \"\"\"\n        if not dm.fs.is_local_path(path):\n            local_path = tempfile.mkdtemp()\n            dm.fs.copy_dir(path, local_path, force=True, progress=True, leave_progress=False)\n        else:\n            local_path = path\n\n        if model_class is None:\n            model_config = AutoConfig.from_pretrained(local_path)\n            architectures = getattr(model_config, \"architectures\", [])\n            if len(architectures) &gt; 0:\n                model_class = MODEL_MAPPING._load_attr_from_module(\n                    model_config.model_type, architectures[0]\n                )\n            else:\n                model_class = AutoModel\n        model = model_class.from_pretrained(local_path).to(device)\n        tokenizer = AutoTokenizer.from_pretrained(local_path)\n        return cls(model, tokenizer)\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFExperiment.load","title":"<code>load(path, model_class=None, device='cpu')</code>  <code>classmethod</code>","text":"<p>Load a model from the given path Args:     path: Path to the model to load     model_class: optional model class to provide if the model should be loaded with a specific class     device: the device to load the model on (\"cpu\" or \"cuda\")</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>@classmethod\ndef load(cls, path: str, model_class=None, device: str = \"cpu\"):\n    \"\"\"Load a model from the given path\n    Args:\n        path: Path to the model to load\n        model_class: optional model class to provide if the model should be loaded with a specific class\n        device: the device to load the model on (\"cpu\" or \"cuda\")\n    \"\"\"\n    if not dm.fs.is_local_path(path):\n        local_path = tempfile.mkdtemp()\n        dm.fs.copy_dir(path, local_path, force=True, progress=True, leave_progress=False)\n    else:\n        local_path = path\n\n    if model_class is None:\n        model_config = AutoConfig.from_pretrained(local_path)\n        architectures = getattr(model_config, \"architectures\", [])\n        if len(architectures) &gt; 0:\n            model_class = MODEL_MAPPING._load_attr_from_module(\n                model_config.model_type, architectures[0]\n            )\n        else:\n            model_class = AutoModel\n    model = model_class.from_pretrained(local_path).to(device)\n    tokenizer = AutoTokenizer.from_pretrained(local_path)\n    return cls(model, tokenizer)\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFExperiment.save","title":"<code>save(model, path, clean_up=False)</code>  <code>classmethod</code>","text":"<p>Save a hugging face model to a specific path</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>HFExperiment</code> <p>model to save</p> required <code>path</code> <code>str</code> <p>path to the folder root where to save the model</p> required <code>clean_up</code> <code>bool</code> <p>whether to clean up the local path after saving</p> <code>False</code> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>@classmethod\ndef save(cls, model: HFExperiment, path: str, clean_up: bool = False):\n    \"\"\"Save a hugging face model to a specific path\n\n    Args:\n        model: model to save\n        path: path to the folder root where to save the model\n        clean_up: whether to clean up the local path after saving\n    \"\"\"\n    local_path = tempfile.mkdtemp()\n    # we can save both the tokenizer and the model to the same path\n    model.model.save_pretrained(local_path)\n    model.tokenizer.save_pretrained(local_path)\n\n    # With transformers&gt;=4.35.0, models are by default saved as safetensors.\n    # For backwards compatibility, we also save the model as the older pickle-based format.\n    model.model.save_pretrained(local_path, safe_serialization=False)\n\n    dm.fs.copy_dir(local_path, path, force=True, progress=True, leave_progress=False)\n    logger.info(f\"Model saved to {path}\")\n    # clean up now\n    if clean_up:\n        mapper = dm.fs.get_mapper(local_path)\n        mapper.fs.delete(local_path, recursive=True)\n    return path\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFModel","title":"<code>HFModel</code>","text":"<p>               Bases: <code>PretrainedStoreModel</code></p> <p>Transformer model loading model loading</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>class HFModel(PretrainedStoreModel):\n    \"\"\"Transformer model loading model loading\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        cache_path: Optional[os.PathLike] = None,\n        store: Optional[ModelStore] = None,\n    ):\n        \"\"\"Model loader initializer\n\n        Args:\n            name (str, optional): Name of the model for ada.\n            cache_path (os.PathLike, optional): Local cache path for faster loading. This is the cache_path parameter for ADA loading !\n        \"\"\"\n\n        super().__init__(name, cache_path=cache_path, store=store)\n        self._model = None\n\n    @classmethod\n    def _ensure_local(cls, object_path: Union[str, os.PathLike]):\n        \"\"\"Make sure the input path is a local path otherwise download it\n\n        Args:\n            object_path: Path to the object\n\n        \"\"\"\n        if dm.fs.is_local_path(object_path):\n            return object_path\n        local_path = tempfile.mkdtemp()\n        if dm.fs.is_file(object_path):\n            local_path = os.path.join(local_path, os.path.basename(object_path))\n            dm.fs.copy_file(object_path, local_path)\n        else:\n            dm.fs.copy_dir(object_path, local_path)\n        return local_path\n\n    @classmethod\n    def from_pretrained(\n        cls,\n        model: Union[str, PreTrainedModel],\n        tokenizer: Union[str, PreTrainedTokenizer, PreTrainedTokenizerFast],\n        model_class=None,\n        model_name: Optional[str] = None,\n    ):\n        \"\"\"Load model using huggingface pretrained model loader hook\n\n        Args:\n            model: Model to load. Can also be the name on the hub or the path to the model\n            tokenizer: Tokenizer to load. Can also be the name on the hub or the path to the tokenizer\n            model_class: optional model class to provide if the model should be loaded with a specific class\n            model_name: optional model name to give to this model.\n        \"\"\"\n\n        # load the model\n        if isinstance(model, PreTrainedModel):\n            model_obj = model\n        else:\n            if dm.fs.exists(model):\n                model = cls._ensure_local(model)\n            if model_class is None:\n                model_config = AutoConfig.from_pretrained(model)\n                architectures = getattr(model_config, \"architectures\", [])\n                if len(architectures) &gt; 0:\n                    model_class = MODEL_MAPPING._load_attr_from_module(\n                        model_config.model_type, architectures[0]\n                    )\n                else:\n                    model_class = AutoModel\n            model_obj = model_class.from_pretrained(model)\n\n        if isinstance(tokenizer, (PreTrainedTokenizer, PreTrainedTokenizerFast)):\n            tokenizer_obj = tokenizer\n        else:\n            if dm.fs.exists(tokenizer):\n                tokenizer = cls._ensure_local(tokenizer)\n            tokenizer_obj = AutoTokenizer.from_pretrained(tokenizer)\n        name = model_name or f\"hf_model_{uuid.uuid4().hex[:8]}\"\n        model = HFModel(name=name, store=ModelStore())\n        model._model = HFExperiment(model=model_obj, tokenizer=tokenizer_obj)\n        return model\n\n    @classmethod\n    def register_pretrained(\n        cls,\n        model: Union[str, PreTrainedModel],\n        tokenizer: Union[str, PreTrainedTokenizer, PreTrainedTokenizerFast],\n        model_card: ModelInfo,\n        model_class=None,\n    ):\n        \"\"\"Register a pretrained huggingface model to the model store\n        Args:\n            model: Model to load. Can also be the name on the hub or the path to the model\n            tokenizer: Tokenizer to load. Can also be the name on the hub or the path to the tokenizer\n            model_class: optional model class to provide if the model should be loaded with a specific class\n            model_card: optional model card to provide for registering this model\n        \"\"\"\n        model = cls.from_pretrained(model, tokenizer, model_class, model_name=model_card.name)\n        model.store.register(model_card, model._model, save_fn=HFExperiment.save)\n        return model\n\n    def get_notation(self, default_notation: Optional[str] = None):\n        \"\"\"Get the notation of the model\"\"\"\n        notation = default_notation\n        try:\n            modelcard = self.store.search(name=self.name)[0]\n            notation = modelcard.inputs\n        except Exception:\n            pass\n        return notation\n\n    def load(self):\n        \"\"\"Load Transformer Pretrained featurizer model\"\"\"\n        if self._model is not None:\n            return self._model\n        download_output_dir = self._artifact_load(\n            name=self.name, download_path=self.cache_path, store=self.store\n        )\n        model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)\n        self._model = HFExperiment.load(model_path)\n        return self._model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFModel.__init__","title":"<code>__init__(name, cache_path=None, store=None)</code>","text":"<p>Model loader initializer</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the model for ada.</p> required <code>cache_path</code> <code>PathLike</code> <p>Local cache path for faster loading. This is the cache_path parameter for ADA loading !</p> <code>None</code> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    cache_path: Optional[os.PathLike] = None,\n    store: Optional[ModelStore] = None,\n):\n    \"\"\"Model loader initializer\n\n    Args:\n        name (str, optional): Name of the model for ada.\n        cache_path (os.PathLike, optional): Local cache path for faster loading. This is the cache_path parameter for ADA loading !\n    \"\"\"\n\n    super().__init__(name, cache_path=cache_path, store=store)\n    self._model = None\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFModel.from_pretrained","title":"<code>from_pretrained(model, tokenizer, model_class=None, model_name=None)</code>  <code>classmethod</code>","text":"<p>Load model using huggingface pretrained model loader hook</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Union[str, PreTrainedModel]</code> <p>Model to load. Can also be the name on the hub or the path to the model</p> required <code>tokenizer</code> <code>Union[str, PreTrainedTokenizer, PreTrainedTokenizerFast]</code> <p>Tokenizer to load. Can also be the name on the hub or the path to the tokenizer</p> required <code>model_class</code> <p>optional model class to provide if the model should be loaded with a specific class</p> <code>None</code> <code>model_name</code> <code>Optional[str]</code> <p>optional model name to give to this model.</p> <code>None</code> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>@classmethod\ndef from_pretrained(\n    cls,\n    model: Union[str, PreTrainedModel],\n    tokenizer: Union[str, PreTrainedTokenizer, PreTrainedTokenizerFast],\n    model_class=None,\n    model_name: Optional[str] = None,\n):\n    \"\"\"Load model using huggingface pretrained model loader hook\n\n    Args:\n        model: Model to load. Can also be the name on the hub or the path to the model\n        tokenizer: Tokenizer to load. Can also be the name on the hub or the path to the tokenizer\n        model_class: optional model class to provide if the model should be loaded with a specific class\n        model_name: optional model name to give to this model.\n    \"\"\"\n\n    # load the model\n    if isinstance(model, PreTrainedModel):\n        model_obj = model\n    else:\n        if dm.fs.exists(model):\n            model = cls._ensure_local(model)\n        if model_class is None:\n            model_config = AutoConfig.from_pretrained(model)\n            architectures = getattr(model_config, \"architectures\", [])\n            if len(architectures) &gt; 0:\n                model_class = MODEL_MAPPING._load_attr_from_module(\n                    model_config.model_type, architectures[0]\n                )\n            else:\n                model_class = AutoModel\n        model_obj = model_class.from_pretrained(model)\n\n    if isinstance(tokenizer, (PreTrainedTokenizer, PreTrainedTokenizerFast)):\n        tokenizer_obj = tokenizer\n    else:\n        if dm.fs.exists(tokenizer):\n            tokenizer = cls._ensure_local(tokenizer)\n        tokenizer_obj = AutoTokenizer.from_pretrained(tokenizer)\n    name = model_name or f\"hf_model_{uuid.uuid4().hex[:8]}\"\n    model = HFModel(name=name, store=ModelStore())\n    model._model = HFExperiment(model=model_obj, tokenizer=tokenizer_obj)\n    return model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFModel.get_notation","title":"<code>get_notation(default_notation=None)</code>","text":"<p>Get the notation of the model</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>def get_notation(self, default_notation: Optional[str] = None):\n    \"\"\"Get the notation of the model\"\"\"\n    notation = default_notation\n    try:\n        modelcard = self.store.search(name=self.name)[0]\n        notation = modelcard.inputs\n    except Exception:\n        pass\n    return notation\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFModel.load","title":"<code>load()</code>","text":"<p>Load Transformer Pretrained featurizer model</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>def load(self):\n    \"\"\"Load Transformer Pretrained featurizer model\"\"\"\n    if self._model is not None:\n        return self._model\n    download_output_dir = self._artifact_load(\n        name=self.name, download_path=self.cache_path, store=self.store\n    )\n    model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)\n    self._model = HFExperiment.load(model_path)\n    return self._model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.HFModel.register_pretrained","title":"<code>register_pretrained(model, tokenizer, model_card, model_class=None)</code>  <code>classmethod</code>","text":"<p>Register a pretrained huggingface model to the model store Args:     model: Model to load. Can also be the name on the hub or the path to the model     tokenizer: Tokenizer to load. Can also be the name on the hub or the path to the tokenizer     model_class: optional model class to provide if the model should be loaded with a specific class     model_card: optional model card to provide for registering this model</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>@classmethod\ndef register_pretrained(\n    cls,\n    model: Union[str, PreTrainedModel],\n    tokenizer: Union[str, PreTrainedTokenizer, PreTrainedTokenizerFast],\n    model_card: ModelInfo,\n    model_class=None,\n):\n    \"\"\"Register a pretrained huggingface model to the model store\n    Args:\n        model: Model to load. Can also be the name on the hub or the path to the model\n        tokenizer: Tokenizer to load. Can also be the name on the hub or the path to the tokenizer\n        model_class: optional model class to provide if the model should be loaded with a specific class\n        model_card: optional model card to provide for registering this model\n    \"\"\"\n    model = cls.from_pretrained(model, tokenizer, model_class, model_name=model_card.name)\n    model.store.register(model_card, model._model, save_fn=HFExperiment.save)\n    return model\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.PretrainedHFTransformer","title":"<code>PretrainedHFTransformer</code>","text":"<p>               Bases: <code>PretrainedMolTransformer</code></p> <p>HuggingFace Transformer for feature extraction.</p> <p>Note</p> <p>For convenience and consistency, this featurizer only accepts as inputs smiles and molecules, then perform the internal conversion, based on the notation provided.</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>class PretrainedHFTransformer(PretrainedMolTransformer):\n    \"\"\"\n    HuggingFace Transformer for feature extraction.\n\n    !!! note\n        For convenience and consistency, this featurizer only accepts as inputs\n        smiles and molecules, then perform the internal conversion, based on the notation provided.\n    \"\"\"\n\n    NEEDS_RANDOM_SEED = [\"bert\", \"roberta\"]\n\n    def __init__(\n        self,\n        kind: Union[str, HFModel] = \"ChemBERTa-77M-MLM\",\n        notation: Optional[str] = \"none\",\n        pooling: str = \"mean\",\n        concat_layers: Union[List[int], int] = -1,\n        prefer_encoder: bool = True,\n        dtype=np.float32,\n        device=\"cpu\",\n        max_length: int = 128,\n        ignore_padding: bool = True,\n        preload: bool = False,\n        n_jobs: int = 0,\n        random_seed: Optional[int] = None,\n        **params,\n    ):\n        \"\"\"\n        HuggingFace Transformer for featurizer extraction\n        The default behaviour of this feature extractor is to return the last hidden state of the encoder\n        similar to what is performed by the pipeline 'feature-extraction' in hugging face.\n\n        !!! warning\n            For bert models, the default pooling layers is a neural network. Therefore, do not use the default\n            Or provide a random seed for reproducibility (in this case pooling will act as random projection to the same manifold)\n\n        !!! note\n            The pooling module of this featurizer is accessible through the `_pooling_obj` attribute.\n\n        Args:\n            kind: name of the featurizer as available in the model store\n            notation: optional line notation to use. Only use if it cannot be found from the model card.\n            pooling: type of pooling to use. One of ['default', 'mean', 'max', 'sum', 'clf', ]. The value \"default\" corresponds to the default litterature pooling for each model type.\n                See `molfeat.utils.pooler.get_default_hf_pooler` for more details.\n            concat_layers: Layer to concat to get the representation. By default the last hidden layer is returned.\n            prefer_encoder: For an encoder-decoder model, prefer the embeddings provided by the encoder.\n            dtype: Data type to output\n            device: Torch device on which to run the featurizer.\n            max_length: Maximum length of the input sequence to consider. Please update this for large sequences\n            ignore_padding: Whether to ignore padding in the representation (default: True) to avoid effect of batching\n            preload: Whether to preload the model into memory or not\n            n_jobs: number of jobs to use\n            random_seed: random seed to use for reproducibility whenever a DNN pooler is used (e.g bert/roberta)\n        \"\"\"\n\n        if not requires.check(\"transformers\"):\n            raise ValueError(\n                \"Cannot find transformers and/or tokenizers. It's required for this featurizer !\"\n            )\n\n        super().__init__(\n            dtype=dtype,\n            device=device,\n            n_jobs=n_jobs,\n            **params,\n        )\n        if concat_layers is None:\n            concat_layers = -1\n        if not isinstance(concat_layers, list):\n            concat_layers = [concat_layers]\n        self.concat_layers = concat_layers\n        self.max_length = max_length\n        self.ignore_padding = ignore_padding\n        self._require_mols = False\n        self.random_seed = random_seed\n        self.preload = preload\n        self.pooling = pooling\n        self.prefer_encoder = prefer_encoder\n        self.device = torch.device(device)\n        self._pooling_obj = None\n        if isinstance(kind, HFModel):\n            self.kind = kind.name\n            self.featurizer = kind\n        else:\n            self.kind = kind\n            self.featurizer = HFModel(name=self.kind)\n        self.notation = self.featurizer.get_notation(notation) or \"none\"\n        self.converter = SmilesConverter(self.notation)\n        if self.preload:\n            self._preload()\n\n    def _update_params(self):\n        \"\"\"Update the parameters of this model\"\"\"\n        # pylint: disable=no-member\n        super()._update_params()\n\n        hf_model = HFModel(\n            name=self.kind,\n        )\n        self.featurizer = hf_model.load()\n        config = self.featurizer.model.config.to_dict()\n        self._pooling_obj = self._pooling_obj = (\n            get_default_hgf_pooler(self.pooling, config, random_seed=self.random_seed)\n            if self._pooling_obj is None\n            else self._pooling_obj\n        )\n\n    def _preload(self):\n        \"\"\"Perform preloading of the model from the store\"\"\"\n        super()._preload()\n        self.featurizer.model.to(self.device)\n        self.featurizer.max_length = self.max_length\n\n        # we can be confident that the model has been loaded here\n        if self._pooling_obj is not None and self.preload:\n            return\n        config = self.featurizer.model.config.to_dict()\n        cur_tokenizer = self.featurizer.tokenizer\n        for special_token_id_name in [\n            \"pad_token_id\",\n            \"bos_token_id\",\n            \"eos_token_id\",\n            \"unk_token_id\",\n            \"sep_token_id\",\n            \"mask_token_id\",\n        ]:\n            token_id = getattr(cur_tokenizer, special_token_id_name)\n            if token_id is not None:\n                config[special_token_id_name] = token_id\n\n        self._pooling_obj = (\n            get_default_hgf_pooler(self.pooling, config, random_seed=self.random_seed)\n            if self._pooling_obj is None\n            else self._pooling_obj\n        )\n        # pooling layer is still none, that means we could not fetch it properly\n        if self._pooling_obj is None:\n            logger.warning(\n                \"Cannot confidently find the pooling layer and therefore will not apply pooling\"\n            )\n\n    def _convert(self, inputs: list, **kwargs):\n        \"\"\"Convert the list of molecules to the right format for embedding\n\n        Args:\n            inputs: inputs to preprocess\n\n        Returns:\n            processed: pre-processed input list\n        \"\"\"\n        self._preload()\n\n        if isinstance(inputs, (str, dm.Mol)):\n            inputs = [inputs]\n\n        def _to_smiles(x):\n            return dm.to_smiles(x) if not isinstance(x, str) else x\n\n        parallel_kwargs = getattr(self, \"parallel_kwargs\", {})\n\n        if len(inputs) &gt; 1:\n            smiles = dm.utils.parallelized(\n                _to_smiles,\n                inputs,\n                n_jobs=self.n_jobs,\n                **parallel_kwargs,\n            )\n            inputs = dm.utils.parallelized(\n                self.converter.encode,\n                smiles,\n                n_jobs=self.n_jobs,\n                **parallel_kwargs,\n            )\n        else:\n            inputs = self.converter.encode(_to_smiles(inputs[0]))\n        # this check is necessary for some tokenizers\n        if isinstance(inputs, str):\n            inputs = [inputs]\n        encoded = self.featurizer.tokenizer(\n            list(inputs),\n            truncation=True,\n            padding=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\",\n        )\n        return encoded\n\n    def _embed(self, inputs, **kwargs):\n        \"\"\"\n        Perform embedding of inputs using the pretrained model\n\n        Args:\n            inputs: smiles or seqs\n            kwargs: any additional parameters\n        \"\"\"\n        self._preload()\n\n        # Move inputs to the correct device\n        inputs = {key: value.to(self.device) for key, value in inputs.items()}\n\n        attention_mask = inputs.get(\"attention_mask\", None)\n        if attention_mask is not None and self.ignore_padding:\n            attention_mask = attention_mask.unsqueeze(-1).to(self.device)  # B, S, 1\n        else:\n            attention_mask = None\n        with torch.no_grad():\n            if (\n                isinstance(self.featurizer.model, EncoderDecoderModel)\n                or hasattr(self.featurizer.model, \"encoder\")\n            ) and self.prefer_encoder:\n                out_dict = self.featurizer.model.encoder(output_hidden_states=True, **inputs)\n            else:\n                out_dict = self.featurizer.model(output_hidden_states=True, **inputs)\n            hidden_state = out_dict[\"hidden_states\"]\n            emb_layers = []\n            for layer in self.concat_layers:\n                emb = hidden_state[layer].detach()  # B, S, D\n                emb = self._pooling_obj(\n                    emb,\n                    inputs[\"input_ids\"],\n                    mask=attention_mask,\n                    ignore_padding=self.ignore_padding,\n                )\n                emb_layers.append(emb)\n            emb = torch.cat(emb_layers, dim=1)\n        return emb.cpu().numpy()  # Move the final tensor to CPU before converting to numpy array\n\n    def set_max_length(self, max_length: int):\n        \"\"\"Set the maximum length for this featurizer\"\"\"\n        self.max_length = max_length\n        self._preload()\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.PretrainedHFTransformer.__init__","title":"<code>__init__(kind='ChemBERTa-77M-MLM', notation='none', pooling='mean', concat_layers=-1, prefer_encoder=True, dtype=np.float32, device='cpu', max_length=128, ignore_padding=True, preload=False, n_jobs=0, random_seed=None, **params)</code>","text":"<p>HuggingFace Transformer for featurizer extraction The default behaviour of this feature extractor is to return the last hidden state of the encoder similar to what is performed by the pipeline 'feature-extraction' in hugging face.</p> <p>Warning</p> <p>For bert models, the default pooling layers is a neural network. Therefore, do not use the default Or provide a random seed for reproducibility (in this case pooling will act as random projection to the same manifold)</p> <p>Note</p> <p>The pooling module of this featurizer is accessible through the <code>_pooling_obj</code> attribute.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>Union[str, HFModel]</code> <p>name of the featurizer as available in the model store</p> <code>'ChemBERTa-77M-MLM'</code> <code>notation</code> <code>Optional[str]</code> <p>optional line notation to use. Only use if it cannot be found from the model card.</p> <code>'none'</code> <code>pooling</code> <code>str</code> <p>type of pooling to use. One of ['default', 'mean', 'max', 'sum', 'clf', ]. The value \"default\" corresponds to the default litterature pooling for each model type. See <code>molfeat.utils.pooler.get_default_hf_pooler</code> for more details.</p> <code>'mean'</code> <code>concat_layers</code> <code>Union[List[int], int]</code> <p>Layer to concat to get the representation. By default the last hidden layer is returned.</p> <code>-1</code> <code>prefer_encoder</code> <code>bool</code> <p>For an encoder-decoder model, prefer the embeddings provided by the encoder.</p> <code>True</code> <code>dtype</code> <p>Data type to output</p> <code>float32</code> <code>device</code> <p>Torch device on which to run the featurizer.</p> <code>'cpu'</code> <code>max_length</code> <code>int</code> <p>Maximum length of the input sequence to consider. Please update this for large sequences</p> <code>128</code> <code>ignore_padding</code> <code>bool</code> <p>Whether to ignore padding in the representation (default: True) to avoid effect of batching</p> <code>True</code> <code>preload</code> <code>bool</code> <p>Whether to preload the model into memory or not</p> <code>False</code> <code>n_jobs</code> <code>int</code> <p>number of jobs to use</p> <code>0</code> <code>random_seed</code> <code>Optional[int]</code> <p>random seed to use for reproducibility whenever a DNN pooler is used (e.g bert/roberta)</p> <code>None</code> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>def __init__(\n    self,\n    kind: Union[str, HFModel] = \"ChemBERTa-77M-MLM\",\n    notation: Optional[str] = \"none\",\n    pooling: str = \"mean\",\n    concat_layers: Union[List[int], int] = -1,\n    prefer_encoder: bool = True,\n    dtype=np.float32,\n    device=\"cpu\",\n    max_length: int = 128,\n    ignore_padding: bool = True,\n    preload: bool = False,\n    n_jobs: int = 0,\n    random_seed: Optional[int] = None,\n    **params,\n):\n    \"\"\"\n    HuggingFace Transformer for featurizer extraction\n    The default behaviour of this feature extractor is to return the last hidden state of the encoder\n    similar to what is performed by the pipeline 'feature-extraction' in hugging face.\n\n    !!! warning\n        For bert models, the default pooling layers is a neural network. Therefore, do not use the default\n        Or provide a random seed for reproducibility (in this case pooling will act as random projection to the same manifold)\n\n    !!! note\n        The pooling module of this featurizer is accessible through the `_pooling_obj` attribute.\n\n    Args:\n        kind: name of the featurizer as available in the model store\n        notation: optional line notation to use. Only use if it cannot be found from the model card.\n        pooling: type of pooling to use. One of ['default', 'mean', 'max', 'sum', 'clf', ]. The value \"default\" corresponds to the default litterature pooling for each model type.\n            See `molfeat.utils.pooler.get_default_hf_pooler` for more details.\n        concat_layers: Layer to concat to get the representation. By default the last hidden layer is returned.\n        prefer_encoder: For an encoder-decoder model, prefer the embeddings provided by the encoder.\n        dtype: Data type to output\n        device: Torch device on which to run the featurizer.\n        max_length: Maximum length of the input sequence to consider. Please update this for large sequences\n        ignore_padding: Whether to ignore padding in the representation (default: True) to avoid effect of batching\n        preload: Whether to preload the model into memory or not\n        n_jobs: number of jobs to use\n        random_seed: random seed to use for reproducibility whenever a DNN pooler is used (e.g bert/roberta)\n    \"\"\"\n\n    if not requires.check(\"transformers\"):\n        raise ValueError(\n            \"Cannot find transformers and/or tokenizers. It's required for this featurizer !\"\n        )\n\n    super().__init__(\n        dtype=dtype,\n        device=device,\n        n_jobs=n_jobs,\n        **params,\n    )\n    if concat_layers is None:\n        concat_layers = -1\n    if not isinstance(concat_layers, list):\n        concat_layers = [concat_layers]\n    self.concat_layers = concat_layers\n    self.max_length = max_length\n    self.ignore_padding = ignore_padding\n    self._require_mols = False\n    self.random_seed = random_seed\n    self.preload = preload\n    self.pooling = pooling\n    self.prefer_encoder = prefer_encoder\n    self.device = torch.device(device)\n    self._pooling_obj = None\n    if isinstance(kind, HFModel):\n        self.kind = kind.name\n        self.featurizer = kind\n    else:\n        self.kind = kind\n        self.featurizer = HFModel(name=self.kind)\n    self.notation = self.featurizer.get_notation(notation) or \"none\"\n    self.converter = SmilesConverter(self.notation)\n    if self.preload:\n        self._preload()\n</code></pre>"},{"location":"api/molfeat.trans.pretrained.hf_transformers.html#molfeat.trans.pretrained.hf_transformers.PretrainedHFTransformer.set_max_length","title":"<code>set_max_length(max_length)</code>","text":"<p>Set the maximum length for this featurizer</p> Source code in <code>molfeat/trans/pretrained/hf_transformers.py</code> <pre><code>def set_max_length(self, max_length: int):\n    \"\"\"Set the maximum length for this featurizer\"\"\"\n    self.max_length = max_length\n    self._preload()\n</code></pre>"},{"location":"api/molfeat.trans.struct.html","title":"molfeat.trans.struct","text":""},{"location":"api/molfeat.trans.struct.html#esm","title":"ESM","text":""},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.esm.ESMProteinFingerprint","title":"<code>ESMProteinFingerprint</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>ESM (Evolutionary Scale Modeling) protein representation embedding. ESM is a transformer protein language model introduced by Facebook FAIR in Rives et al., 2019: 'Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences'</p> Source code in <code>molfeat/trans/struct/esm.py</code> <pre><code>class ESMProteinFingerprint(MoleculeTransformer):\n    \"\"\"\n    ESM (Evolutionary Scale Modeling) protein representation embedding.\n    ESM is a transformer protein language model introduced by Facebook FAIR in Rives et al., 2019:\n    'Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences'\n    \"\"\"\n\n    def __init__(\n        self,\n        featurizer: str = \"esm1b_t33_650M_UR50S\",\n        loader_repo_or_dir: str = \"facebookresearch/esm:main\",\n        device: Optional[str] = None,\n        layers: List[int] = None,\n        pooling: str = \"mean\",\n        dtype: Callable = None,\n        contact: bool = False,\n        **kwargs,\n    ):\n        \"\"\"Constructor for ESM protein representation\n\n        Args:\n            featurizer: Name of the ESM model to use. Defaults to \"esm1b_t33_650M_UR50S\".\n            loader_repo_or_dir: Path to local dir containing the model or to a github repo. Default to \"facebookresearch/esm:main\n            device: Torch device to move the model to. Defaults to None.\n            layers: Layers to use to extract information. Defaults to None, which is the last layers.\n            pooling: Pooling method to use for sequence embedding. Defaults to \"mean\".\n                If you set pooling to None, token representation will be returned (excluding BOS)\n            dtype: Representation output datatype. Defaults to None.\n            contact: Whether to return the predictied attention contact instead of the representation. Defaults to False.\n        \"\"\"\n        self._model_name = featurizer\n        self.device = device\n        self.dtype = dtype\n        self.featurizer = None\n        self.alphabet = None\n        self.batch_converter = None\n        self._fitted = True\n        self.cols_to_keep = None\n        self.repr_layers = layers\n        self.repo_or_dir = loader_repo_or_dir\n        self.contact = contact\n        max_layer_pattern = re.compile(\".*_t([0-9]+)_.*\")\n        self._max_layers = int(max_layer_pattern.match(featurizer).group(1))\n        if layers is None:\n            self.repr_layers = [self._max_layers]\n        if any(lay &gt; self._max_layers for lay in self.repr_layers):\n            raise ValueError(\n                \"You are requesting more layers than available for this pretrained model\"\n            )\n        self._representation = \"seq\"\n        self.pooling = Pooling(dim=0, name=pooling)\n        if pooling is None:\n            self._representation = \"token\"\n        self._feat_length = None\n        self._load_model()\n\n    def _load_model(self):\n        \"\"\"Load model internally\"\"\"\n        self.featurizer, self.alphabet = torch.hub.load(self.repo_or_dir, self._model_name)  # type: ignore\n        self.batch_converter = self.alphabet.get_batch_converter()\n        if self.device is not None:\n            self.featurizer = self.featurizer.to(self.device)\n        self.featurizer.eval()\n\n    def __len__(self):\n        \"\"\"Get featurizer length\"\"\"\n        if self._feat_length is None and not self.contact:\n            embds = self._transform(\"MMMM\")\n            self._feat_length = embds.shape[-1]\n        return self._feat_length\n\n    @property\n    def n_layers(self):\n        \"\"\"Number of layers used in the current embeddings\"\"\"\n        return len(self.repr_layers)\n\n    @torch.no_grad()\n    def _embed(self, prot_seqs: List[str], prot_names: Optional[List[str]] = None, **kwargs):\n        r\"\"\"\n        Compute features for a single molecule.\n        This method would potentially need to be reimplemented by child classes\n\n        Args:\n           prot_seqs: protein sequences as a sequence of amino acids\n           prot_names: protein names\n\n        Returns\n            feat: list of N_SEQ representation, each of size (SEQ_LEN, FEAT_DIM * N_LAYERS) for token embeddings\n                and (FEAT_DIM * N_LAYERS) for sequence embeddings. Note that SEQ_LEN will include the stop token.\n\n        \"\"\"\n        if isinstance(prot_seqs, str):\n            prot_seqs = [prot_seqs]\n        if prot_names is None:\n            prot_names = [\"protein_{i}\" for i in range(len(prot_seqs))]\n        if isinstance(prot_names, str):\n            prot_names = [prot_names]\n        if len(prot_seqs) != len(prot_names):\n            raise ValueError(\"Must provide the same number of protein sequence and label\")\n        data = list(zip(prot_names, prot_seqs))\n        *_, batch_tokens = self.batch_converter(data)\n        if self.device is not None:\n            batch_tokens = batch_tokens.to(self.device)\n\n        results = self.featurizer(\n            batch_tokens, repr_layers=self.repr_layers, return_contacts=self.contact\n        )\n        embeddings = []\n        if self.contact:\n            for _, (seq, att_concats) in enumerate(zip(prot_seqs, results[\"contacts\"])):\n                embeddings.append(att_concats[: len(seq), : len(seq)])\n        else:\n            representation = torch.stack(\n                [results[\"representations\"][x] for x in self.repr_layers], dim=-1\n            )\n            if self._representation.startswith(\"seq\"):\n                for seq, token_rep in zip(prot_seqs, representation):\n                    embeddings.append(\n                        self.pooling(token_rep[1 : len(seq) + 1]).view(1, -1).squeeze(0)\n                    )\n            else:\n                embeddings = list(\n                    representation.view(representation.shape[0], representation.shape[1], -1)\n                )\n        return embeddings\n\n    def __repr__(self):\n        return \"{}(model={}, pooling={}, dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self._model_name),\n            _parse_to_evaluable_str(self.pooling.name),\n            _parse_to_evaluable_str(self.dtype),\n        )\n\n    def _transform(self, protein_seq: str, protein_name: str = None):\n        \"\"\"\n        Transform a protein sequence into a feature vector.\n\n        Args:\n            protein: protein sequence as amino acid sequences\n            protein_name: protein name\n\n        Returns:\n            Embedding of size (SEQ_LEN, FEAT_DIM, N_LAYERS) for token embeddings\n                and (FEAT_DIM * N_LAYERS) for sequence embeddings\n        \"\"\"\n        return self._embed(protein_seq, protein_name)[0]\n\n    def transform(self, seqs: List[str], names: Optional[List[str]] = None, **kwargs):\n        \"\"\"\n        Transform a list of protein sequence into a feature vector.\n\n        Args:\n            seqs: list of protein sequence as amino acids\n            names: protein names\n\n        Returns:\n            Embedding of size (N_SEQS, SEQ_LEN, FEAT_DIM * N_LAYERS) for token embeddings\n                and (N_SEQS, FEAT_DIM * N_LAYERS) for sequence embeddings. Use\n        \"\"\"\n        if (\n            names is None\n            and isinstance(seqs, list)\n            and isinstance(seqs[0], list)\n            and len(seqs[0]) == 2\n        ):\n            names, seqs = zip(*seqs)\n            seqs = list(seqs)\n            names = list(names)\n        return self._embed(seqs, names)\n\n    def __call__(\n        self,\n        seqs: List[str],\n        names: Optional[List[str]] = None,\n        ignore_errors: bool = False,\n        enforce_dtype: bool = True,\n        **kwargs,\n    ):\n        r\"\"\"\n        Compute molecular representation of a protein sequence.\n        If ignore_error is True, a list of features and valid ids are returned.\n\n        Args:\n            seqs: list of protein sequence as amino acids\n            names: protein names\n            enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n            ignore_errors: Whether to ignore errors during featurization or raise an error.\n            kwargs: Named parameters for the transform method\n\n        Returns:\n            feats: list of valid embeddings\n            ids: all valid positions that did not failed during featurization.\n                Only returned when ignore_errors is True.\n\n        \"\"\"\n        features = self.transform(seqs, names, ignore_errors=ignore_errors, **kwargs)\n        ids = np.arange(len(features))\n        if ignore_errors:\n            features, ids = self._filter_none(features)\n        if self.dtype is not None and enforce_dtype:\n            if self.contact or not self._representation.startswith(\"seq\"):\n                features = [\n                    datatype.cast(feat, dtype=self.dtype, columns=self.columns) for feat in features\n                ]\n            else:\n                features = datatype.cast(features, dtype=self.dtype, columns=self.columns)\n        if not ignore_errors:\n            return features\n        return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.esm.ESMProteinFingerprint.n_layers","title":"<code>n_layers</code>  <code>property</code>","text":"<p>Number of layers used in the current embeddings</p>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.esm.ESMProteinFingerprint.__call__","title":"<code>__call__(seqs, names=None, ignore_errors=False, enforce_dtype=True, **kwargs)</code>","text":"<p>Compute molecular representation of a protein sequence. If ignore_error is True, a list of features and valid ids are returned.</p> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <code>List[str]</code> <p>list of protein sequence as amino acids</p> required <code>names</code> <code>Optional[List[str]]</code> <p>protein names</p> <code>None</code> <code>enforce_dtype</code> <code>bool</code> <p>whether to enforce the instance dtype in the generated fingerprint</p> <code>True</code> <code>ignore_errors</code> <code>bool</code> <p>Whether to ignore errors during featurization or raise an error.</p> <code>False</code> <code>kwargs</code> <p>Named parameters for the transform method</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>feats</code> <p>list of valid embeddings</p> <code>ids</code> <p>all valid positions that did not failed during featurization. Only returned when ignore_errors is True.</p> Source code in <code>molfeat/trans/struct/esm.py</code> <pre><code>def __call__(\n    self,\n    seqs: List[str],\n    names: Optional[List[str]] = None,\n    ignore_errors: bool = False,\n    enforce_dtype: bool = True,\n    **kwargs,\n):\n    r\"\"\"\n    Compute molecular representation of a protein sequence.\n    If ignore_error is True, a list of features and valid ids are returned.\n\n    Args:\n        seqs: list of protein sequence as amino acids\n        names: protein names\n        enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n        ignore_errors: Whether to ignore errors during featurization or raise an error.\n        kwargs: Named parameters for the transform method\n\n    Returns:\n        feats: list of valid embeddings\n        ids: all valid positions that did not failed during featurization.\n            Only returned when ignore_errors is True.\n\n    \"\"\"\n    features = self.transform(seqs, names, ignore_errors=ignore_errors, **kwargs)\n    ids = np.arange(len(features))\n    if ignore_errors:\n        features, ids = self._filter_none(features)\n    if self.dtype is not None and enforce_dtype:\n        if self.contact or not self._representation.startswith(\"seq\"):\n            features = [\n                datatype.cast(feat, dtype=self.dtype, columns=self.columns) for feat in features\n            ]\n        else:\n            features = datatype.cast(features, dtype=self.dtype, columns=self.columns)\n    if not ignore_errors:\n        return features\n    return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.esm.ESMProteinFingerprint.__init__","title":"<code>__init__(featurizer='esm1b_t33_650M_UR50S', loader_repo_or_dir='facebookresearch/esm:main', device=None, layers=None, pooling='mean', dtype=None, contact=False, **kwargs)</code>","text":"<p>Constructor for ESM protein representation</p> <p>Parameters:</p> Name Type Description Default <code>featurizer</code> <code>str</code> <p>Name of the ESM model to use. Defaults to \"esm1b_t33_650M_UR50S\".</p> <code>'esm1b_t33_650M_UR50S'</code> <code>loader_repo_or_dir</code> <code>str</code> <p>Path to local dir containing the model or to a github repo. Default to \"facebookresearch/esm:main</p> <code>'facebookresearch/esm:main'</code> <code>device</code> <code>Optional[str]</code> <p>Torch device to move the model to. Defaults to None.</p> <code>None</code> <code>layers</code> <code>List[int]</code> <p>Layers to use to extract information. Defaults to None, which is the last layers.</p> <code>None</code> <code>pooling</code> <code>str</code> <p>Pooling method to use for sequence embedding. Defaults to \"mean\". If you set pooling to None, token representation will be returned (excluding BOS)</p> <code>'mean'</code> <code>dtype</code> <code>Callable</code> <p>Representation output datatype. Defaults to None.</p> <code>None</code> <code>contact</code> <code>bool</code> <p>Whether to return the predictied attention contact instead of the representation. Defaults to False.</p> <code>False</code> Source code in <code>molfeat/trans/struct/esm.py</code> <pre><code>def __init__(\n    self,\n    featurizer: str = \"esm1b_t33_650M_UR50S\",\n    loader_repo_or_dir: str = \"facebookresearch/esm:main\",\n    device: Optional[str] = None,\n    layers: List[int] = None,\n    pooling: str = \"mean\",\n    dtype: Callable = None,\n    contact: bool = False,\n    **kwargs,\n):\n    \"\"\"Constructor for ESM protein representation\n\n    Args:\n        featurizer: Name of the ESM model to use. Defaults to \"esm1b_t33_650M_UR50S\".\n        loader_repo_or_dir: Path to local dir containing the model or to a github repo. Default to \"facebookresearch/esm:main\n        device: Torch device to move the model to. Defaults to None.\n        layers: Layers to use to extract information. Defaults to None, which is the last layers.\n        pooling: Pooling method to use for sequence embedding. Defaults to \"mean\".\n            If you set pooling to None, token representation will be returned (excluding BOS)\n        dtype: Representation output datatype. Defaults to None.\n        contact: Whether to return the predictied attention contact instead of the representation. Defaults to False.\n    \"\"\"\n    self._model_name = featurizer\n    self.device = device\n    self.dtype = dtype\n    self.featurizer = None\n    self.alphabet = None\n    self.batch_converter = None\n    self._fitted = True\n    self.cols_to_keep = None\n    self.repr_layers = layers\n    self.repo_or_dir = loader_repo_or_dir\n    self.contact = contact\n    max_layer_pattern = re.compile(\".*_t([0-9]+)_.*\")\n    self._max_layers = int(max_layer_pattern.match(featurizer).group(1))\n    if layers is None:\n        self.repr_layers = [self._max_layers]\n    if any(lay &gt; self._max_layers for lay in self.repr_layers):\n        raise ValueError(\n            \"You are requesting more layers than available for this pretrained model\"\n        )\n    self._representation = \"seq\"\n    self.pooling = Pooling(dim=0, name=pooling)\n    if pooling is None:\n        self._representation = \"token\"\n    self._feat_length = None\n    self._load_model()\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.esm.ESMProteinFingerprint.__len__","title":"<code>__len__()</code>","text":"<p>Get featurizer length</p> Source code in <code>molfeat/trans/struct/esm.py</code> <pre><code>def __len__(self):\n    \"\"\"Get featurizer length\"\"\"\n    if self._feat_length is None and not self.contact:\n        embds = self._transform(\"MMMM\")\n        self._feat_length = embds.shape[-1]\n    return self._feat_length\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.esm.ESMProteinFingerprint.transform","title":"<code>transform(seqs, names=None, **kwargs)</code>","text":"<p>Transform a list of protein sequence into a feature vector.</p> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <code>List[str]</code> <p>list of protein sequence as amino acids</p> required <code>names</code> <code>Optional[List[str]]</code> <p>protein names</p> <code>None</code> <p>Returns:</p> Type Description <p>Embedding of size (N_SEQS, SEQ_LEN, FEAT_DIM * N_LAYERS) for token embeddings and (N_SEQS, FEAT_DIM * N_LAYERS) for sequence embeddings. Use</p> Source code in <code>molfeat/trans/struct/esm.py</code> <pre><code>def transform(self, seqs: List[str], names: Optional[List[str]] = None, **kwargs):\n    \"\"\"\n    Transform a list of protein sequence into a feature vector.\n\n    Args:\n        seqs: list of protein sequence as amino acids\n        names: protein names\n\n    Returns:\n        Embedding of size (N_SEQS, SEQ_LEN, FEAT_DIM * N_LAYERS) for token embeddings\n            and (N_SEQS, FEAT_DIM * N_LAYERS) for sequence embeddings. Use\n    \"\"\"\n    if (\n        names is None\n        and isinstance(seqs, list)\n        and isinstance(seqs[0], list)\n        and len(seqs[0]) == 2\n    ):\n        names, seqs = zip(*seqs)\n        seqs = list(seqs)\n        names = list(names)\n    return self._embed(seqs, names)\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#bio-embeddings","title":"Bio Embeddings","text":""},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.prot1D.ProtBioFingerprint","title":"<code>ProtBioFingerprint</code>","text":"<p>               Bases: <code>MoleculeTransformer</code></p> <p>Wrapper for general purpose biological sequence representations, as provided by <code>bio_embeddings</code></p> <p>For a list of available embeddings, see: https://docs.bioembeddings.com/v0.2.2/api/bio_embeddings.embed.html</p> <p>!!! note:     The embeddings proposed here are the general purpose embeddings, meaning that task-specific     embeddings offered by <code>bio_embeddings</code> (e.g PBTucker, DeepBlast) are not included.</p> <pre><code>According to the bio_embeddings documentation, `prottrans_bert_bfd` and `seqvec` are the best embeddings.\n</code></pre> Source code in <code>molfeat/trans/struct/prot1D.py</code> <pre><code>class ProtBioFingerprint(MoleculeTransformer):\n    \"\"\"\n    Wrapper for general purpose biological sequence representations, as provided by [`bio_embeddings`](https://github.com/sacdallago/bio_embeddings)\n\n    For a list of available embeddings, see: https://docs.bioembeddings.com/v0.2.2/api/bio_embeddings.embed.html\n\n    !!! note:\n        The embeddings proposed here are the general purpose embeddings, meaning that task-specific\n        embeddings offered by `bio_embeddings` (e.g PBTucker, DeepBlast) are not included.\n\n        According to the bio_embeddings documentation, `prottrans_bert_bfd` and `seqvec` are the best embeddings.\n    \"\"\"\n\n    SUPPORTED_EMBEDDINGS = [\n        \"bepler\",\n        \"cpcprot\",\n        \"esm\",\n        \"esm1b\",\n        \"esm1v\",\n        \"fasttext\",\n        \"glove\",\n        \"one_hot_encoding\",\n        \"plus_rnn\",\n        \"prottrans_albert_bfd\",\n        \"prottrans_bert_bfd\",\n        \"prottrans_t5_bfd\",\n        \"prottrans_t5_uniref50\",\n        \"prottrans_t5_xl_u50\",\n        \"prottrans_xlnet_uniref100\",\n        \"seqvec\",\n        \"unirep\",\n        \"word2vec\",\n    ]\n\n    def __init__(\n        self,\n        featurizer: Union[str, Callable] = \"seqvec\",\n        pooling: str = \"mean\",\n        dtype: Callable = np.float32,\n        device: Optional[Union[torch.device, str]] = None,\n        layer_pooling: str = \"sum\",\n        **kwargs,\n    ):\n        \"\"\"Constructor for Deep Learning based Protein representation.\n        SeqVec featurizer will e\n\n        Args:\n            featurizer: Name of callable of the embedding model\n            pooling: Pooling method to use for sequence embedding. Defaults to \"mean\".\n                If you set pooling to None, token representation will be returned\n            dtype: Representation output datatype. Defaults to None.\n            device: Torch device to move the model to. Defaults to None.\n            layer_pooling: Layer-wise pooling method to use when &gt; 1 layer exists. Default to 'sum'.\n                If None, last layers is taken. This is relevant for `seqvec` mostly\n        \"\"\"\n        if not requires.check(\"bio_embeddings\"):\n            raise ValueError(\n                \"Cannot use this featurizer without bio_embeddings (pip install 'bio_embeddings[all]').\"\n            )\n\n        if isinstance(featurizer, bio_embedder.EmbedderInterface):\n            featurizer = featurizer\n            self._model_name = self.featurizer.name\n        else:\n            if (\n                not isinstance(featurizer, str)\n                or featurizer.lower() not in self.SUPPORTED_EMBEDDINGS\n            ):\n                raise ValueError(\"Unknown featurizer: {}\".format(featurizer))\n            self._model_name = featurizer.lower()\n            featurizer = bio_embedder.name_to_embedder[self._model_name](device=device, **kwargs)\n\n        super().__init__(featurizer=featurizer, dtype=dtype, **kwargs)\n        self._fitted = True\n        self._representation = \"seq\"\n        self.pooling = Pooling(dim=0, name=pooling)\n        self.layer_pooling = Pooling(dim=0, name=layer_pooling)\n        if pooling is None:\n            self._representation = \"token\"\n        self._feat_length = None\n\n    def __len__(self):\n        \"\"\"Get featurizer length\"\"\"\n        return self.featurizer.embedding_dimension\n\n    @property\n    def n_layers(self):\n        \"\"\"Get the number of layers used in this embedding\"\"\"\n        return self.featurizer.number_of_layers\n\n    def __repr__(self):\n        return \"{}(model={}, pooling={}, dtype={})\".format(\n            self.__class__.__name__,\n            _parse_to_evaluable_str(self._model_name),\n            _parse_to_evaluable_str(self.pooling.name),\n            _parse_to_evaluable_str(self.dtype),\n        )\n\n    def _pool(self, embedding: list):\n        \"\"\"Perform embedding pooling\n        Args:\n            embedding: input embedding\n        \"\"\"\n        if self.n_layers &gt; 1 and self.layer_pooling.name is not None:\n            embedding = self.layer_pooling(embedding)\n        if len(embedding.shape) &gt; 2:\n            # we forcefully take the last layers\n            embedding = embedding[-1]\n        return self.pooling(embedding)\n\n    def _transform(\n        self,\n        protein_seq: str,\n        **kwargs,\n    ):\n        \"\"\"\n        Transform a protein/nucleotide sequence into a feature vector.\n\n        Args:\n            protein: protein sequence as amino acid sequences\n\n        Returns:\n            Embedding of size (FEAT_DIM, N_LAYERS) for token embeddings\n                and (FEAT_DIM, N_LAYERS) for sequence embeddings\n        \"\"\"\n\n        rep = self.featurizer.embed(protein_seq)\n        return self._pool(rep)\n\n    def transform(self, seqs: List[str], names: Optional[List[str]] = None, **kwargs):\n        \"\"\"\n        Transform a list of protein/nucleotide sequence into a feature vector.\n\n        Args:\n            seqs: list of protein/nucleotide sequence as amino acids\n            names: names of the macromolecules.  Will be ignored\n            kwargs: additional arguments for the featurizer\n\n        Returns:\n            Embedding of size (N_SEQS, FEAT_DIM) for token embeddings\n                and (FEAT_DIM, N_LAYERS) for sequence embeddings\n        \"\"\"\n        if not isinstance(seqs, list):\n            seqs = [seqs]\n        if isinstance(seqs[0], (list, tuple)) and len(seqs[0]) == 2:\n            _, seqs = zip(*seqs)\n            seqs = list(seqs)\n        res = list(self.featurizer.embed_many(seqs, **kwargs))\n        res = [self._pool(x) for x in res]\n        return res\n\n    def __call__(\n        self,\n        seqs: List[str],\n        ignore_errors: bool = False,\n        enforce_dtype: bool = True,\n        **kwargs,\n    ):\n        r\"\"\"\n        Compute molecular representation of a protein sequence.\n        If ignore_error is True, a list of features and valid ids are returned.\n\n        Args:\n            seqs: list of protein or nucleotide sequence as amino acids\n            enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n            ignore_errors: Whether to ignore errors during featurization or raise an error.\n            kwargs: Named parameters for the transform method\n\n        Returns:\n            feats: list of valid embeddings\n            ids: all valid positions that did not failed during featurization.\n                Only returned when ignore_errors is True.\n\n        \"\"\"\n        features = self.transform(seqs, **kwargs)\n        ids = np.arange(len(features))\n        if ignore_errors:\n            features, ids = self._filter_none(features)\n        if self.dtype is not None and enforce_dtype:\n            if self._representation.startswith(\"token\"):\n                features = [\n                    datatype.cast(feat, dtype=self.dtype, columns=self.columns) for feat in features\n                ]\n            else:\n                features = datatype.cast(features, dtype=self.dtype, columns=self.columns)\n        if not ignore_errors:\n            return features\n        return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.prot1D.ProtBioFingerprint.n_layers","title":"<code>n_layers</code>  <code>property</code>","text":"<p>Get the number of layers used in this embedding</p>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.prot1D.ProtBioFingerprint.__call__","title":"<code>__call__(seqs, ignore_errors=False, enforce_dtype=True, **kwargs)</code>","text":"<p>Compute molecular representation of a protein sequence. If ignore_error is True, a list of features and valid ids are returned.</p> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <code>List[str]</code> <p>list of protein or nucleotide sequence as amino acids</p> required <code>enforce_dtype</code> <code>bool</code> <p>whether to enforce the instance dtype in the generated fingerprint</p> <code>True</code> <code>ignore_errors</code> <code>bool</code> <p>Whether to ignore errors during featurization or raise an error.</p> <code>False</code> <code>kwargs</code> <p>Named parameters for the transform method</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>feats</code> <p>list of valid embeddings</p> <code>ids</code> <p>all valid positions that did not failed during featurization. Only returned when ignore_errors is True.</p> Source code in <code>molfeat/trans/struct/prot1D.py</code> <pre><code>def __call__(\n    self,\n    seqs: List[str],\n    ignore_errors: bool = False,\n    enforce_dtype: bool = True,\n    **kwargs,\n):\n    r\"\"\"\n    Compute molecular representation of a protein sequence.\n    If ignore_error is True, a list of features and valid ids are returned.\n\n    Args:\n        seqs: list of protein or nucleotide sequence as amino acids\n        enforce_dtype: whether to enforce the instance dtype in the generated fingerprint\n        ignore_errors: Whether to ignore errors during featurization or raise an error.\n        kwargs: Named parameters for the transform method\n\n    Returns:\n        feats: list of valid embeddings\n        ids: all valid positions that did not failed during featurization.\n            Only returned when ignore_errors is True.\n\n    \"\"\"\n    features = self.transform(seqs, **kwargs)\n    ids = np.arange(len(features))\n    if ignore_errors:\n        features, ids = self._filter_none(features)\n    if self.dtype is not None and enforce_dtype:\n        if self._representation.startswith(\"token\"):\n            features = [\n                datatype.cast(feat, dtype=self.dtype, columns=self.columns) for feat in features\n            ]\n        else:\n            features = datatype.cast(features, dtype=self.dtype, columns=self.columns)\n    if not ignore_errors:\n        return features\n    return features, ids\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.prot1D.ProtBioFingerprint.__init__","title":"<code>__init__(featurizer='seqvec', pooling='mean', dtype=np.float32, device=None, layer_pooling='sum', **kwargs)</code>","text":"<p>Constructor for Deep Learning based Protein representation. SeqVec featurizer will e</p> <p>Parameters:</p> Name Type Description Default <code>featurizer</code> <code>Union[str, Callable]</code> <p>Name of callable of the embedding model</p> <code>'seqvec'</code> <code>pooling</code> <code>str</code> <p>Pooling method to use for sequence embedding. Defaults to \"mean\". If you set pooling to None, token representation will be returned</p> <code>'mean'</code> <code>dtype</code> <code>Callable</code> <p>Representation output datatype. Defaults to None.</p> <code>float32</code> <code>device</code> <code>Optional[Union[device, str]]</code> <p>Torch device to move the model to. Defaults to None.</p> <code>None</code> <code>layer_pooling</code> <code>str</code> <p>Layer-wise pooling method to use when &gt; 1 layer exists. Default to 'sum'. If None, last layers is taken. This is relevant for <code>seqvec</code> mostly</p> <code>'sum'</code> Source code in <code>molfeat/trans/struct/prot1D.py</code> <pre><code>def __init__(\n    self,\n    featurizer: Union[str, Callable] = \"seqvec\",\n    pooling: str = \"mean\",\n    dtype: Callable = np.float32,\n    device: Optional[Union[torch.device, str]] = None,\n    layer_pooling: str = \"sum\",\n    **kwargs,\n):\n    \"\"\"Constructor for Deep Learning based Protein representation.\n    SeqVec featurizer will e\n\n    Args:\n        featurizer: Name of callable of the embedding model\n        pooling: Pooling method to use for sequence embedding. Defaults to \"mean\".\n            If you set pooling to None, token representation will be returned\n        dtype: Representation output datatype. Defaults to None.\n        device: Torch device to move the model to. Defaults to None.\n        layer_pooling: Layer-wise pooling method to use when &gt; 1 layer exists. Default to 'sum'.\n            If None, last layers is taken. This is relevant for `seqvec` mostly\n    \"\"\"\n    if not requires.check(\"bio_embeddings\"):\n        raise ValueError(\n            \"Cannot use this featurizer without bio_embeddings (pip install 'bio_embeddings[all]').\"\n        )\n\n    if isinstance(featurizer, bio_embedder.EmbedderInterface):\n        featurizer = featurizer\n        self._model_name = self.featurizer.name\n    else:\n        if (\n            not isinstance(featurizer, str)\n            or featurizer.lower() not in self.SUPPORTED_EMBEDDINGS\n        ):\n            raise ValueError(\"Unknown featurizer: {}\".format(featurizer))\n        self._model_name = featurizer.lower()\n        featurizer = bio_embedder.name_to_embedder[self._model_name](device=device, **kwargs)\n\n    super().__init__(featurizer=featurizer, dtype=dtype, **kwargs)\n    self._fitted = True\n    self._representation = \"seq\"\n    self.pooling = Pooling(dim=0, name=pooling)\n    self.layer_pooling = Pooling(dim=0, name=layer_pooling)\n    if pooling is None:\n        self._representation = \"token\"\n    self._feat_length = None\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.prot1D.ProtBioFingerprint.__len__","title":"<code>__len__()</code>","text":"<p>Get featurizer length</p> Source code in <code>molfeat/trans/struct/prot1D.py</code> <pre><code>def __len__(self):\n    \"\"\"Get featurizer length\"\"\"\n    return self.featurizer.embedding_dimension\n</code></pre>"},{"location":"api/molfeat.trans.struct.html#molfeat.trans.struct.prot1D.ProtBioFingerprint.transform","title":"<code>transform(seqs, names=None, **kwargs)</code>","text":"<p>Transform a list of protein/nucleotide sequence into a feature vector.</p> <p>Parameters:</p> Name Type Description Default <code>seqs</code> <code>List[str]</code> <p>list of protein/nucleotide sequence as amino acids</p> required <code>names</code> <code>Optional[List[str]]</code> <p>names of the macromolecules.  Will be ignored</p> <code>None</code> <code>kwargs</code> <p>additional arguments for the featurizer</p> <code>{}</code> <p>Returns:</p> Type Description <p>Embedding of size (N_SEQS, FEAT_DIM) for token embeddings and (FEAT_DIM, N_LAYERS) for sequence embeddings</p> Source code in <code>molfeat/trans/struct/prot1D.py</code> <pre><code>def transform(self, seqs: List[str], names: Optional[List[str]] = None, **kwargs):\n    \"\"\"\n    Transform a list of protein/nucleotide sequence into a feature vector.\n\n    Args:\n        seqs: list of protein/nucleotide sequence as amino acids\n        names: names of the macromolecules.  Will be ignored\n        kwargs: additional arguments for the featurizer\n\n    Returns:\n        Embedding of size (N_SEQS, FEAT_DIM) for token embeddings\n            and (FEAT_DIM, N_LAYERS) for sequence embeddings\n    \"\"\"\n    if not isinstance(seqs, list):\n        seqs = [seqs]\n    if isinstance(seqs[0], (list, tuple)) and len(seqs[0]) == 2:\n        _, seqs = zip(*seqs)\n        seqs = list(seqs)\n    res = list(self.featurizer.embed_many(seqs, **kwargs))\n    res = [self._pool(x) for x in res]\n    return res\n</code></pre>"},{"location":"api/molfeat.utils.html","title":"molfeat.utils","text":""},{"location":"api/molfeat.utils.html#cache","title":"Cache","text":""},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList","title":"<code>CacheList</code>","text":"<p>Proxy for supporting search using a list of cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>class CacheList:\n    \"\"\"Proxy for supporting search using a list of cache\"\"\"\n\n    def __init__(self, *caches):\n        self.caches = caches\n\n    def __getitem__(self, key):\n        for cache in self.caches:\n            val = cache.get(key)\n            if val is not None:\n                return val\n        raise KeyError(f\"{key} not found in any cache\")\n\n    def __contains__(self, key: Any):\n        \"\"\"Check whether a key is in the cache\n        Args:\n            key: key to check in the cache\n        \"\"\"\n        return any(key in cache for cache in self.caches)\n\n    def __len__(self):\n        \"\"\"Return the length of the cache\"\"\"\n        return sum(len(c) for c in self.caches)\n\n    def __iter__(self):\n        \"\"\"Iterate over all the caches\"\"\"\n        return itertools.chain(*iter(self.cache))\n\n    def __setitem__(self, key: Any, item: Any):\n        \"\"\"Add an item to the cache\n\n        Args:\n            key: input key to set\n            item: value of the key to set\n        \"\"\"\n        # select a random cache and add the item to the cache\n        cache = random.choice(self.caches)\n        cache.update({key: item})\n\n    def __call__(self, *args, **kwargs):\n        \"\"\"\n        Compute the features for a list of molecules and save them to the cache\n        \"\"\"\n\n        raise NotImplementedError(\n            \"Dynamic updating of a cache list using a featurizer is not supported!\"\n        )\n\n    def clear(self, *args, **kwargs):\n        \"\"\"Clear all the caches and make them inaccesible\"\"\"\n        for cache in self.caches:\n            cache.clear(*args, **kwargs)\n\n    def update(self, new_cache: Mapping[Any, Any]):\n        cache = random.choice(self.caches)\n        cache.update(new_cache)\n\n    def get(self, key, default: Optional[Any] = None):\n        \"\"\"Get the cached value for a specific key\n        Args:\n            key: key to get\n            default: default value to return when the key is not found\n        \"\"\"\n        for cache in self.caches:\n            val = cache.get(key)\n            if val is not None:\n                return val\n        return default\n\n    def keys(self):\n        \"\"\"Get list of keys in the cache\"\"\"\n        return list(itertools.chain(*(c.keys() for c in self.caches)))\n\n    def values(self):\n        \"\"\"Get list of values in the cache\"\"\"\n        return list(itertools.chain(*(c.values() for c in self.caches)))\n\n    def items(self):\n        \"\"\"Return iterator of key, values in the cache\"\"\"\n        return list(itertools.chain(*(c.items() for c in self.caches)))\n\n    def to_dict(self):\n        \"\"\"Convert current cache to a dictionary\"\"\"\n        return dict(self.items())\n\n    def fetch(\n        self,\n        mols: List[Union[dm.Mol, str]],\n    ):\n        \"\"\"Get the representation for a single\n\n        Args:\n            mols: list of molecules\n        \"\"\"\n        if isinstance(mols, str) or not isinstance(mols, Iterable):\n            mols = [mols]\n        return [self.get(mol) for mol in mols]\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Compute the features for a list of molecules and save them to the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __call__(self, *args, **kwargs):\n    \"\"\"\n    Compute the features for a list of molecules and save them to the cache\n    \"\"\"\n\n    raise NotImplementedError(\n        \"Dynamic updating of a cache list using a featurizer is not supported!\"\n    )\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check whether a key is in the cache Args:     key: key to check in the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __contains__(self, key: Any):\n    \"\"\"Check whether a key is in the cache\n    Args:\n        key: key to check in the cache\n    \"\"\"\n    return any(key in cache for cache in self.caches)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over all the caches</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over all the caches\"\"\"\n    return itertools.chain(*iter(self.cache))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __len__(self):\n    \"\"\"Return the length of the cache\"\"\"\n    return sum(len(c) for c in self.caches)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.__setitem__","title":"<code>__setitem__(key, item)</code>","text":"<p>Add an item to the cache</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Any</code> <p>input key to set</p> required <code>item</code> <code>Any</code> <p>value of the key to set</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __setitem__(self, key: Any, item: Any):\n    \"\"\"Add an item to the cache\n\n    Args:\n        key: input key to set\n        item: value of the key to set\n    \"\"\"\n    # select a random cache and add the item to the cache\n    cache = random.choice(self.caches)\n    cache.update({key: item})\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.clear","title":"<code>clear(*args, **kwargs)</code>","text":"<p>Clear all the caches and make them inaccesible</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def clear(self, *args, **kwargs):\n    \"\"\"Clear all the caches and make them inaccesible\"\"\"\n    for cache in self.caches:\n        cache.clear(*args, **kwargs)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.fetch","title":"<code>fetch(mols)</code>","text":"<p>Get the representation for a single</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Union[Mol, str]]</code> <p>list of molecules</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>def fetch(\n    self,\n    mols: List[Union[dm.Mol, str]],\n):\n    \"\"\"Get the representation for a single\n\n    Args:\n        mols: list of molecules\n    \"\"\"\n    if isinstance(mols, str) or not isinstance(mols, Iterable):\n        mols = [mols]\n    return [self.get(mol) for mol in mols]\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.get","title":"<code>get(key, default=None)</code>","text":"<p>Get the cached value for a specific key Args:     key: key to get     default: default value to return when the key is not found</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def get(self, key, default: Optional[Any] = None):\n    \"\"\"Get the cached value for a specific key\n    Args:\n        key: key to get\n        default: default value to return when the key is not found\n    \"\"\"\n    for cache in self.caches:\n        val = cache.get(key)\n        if val is not None:\n            return val\n    return default\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.items","title":"<code>items()</code>","text":"<p>Return iterator of key, values in the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def items(self):\n    \"\"\"Return iterator of key, values in the cache\"\"\"\n    return list(itertools.chain(*(c.items() for c in self.caches)))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.keys","title":"<code>keys()</code>","text":"<p>Get list of keys in the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def keys(self):\n    \"\"\"Get list of keys in the cache\"\"\"\n    return list(itertools.chain(*(c.keys() for c in self.caches)))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert current cache to a dictionary</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def to_dict(self):\n    \"\"\"Convert current cache to a dictionary\"\"\"\n    return dict(self.items())\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.CacheList.values","title":"<code>values()</code>","text":"<p>Get list of values in the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def values(self):\n    \"\"\"Get list of values in the cache\"\"\"\n    return list(itertools.chain(*(c.values() for c in self.caches)))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.DataCache","title":"<code>DataCache</code>","text":"<p>               Bases: <code>_Cache</code></p> <p>Molecular features caching system that cache computed values in memory for reuse later</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>class DataCache(_Cache):\n    \"\"\"\n    Molecular features caching system that cache computed values in memory for reuse later\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        n_jobs: int = -1,\n        mol_hasher: Optional[Union[Callable, str, MolToKey]] = None,\n        verbose: Union[bool, int] = False,\n        cache_file: Optional[Union[os.PathLike, bool]] = None,\n        delete_on_exit: bool = False,\n        clear_on_exit: bool = True,\n    ):\n        \"\"\"Precomputed fingerprint caching callback\n\n        Args:\n            name: name of the cache\n            n_jobs: number of parallel jobs to use when performing any computation\n            mol_hasher: function to use to hash molecules. If not provided, `dm.unique_id`` is used by default\n            verbose: whether to print progress. Default to False\n            cache_file: Cache location. Defaults to None, which will use in-memory caching.\n            delete_on_exit: Whether to delete the cache file on exit. Defaults to False.\n            clear_on_exit: Whether to clear the cache on exit of the interpreter. Default to True\n        \"\"\"\n        super().__init__(name=name, mol_hasher=mol_hasher, n_jobs=n_jobs, verbose=verbose)\n\n        if cache_file is True:\n            cache_file = pathlib.Path(\n                platformdirs.user_cache_dir(appname=\"molfeat\")\n            ) / \"precomputed/{}_{}.db\".format(self.name, str(uuid.uuid4())[:8])\n\n            cache_file = str(cache_file)\n        self.cache_file = cache_file\n        self.cache = {}\n        self._initialize_cache()\n        self.delete_on_exit = delete_on_exit\n        self.clear_on_exit = clear_on_exit\n        if self.clear_on_exit:\n            atexit.register(partial(self.clear, delete=delete_on_exit))\n\n    def _initialize_cache(self):\n        if self.cache_file not in [None, False]:\n            # force creation of cache directory\n            cache_parent = pathlib.Path(self.cache_file).parent\n            cache_parent.mkdir(parents=True, exist_ok=True)\n            self.cache = shelve.open(self.cache_file)\n        else:\n            self.cache = {}\n\n    def clear(self, delete: bool = False):\n        \"\"\"Clear cache memory if needed.\n        Note that a cleared cache cannot be used anymore\n\n        Args:\n            delete: whether to delete the cache file if on disk\n        \"\"\"\n        self.cache.clear()\n        if isinstance(self.cache, shelve.Shelf):\n            self.cache.close()\n            # EN: temporary set it to a dict before reopening\n            # this needs to be done to prevent operating on close files\n            self.cache = {}\n        if delete:\n            if self.cache_file is not None:\n                for path in glob.glob(str(self.cache_file) + \"*\"):\n                    try:\n                        os.unlink(path)\n                    except Exception:  # noqa\n                        pass\n        else:\n            self._initialize_cache()\n\n    def update(self, new_cache: Mapping[Any, Any]):\n        \"\"\"Update the cache with new values\n\n        Args:\n            new_cache: new cache with items to use to update current cache\n        \"\"\"\n        for k, v in new_cache.items():\n            k = self.mol_hasher(k)\n            self.cache[k] = v\n        return self\n\n    def _sync_cache(self):\n        \"\"\"Perform a cache sync to ensure values are up to date\"\"\"\n        if isinstance(self.cache, shelve.Shelf):\n            self.cache.sync()\n\n    @classmethod\n    def load_from_file(cls, filepath: Union[os.PathLike, str]):\n        \"\"\"Load a datache from a file (including remote file)\n\n        Args:\n            filepath: path to the file to load\n        \"\"\"\n        cached_data = None\n        with fsspec.open(filepath, \"rb\") as f:\n            cached_data = joblib.load(f)\n        data = cached_data.pop(\"data\", {})\n        new_cache = cls(**cached_data)\n        new_cache.update(data)\n        return new_cache\n\n    def save_to_file(self, filepath: Union[os.PathLike, str]):\n        \"\"\"Save the cache to a file\n\n        Args:\n            filepath: path to the file to save\n        \"\"\"\n        information = dict(\n            name=self.name,\n            n_jobs=self.n_jobs,\n            mol_hasher=self.mol_hasher,\n            verbose=self.verbose,\n            cache_file=(self.cache_file is not None),\n            delete_on_exit=self.delete_on_exit,\n        )\n        information[\"data\"] = self.to_dict()\n        with fsspec.open(filepath, \"wb\") as f:\n            joblib.dump(information, f)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.DataCache.__init__","title":"<code>__init__(name, n_jobs=-1, mol_hasher=None, verbose=False, cache_file=None, delete_on_exit=False, clear_on_exit=True)</code>","text":"<p>Precomputed fingerprint caching callback</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the cache</p> required <code>n_jobs</code> <code>int</code> <p>number of parallel jobs to use when performing any computation</p> <code>-1</code> <code>mol_hasher</code> <code>Optional[Union[Callable, str, MolToKey]]</code> <p>function to use to hash molecules. If not provided, `dm.unique_id`` is used by default</p> <code>None</code> <code>verbose</code> <code>Union[bool, int]</code> <p>whether to print progress. Default to False</p> <code>False</code> <code>cache_file</code> <code>Optional[Union[PathLike, bool]]</code> <p>Cache location. Defaults to None, which will use in-memory caching.</p> <code>None</code> <code>delete_on_exit</code> <code>bool</code> <p>Whether to delete the cache file on exit. Defaults to False.</p> <code>False</code> <code>clear_on_exit</code> <code>bool</code> <p>Whether to clear the cache on exit of the interpreter. Default to True</p> <code>True</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    n_jobs: int = -1,\n    mol_hasher: Optional[Union[Callable, str, MolToKey]] = None,\n    verbose: Union[bool, int] = False,\n    cache_file: Optional[Union[os.PathLike, bool]] = None,\n    delete_on_exit: bool = False,\n    clear_on_exit: bool = True,\n):\n    \"\"\"Precomputed fingerprint caching callback\n\n    Args:\n        name: name of the cache\n        n_jobs: number of parallel jobs to use when performing any computation\n        mol_hasher: function to use to hash molecules. If not provided, `dm.unique_id`` is used by default\n        verbose: whether to print progress. Default to False\n        cache_file: Cache location. Defaults to None, which will use in-memory caching.\n        delete_on_exit: Whether to delete the cache file on exit. Defaults to False.\n        clear_on_exit: Whether to clear the cache on exit of the interpreter. Default to True\n    \"\"\"\n    super().__init__(name=name, mol_hasher=mol_hasher, n_jobs=n_jobs, verbose=verbose)\n\n    if cache_file is True:\n        cache_file = pathlib.Path(\n            platformdirs.user_cache_dir(appname=\"molfeat\")\n        ) / \"precomputed/{}_{}.db\".format(self.name, str(uuid.uuid4())[:8])\n\n        cache_file = str(cache_file)\n    self.cache_file = cache_file\n    self.cache = {}\n    self._initialize_cache()\n    self.delete_on_exit = delete_on_exit\n    self.clear_on_exit = clear_on_exit\n    if self.clear_on_exit:\n        atexit.register(partial(self.clear, delete=delete_on_exit))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.DataCache.clear","title":"<code>clear(delete=False)</code>","text":"<p>Clear cache memory if needed. Note that a cleared cache cannot be used anymore</p> <p>Parameters:</p> Name Type Description Default <code>delete</code> <code>bool</code> <p>whether to delete the cache file if on disk</p> <code>False</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def clear(self, delete: bool = False):\n    \"\"\"Clear cache memory if needed.\n    Note that a cleared cache cannot be used anymore\n\n    Args:\n        delete: whether to delete the cache file if on disk\n    \"\"\"\n    self.cache.clear()\n    if isinstance(self.cache, shelve.Shelf):\n        self.cache.close()\n        # EN: temporary set it to a dict before reopening\n        # this needs to be done to prevent operating on close files\n        self.cache = {}\n    if delete:\n        if self.cache_file is not None:\n            for path in glob.glob(str(self.cache_file) + \"*\"):\n                try:\n                    os.unlink(path)\n                except Exception:  # noqa\n                    pass\n    else:\n        self._initialize_cache()\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.DataCache.load_from_file","title":"<code>load_from_file(filepath)</code>  <code>classmethod</code>","text":"<p>Load a datache from a file (including remote file)</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[PathLike, str]</code> <p>path to the file to load</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>@classmethod\ndef load_from_file(cls, filepath: Union[os.PathLike, str]):\n    \"\"\"Load a datache from a file (including remote file)\n\n    Args:\n        filepath: path to the file to load\n    \"\"\"\n    cached_data = None\n    with fsspec.open(filepath, \"rb\") as f:\n        cached_data = joblib.load(f)\n    data = cached_data.pop(\"data\", {})\n    new_cache = cls(**cached_data)\n    new_cache.update(data)\n    return new_cache\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.DataCache.save_to_file","title":"<code>save_to_file(filepath)</code>","text":"<p>Save the cache to a file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[PathLike, str]</code> <p>path to the file to save</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>def save_to_file(self, filepath: Union[os.PathLike, str]):\n    \"\"\"Save the cache to a file\n\n    Args:\n        filepath: path to the file to save\n    \"\"\"\n    information = dict(\n        name=self.name,\n        n_jobs=self.n_jobs,\n        mol_hasher=self.mol_hasher,\n        verbose=self.verbose,\n        cache_file=(self.cache_file is not None),\n        delete_on_exit=self.delete_on_exit,\n    )\n    information[\"data\"] = self.to_dict()\n    with fsspec.open(filepath, \"wb\") as f:\n        joblib.dump(information, f)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.DataCache.update","title":"<code>update(new_cache)</code>","text":"<p>Update the cache with new values</p> <p>Parameters:</p> Name Type Description Default <code>new_cache</code> <code>Mapping[Any, Any]</code> <p>new cache with items to use to update current cache</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>def update(self, new_cache: Mapping[Any, Any]):\n    \"\"\"Update the cache with new values\n\n    Args:\n        new_cache: new cache with items to use to update current cache\n    \"\"\"\n    for k, v in new_cache.items():\n        k = self.mol_hasher(k)\n        self.cache[k] = v\n    return self\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache","title":"<code>FileCache</code>","text":"<p>               Bases: <code>_Cache</code></p> <p>Read only cache that holds in precomputed data in a pickle, csv or h5py file.</p> <p>The convention used requires the 'keys' and  'values' columns when the input file needs to be loaded as a dataframe.</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>class FileCache(_Cache):\n    \"\"\"\n    Read only cache that holds in precomputed data in a pickle, csv or h5py file.\n\n    The convention used requires the 'keys' and  'values' columns when\n    the input file needs to be loaded as a dataframe.\n    \"\"\"\n\n    _PICKLE_PROTOCOL = 4\n    SUPPORTED_TYPES = [\"pickle\", \"pkl\", \"csv\", \"parquet\", \"pq\", \"hdf5\", \"h5\"]\n\n    def __init__(\n        self,\n        cache_file: Union[os.PathLike, str],\n        name: Optional[str] = None,\n        mol_hasher: Optional[Union[Callable, str, MolToKey]] = None,\n        n_jobs: Optional[int] = None,\n        verbose: Union[bool, int] = False,\n        file_type: str = \"parquet\",\n        clear_on_exit: bool = True,\n        parquet_kwargs: Optional[Dict[Any, Any]] = None,\n    ):\n        \"\"\"Precomputed fingerprint caching callback\n\n        !!! note\n            Do not pickle this object, instead use the provided saving methods.\n\n        Args:\n            cache_file: Cache location. Can be a local file or a remote file\n            name: optional name to give the cache\n            mol_hasher: function to use to hash molecules. If not provided, `dm.unique_id` is used by default\n            n_jobs: number of parallel jobs to use when performing any computation\n            verbose: whether to print information about the cache\n            clear_on_exit: whether to clear the cache on exit of the interpreter\n            file_type: File type that was provided. One of \"csv\", \"pickle\", \"hdf5\" and \"parquet\"\n                For \"csv\" and \"parquet\", we expect columns \"keys\" and \"values\"\n                For a pickle, we expect either a mapping or a dataframe with \"keys\" and \"values\" columns\n            parquet_kwargs: Argument to pass to the parquet reader.\n        \"\"\"\n        super().__init__(name=name, mol_hasher=mol_hasher, n_jobs=n_jobs, verbose=verbose)\n\n        self.cache_file = cache_file\n        self.file_type = file_type\n        self.parquet_kwargs = parquet_kwargs or {}\n        self.clear_on_exit = clear_on_exit\n\n        if self.file_type not in FileCache.SUPPORTED_TYPES:\n            raise ValueError(\n                f\"Unsupported file type, expected one of {FileCache.SUPPORTED_TYPES}, got '{self.file_type}'\"\n            )\n\n        if self.cache_file is not None and dm.fs.exists(self.cache_file):\n            self._load_cache()\n        else:\n            self.cache = {}\n\n        if self.clear_on_exit:\n            atexit.register(self.clear)\n\n    def clear(self):\n        \"\"\"Clear cache memory at exit and close any open file\n        Note that a cleared cache cannot be used anymore !\n        \"\"\"\n        if self.file_type in [\"hdf5\", \"h5\"]:\n            self.cache.close()\n        else:\n            del self.cache\n        # reset cache to empty\n        self.cache = {}\n\n    def items(self):\n        \"\"\"Return iterator of key, values in the cache\"\"\"\n        if self.file_type in [\"hdf5\", \"h5\"]:\n            return ((k, np.asarray(v)) for k, v in self.cache.items())\n        return super().items()\n\n    def _load_cache(self):\n        \"\"\"Load cache internally if needed\"\"\"\n\n        file_exists = dm.utils.fs.exists(self.cache_file)\n\n        if self.file_type in [\"hdf5\", \"h5\"]:\n            f = fsspec.open(\"simplecache::\" + self.cache_file, \"rb+\").open()\n            self.cache = h5py.File(f, \"r+\")\n\n        elif not file_exists:\n            self.cache = {}\n\n        elif self.file_type in [\"pickle\", \"pkl\"]:\n            with fsspec.open(self.cache_file, \"rb\") as IN:\n                self.cache = joblib.load(IN)\n\n        elif self.file_type == \"csv\":\n            with fsspec.open(self.cache_file, \"rb\") as IN:\n                # Allow the CSV file to exist but with an empty content\n                try:\n                    self.cache = pd.read_csv(\n                        IN,\n                        converters={\"values\": lambda x: commons.unpack_bits(ast.literal_eval(x))},\n                    )\n                except pandas.errors.EmptyDataError:\n                    self.cache = {}\n\n        elif self.file_type in [\"parquet\", \"pq\"]:\n            self.cache = pd.read_parquet(\n                self.cache_file,\n                columns=[\"keys\", \"values\"],\n                **self.parquet_kwargs,\n            )\n        # convert dataframe to dict if needed\n        if isinstance(self.cache, pd.DataFrame):\n            self.cache = self.cache.set_index(\"keys\").to_dict()[\"values\"]\n\n    def update(self, new_cache: Mapping[Any, Any]):\n        \"\"\"Update the cache with new values\n\n        Args:\n            new_cache: new cache with items to use to update current cache\n        \"\"\"\n        for k, v in new_cache.items():\n            key = self.mol_hasher(k)\n            if self.file_type in [\"hdf5\", \"h5\"]:\n                self.cache.create_dataset(key, data=v)\n            else:\n                self.cache[key] = v\n        return self\n\n    @classmethod\n    def load_from_file(cls, filepath: Union[os.PathLike, str], **kwargs):\n        \"\"\"Load a FileCache from a file\n\n        Args:\n            filepath: path to the file to load\n            kwargs: keyword arguments to pass to the constructor\n        \"\"\"\n        new_cache = cls(cache_file=filepath, **kwargs)\n        return new_cache\n\n    def to_dataframe(self, pack_bits: bool = False):\n        \"\"\"Convert the cache to a dataframe. The converted dataframe would have `keys` and `values` columns\n\n        Args:\n            pack_bits: whether to pack the values columns into bits.\n                By using molfeat.utils.commons.unpack_bits, the values column can be reloaded as an array\n        \"\"\"\n        if pack_bits:\n            loaded_items = [\n                (k, commons.pack_bits(x, protocol=self._PICKLE_PROTOCOL)) for k, x in self.items()\n            ]\n        else:\n            loaded_items = self.items()\n        df = pd.DataFrame(loaded_items, columns=[\"keys\", \"values\"])\n        return df\n\n    def save_to_file(\n        self,\n        filepath: Optional[Union[os.PathLike, str]] = None,\n        file_type: Optional[str] = None,\n        **kwargs,\n    ):\n        \"\"\"Save the cache to a file\n\n        Args:\n            filepath: path to the file to save. If None, the cache is saved to the original file.\n            file_type: format used to save the cache to file one of \"pickle\", \"csv\", \"hdf5\", \"parquet\".\n                If None, the original file type is used.\n            kwargs: keyword arguments to pass to the serializer to disk (e.g to pass to pd.to_csv or pd.to_parquet)\n        \"\"\"\n\n        if filepath is None:\n            filepath = self.cache_file\n\n        if file_type is None:\n            file_type = self.file_type\n\n        if file_type in [\"pkl\", \"pickle\"]:\n            with fsspec.open(filepath, \"wb\") as f:\n                joblib.dump(self.to_dict(), f)\n\n        elif file_type in [\"csv\", \"parquet\", \"pq\"]:\n            df = self.to_dataframe(pack_bits=(file_type == \"csv\"))\n\n            if file_type == \"csv\":\n                with fsspec.open(filepath, \"w\") as f:\n                    df.to_csv(f, index=False, **kwargs)\n            else:\n                df.to_parquet(filepath, index=False, **kwargs)\n\n        elif file_type in [\"hdf5\", \"h5\"]:\n            with fsspec.open(filepath, \"wb\") as IN:\n                with h5py.File(IN, \"w\") as f:\n                    for k, v in self.items():\n                        f.create_dataset(k, data=v)\n        else:\n            raise ValueError(\"Unsupported output protocol: {}\".format(file_type))\n\n    def to_state_dict(self, save_to_file: bool = True) -&gt; dict:\n        \"\"\"Serialize the cache to a state dict.\n\n        Args:\n            save_to_file: whether to save the cache to file.\n        \"\"\"\n\n        if save_to_file is True:\n            self.save_to_file()\n\n        state = {}\n        state[\"_cache_name\"] = \"FileCache\"\n        state[\"cache_file\"] = self.cache_file\n        state[\"name\"] = self.name\n        state[\"n_jobs\"] = self.n_jobs\n        state[\"verbose\"] = self.verbose\n        state[\"file_type\"] = self.file_type\n        state[\"clear_on_exit\"] = self.clear_on_exit\n        state[\"parquet_kwargs\"] = self.parquet_kwargs\n        state[\"mol_hasher\"] = self.mol_hasher.to_state_dict()\n\n        return state\n\n    @staticmethod\n    def from_state_dict(state: dict, override_args: Optional[dict] = None) -&gt; \"FileCache\":\n        # Don't alter the original state dict\n        state = copy.deepcopy(state)\n\n        cache_name = state.pop(\"_cache_name\")\n\n        if cache_name != \"FileCache\":\n            raise ValueError(f\"The cache object name is invalid: {cache_name}\")\n\n        # Load the MolToKey object\n        state[\"mol_hasher\"] = MolToKey.from_state_dict(state[\"mol_hasher\"])\n\n        if override_args is not None:\n            state.update(override_args)\n\n        return FileCache(**state)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.__init__","title":"<code>__init__(cache_file, name=None, mol_hasher=None, n_jobs=None, verbose=False, file_type='parquet', clear_on_exit=True, parquet_kwargs=None)</code>","text":"<p>Precomputed fingerprint caching callback</p> <p>Note</p> <p>Do not pickle this object, instead use the provided saving methods.</p> <p>Parameters:</p> Name Type Description Default <code>cache_file</code> <code>Union[PathLike, str]</code> <p>Cache location. Can be a local file or a remote file</p> required <code>name</code> <code>Optional[str]</code> <p>optional name to give the cache</p> <code>None</code> <code>mol_hasher</code> <code>Optional[Union[Callable, str, MolToKey]]</code> <p>function to use to hash molecules. If not provided, <code>dm.unique_id</code> is used by default</p> <code>None</code> <code>n_jobs</code> <code>Optional[int]</code> <p>number of parallel jobs to use when performing any computation</p> <code>None</code> <code>verbose</code> <code>Union[bool, int]</code> <p>whether to print information about the cache</p> <code>False</code> <code>clear_on_exit</code> <code>bool</code> <p>whether to clear the cache on exit of the interpreter</p> <code>True</code> <code>file_type</code> <code>str</code> <p>File type that was provided. One of \"csv\", \"pickle\", \"hdf5\" and \"parquet\" For \"csv\" and \"parquet\", we expect columns \"keys\" and \"values\" For a pickle, we expect either a mapping or a dataframe with \"keys\" and \"values\" columns</p> <code>'parquet'</code> <code>parquet_kwargs</code> <code>Optional[Dict[Any, Any]]</code> <p>Argument to pass to the parquet reader.</p> <code>None</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __init__(\n    self,\n    cache_file: Union[os.PathLike, str],\n    name: Optional[str] = None,\n    mol_hasher: Optional[Union[Callable, str, MolToKey]] = None,\n    n_jobs: Optional[int] = None,\n    verbose: Union[bool, int] = False,\n    file_type: str = \"parquet\",\n    clear_on_exit: bool = True,\n    parquet_kwargs: Optional[Dict[Any, Any]] = None,\n):\n    \"\"\"Precomputed fingerprint caching callback\n\n    !!! note\n        Do not pickle this object, instead use the provided saving methods.\n\n    Args:\n        cache_file: Cache location. Can be a local file or a remote file\n        name: optional name to give the cache\n        mol_hasher: function to use to hash molecules. If not provided, `dm.unique_id` is used by default\n        n_jobs: number of parallel jobs to use when performing any computation\n        verbose: whether to print information about the cache\n        clear_on_exit: whether to clear the cache on exit of the interpreter\n        file_type: File type that was provided. One of \"csv\", \"pickle\", \"hdf5\" and \"parquet\"\n            For \"csv\" and \"parquet\", we expect columns \"keys\" and \"values\"\n            For a pickle, we expect either a mapping or a dataframe with \"keys\" and \"values\" columns\n        parquet_kwargs: Argument to pass to the parquet reader.\n    \"\"\"\n    super().__init__(name=name, mol_hasher=mol_hasher, n_jobs=n_jobs, verbose=verbose)\n\n    self.cache_file = cache_file\n    self.file_type = file_type\n    self.parquet_kwargs = parquet_kwargs or {}\n    self.clear_on_exit = clear_on_exit\n\n    if self.file_type not in FileCache.SUPPORTED_TYPES:\n        raise ValueError(\n            f\"Unsupported file type, expected one of {FileCache.SUPPORTED_TYPES}, got '{self.file_type}'\"\n        )\n\n    if self.cache_file is not None and dm.fs.exists(self.cache_file):\n        self._load_cache()\n    else:\n        self.cache = {}\n\n    if self.clear_on_exit:\n        atexit.register(self.clear)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.clear","title":"<code>clear()</code>","text":"<p>Clear cache memory at exit and close any open file Note that a cleared cache cannot be used anymore !</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def clear(self):\n    \"\"\"Clear cache memory at exit and close any open file\n    Note that a cleared cache cannot be used anymore !\n    \"\"\"\n    if self.file_type in [\"hdf5\", \"h5\"]:\n        self.cache.close()\n    else:\n        del self.cache\n    # reset cache to empty\n    self.cache = {}\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.items","title":"<code>items()</code>","text":"<p>Return iterator of key, values in the cache</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def items(self):\n    \"\"\"Return iterator of key, values in the cache\"\"\"\n    if self.file_type in [\"hdf5\", \"h5\"]:\n        return ((k, np.asarray(v)) for k, v in self.cache.items())\n    return super().items()\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.load_from_file","title":"<code>load_from_file(filepath, **kwargs)</code>  <code>classmethod</code>","text":"<p>Load a FileCache from a file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[PathLike, str]</code> <p>path to the file to load</p> required <code>kwargs</code> <p>keyword arguments to pass to the constructor</p> <code>{}</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>@classmethod\ndef load_from_file(cls, filepath: Union[os.PathLike, str], **kwargs):\n    \"\"\"Load a FileCache from a file\n\n    Args:\n        filepath: path to the file to load\n        kwargs: keyword arguments to pass to the constructor\n    \"\"\"\n    new_cache = cls(cache_file=filepath, **kwargs)\n    return new_cache\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.save_to_file","title":"<code>save_to_file(filepath=None, file_type=None, **kwargs)</code>","text":"<p>Save the cache to a file</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Optional[Union[PathLike, str]]</code> <p>path to the file to save. If None, the cache is saved to the original file.</p> <code>None</code> <code>file_type</code> <code>Optional[str]</code> <p>format used to save the cache to file one of \"pickle\", \"csv\", \"hdf5\", \"parquet\". If None, the original file type is used.</p> <code>None</code> <code>kwargs</code> <p>keyword arguments to pass to the serializer to disk (e.g to pass to pd.to_csv or pd.to_parquet)</p> <code>{}</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def save_to_file(\n    self,\n    filepath: Optional[Union[os.PathLike, str]] = None,\n    file_type: Optional[str] = None,\n    **kwargs,\n):\n    \"\"\"Save the cache to a file\n\n    Args:\n        filepath: path to the file to save. If None, the cache is saved to the original file.\n        file_type: format used to save the cache to file one of \"pickle\", \"csv\", \"hdf5\", \"parquet\".\n            If None, the original file type is used.\n        kwargs: keyword arguments to pass to the serializer to disk (e.g to pass to pd.to_csv or pd.to_parquet)\n    \"\"\"\n\n    if filepath is None:\n        filepath = self.cache_file\n\n    if file_type is None:\n        file_type = self.file_type\n\n    if file_type in [\"pkl\", \"pickle\"]:\n        with fsspec.open(filepath, \"wb\") as f:\n            joblib.dump(self.to_dict(), f)\n\n    elif file_type in [\"csv\", \"parquet\", \"pq\"]:\n        df = self.to_dataframe(pack_bits=(file_type == \"csv\"))\n\n        if file_type == \"csv\":\n            with fsspec.open(filepath, \"w\") as f:\n                df.to_csv(f, index=False, **kwargs)\n        else:\n            df.to_parquet(filepath, index=False, **kwargs)\n\n    elif file_type in [\"hdf5\", \"h5\"]:\n        with fsspec.open(filepath, \"wb\") as IN:\n            with h5py.File(IN, \"w\") as f:\n                for k, v in self.items():\n                    f.create_dataset(k, data=v)\n    else:\n        raise ValueError(\"Unsupported output protocol: {}\".format(file_type))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.to_dataframe","title":"<code>to_dataframe(pack_bits=False)</code>","text":"<p>Convert the cache to a dataframe. The converted dataframe would have <code>keys</code> and <code>values</code> columns</p> <p>Parameters:</p> Name Type Description Default <code>pack_bits</code> <code>bool</code> <p>whether to pack the values columns into bits. By using molfeat.utils.commons.unpack_bits, the values column can be reloaded as an array</p> <code>False</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def to_dataframe(self, pack_bits: bool = False):\n    \"\"\"Convert the cache to a dataframe. The converted dataframe would have `keys` and `values` columns\n\n    Args:\n        pack_bits: whether to pack the values columns into bits.\n            By using molfeat.utils.commons.unpack_bits, the values column can be reloaded as an array\n    \"\"\"\n    if pack_bits:\n        loaded_items = [\n            (k, commons.pack_bits(x, protocol=self._PICKLE_PROTOCOL)) for k, x in self.items()\n        ]\n    else:\n        loaded_items = self.items()\n    df = pd.DataFrame(loaded_items, columns=[\"keys\", \"values\"])\n    return df\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.to_state_dict","title":"<code>to_state_dict(save_to_file=True)</code>","text":"<p>Serialize the cache to a state dict.</p> <p>Parameters:</p> Name Type Description Default <code>save_to_file</code> <code>bool</code> <p>whether to save the cache to file.</p> <code>True</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def to_state_dict(self, save_to_file: bool = True) -&gt; dict:\n    \"\"\"Serialize the cache to a state dict.\n\n    Args:\n        save_to_file: whether to save the cache to file.\n    \"\"\"\n\n    if save_to_file is True:\n        self.save_to_file()\n\n    state = {}\n    state[\"_cache_name\"] = \"FileCache\"\n    state[\"cache_file\"] = self.cache_file\n    state[\"name\"] = self.name\n    state[\"n_jobs\"] = self.n_jobs\n    state[\"verbose\"] = self.verbose\n    state[\"file_type\"] = self.file_type\n    state[\"clear_on_exit\"] = self.clear_on_exit\n    state[\"parquet_kwargs\"] = self.parquet_kwargs\n    state[\"mol_hasher\"] = self.mol_hasher.to_state_dict()\n\n    return state\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.FileCache.update","title":"<code>update(new_cache)</code>","text":"<p>Update the cache with new values</p> <p>Parameters:</p> Name Type Description Default <code>new_cache</code> <code>Mapping[Any, Any]</code> <p>new cache with items to use to update current cache</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>def update(self, new_cache: Mapping[Any, Any]):\n    \"\"\"Update the cache with new values\n\n    Args:\n        new_cache: new cache with items to use to update current cache\n    \"\"\"\n    for k, v in new_cache.items():\n        key = self.mol_hasher(k)\n        if self.file_type in [\"hdf5\", \"h5\"]:\n            self.cache.create_dataset(key, data=v)\n        else:\n            self.cache[key] = v\n    return self\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MPDataCache","title":"<code>MPDataCache</code>","text":"<p>               Bases: <code>DataCache</code></p> <p>A datacache that supports multiprocessing natively</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>class MPDataCache(DataCache):\n    \"\"\"A datacache that supports multiprocessing natively\"\"\"\n\n    def __init__(\n        self,\n        name: Optional[str] = None,\n        n_jobs: int = -1,\n        mol_hasher: Optional[Union[Callable, str, MolToKey]] = None,\n        verbose: Union[bool, int] = False,\n        clear_on_exit: bool = False,\n    ):\n        \"\"\"Multiprocessing datacache that save cache into a shared memory\n\n        Args:\n            name: name of the cache\n            n_jobs: number of parallel jobs to use when performing any computation\n            mol_hasher: function to use to hash molecules. If not provided, `dm.unique_id`` is used by default\n            verbose: whether to print progress. Default to False\n            clear_on_exit: Whether to clear the cache on exit. Default is False to allow sharing the cache content\n        \"\"\"\n        super().__init__(\n            name=name,\n            n_jobs=n_jobs,\n            mol_hasher=mol_hasher,\n            cache_file=None,\n            verbose=verbose,\n            delete_on_exit=False,\n            clear_on_exit=clear_on_exit,\n        )\n\n    def _initialize_cache(self):\n        \"\"\"Initialize empty cache using a shared dict\"\"\"\n        manager = mp.Manager()  # this might not be a great idea to initialize everytime...\n        self.cache = manager.dict()\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MPDataCache.__init__","title":"<code>__init__(name=None, n_jobs=-1, mol_hasher=None, verbose=False, clear_on_exit=False)</code>","text":"<p>Multiprocessing datacache that save cache into a shared memory</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>Optional[str]</code> <p>name of the cache</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>number of parallel jobs to use when performing any computation</p> <code>-1</code> <code>mol_hasher</code> <code>Optional[Union[Callable, str, MolToKey]]</code> <p>function to use to hash molecules. If not provided, `dm.unique_id`` is used by default</p> <code>None</code> <code>verbose</code> <code>Union[bool, int]</code> <p>whether to print progress. Default to False</p> <code>False</code> <code>clear_on_exit</code> <code>bool</code> <p>Whether to clear the cache on exit. Default is False to allow sharing the cache content</p> <code>False</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __init__(\n    self,\n    name: Optional[str] = None,\n    n_jobs: int = -1,\n    mol_hasher: Optional[Union[Callable, str, MolToKey]] = None,\n    verbose: Union[bool, int] = False,\n    clear_on_exit: bool = False,\n):\n    \"\"\"Multiprocessing datacache that save cache into a shared memory\n\n    Args:\n        name: name of the cache\n        n_jobs: number of parallel jobs to use when performing any computation\n        mol_hasher: function to use to hash molecules. If not provided, `dm.unique_id`` is used by default\n        verbose: whether to print progress. Default to False\n        clear_on_exit: Whether to clear the cache on exit. Default is False to allow sharing the cache content\n    \"\"\"\n    super().__init__(\n        name=name,\n        n_jobs=n_jobs,\n        mol_hasher=mol_hasher,\n        cache_file=None,\n        verbose=verbose,\n        delete_on_exit=False,\n        clear_on_exit=clear_on_exit,\n    )\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MolToKey","title":"<code>MolToKey</code>","text":"<p>Convert a molecule to a key</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>class MolToKey:\n    \"\"\"Convert a molecule to a key\"\"\"\n\n    SUPPORTED_HASH_FN = {\n        \"dm.unique_id\": dm.unique_id,\n        \"dm.to_inchikey\": dm.to_inchikey,\n    }\n\n    def __init__(self, hash_fn: Optional[Union[Callable, str]] = \"dm.unique_id\"):\n        \"\"\"Init function for molecular key generator.\n\n        Args:\n            hash_fn: hash function to use for the molecular key\n        \"\"\"\n\n        if isinstance(hash_fn, str):\n            if hash_fn not in self.SUPPORTED_HASH_FN:\n                raise ValueError(\n                    f\"Hash function {hash_fn} is not supported. \"\n                    f\"Supported hash functions are: {self.SUPPORTED_HASH_FN.keys()}\"\n                )\n\n            self.hash_name = hash_fn\n            self.hash_fn = self.SUPPORTED_HASH_FN[hash_fn]\n\n        else:\n            self.hash_fn = hash_fn\n            self.hash_name = None\n\n            if self.hash_fn is None:\n                self.hash_fn = dm.unique_id\n                self.hash_name = \"dm.unique_id\"\n\n    def __call__(self, mol: dm.Mol):\n        \"\"\"Convert a molecule object to a key that can be used for the cache system\n\n        Args:\n            mol: input molecule object\n        \"\"\"\n        with dm.without_rdkit_log():\n            is_mol = dm.to_mol(mol) is not None\n            if is_mol and self.hash_fn is not None:\n                return self.hash_fn(mol)\n        return mol\n\n    def to_state_dict(self):\n        \"\"\"Serialize MolToKey to a state dict.\"\"\"\n\n        if self.hash_name is None:\n            raise ValueError(\n                \"The hash function has been provided as a function and not a string. \"\n                \"So it's impossible to save the state. You must specifiy the hash function as a string instead.\"\n            )\n\n        state = {}\n        state[\"hash_name\"] = self.hash_name\n        return state\n\n    @staticmethod\n    def from_state_dict(state: dict) -&gt; \"MolToKey\":\n        \"\"\"Load a MolToKey object from a state dict.\"\"\"\n        return MolToKey(hash_fn=state[\"hash_name\"])\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MolToKey.__call__","title":"<code>__call__(mol)</code>","text":"<p>Convert a molecule object to a key that can be used for the cache system</p> <p>Parameters:</p> Name Type Description Default <code>mol</code> <code>Mol</code> <p>input molecule object</p> required Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __call__(self, mol: dm.Mol):\n    \"\"\"Convert a molecule object to a key that can be used for the cache system\n\n    Args:\n        mol: input molecule object\n    \"\"\"\n    with dm.without_rdkit_log():\n        is_mol = dm.to_mol(mol) is not None\n        if is_mol and self.hash_fn is not None:\n            return self.hash_fn(mol)\n    return mol\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MolToKey.__init__","title":"<code>__init__(hash_fn='dm.unique_id')</code>","text":"<p>Init function for molecular key generator.</p> <p>Parameters:</p> Name Type Description Default <code>hash_fn</code> <code>Optional[Union[Callable, str]]</code> <p>hash function to use for the molecular key</p> <code>'dm.unique_id'</code> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def __init__(self, hash_fn: Optional[Union[Callable, str]] = \"dm.unique_id\"):\n    \"\"\"Init function for molecular key generator.\n\n    Args:\n        hash_fn: hash function to use for the molecular key\n    \"\"\"\n\n    if isinstance(hash_fn, str):\n        if hash_fn not in self.SUPPORTED_HASH_FN:\n            raise ValueError(\n                f\"Hash function {hash_fn} is not supported. \"\n                f\"Supported hash functions are: {self.SUPPORTED_HASH_FN.keys()}\"\n            )\n\n        self.hash_name = hash_fn\n        self.hash_fn = self.SUPPORTED_HASH_FN[hash_fn]\n\n    else:\n        self.hash_fn = hash_fn\n        self.hash_name = None\n\n        if self.hash_fn is None:\n            self.hash_fn = dm.unique_id\n            self.hash_name = \"dm.unique_id\"\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MolToKey.from_state_dict","title":"<code>from_state_dict(state)</code>  <code>staticmethod</code>","text":"<p>Load a MolToKey object from a state dict.</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>@staticmethod\ndef from_state_dict(state: dict) -&gt; \"MolToKey\":\n    \"\"\"Load a MolToKey object from a state dict.\"\"\"\n    return MolToKey(hash_fn=state[\"hash_name\"])\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.cache.MolToKey.to_state_dict","title":"<code>to_state_dict()</code>","text":"<p>Serialize MolToKey to a state dict.</p> Source code in <code>molfeat/utils/cache.py</code> <pre><code>def to_state_dict(self):\n    \"\"\"Serialize MolToKey to a state dict.\"\"\"\n\n    if self.hash_name is None:\n        raise ValueError(\n            \"The hash function has been provided as a function and not a string. \"\n            \"So it's impossible to save the state. You must specifiy the hash function as a string instead.\"\n        )\n\n    state = {}\n    state[\"hash_name\"] = self.hash_name\n    return state\n</code></pre>"},{"location":"api/molfeat.utils.html#common-utils","title":"Common utils","text":"<p>Common utility functions</p>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.align_conformers","title":"<code>align_conformers(mols, ref_id=0, copy=True, conformer_id=-1)</code>","text":"<p>Align a list of molecules to a reference molecule.</p> <p>Note: consider adding me to <code>datamol</code>.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>List[Mol]</code> <p>List of molecules to align. All the molecules must have a conformer.</p> required <code>ref_id</code> <code>int</code> <p>Index of the reference molecule. By default, the first molecule in the list will be used as reference.</p> <code>0</code> <code>copy</code> <code>bool</code> <p>Whether to copy the molecules before performing the alignement.</p> <code>True</code> <code>conformer_id</code> <code>int</code> <p>Conformer id to use.</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>mols</code> <p>The aligned molecules.</p> <code>scores</code> <p>The score of the alignement.</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def align_conformers(\n    mols: List[dm.Mol],\n    ref_id: int = 0,\n    copy: bool = True,\n    conformer_id: int = -1,\n):\n    \"\"\"Align a list of molecules to a reference molecule.\n\n    Note: consider adding me to `datamol`.\n\n    Args:\n        mols: List of molecules to align. All the molecules must have a conformer.\n        ref_id: Index of the reference molecule. By default, the first molecule in the list\n            will be used as reference.\n        copy: Whether to copy the molecules before performing the alignement.\n        conformer_id: Conformer id to use.\n\n    Returns:\n        mols: The aligned molecules.\n        scores: The score of the alignement.\n    \"\"\"\n\n    # Check all input molecules has a conformer\n    if not all([mol.GetNumConformers() &gt;= 1 for mol in mols]):\n        raise ValueError(\"One or more input molecules is missing a conformer.\")\n\n    # Make a copy of the molecules since they are going to be modified\n    if copy:\n        mols = [dm.copy_mol(mol) for mol in mols]\n\n    # Compute Crippen contributions for every atoms and molecules\n    crippen_contribs = [rdMolDescriptors._CalcCrippenContribs(mol) for mol in mols]\n\n    # Split reference and probe molecules\n    crippen_contrib_ref = crippen_contribs[ref_id]\n    crippen_contrib_probes = crippen_contribs\n    mol_ref = mols[ref_id]\n    mol_probes = mols\n\n    # Loop and align\n    scores = []\n    for i, mol in enumerate(mol_probes):\n        crippenO3A = rdMolAlign.GetCrippenO3A(\n            prbMol=mol,\n            refMol=mol_ref,\n            prbCrippenContribs=crippen_contrib_probes[i],\n            refCrippenContribs=crippen_contrib_ref,\n            prbCid=conformer_id,\n            refCid=conformer_id,\n            maxIters=50,\n        )\n        crippenO3A.Align()\n\n        scores.append(crippenO3A.Score())\n\n    scores = np.array(scores)\n\n    return mols, scores\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.concat_dict","title":"<code>concat_dict(prop_dict, new_name, order=None)</code>","text":"<p>Concat properties in dict into a single key dict</p> <p>Parameters:</p> Name Type Description Default <code>prop_dict</code> <code>dict</code> <p>Input dict of property names and their computed values</p> required <code>new_name</code> <code>str</code> <p>new name under which the concatenated property dict will be returned</p> required <code>order</code> <code>Optional[Iterable[str]]</code> <p>Optional list of key that specifies the order in which concatenation should be done. Sorting list by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>dictionary of concatenated output values with a single key corresponding to new_name</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def concat_dict(prop_dict: dict, new_name: str, order: Optional[Iterable[str]] = None):\n    \"\"\"Concat properties in dict into a single key dict\n\n    Args:\n        prop_dict (dict): Input dict of property names and their computed values\n        new_name (str): new name under which the concatenated property dict will be returned\n        order: Optional list of key that specifies the order in which concatenation should be done. Sorting list by default\n\n    Returns:\n        dict: dictionary of concatenated output values with a single key corresponding to new_name\n    \"\"\"\n    if not order:\n        order = list(sorted(prop_dict.keys()))\n\n    if len(order) &gt; 0:\n        concatenated_val = np.concatenate([prop_dict[x] for x in order], axis=1)\n        output_dict = {new_name: concatenated_val}\n    return output_dict\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.ensure_picklable","title":"<code>ensure_picklable(fn)</code>","text":"<p>Ensure a function is picklable</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>function to be pickled</p> required Source code in <code>molfeat/utils/commons.py</code> <pre><code>def ensure_picklable(fn: Callable):\n    \"\"\"Ensure a function is picklable\n\n    Args:\n        fn: function to be pickled\n    \"\"\"\n    if inspect.isfunction(fn) and fn.__name__ == \"&lt;lambda&gt;\":\n        return wrap_non_picklable_objects(fn)\n    return fn\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.filter_arguments","title":"<code>filter_arguments(fn, params)</code>","text":"<p>Filter the argument of a function to only retain the valid ones</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>Function for which arguments will be checked</p> required <code>params</code> <code>dict</code> <p>key-val dictionary of arguments to pass to the input function</p> required <p>Returns:</p> Name Type Description <code>params_filtered</code> <code>dict</code> <p>dict of filtered arguments for the function</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def filter_arguments(fn: Callable, params: dict):\n    \"\"\"Filter the argument of a function to only retain the valid ones\n\n    Args:\n        fn: Function for which arguments will be checked\n        params: key-val dictionary of arguments to pass to the input function\n\n    Returns:\n        params_filtered (dict): dict of filtered arguments for the function\n    \"\"\"\n    accepted_dict = inspect.signature(fn).parameters\n    accepted_list = []\n    for key in accepted_dict.keys():\n        param = str(accepted_dict[key])\n        if param[0] != \"*\":\n            accepted_list.append(param)\n    params_filtered = {key: params[key] for key in list(set(accepted_list) &amp; set(params.keys()))}\n    return params_filtered\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.fn_to_hex","title":"<code>fn_to_hex(fn)</code>","text":"<p>Pickle an object and return its hex representation</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <p>object to pickle</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>hex representation of object</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def fn_to_hex(fn):\n    \"\"\"Pickle an object and return its hex representation\n\n    Args:\n        fn: object to pickle\n\n    Returns:\n        str: hex representation of object\n    \"\"\"\n    bytes_str = pickle.dumps(ensure_picklable(fn))\n    return bytes_str.hex()\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.fold_count_fp","title":"<code>fold_count_fp(fp, dim=2 ** 10, binary=False)</code>","text":"<p>Fast folding of a count fingerprint to the specified dimension</p> <p>Parameters:</p> Name Type Description Default <code>fp</code> <code>Iterable</code> <p>iterable fingerprint</p> required <code>dim</code> <code>int</code> <p>dimension of the folded array if not provided. Defaults to 2**10.</p> <code>2 ** 10</code> <code>binary</code> <code>bool</code> <p>whether to fold into a binary array or take use a count vector</p> <code>False</code> <p>Returns:</p> Name Type Description <code>folded</code> <p>returns folded array to the provided dimension</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def fold_count_fp(fp: Iterable, dim: int = 2**10, binary: bool = False):\n    \"\"\"Fast folding of a count fingerprint to the specified dimension\n\n    Args:\n        fp: iterable fingerprint\n        dim: dimension of the folded array if not provided. Defaults to 2**10.\n        binary: whether to fold into a binary array or take use a count vector\n\n    Returns:\n        folded: returns folded array to the provided dimension\n    \"\"\"\n    if hasattr(fp, \"GetNonzeroElements\"):\n        tmp = fp.GetNonzeroElements()\n    elif hasattr(fp, \"GetOnBits\"):\n        # try to get the dict of onbit\n        on_bits = fp.GetOnBits()\n        tmp = dict(zip(on_bits, np.ones(len(on_bits))))\n    else:\n        raise ValueError(f\"Format {type(fp)} is not supported\")\n    out = (\n        coo_matrix(\n            (\n                list(tmp.values()),\n                (np.repeat(0, len(tmp)), [i % dim for i in tmp.keys()]),\n            ),\n            shape=(1, dim),\n        )\n        .toarray()\n        .flatten()\n    )\n    if binary:\n        out = np.clip(out, a_min=0, a_max=1)\n    return out\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.get_class_name","title":"<code>get_class_name(cls)</code>","text":"<p>Get class full name</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type</code> <p>name of the class</p> required Source code in <code>molfeat/utils/commons.py</code> <pre><code>def get_class_name(cls: Type):\n    \"\"\"Get class full name\n\n    Args:\n        cls: name of the class\n    \"\"\"\n    module = cls.__module__\n    name = cls.__qualname__\n    if module is not None and module != \"__builtin__\":\n        name = module + \".\" + name\n    return name\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.hex_to_fn","title":"<code>hex_to_fn(hex)</code>","text":"<p>Load a hex string as a callable. Raise error on fail</p> <p>Parameters:</p> Name Type Description Default <code>hex</code> <code>str</code> <p>hex string to load as a callable</p> required <p>Returns:</p> Name Type Description <code>callable</code> <p>callable loaded from the hex string</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def hex_to_fn(hex: str):\n    \"\"\"Load a hex string as a callable. Raise error on fail\n\n    Args:\n        hex: hex string to load as a callable\n\n    Returns:\n        callable: callable loaded from the hex string\n    \"\"\"\n    # EN: pickling with pickle is probably faster\n    fn = pickle.loads(bytes.fromhex(hex))\n    return fn\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.is_callable","title":"<code>is_callable(func)</code>","text":"<p>Check if func is a function or a callable</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def is_callable(func):\n    r\"\"\"\n    Check if func is a function or a callable\n    \"\"\"\n    return func and (isinstance(func, FUNCTYPES) or callable(func))\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.one_hot_encoding","title":"<code>one_hot_encoding(val, allowable_set, encode_unknown=False, dtype=int)</code>","text":"<p>Converts a single value to a one-hot vector.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>int</code> <p>class to be converted into a one hot vector</p> required <code>allowable_set</code> <code>Iterable</code> <p>a list or 1D array of allowed choices for val to take</p> required <code>dtype</code> <code>Callable</code> <p>data type of the the return. Default = int.</p> <code>int</code> <code>encode_unknown</code> <code>bool</code> <p>whether to map inputs not in allowable set to an additional last element.</p> <code>False</code> <p>Returns:</p> Type Description <p>A numpy 1D array of length len(allowable_set) + 1</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def one_hot_encoding(\n    val: int,\n    allowable_set: Iterable,\n    encode_unknown: bool = False,\n    dtype: Callable = int,\n):\n    r\"\"\"Converts a single value to a one-hot vector.\n\n    Args:\n        val: class to be converted into a one hot vector\n        allowable_set: a list or 1D array of allowed choices for val to take\n        dtype: data type of the the return. Default = int.\n        encode_unknown: whether to map inputs not in allowable set to an additional last element.\n\n    Returns:\n        A numpy 1D array of length len(allowable_set) + 1\n    \"\"\"\n\n    encoding = np.zeros(len(allowable_set) + int(encode_unknown), dtype=dtype)\n    # not using index of, in case, someone fuck up\n    # and there are duplicates in the allowed choices\n    for i, v in enumerate(allowable_set):\n        if v == val:\n            encoding[i] = 1\n    if np.sum(encoding) == 0 and encode_unknown:  # aka not found\n        encoding[-1] = 1\n    return encoding\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.pack_bits","title":"<code>pack_bits(obj, protocol=4)</code>","text":"<p>Pack an object into a bits representation</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <p>object to pack</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <p>byte-packed version of object</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def pack_bits(obj, protocol=4):\n    \"\"\"Pack an object into a bits representation\n\n    Args:\n        obj: object to pack\n\n    Returns:\n        bytes: byte-packed version of object\n    \"\"\"\n    return pickle.dumps(obj, protocol=protocol)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.pack_graph","title":"<code>pack_graph(batch_G, batch_x)</code>","text":"<p>Pack a batch of graph and atom features into a single graph</p> <p>Parameters:</p> Name Type Description Default <code>batch_G</code> <code>List[FloatTensor]</code> <p>List of adjacency graph, each of size (n_i, n_i).</p> required <code>batch_x</code> <code>List[FloatTensor]</code> <p>List of atom feature matrices, each of size (n_i, F), F being the number of features</p> required <p>Returns:</p> Type Description <p>new_batch_G, new_batch_x: torch.LongTensor 2D, torch.Tensor 2D This tuple represents a new arbitrary graph that contains the whole batch, and the corresponding atom feature matrix. new_batch_G has a size (N, N), with :math:<code>N = \\sum_i n_i</code>, while new_batch_x has size (N,D)</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def pack_graph(\n    batch_G: List[torch.FloatTensor],\n    batch_x: List[torch.FloatTensor],\n):\n    r\"\"\"\n    Pack a batch of graph and atom features into a single graph\n\n    Args:\n        batch_G: List of adjacency graph, each of size (n_i, n_i).\n        batch_x: List of atom feature matrices, each of size (n_i, F), F being the number of features\n\n    Returns:\n        new_batch_G, new_batch_x: torch.LongTensor 2D, torch.Tensor 2D\n            This tuple represents a new arbitrary graph that contains the whole batch,\n            and the corresponding atom feature matrix. new_batch_G has a size (N, N), with :math:`N = \\sum_i n_i`,\n            while new_batch_x has size (N,D)\n    \"\"\"\n\n    new_batch_x = torch.cat(tuple(batch_x), dim=0)\n    n_neigb = new_batch_x.shape[0]\n    # should be on the same device\n    new_batch_G = batch_G[0].new_zeros((n_neigb, n_neigb))\n    cur_ind = 0\n    for g in batch_G:\n        g_size = g.shape[0] + cur_ind\n        new_batch_G[cur_ind:g_size, cur_ind:g_size] = g\n        cur_ind = g_size\n    return new_batch_G, new_batch_x\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.requires_conformer","title":"<code>requires_conformer(calculator)</code>","text":"<p>Decorator for any descriptor calculator that requires conformers</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def requires_conformer(calculator: Callable):\n    \"\"\"Decorator for any descriptor calculator that requires conformers\"\"\"\n\n    # this is a method or __call__\n    if inspect.getfullargspec(calculator).args[0] == \"self\":\n\n        @functools.wraps(calculator)\n        def calculator_wrapper(ref, mol, *args, **kwargs):\n            mol = dm.to_mol(mol)\n            if mol.GetNumConformers() &lt; 1:\n                raise ValueError(\"Expected a molecule with conformers information.\")\n            return calculator(ref, mol, *args, **kwargs)\n\n    else:\n\n        @functools.wraps(calculator)\n        def calculator_wrapper(mol, *args, **kwargs):\n            mol = dm.to_mol(mol)\n            if mol.GetNumConformers() &lt; 1:\n                raise ValueError(\"Expected a molecule with conformers information.\")\n            return calculator(mol, *args, **kwargs)\n\n    return calculator_wrapper\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.requires_standardization","title":"<code>requires_standardization(calculator=None, *, disconnect_metals=True, remove_salt=True, **standardize_kwargs)</code>","text":"<p>Decorator for any descriptor calculator that required standardization of the molecules Args:     calculator: calculator to wrap     disconnect_metals: whether to force metal disconnection     remove_salt: whether to remove salt from the molecule</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def requires_standardization(\n    calculator: Callable = None,\n    *,\n    disconnect_metals: bool = True,\n    remove_salt: bool = True,\n    **standardize_kwargs,\n):\n    \"\"\"Decorator for any descriptor calculator that required standardization of the molecules\n    Args:\n        calculator: calculator to wrap\n        disconnect_metals: whether to force metal disconnection\n        remove_salt: whether to remove salt from the molecule\n    \"\"\"\n\n    def _standardize_mol(calculator):\n        @functools.wraps(calculator)\n        def wrapped_function(mol, *args, **kwargs):\n            mol = _clean_mol_for_descriptors(\n                mol,\n                disconnect_metals=disconnect_metals,\n                remove_salt=remove_salt,\n                **standardize_kwargs,\n            )\n            return calculator(mol, *args, **kwargs)\n\n        @functools.wraps(calculator)\n        def class_wrapped_function(ref, mol, *args, **kwargs):\n            if not getattr(ref, \"do_not_standardize\", False):\n                mol = _clean_mol_for_descriptors(\n                    mol,\n                    disconnect_metals=disconnect_metals,\n                    remove_salt=remove_salt,\n                    **standardize_kwargs,\n                )\n            return calculator(ref, mol, *args, **kwargs)\n\n        if inspect.getfullargspec(calculator).args[0] == \"self\":\n            return class_wrapped_function\n        return wrapped_function\n\n    if calculator is not None:\n        return _standardize_mol(calculator)\n    return _standardize_mol\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.sha256sum","title":"<code>sha256sum(filepath)</code>","text":"<p>Return the sha256 sum hash of a file or a directory</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>Union[str, PathLike]</code> <p>The path to the file to compute the MD5 hash on.</p> required Source code in <code>molfeat/utils/commons.py</code> <pre><code>def sha256sum(filepath: Union[str, os.PathLike]):\n    \"\"\"Return the sha256 sum hash of a file or a directory\n\n    Args:\n        filepath: The path to the file to compute the MD5 hash on.\n    \"\"\"\n    if dm.fs.is_dir(filepath):\n        files = list(dm.fs.glob(os.path.join(filepath, \"**\", \"*\")))\n    else:\n        files = [filepath]\n    file_hash = hashlib.sha256()\n    for filepath in sorted(files):\n        with fsspec.open(filepath) as f:\n            file_hash.update(f.read())  # type: ignore\n    file_hash = file_hash.hexdigest()\n    return file_hash\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.commons.unpack_bits","title":"<code>unpack_bits(bvalues)</code>","text":"<p>Pack an object into a bits representation</p> <p>Parameters:</p> Name Type Description Default <code>bvalues</code> <p>bytes to be unpacked</p> required <p>Returns:</p> Name Type Description <code>obj</code> <p>object that was packed</p> Source code in <code>molfeat/utils/commons.py</code> <pre><code>def unpack_bits(bvalues):\n    \"\"\"Pack an object into a bits representation\n\n    Args:\n        bvalues: bytes to be unpacked\n\n    Returns:\n        obj: object that was packed\n    \"\"\"\n    return pickle.loads(bvalues)\n</code></pre>"},{"location":"api/molfeat.utils.html#require-module","title":"Require module","text":""},{"location":"api/molfeat.utils.html#molfeat.utils.requires.check","title":"<code>check(module, min_version=None, max_version=None)</code>  <code>cached</code>","text":"<p>Check if module is available for import</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>name of the module to check</p> required <code>min_version</code> <code>Optional[str]</code> <p>optional minimum version string to check</p> <code>None</code> <code>max_version</code> <code>Optional[str]</code> <p>optional maximum version string to check</p> <code>None</code> Source code in <code>molfeat/utils/requires.py</code> <pre><code>@functools.lru_cache()\ndef check(module: str, min_version: Optional[str] = None, max_version: Optional[str] = None):\n    \"\"\"Check if module is available for import\n\n    Args:\n        module: name of the module to check\n        min_version: optional minimum version string to check\n        max_version: optional maximum version string to check\n    \"\"\"\n    imported_module = None\n    version = None\n    min_version = pkg_version.parse(min_version) if min_version is not None else None\n    max_version = pkg_version.parse(max_version) if max_version is not None else None\n    try:\n        imported_module = importlib.import_module(module)\n        version = getattr(imported_module, \"__version__\", None)\n    except ImportError:\n        return False\n    if version is not None:\n        try:\n            version = pkg_version.parse(version)\n        except pkg_version.InvalidVersion:\n            # EN: packaging v22 removed LegacyVersion which has consequences\n            version = None\n    return version is None or (\n        (min_version is None or version &gt;= min_version)\n        and (max_version is None or version &lt;= max_version)\n    )\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.requires.mock","title":"<code>mock(name)</code>","text":"<p>Mock a function to raise an error</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the module or function to mock</p> required Source code in <code>molfeat/utils/requires.py</code> <pre><code>def mock(name: str):\n    \"\"\"Mock a function to raise an error\n\n    Args:\n        name: name of the module or function to mock\n\n    \"\"\"\n    return lambda: (_ for _ in ()).throw(Exception(f\"{name} is not available\"))\n</code></pre>"},{"location":"api/molfeat.utils.html#datatype-conversion","title":"Datatype Conversion","text":""},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.as_numpy_array_if_possible","title":"<code>as_numpy_array_if_possible(arr, dtype)</code>","text":"<p>Convert an input array to a numpy datatype if possible Args:     arr: input array     dtype: optional numpy datatype</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def as_numpy_array_if_possible(arr, dtype: Optional[None]):\n    \"\"\"Convert an input array to a numpy datatype if possible\n    Args:\n        arr: input array\n        dtype: optional numpy datatype\n    \"\"\"\n    with suppress(Exception):\n        # we only consider auto casting to numpu\n        # when the user requests 'a numpy datatype'.\n        if (dtype is not None and is_dtype_numpy(dtype)) or (\n            dtype in [pd.DataFrame, \"dataframe\", \"pandas\", \"df\"]\n        ):\n            # skip any non compatible type\n            # meaning it should be a list of list or a list of numpy array or a 2D numpy array.\n            if (\n                isinstance(arr, (list, np.ndarray))\n                and isinstance(arr[0], (np.ndarray, list))\n                and np.isscalar(arr[0][0])\n            ):\n                return sk_utils.check_array(\n                    arr, accept_sparse=True, force_all_finite=False, ensure_2d=False, allow_nd=True\n                )\n    return arr\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.cast","title":"<code>cast(fp, dtype=None, columns=None)</code>","text":"<p>Change the datatype of a list of input array</p> <p>Parameters:</p> Name Type Description Default <code>fp</code> <code>array</code> <p>Input array to cast (2D)</p> required <code>dtype</code> <code>Optional[Callable]</code> <p>datatype to cast to</p> <code>None</code> <code>columns</code> <code>Optional[Iterable]</code> <p>column names for pandas dataframe</p> <code>None</code> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def cast(fp, dtype: Optional[Callable] = None, columns: Optional[Iterable] = None):\n    \"\"\"Change the datatype of a list of input array\n\n    Args:\n        fp (array): Input array to cast (2D)\n        dtype: datatype to cast to\n        columns: column names for pandas dataframe\n    \"\"\"\n    if fp is None or dtype is None:\n        return fp\n    if isinstance(fp, dict):\n        fp = {k: cast(v, dtype=dtype, columns=columns) for k, v in fp.items()}\n    elif dtype in [tuple, list]:\n        fp = list(fp)\n    elif is_dtype_numpy(dtype):\n        if isinstance(fp, (list, tuple)) and not np.isscalar(fp[0]):\n            fp = [to_numpy(fp_i, dtype=dtype) for fp_i in fp]\n            fp = to_numpy(fp, dtype=dtype)\n        else:\n            fp = to_numpy(fp, dtype=dtype)\n    elif is_dtype_tensor(dtype):\n        if isinstance(fp, (list, tuple)) and not np.isscalar(fp[0]):\n            tmp_fp = to_numpy(fp[0])\n            if len(tmp_fp.shape) &gt; 1:\n                fp = torch.cat([to_tensor(fp_i, dtype=dtype) for fp_i in fp])\n            else:\n                fp = torch.stack([to_tensor(fp_i, dtype=dtype) for fp_i in fp])\n        else:\n            fp = to_tensor(fp, dtype=dtype)\n    elif dtype in [pd.DataFrame, \"dataframe\", \"pandas\", \"df\"]:\n        fp = [feat if feat is not None else [] for feat in fp]\n        fp = pd.DataFrame(fp)\n        if columns is not None:\n            fp.columns = columns\n    elif is_dtype_bitvect(dtype):\n        fp = [to_fp(feat, sparse=(dtype == SparseBitVect)) for feat in fp]\n    else:\n        raise TypeError(\"The type {} is not supported\".format(dtype))\n    return fp\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.ensure_explicit","title":"<code>ensure_explicit(x)</code>","text":"<p>Ensure that the input vector is not a sparse bit vector</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[SparseBitVect, ExplicitBitVect]</code> <p>input vector</p> required <p>Returns:</p> Name Type Description <code>converted</code> <p>ExplicitBitVect if input is SparseBitVec, else input as is</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def ensure_explicit(x: Union[SparseBitVect, ExplicitBitVect]):\n    \"\"\"Ensure that the input vector is not a sparse bit vector\n\n    Args:\n        x: input vector\n\n    Returns:\n        converted: ExplicitBitVect if input is SparseBitVec, else input as is\n    \"\"\"\n    if isinstance(x, SparseBitVect):\n        x = ConvertToExplicit(x)\n    return x\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.is_dtype_bitvect","title":"<code>is_dtype_bitvect(dtype)</code>","text":"<p>Verify if the dtype is a bitvect type</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>callable</code> <p>The dtype of a value. E.g. np.int32, str, torch.float</p> required <p>Returns:</p> Type Description <p>A boolean saying if the dtype is a torch dtype</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def is_dtype_bitvect(dtype):\n    \"\"\"\n    Verify if the dtype is a bitvect type\n\n    Args:\n        dtype (callable): The dtype of a value. E.g. np.int32, str, torch.float\n\n    Returns:\n        A boolean saying if the dtype is a torch dtype\n    \"\"\"\n    return dtype in [ExplicitBitVect, SparseBitVect] or isinstance(\n        dtype, (ExplicitBitVect, SparseBitVect)\n    )\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.is_dtype_numpy","title":"<code>is_dtype_numpy(dtype)</code>","text":"<p>Verify if the dtype is a numpy dtype</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>callable</code> <p>The dtype of a value. E.g. np.int32, str, torch.float</p> required <p>Returns     A boolean saying if the dtype is a numpy dtype</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def is_dtype_numpy(dtype):\n    r\"\"\"\n    Verify if the dtype is a numpy dtype\n\n    Args:\n        dtype (callable): The dtype of a value. E.g. np.int32, str, torch.float\n    Returns\n        A boolean saying if the dtype is a numpy dtype\n    \"\"\"\n    # special case where user provides a type\n    if isinstance(dtype, str):\n        with suppress(Exception):\n            dtype = np.dtype(dtype).type\n    is_torch = is_dtype_tensor(dtype)\n    is_num = dtype in (int, float, complex)\n    if hasattr(dtype, \"__module__\"):\n        is_numpy = dtype.__module__ == \"numpy\"\n    else:\n        is_numpy = False\n    return (is_num or is_numpy) and not is_torch\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.is_dtype_tensor","title":"<code>is_dtype_tensor(dtype)</code>","text":"<p>Verify if the dtype is a torch dtype</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>callable</code> <p>The dtype of a value. E.g. np.int32, str, torch.float</p> required <p>Returns:</p> Type Description <p>A boolean saying if the dtype is a torch dtype</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def is_dtype_tensor(dtype):\n    r\"\"\"\n    Verify if the dtype is a torch dtype\n\n    Args:\n        dtype (callable): The dtype of a value. E.g. np.int32, str, torch.float\n\n    Returns:\n        A boolean saying if the dtype is a torch dtype\n    \"\"\"\n    return isinstance(dtype, torch.dtype) or (dtype == torch.Tensor)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.is_null","title":"<code>is_null(obj)</code>","text":"<p>Check if an obj is null (nan, None or array of nan)</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def is_null(obj):\n    \"\"\"Check if an obj is null (nan, None or array of nan)\"\"\"\n    array_nan = False\n    all_none = False\n    try:\n        tmp = to_numpy(obj)\n        array_nan = np.all(np.isnan(tmp))\n    except Exception:\n        pass\n    try:\n        all_none = all(x is None for x in obj)\n    except Exception:\n        pass\n    return obj is None or all_none or array_nan\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.to_fp","title":"<code>to_fp(arr, bitvect=True, sparse=False)</code>","text":"<p>Convert numpy array to fingerprint</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Numpy array to convert to bitvec</p> required <code>bitvect</code> <code>bool</code> <p>whether to assume the data is a bitvect or intvect</p> <code>True</code> <code>sparse</code> <code>bool</code> <p>whether to convert to sparse bit vect</p> <code>False</code> <p>Returns:</p> Name Type Description <code>fp</code> <p>RDKit bit vector</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def to_fp(arr: np.ndarray, bitvect: bool = True, sparse: bool = False):\n    \"\"\"Convert numpy array to fingerprint\n\n    Args:\n        arr: Numpy array to convert to bitvec\n        bitvect: whether to assume the data is a bitvect or intvect\n        sparse: whether to convert to sparse bit vect\n\n    Returns:\n        fp: RDKit bit vector\n    \"\"\"\n    if not isinstance(arr, list) and arr.ndim &gt; 1:\n        raise ValueError(\"Expect a 1D array as input !\")\n    if not bitvect:\n        fp = UIntSparseIntVect(len(arr))\n        for ix, value in enumerate(arr):\n            fp[ix] = int(value)\n    elif sparse:\n        onbits = np.where(arr == 1)[0].tolist()\n        fp = SparseBitVect(arr.shape[0])\n        fp.SetBitsFromList(onbits)\n    else:\n        arr = np.asarray(arr)\n        bitstring = \"\".join(arr.astype(str))\n        fp = CreateFromBitString(bitstring)\n    return fp\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.to_numpy","title":"<code>to_numpy(x, copy=False, dtype=None)</code>","text":"<p>Convert a tensor to numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Object</code> <p>The Python object to convert.</p> required <code>copy</code> <code>bool</code> <p>Whether to copy the memory. By default, if a tensor is already on CPU, the Numpy array will be a view of the tensor.</p> <code>False</code> <code>dtype</code> <code>callable</code> <p>Optional type to cast the values to</p> <code>None</code> <p>Returns:</p> Type Description <p>A new Python object with the same structure as <code>x</code> but where the tensors are now Numpy</p> <p>arrays. Not supported type are left as reference in the new object.</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def to_numpy(x, copy=False, dtype=None):\n    r\"\"\"\n    Convert a tensor to numpy array.\n\n    Args:\n        x (Object): The Python object to convert.\n        copy (bool, optional): Whether to copy the memory.\n            By default, if a tensor is already on CPU, the\n            Numpy array will be a view of the tensor.\n        dtype (callable, optional): Optional type to cast the values to\n\n    Returns:\n        A new Python object with the same structure as `x` but where the tensors are now Numpy\n        arrays. Not supported type are left as reference in the new object.\n    \"\"\"\n    if isinstance(x, (list, tuple, np.ndarray)) and torch.is_tensor(x[0]):\n        x = [to_numpy(xi, copy=copy, dtype=dtype) for xi in x]\n    if isinstance(x, np.ndarray):\n        pass\n    elif torch.is_tensor(x):\n        x = x.cpu().detach().numpy()\n        x = x.copy()\n    elif isinstance(x, SparseBitVect):\n        tmp = np.zeros(x.GetNumBits(), dtype=int)\n        for n_bit in list(x.GetOnBits()):\n            tmp[n_bit] = 1\n        x = tmp\n    elif isinstance(x, ExplicitBitVect):\n        x = dm.fp_to_array(x)\n    elif hasattr(x, \"GetNonzeroElements\"):\n        # one of the other rdkit type\n        tmp = np.zeros(x.GetLength())\n        bit_idx, values = np.array(list(x.GetNonzeroElements().items())).T\n        tmp[bit_idx] = values\n        x = tmp\n    else:\n        x = np.asarray(x)\n    if dtype is not None:\n        x = x.astype(dtype)\n    return x\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.to_sparse","title":"<code>to_sparse(x, dtype=None)</code>","text":"<p>Converts dense tensor x to sparse format</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>tensor to convert</p> required <code>dtype</code> <code>dtype</code> <p>Enforces new data type for the output. If None, it keeps the same datatype as x (Default: None)</p> <code>None</code> <p>Returns:     new torch.sparse Tensor</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def to_sparse(x, dtype=None):\n    r\"\"\"\n    Converts dense tensor x to sparse format\n\n    Args:\n        x (torch.Tensor): tensor to convert\n        dtype (torch.dtype, optional): Enforces new data type for the output.\n            If None, it keeps the same datatype as x (Default: None)\n    Returns:\n        new torch.sparse Tensor\n    \"\"\"\n\n    if dtype is not None:\n        x = x.type(dtype)\n\n    x_typename = torch.typename(x).split(\".\")[-1]\n    sparse_tensortype = getattr(torch.sparse, x_typename)\n\n    indices = torch.nonzero(x)\n    if len(indices.shape) == 0:  # if all elements are zeros\n        return sparse_tensortype(*x.shape)\n    indices = indices.t()\n    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n    return sparse_tensortype(indices, values, x.size())\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.datatype.to_tensor","title":"<code>to_tensor(x, gpu=False, dtype=None)</code>","text":"<p>Convert a numpy array to tensor. The tensor type will be the same as the original array, unless specify otherwise</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Numpy array to convert to tensor type</p> required <code>gpu</code> <code>bool optional</code> <p>Whether to move tensor to gpu. Default False</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>Enforces new data type for the output</p> <code>None</code> <p>Returns:</p> Type Description <p>New torch.Tensor</p> Source code in <code>molfeat/utils/datatype.py</code> <pre><code>def to_tensor(x, gpu=False, dtype=None):\n    r\"\"\"\n    Convert a numpy array to tensor. The tensor type will be\n    the same as the original array, unless specify otherwise\n\n    Args:\n        x (numpy.ndarray): Numpy array to convert to tensor type\n        gpu (bool optional): Whether to move tensor to gpu. Default False\n        dtype (torch.dtype, optional): Enforces new data type for the output\n\n    Returns:\n        New torch.Tensor\n    \"\"\"\n    if not torch.is_tensor(x):\n        try:\n            if torch.is_tensor(x[0]):\n                x = torch.stack(x)\n        except Exception:\n            pass\n        x = torch.as_tensor(x)\n    if dtype is not None:\n        x = x.to(dtype=dtype)\n    if gpu and torch.cuda.is_available():\n        x = x.cuda()\n    return x\n</code></pre>"},{"location":"api/molfeat.utils.html#pooling","title":"Pooling","text":""},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.BartPooler","title":"<code>BartPooler</code>","text":"<p>               Bases: <code>Module</code></p> <p>Default Bart pooler as implemented in huggingface transformers The Bart pooling function focusing on the eos token ([EOS]) to get a sentence representation.</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>class BartPooler(nn.Module):\n    \"\"\"\n    Default Bart pooler as implemented in huggingface transformers\n    The Bart pooling function focusing on the eos token ([EOS]) to get a sentence representation.\n    \"\"\"\n\n    def __init__(self, config, **kwargs):\n        super().__init__()\n        self.config = config\n\n    def forward(\n        self, h: torch.Tensor, inputs: Optional[torch.Tensor] = None, **kwargs\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward pass of the pooling layer\n\n        Args:\n            h: hidden representation of the input sequence to pool over\n            inputs: inputs tokens to the bart underlying model\n\n        Returns:\n            pooled_output: pooled representation of the input sequence\n        \"\"\"\n        eos_mask = inputs.eq(self.config.get(\"eos_token_id\"))\n        if len(torch.unique_consecutive(eos_mask.sum(1))) &gt; 1:\n            raise ValueError(\"All examples must have the same number of &lt;eos&gt; tokens.\")\n        pooled_output = h[eos_mask, :].view(h.size(0), -1, h.size(-1))[:, -1, :]\n        return pooled_output\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.BartPooler.forward","title":"<code>forward(h, inputs=None, **kwargs)</code>","text":"<p>Forward pass of the pooling layer</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>Tensor</code> <p>hidden representation of the input sequence to pool over</p> required <code>inputs</code> <code>Optional[Tensor]</code> <p>inputs tokens to the bart underlying model</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pooled_output</code> <code>Tensor</code> <p>pooled representation of the input sequence</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def forward(\n    self, h: torch.Tensor, inputs: Optional[torch.Tensor] = None, **kwargs\n) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the pooling layer\n\n    Args:\n        h: hidden representation of the input sequence to pool over\n        inputs: inputs tokens to the bart underlying model\n\n    Returns:\n        pooled_output: pooled representation of the input sequence\n    \"\"\"\n    eos_mask = inputs.eq(self.config.get(\"eos_token_id\"))\n    if len(torch.unique_consecutive(eos_mask.sum(1))) &gt; 1:\n        raise ValueError(\"All examples must have the same number of &lt;eos&gt; tokens.\")\n    pooled_output = h[eos_mask, :].view(h.size(0), -1, h.size(-1))[:, -1, :]\n    return pooled_output\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.BertPooler","title":"<code>BertPooler</code>","text":"<p>               Bases: <code>Module</code></p> <p>Default Bert pooler as implemented in huggingface transformers The bert pooling function focuses on a projection of the first token ([CLS]) to get a sentence representation.</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>class BertPooler(nn.Module):\n    \"\"\"\n    Default Bert pooler as implemented in huggingface transformers\n    The bert pooling function focuses on a projection of the first token ([CLS]) to get a sentence representation.\n    \"\"\"\n\n    def __init__(\n        self,\n        config,\n        activation: Optional[Callable] = None,\n        random_seed: int = None,\n        **kwargs,\n    ):\n        super().__init__()\n        self.config = config\n        self.random_seed = random_seed\n        if self.random_seed is not None:\n            torch.manual_seed(self.random_seed)\n        hidden_size = config.get(\"hidden_size\")\n        self.dense = nn.Linear(hidden_size, hidden_size)\n        self.activation = nn.Tanh() if activation is None else activation\n\n    def forward(\n        self, h: torch.Tensor, inputs: Optional[torch.Tensor] = None, **kwargs\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward pass of the pooling layer\n\n        Args:\n            h: hidden representation of the input sequence to pool over\n            inputs: optional input that has been provided to the underlying bert model\n\n        Returns:\n            pooled_output: pooled representation of the input sequence\n        \"\"\"\n        # We \"pool\" the model by simply taking the hidden state corresponding\n        # to the first token.\n        first_token_tensor = h[:, 0]\n        pooled_output = self.dense(first_token_tensor)\n        pooled_output = self.activation(pooled_output)\n        return pooled_output\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.BertPooler.forward","title":"<code>forward(h, inputs=None, **kwargs)</code>","text":"<p>Forward pass of the pooling layer</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>Tensor</code> <p>hidden representation of the input sequence to pool over</p> required <code>inputs</code> <code>Optional[Tensor]</code> <p>optional input that has been provided to the underlying bert model</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pooled_output</code> <code>Tensor</code> <p>pooled representation of the input sequence</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def forward(\n    self, h: torch.Tensor, inputs: Optional[torch.Tensor] = None, **kwargs\n) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the pooling layer\n\n    Args:\n        h: hidden representation of the input sequence to pool over\n        inputs: optional input that has been provided to the underlying bert model\n\n    Returns:\n        pooled_output: pooled representation of the input sequence\n    \"\"\"\n    # We \"pool\" the model by simply taking the hidden state corresponding\n    # to the first token.\n    first_token_tensor = h[:, 0]\n    pooled_output = self.dense(first_token_tensor)\n    pooled_output = self.activation(pooled_output)\n    return pooled_output\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.GPTPooler","title":"<code>GPTPooler</code>","text":"<p>               Bases: <code>Module</code></p> <p>Default GPT pooler as implemented in huggingface transformers The GPT pooling function focusing on the last non-padding token given sequence length to get a sentence representation.</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>class GPTPooler(nn.Module):\n    \"\"\"\n    Default GPT pooler as implemented in huggingface transformers\n    The GPT pooling function focusing on the last non-padding token given sequence length to get a sentence representation.\n    \"\"\"\n\n    def __init__(self, config, **kwargs):\n        super().__init__()\n        self.config = config\n        self.pad_token_id = config.get(\"pad_token_id\")\n\n    def forward(\n        self, h: torch.Tensor, inputs: Optional[torch.Tensor] = None, **kwargs\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward pass of the pooling layer\n\n        Args:\n            h: hidden representation of the input sequence to pool over\n            inputs: inputs tokens to the bart underlying model\n\n        Returns:\n            pooled_output: pooled representation of the input sequence\n        \"\"\"\n        batch_size, sequence_lengths = inputs.shape[:2]\n\n        assert (\n            self.pad_token_id is not None or batch_size == 1\n        ), \"Cannot handle batch sizes &gt; 1 if no padding token is defined.\"\n        if self.pad_token_id is None:\n            sequence_lengths = -1\n            logger.warning(\n                f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n                f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n            )\n        else:\n            sequence_lengths = torch.ne(inputs, self.pad_token_id).sum(-1) - 1\n        pooled_output = h[torch.arange(batch_size), sequence_lengths]\n        return pooled_output\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.GPTPooler.forward","title":"<code>forward(h, inputs=None, **kwargs)</code>","text":"<p>Forward pass of the pooling layer</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>Tensor</code> <p>hidden representation of the input sequence to pool over</p> required <code>inputs</code> <code>Optional[Tensor]</code> <p>inputs tokens to the bart underlying model</p> <code>None</code> <p>Returns:</p> Name Type Description <code>pooled_output</code> <code>Tensor</code> <p>pooled representation of the input sequence</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def forward(\n    self, h: torch.Tensor, inputs: Optional[torch.Tensor] = None, **kwargs\n) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the pooling layer\n\n    Args:\n        h: hidden representation of the input sequence to pool over\n        inputs: inputs tokens to the bart underlying model\n\n    Returns:\n        pooled_output: pooled representation of the input sequence\n    \"\"\"\n    batch_size, sequence_lengths = inputs.shape[:2]\n\n    assert (\n        self.pad_token_id is not None or batch_size == 1\n    ), \"Cannot handle batch sizes &gt; 1 if no padding token is defined.\"\n    if self.pad_token_id is None:\n        sequence_lengths = -1\n        logger.warning(\n            f\"{self.__class__.__name__} will not detect padding tokens in `inputs_embeds`. Results may be \"\n            f\"unexpected if using padding tokens in conjunction with `inputs_embeds.`\"\n        )\n    else:\n        sequence_lengths = torch.ne(inputs, self.pad_token_id).sum(-1) - 1\n    pooled_output = h[torch.arange(batch_size), sequence_lengths]\n    return pooled_output\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.HFPooler","title":"<code>HFPooler</code>","text":"<p>               Bases: <code>Module</code></p> <p>Default Pooler based on Molfeat Pooling layer</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>class HFPooler(nn.Module):\n    \"\"\"Default Pooler based on Molfeat Pooling layer\"\"\"\n\n    def __init__(self, config, dim: int = 1, name: str = \"mean\", **kwargs):\n        super().__init__()\n        self.config = config\n        self.pooling = Pooling(dim=dim, name=name)\n\n    def forward(\n        self,\n        h: torch.Tensor,\n        inputs: Optional[torch.Tensor] = None,\n        mask: Optional[torch.Tensor] = None,\n        ignore_padding: bool = True,\n        **kwargs,\n    ) -&gt; torch.Tensor:\n        \"\"\"Forward pass of the pooling layer\n\n        Args:\n            h: hidden representation of the input sequence to pool over\n            inputs: optional input that has been provided to the underlying bert model\n            mask: optional mask to use in place of computing the padding specific mask\n            ignore_padding: whether to ignore padding tokens when pooling\n\n        Returns:\n            pooled_output: pooled representation of the input sequence\n        \"\"\"\n        if mask is None and ignore_padding:\n            mask = inputs.ne(self.config.get(\"pad_token_id\"))\n        if mask.ndim == 2:\n            mask = mask.unsqueeze(-1)  # B, S, 1\n        return self.pooling(h, indices=None, mask=mask)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.HFPooler.forward","title":"<code>forward(h, inputs=None, mask=None, ignore_padding=True, **kwargs)</code>","text":"<p>Forward pass of the pooling layer</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>Tensor</code> <p>hidden representation of the input sequence to pool over</p> required <code>inputs</code> <code>Optional[Tensor]</code> <p>optional input that has been provided to the underlying bert model</p> <code>None</code> <code>mask</code> <code>Optional[Tensor]</code> <p>optional mask to use in place of computing the padding specific mask</p> <code>None</code> <code>ignore_padding</code> <code>bool</code> <p>whether to ignore padding tokens when pooling</p> <code>True</code> <p>Returns:</p> Name Type Description <code>pooled_output</code> <code>Tensor</code> <p>pooled representation of the input sequence</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def forward(\n    self,\n    h: torch.Tensor,\n    inputs: Optional[torch.Tensor] = None,\n    mask: Optional[torch.Tensor] = None,\n    ignore_padding: bool = True,\n    **kwargs,\n) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the pooling layer\n\n    Args:\n        h: hidden representation of the input sequence to pool over\n        inputs: optional input that has been provided to the underlying bert model\n        mask: optional mask to use in place of computing the padding specific mask\n        ignore_padding: whether to ignore padding tokens when pooling\n\n    Returns:\n        pooled_output: pooled representation of the input sequence\n    \"\"\"\n    if mask is None and ignore_padding:\n        mask = inputs.ne(self.config.get(\"pad_token_id\"))\n    if mask.ndim == 2:\n        mask = mask.unsqueeze(-1)  # B, S, 1\n    return self.pooling(h, indices=None, mask=mask)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.Pooling","title":"<code>Pooling</code>","text":"<p>               Bases: <code>Module</code></p> <p>Perform simple pooling on a tensor over one dimension</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>class Pooling(nn.Module):\n    \"\"\"\n    Perform simple pooling on a tensor over one dimension\n    \"\"\"\n\n    SUPPORTED_POOLING = [\"mean\", \"avg\", \"max\", \"sum\", \"clf\", None]\n\n    def __init__(self, dim: int = 1, name: str = \"max\"):\n        \"\"\"\n        Pooling for embeddings\n\n        Args:\n            dim: dimension to pool over, default is 1\n            name: pooling type. Default is 'mean'.\n        \"\"\"\n        super().__init__()\n        self.dim = dim\n        self.name = name\n\n    def forward(self, x, indices: List[int] = None, mask: torch.Tensor = None) -&gt; torch.Tensor:\n        \"\"\"Perform a pooling operation on the input tensor\n\n        Args:\n            x: input tensor to pull over\n            indices: Subset of indices to pool over. Defaults to None for all indices.\n            mask: binary mask to apply when pooling. Defaults to None, which is a matrix of 1.\n                If mask is provided it takes precedence over indices.\n        \"\"\"\n        x = torch.as_tensor(x)\n        if mask is None:\n            mask = torch.ones_like(x)\n        if indices is not None:\n            mask[:, indices] = 0\n        neg_inf = torch.finfo(x.dtype).min\n        if mask.ndim == 2:\n            mask = mask.unsqueeze(-1)  # B, S, 1\n        if self.name == \"clf\":\n            return x[:, 0, :]\n        if self.name == \"max\":\n            tmp = x.masked_fill(mask, neg_inf)\n            return torch.max(tmp, dim=self.dim)[0]\n        elif self.name in [\"mean\", \"avg\"]:\n            return torch.sum(x * mask, dim=self.dim) / mask.sum(self.dim)\n        elif self.name == \"sum\":\n            return torch.sum(x * mask, dim=self.dim)\n        return x\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.Pooling.__init__","title":"<code>__init__(dim=1, name='max')</code>","text":"<p>Pooling for embeddings</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>dimension to pool over, default is 1</p> <code>1</code> <code>name</code> <code>str</code> <p>pooling type. Default is 'mean'.</p> <code>'max'</code> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def __init__(self, dim: int = 1, name: str = \"max\"):\n    \"\"\"\n    Pooling for embeddings\n\n    Args:\n        dim: dimension to pool over, default is 1\n        name: pooling type. Default is 'mean'.\n    \"\"\"\n    super().__init__()\n    self.dim = dim\n    self.name = name\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.Pooling.forward","title":"<code>forward(x, indices=None, mask=None)</code>","text":"<p>Perform a pooling operation on the input tensor</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>input tensor to pull over</p> required <code>indices</code> <code>List[int]</code> <p>Subset of indices to pool over. Defaults to None for all indices.</p> <code>None</code> <code>mask</code> <code>Tensor</code> <p>binary mask to apply when pooling. Defaults to None, which is a matrix of 1. If mask is provided it takes precedence over indices.</p> <code>None</code> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def forward(self, x, indices: List[int] = None, mask: torch.Tensor = None) -&gt; torch.Tensor:\n    \"\"\"Perform a pooling operation on the input tensor\n\n    Args:\n        x: input tensor to pull over\n        indices: Subset of indices to pool over. Defaults to None for all indices.\n        mask: binary mask to apply when pooling. Defaults to None, which is a matrix of 1.\n            If mask is provided it takes precedence over indices.\n    \"\"\"\n    x = torch.as_tensor(x)\n    if mask is None:\n        mask = torch.ones_like(x)\n    if indices is not None:\n        mask[:, indices] = 0\n    neg_inf = torch.finfo(x.dtype).min\n    if mask.ndim == 2:\n        mask = mask.unsqueeze(-1)  # B, S, 1\n    if self.name == \"clf\":\n        return x[:, 0, :]\n    if self.name == \"max\":\n        tmp = x.masked_fill(mask, neg_inf)\n        return torch.max(tmp, dim=self.dim)[0]\n    elif self.name in [\"mean\", \"avg\"]:\n        return torch.sum(x * mask, dim=self.dim) / mask.sum(self.dim)\n    elif self.name == \"sum\":\n        return torch.sum(x * mask, dim=self.dim)\n    return x\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.pooler.get_default_hgf_pooler","title":"<code>get_default_hgf_pooler(name, config, **kwargs)</code>","text":"<p>Get default HuggingFace pooler based on the model name Args:     name: name of the model     config: config of the model     kwargs: additional arguments to pass to the pooler</p> Source code in <code>molfeat/utils/pooler.py</code> <pre><code>def get_default_hgf_pooler(name, config, **kwargs):\n    \"\"\"Get default HuggingFace pooler based on the model name\n    Args:\n        name: name of the model\n        config: config of the model\n        kwargs: additional arguments to pass to the pooler\n    \"\"\"\n    model_type = config.get(\"model_type\", None)\n    if name not in [\"bert\", \"roberta\", \"gpt\", \"bart\"] and name in Pooling.SUPPORTED_POOLING[:-1]:\n        return HFPooler(config, name=name, **kwargs)\n    names = [name]\n    if model_type is not None:\n        names += [model_type]\n    if any(x in [\"bert\", \"roberta\"] for x in names):\n        return BertPooler(config, **kwargs)\n    elif any(x.startswith(\"gpt\") for x in names):\n        return GPTPooler(config, **kwargs)\n    elif any(x == \"bart\" for x in names):\n        return BartPooler(config, **kwargs)\n    return None\n</code></pre>"},{"location":"api/molfeat.utils.html#mol-format-converters","title":"Mol Format Converters","text":""},{"location":"api/molfeat.utils.html#molfeat.utils.converters.SmilesConverter","title":"<code>SmilesConverter</code>","text":"<p>Molecule line notation conversion from smiles to selfies or inchi</p> Source code in <code>molfeat/utils/converters.py</code> <pre><code>class SmilesConverter:\n    \"\"\"Molecule line notation conversion from smiles to selfies or inchi\"\"\"\n\n    SUPPORTED_LINE_NOTATIONS = [\n        \"none\",\n        \"smiles\",\n        \"selfies\",\n        \"inchi\",\n    ]\n\n    def __init__(self, target: str = None):\n        \"\"\"\n        Convert input smiles to a target line notation\n\n        Args:\n            target: target representation.\n        \"\"\"\n        self.target = target\n\n        if self.target is not None and self.target not in self.SUPPORTED_LINE_NOTATIONS:\n            raise ValueError(\n                f\"{target} is not a supported line representation. Choose from {self.SUPPORTED_LINE_NOTATIONS}\"\n            )\n\n        if self.target == \"smiles\" or (self.target is None or self.target == \"none\"):\n            self.converter = None\n        elif self.target == \"inchi\":\n            self.converter = types.SimpleNamespace(decode=dm.from_inchi, encode=dm.to_inchi)\n        elif self.target == \"selfies\":\n            self.converter = types.SimpleNamespace(decode=dm.from_selfies, encode=dm.to_selfies)\n\n    def decode(self, inp: str):\n        \"\"\"Decode inputs into smiles\n\n        Args:\n            inp: input representation to decode\n        \"\"\"\n        if self.converter is None:\n            return inp\n        with dm.without_rdkit_log():\n            try:\n                decoded = self.converter.decode(inp)\n                return decoded.strip()\n            except Exception:  # (deepsmiles.DecodeError, ValueError, AttributeError, IndexError):\n                return None\n\n    def encode(self, smiles: str):\n        \"\"\"Encode a input smiles into target line notation\n\n        Args:\n            smiles: input smiles to encode\n        \"\"\"\n        if self.converter is None:\n            return smiles\n        with dm.without_rdkit_log():\n            try:\n                encoded = self.converter.encode(smiles)\n                return encoded.strip()\n            except Exception:\n                return None\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.converters.SmilesConverter.__init__","title":"<code>__init__(target=None)</code>","text":"<p>Convert input smiles to a target line notation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>target representation.</p> <code>None</code> Source code in <code>molfeat/utils/converters.py</code> <pre><code>def __init__(self, target: str = None):\n    \"\"\"\n    Convert input smiles to a target line notation\n\n    Args:\n        target: target representation.\n    \"\"\"\n    self.target = target\n\n    if self.target is not None and self.target not in self.SUPPORTED_LINE_NOTATIONS:\n        raise ValueError(\n            f\"{target} is not a supported line representation. Choose from {self.SUPPORTED_LINE_NOTATIONS}\"\n        )\n\n    if self.target == \"smiles\" or (self.target is None or self.target == \"none\"):\n        self.converter = None\n    elif self.target == \"inchi\":\n        self.converter = types.SimpleNamespace(decode=dm.from_inchi, encode=dm.to_inchi)\n    elif self.target == \"selfies\":\n        self.converter = types.SimpleNamespace(decode=dm.from_selfies, encode=dm.to_selfies)\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.converters.SmilesConverter.decode","title":"<code>decode(inp)</code>","text":"<p>Decode inputs into smiles</p> <p>Parameters:</p> Name Type Description Default <code>inp</code> <code>str</code> <p>input representation to decode</p> required Source code in <code>molfeat/utils/converters.py</code> <pre><code>def decode(self, inp: str):\n    \"\"\"Decode inputs into smiles\n\n    Args:\n        inp: input representation to decode\n    \"\"\"\n    if self.converter is None:\n        return inp\n    with dm.without_rdkit_log():\n        try:\n            decoded = self.converter.decode(inp)\n            return decoded.strip()\n        except Exception:  # (deepsmiles.DecodeError, ValueError, AttributeError, IndexError):\n            return None\n</code></pre>"},{"location":"api/molfeat.utils.html#molfeat.utils.converters.SmilesConverter.encode","title":"<code>encode(smiles)</code>","text":"<p>Encode a input smiles into target line notation</p> <p>Parameters:</p> Name Type Description Default <code>smiles</code> <code>str</code> <p>input smiles to encode</p> required Source code in <code>molfeat/utils/converters.py</code> <pre><code>def encode(self, smiles: str):\n    \"\"\"Encode a input smiles into target line notation\n\n    Args:\n        smiles: input smiles to encode\n    \"\"\"\n    if self.converter is None:\n        return smiles\n    with dm.without_rdkit_log():\n        try:\n            encoded = self.converter.encode(smiles)\n            return encoded.strip()\n        except Exception:\n            return None\n</code></pre>"},{"location":"api/molfeat.viz.html","title":"<code>molfeat.viz</code>","text":""},{"location":"api/molfeat.viz.html#molfeat.viz.colors_from_feature_factory","title":"<code>colors_from_feature_factory(feature_factory, cmap_name='Set1', alpha=1.0)</code>","text":"<p>Get a list of colors for a given feature factory. For the same <code>feature_factory</code> the returned colors will be the same.</p> <p>Parameters:</p> Name Type Description Default <code>feature_factory</code> <code>MolChemicalFeatureFactory</code> <p>Feature factory to use.</p> required <code>cmap_name</code> <code>str</code> <p>Matplotlib colormap name.</p> <code>'Set1'</code> <code>alpha</code> <code>float</code> <p>Alpha value for the colors.</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>colors</code> <p>Dict of feature_name as keys and colors as values.</p> Source code in <code>molfeat/viz.py</code> <pre><code>def colors_from_feature_factory(\n    feature_factory: rdMolChemicalFeatures.MolChemicalFeatureFactory,\n    cmap_name: str = \"Set1\",\n    alpha: float = 1.0,\n):\n    \"\"\"Get a list of colors for a given feature factory. For the same\n    `feature_factory` the returned colors will be the same.\n\n    Args:\n        feature_factory: Feature factory to use.\n        cmap_name: Matplotlib colormap name.\n        alpha: Alpha value for the colors.\n\n    Returns:\n        colors: Dict of feature_name as keys and colors as values.\n    \"\"\"\n    cmap_name = \"Set1\"\n\n    cmap = matplotlib.colormaps[cmap_name]\n    cmap_n = cmap.N  # type: ignore\n\n    colors = {}\n    for i, name in enumerate(feature_factory.GetFeatureFamilies()):\n        color: List[float] = list(cmap(i % cmap_n))\n        color[3] = alpha\n        colors[name] = color\n\n    return colors\n</code></pre>"},{"location":"api/molfeat.viz.html#molfeat.viz.show_mols","title":"<code>show_mols(mols)</code>","text":"<p>Generate a view of the molecules.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>Union[Mol, List[Mol]]</code> <p>A mol or a list of mols.</p> required <p>Returns:</p> Type Description <p>nglview.widget.NGLWidget</p> Source code in <code>molfeat/viz.py</code> <pre><code>def show_mols(mols: Union[dm.Mol, List[dm.Mol]]):\n    \"\"\"Generate a view of the molecules.\n\n    Args:\n        mols: A mol or a list of mols.\n\n    Returns:\n        nglview.widget.NGLWidget\n    \"\"\"\n\n    import nglview as nv\n\n    if isinstance(mols, dm.Mol):\n        mols = [mols]\n\n    view = nv.NGLWidget()\n    for mol in mols:\n        component = view.add_component(mol)\n        component.clear()  # type: ignore\n        component.add_ball_and_stick(multipleBond=True)  # type: ignore\n\n    return view\n</code></pre>"},{"location":"api/molfeat.viz.html#molfeat.viz.show_pharm_features","title":"<code>show_pharm_features(mols, features, feature_factory, alpha=1.0, sphere_radius=0.4, show_legend=True)</code>","text":"<p>Generate a view of the molecules with pharmacophoric features.</p> <p>Parameters:</p> Name Type Description Default <code>mols</code> <code>Union[Mol, List[Mol]]</code> <p>A mol or a list of mols.</p> required <code>features</code> <code>DataFrame</code> <p>Features data. Columns must contain at least \"feature_name\", \"feature_id\", and \"feature_coords\".</p> required <code>feature_factory</code> <code>MolChemicalFeatureFactory</code> <p>Feature factory to display consistent colors.</p> required <code>alpha</code> <code>float</code> <p>Alpha value for the colors (currently not working).</p> <code>1.0</code> <code>sphere_radius</code> <code>float</code> <p>Radius of the spheres for the features.</p> <code>0.4</code> <code>show_legend</code> <code>bool</code> <p>Display the legend (the layout is bad but at least it shows the legend).</p> <code>True</code> <p>Returns:</p> Type Description <p>nglview.widget.NGLWidget</p> Source code in <code>molfeat/viz.py</code> <pre><code>def show_pharm_features(\n    mols: Union[dm.Mol, List[dm.Mol]],\n    features: pd.DataFrame,\n    feature_factory: rdMolChemicalFeatures.MolChemicalFeatureFactory,\n    alpha: float = 1.0,\n    sphere_radius: float = 0.4,\n    show_legend: bool = True,\n):\n    \"\"\"Generate a view of the molecules with pharmacophoric features.\n\n    Args:\n        mols: A mol or a list of mols.\n        features: Features data. Columns must contain at least\n            \"feature_name\", \"feature_id\", and \"feature_coords\".\n        feature_factory: Feature factory to display consistent colors.\n        alpha: Alpha value for the colors (currently not working).\n        sphere_radius: Radius of the spheres for the features.\n        show_legend: Display the legend (the layout is bad but at least it\n            shows the legend).\n\n    Returns:\n        nglview.widget.NGLWidget\n    \"\"\"\n\n    import ipywidgets as ipy\n\n    # Get mols view\n    mol_view = show_mols(mols)\n\n    # Get colors\n    colors = colors_from_feature_factory(feature_factory, alpha=alpha)\n\n    # Add features to the viz\n    for _, row in features.iterrows():\n        color = colors[row[\"feature_name\"]]\n        label = f\"{row['feature_name']}_{row['feature_id']}\"\n        mol_view.shape.add_sphere(row[\"coords\"], color, sphere_radius, label)  # type: ignore\n\n    if not show_legend:\n        return mol_view\n\n    # Build legend widget\n    colors_widget = _build_colors_widget(colors)\n\n    main_layout = ipy.Layout(\n        display=\"flex\",\n        flex_flow=\"column\",\n        align_content=\"center\",\n    )\n    main_widget = ipy.HBox([mol_view, colors_widget], layout=main_layout)  # type: ignore\n\n    return main_widget\n</code></pre>"},{"location":"community/contributions.html","title":"Community contributions","text":"<p>We love community contributions! </p> <p>This page is to celebrate and showcase the contributors that have gone above and beyond!</p> <p>Is your work not listed here?</p> <p>We do our best to list all the work we are aware of, but if we missed your contribution feel free to open a Github issue to let us know! We will add it as soon as possible.</p>"},{"location":"community/contributions.html#plugins","title":"Plugins","text":"<p>Plugins add new featurizers to the molfeat ecosystem by extending its functionality with plug-and-play components. To learn more, see Extending molfeat.</p> Link Name Author Description molfeat-padel @datamol.io Adds support for the PaDeL descriptors, as introduced by Yap, 2010. This is the official exemplary plugin for molfeat. molfeat-hype @maclandrol Investigates the performance of embeddings from various LLMs trained without explicit molecular context for molecular modeling"},{"location":"community/contributions.html#tutorials","title":"Tutorials","text":"<p>Tutorials allow newcomers to quickly get their hands dirty with step-by-step instructions. It's therefore great that some of our community members have taken the time to demonstrate how they use molfeat.</p> Link Name Author Description Practical cheminformatics @PatWalters This tutorial shows how to train a QSAR using just 8 lines of code, among others by utilizing tools from the datamol.io ecosystem. PyG GNN on Graphcore IPUs @s-maddrellmander This tutorial adapts the Training a GNN with PyG to show how to leverage Graphcore IPUs. Transformer on Graphcore IPUs @s-maddrellmander This tutorial adapts the Finetuning a pre-trained transformer to show how to leverage Graphcore IPUs."},{"location":"community/contributions.html#projects","title":"Projects","text":"<p>Check out these awesome community projects that use Molfeat. | Link                                                                                                                                       | Name | Author                                   | Description                                                                                                                                                                                       | | ---------------------------------------------------------------------------------------------------------------------------------------------- | -------- | -------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | |  | AC Suite | @cmvcordova | The Activity Cliff (AC) Suite is a Pytorch Lightning + Hydra integrated utility to train and evaluate models for molecular property prediction based on the Matched Molecular Pair (MMP) abstraction. |</p>"},{"location":"community/contributions.html#code","title":"Code","text":"<p>From bug fixes to new features, code contributions directly benefit the molfeat package and everyone that uses it! </p> <p> </p>"},{"location":"community/get_involved.html","title":"Get involved","text":"<p>Whether you are a first-time contributor or open-source veteran, we welcome any contribution to the <code>molfeat</code> package.  Your contributions help to make sure this package can remain free-to-use and open-source.</p>"},{"location":"community/get_involved.html#contribute","title":"Contribute","text":"<p>The most straight-forward way to contribute is through Github. In short, you can help by: </p> <ul> <li> Star the repository on Github.</li> <li> Fix existing code issues. </li> <li> Report bugs or request new features. </li> <li> Answer questions of - and interact with - community members.</li> <li> Improve existing documentation or add new tutorials.</li> </ul> <p>To learn more about this, please see the Developers documentation.</p>"},{"location":"community/get_involved.html#slack","title":"Slack","text":"<p>The molfeat community is part of the M2D2 community. To orchestrate these efforts the <code>#molfeat</code> channel  was created in the M2D2 Slack. Similar to a forum, this channel allows people to ask questions, make suggestions,  showcase your work or discuss new features. </p>"},{"location":"community/get_involved.html#datamolio","title":"Datamol.io","text":"<p>Molfeat is part of the datamol.io ecosystem. If you enjoy molfeat, consider giving our other tools a look as well. These tools are designed to be synergetic and have complementary features.</p>"},{"location":"developers/contribute.html","title":"Contribute","text":"<p>Welcome to the molfeat community! We appreciate everyone's contribution and welcome all. Apart from code contributions, there are various other ways to support the community. If you would like to get involved, please see the community documentation for more details on how to contribute. However you choose to contribute, please be mindful and respect our code of conduct.</p> <p>Get inspired by community contributions</p> <p>As we love community contributions, we decided to create a dedicate space in our documentation to highlight and celebrate such contributions. Visit Community Contribitons to learn more!</p> <p>The rest of this page details the development lifecycle of molfeat.</p>"},{"location":"developers/contribute.html#setup-a-dev-environment","title":"Setup a dev environment","text":"<p>To contribute, you will first need to setup a dev environment. Follow the steps below:</p> <ol> <li> <p>Fork the repository by    clicking on the Fork button on the repository's page. This creates a copy of the code under your GitHub user account.</p> </li> <li> <p>Clone your fork to your local disk, and add the base repository as a remote:</p> <pre><code>git clone git@github.com:&lt;your Github handle&gt;/molfeat.git\ncd molfeat\ngit remote add upstream https://github.com/datamol-io/molfeat.git\n</code></pre> </li> <li> <p>Create a new branch to hold your development changes:</p> <pre><code>git checkout -b useful-branch-name\n</code></pre> <p>Do not work on the <code>main</code> branch!</p> </li> <li> <p>Once you have a local copy, setup a development environment and install the dependencies. </p> <p>It is strongly recommended that you do so in a new conda environment. </p> <pre><code>mamba env create -n molfeat -f env.yml\nconda activate molfeat\npip install -e . --no-deps\n</code></pre> <p>If you absolutely cannot use <code>conda/mamba</code>, please use the following pip install command in your virtual environment:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre> <p>If molfeat was already installed in the virtual environment, remove it with <code>pip uninstall molfeat</code> first, before reinstalling it in editable mode with the <code>-e</code> flag.</p> </li> <li> <p>Make your changes and modifications on your branch.</p> <p>As you work on your code, you should make sure the test suite passes. Run the tests impacted by your changes like this:</p> <pre><code>pytest tests/&lt;TEST_TO_RUN&gt;.py\n</code></pre> </li> <li> <p>Commit your code, push it to your forked repository and open a pull request with a detailed description of your changes and why they are valuable. </p> </li> </ol>"},{"location":"developers/contribute.html#continuous-integration","title":"Continuous Integration","text":"<p>molfeat uses Github Actions to:</p> <ul> <li>Build and test <code>molfeat</code>.</li> <li>Check code formating the code: <code>black</code>.</li> <li>Documentation: build and deploy the documentation on <code>main</code> and for every new git tag.</li> </ul>"},{"location":"developers/contribute.html#run-tests-globally","title":"Run tests globally","text":"<pre><code>pytest\n</code></pre>"},{"location":"developers/contribute.html#build-the-documentation","title":"Build the documentation","text":"<p>You can build and serve the documentation locally with:</p> <pre><code># Build and serve the doc\nmkdocs serve\n</code></pre>"},{"location":"developers/contribute.html#submitting-pull-requests","title":"Submitting Pull Requests","text":"<p>If you're considering a large code contribution to molfeat, please open an issue first to get early feedback on the idea.</p> <p>Once you think the code is ready to be reviewed, push it to your fork and open a pull request. We will assign a reviewer to your PR. For a change to be accepted all existing tests will need to pass. We expect additional tests and documentation for any new features.</p> <p>If you are developing a plugin for molfeat, please refer to the corresponding section Extending molfeat</p>"},{"location":"developers/contribute.html#adding-etl-notebooks","title":"Adding ETL Notebooks","text":"<p>The ETL (extraction, transformation, and loading) scripts document the process of creating new featurizers, and we make our ETL notebooks open to the community for transparency purposes. As a developer adding new featurizers, please document your process in the etl notebook folder.</p> <p>By documenting your process in the ETL notebook, you help ensure that the registration of new models can be reviewed by the community and provide greater visibility into the development process. This can help build trust with our users and contributors, and encourage collaboration and feedback.</p>"},{"location":"developers/contribute.html#releasing-a-new-version","title":"Releasing a New Version","text":"<p>To release a new version, code maintainers can use the <code>release</code> GitHub action. However, before releasing a new version, it is important to coordinate with the code owners to ensure that the release roadmap is followed and any critical pull requests have been merged.</p> <p>The release roadmap should be followed to ensure that the new version is stable, functional, and meets the requirements of the release. This includes proper testing, documentation, and ensuring backward compatibility where necessary. By following these guidelines, we can ensure that new versions are released smoothly and efficiently, with clear communication to our users and contributors.</p>"},{"location":"developers/create-plugin.html","title":"Plugins","text":"<p>Molecular featurization is an active area of research leading to the steady emergence of new approaches to solve this complex set of problems. As new molecular featurizers emerge, you can easily add yours to molfeat and share it with the rest of the community.</p> <p>For developers that are planning to extend molfeat functionality, we recommend using the plugin system. The use of a plugin system ensures that the core package remains easy to install and as light as possible, while making it easy to extend its functionality with plug-and-play components. Additionally, it ensures that plugins can be developed independently of the core package, removing the bottleneck of a central party that reviews and approves new plugins.</p> <p>However, plugins are not always required and sometimes a simple pull request is the better option. </p> Do use plugins if... Do not use plugins if... If a new featurizer can not be loaded by current classes. If a new featurizer can already be loaded through existing classes. If a new featurizer requires additional, possibly difficult-to-install dependencies. If a new featurizer requires no additional dependencies. If you want to make a new class of featurizers available to the molfeat community. If you can show through benchmarks that a featurizer is so performant, it should be available as part of the core package. If you want to extend the functionality of molfeat for private / internal use. <p>Decided you don't need a plugin after all?</p> <p>Consult the tutorials to learn how to extend molfeat's functionality without plugins.</p> <p>The rest of this document details how to package molfeat plugins (or extensions) so that they can be tested, published and eventually reused by others. </p> <p>We recommend molfeat plugins be bundled and distributed as a Python package that provides a set of extensions to molfeat.</p>"},{"location":"developers/create-plugin.html#quickstart","title":"Quickstart","text":"<p>The fastest way to jumpstart a molfeat plugin package is to start with an existing template repository. The molfeat-padel demo plugin package provides a starting point to understand the basic folder structure and our naming convention. Please reachout to us on github if you need help to get started.</p> <p>In the following document, we explain the conventions used when building a molfeat plugin.</p>"},{"location":"developers/create-plugin.html#choosing-a-name","title":"Choosing a name","text":"<p>The naming convention for molfeat plugin packages is `</p> <ul> <li><code>molfeat-&lt;myplugin&gt;</code> for the plugin distribution on PyPI or Conda.</li> <li><code>molfeat_&lt;myplugin&gt;</code> for the corresponding python package (since python package names cannot contain dashes), leading to the following folder structure:</li> </ul> <pre><code>    molfeat-myplugin/\n       molfeat_myplugin/\n          __init__.py\n</code></pre> <p>If you intend to eventually publish your plugin package, please go to the Register a plugin and choose a name that is not already taken. You are also encouraged to pre-register your package (see instructions provided), both to reserve your plugin name and to inform others of your ongoing development.</p>"},{"location":"developers/create-plugin.html#folder-structure","title":"Folder structure","text":"<p>The overall folder structure of your plugin is up to you, but it is useful to follow a set of basic conventions. Here is an example of a folder structure for a molfeat plugin, illustrating different levels of nesting</p> <pre><code>molfeat-myplugin/           - distribution folder\n   tests/                   - tests directory (possibly with subdirectories)\n   molfeat_myplugin/        - top-level package (from molfeat_myplugin import ..)\n      __init__.py\n      calc/\n         __init__.py\n         myplugin.py      - contains my plugin SerializableCalculator\n      trans/\n         __init__.py\n         myplugin.py       - contains my plugin MoleculeTransformer\n      data/\n         __init__.py    - contains code-specific MyData data format\n      ...\n   setup.py             - setup.py file (optional based on your pyproject.toml content)\n   LICENSE              - license of your plugin\n   MANIFEST.in          - lists non-python files to be installed, such as LICENSE\n   README.md            - project description for github and PyPI\n   pyproject.toml       - plugin metadata: installation requirements, author, entry points, etc.\n   ...\n</code></pre>"},{"location":"developers/create-plugin.html#registering-plugins-through-entry-points","title":"Registering plugins through entry points","text":"<p>A molfeat plugin is an extension of molfeat that announces itself by means of a new entry point. Adding a new entry point consists of the following steps:</p> <ol> <li> <p>Deciding on a name. We strongly suggest starting the name of each     entry point with the name of the plugin package (omitting the     'molfeat-' prefix). For a package <code>molfeat-myplugin</code>, this will     usually mean <code>\"myplugin.&lt;something&gt;\"</code></p> </li> <li> <p>Finding the right entry point group. Three main entry point are defined in molfeat <code>molfeat.calc</code> (for single molecule calculator: <code>SerializableCalculator</code>, which your class should inherit from), <code>molfeat.trans</code> (for <code>MoleculeTransformers</code>) and <code>molfeat.trans.pretrained</code> (for <code>PretrainedMolTransformer</code>)</p> </li> <li> <p>Adding the entry point to the <code>entry_points</code> field in the     <code>pyproject.toml</code> file:</p> <pre><code>  ...\n  [project.entry-points.\"molfeat.calc\"]\n  \"myplugin.&lt;something&gt;\" = \"molfeat_myplugin.calc.some:MysomethingCalculator\"\n  [project.entry-points.\"molfeat.trans\"]\n  \"myplugin.&lt;something&gt;\" = \"molfeat_myplugin.trans.some:MysomethingMoleculeTransformer\"\n  ...\n</code></pre> </li> </ol> <p>For further details, see the Python packaging user guide.</p> <p>The core molfeat package will automatically discover new molfeat plugins and appropriately make them accessible and importable. </p> <p>For example, upon proper registration of a plugin offering a new <code>SerializableCalculator</code>, it should be directly accessible in the list of available calculators for <code>MoleculeTransformer</code>.</p> <p>The following example shows how to discover the newly added functionality of the <code>molfeat-padel</code> plugin package automatically when installed.  In this example, all three scenarios are valid.</p>"},{"location":"developers/create-plugin.html#1-initializing-the-calculator-through-the-plugin-package","title":"1. Initializing the calculator through the plugin package.","text":"<pre><code>from molfeat.trans import MoleculeTransformer\n\nfrom molfeat_padel.calc.padel import PadelDescriptors\nmol_transf = MoleculeTransformer(featurizer=PadelDescriptors())\n</code></pre>"},{"location":"developers/create-plugin.html#2-explicitly-load-registered-plugins-to-automatically-discover-padeldescriptors","title":"2. Explicitly load registered plugins to automatically discover <code>PadelDescriptors</code>.","text":"<pre><code>from molfeat.trans import MoleculeTransformer\nfrom molfeat.plugins import load_registered_plugins\nload_registered_plugins(add_submodules=True)\n\n# PadelDescriptors is now available under the core `molfeat.calc`\nfrom molfeat.calc import PadelDescriptors\nmol_transf = MoleculeTransformer(featurizer=PadelDescriptors())\nmol_transf = MoleculeTransformer(featurizer=\"PadelDescriptors\")\n</code></pre>"},{"location":"developers/create-plugin.html#3-import-the-plugin-to-automatically-discover-the-padeldescriptors","title":"3. Import the plugin to automatically discover the <code>PadelDescriptors</code>.","text":"<pre><code>from molfeat.trans import MoleculeTransformer\nimport molfeat_padel\n\n# works because PadelDescriptors is imported in the root init of molfeat_padel\nmol_transf = MoleculeTransformer(featurizer=\"PadelDescriptors\")\n</code></pre>"},{"location":"developers/create-plugin.html#testing-a-plugin-package","title":"Testing a plugin package","text":"<p>Writing tests for your molfeat plugins and running continuous integration tests using free platforms like GitHub Actions is the best way to ensure that your plugin works and keeps working as it is being developed. We recommend using the pytest framework for testing molfeat plugins.</p>"},{"location":"developers/create-plugin.html#documenting-a-plugin-package","title":"Documenting a plugin package","text":"<p>molfeat plugin packages are python packages, and general best practises for writing python documentation apply.</p> <p>In the following, we mention a few hints that apply specifically to molfeat plugins.</p>"},{"location":"developers/create-plugin.html#repository-level-documentation","title":"Repository-level documentation","text":"<p>Since the source code of most molfeat plugins is hosted on GitHub, the first contact of a new user with your plugin package is likely the landing page of your GitHub repository.</p> <ul> <li>Make sure to have a useful <code>README.md</code>, describing what your     plugin does, how to install it and how to run it.</li> <li>Leaving a contact email and adding a license is also a good idea.</li> <li>Make sure the information in the <code>pyproject.toml</code> file is correct     and up to date (in particular the version number)</li> <li>Optionally add a documentation website to provide tutorials</li> </ul>"},{"location":"developers/create-plugin.html#source-code-level-documentation","title":"Source-code-level documentation","text":"<p>Source-code level documentation matters both for users of your plugin's python API and, particularly, for attracting contributions from others.</p> <p>When adding new types of calculations or workflows, make sure to use docstrings, and use the <code>help</code> argument to document input ports and output ports.</p>"},{"location":"developers/create-plugin.html#registering-your-plugin-as-official-molfeat-plugin","title":"Registering your plugin as official molfeat plugin","text":"<p>Once you have designed and tested your plugin package, you can officially register it to be listed on the molfeat website by following the instructions at Register a plugin </p>"},{"location":"developers/register-plugin.html","title":"molfeat plugin registry","text":"<p>This document explains how to register a plugin in <code>molfeat</code> for listing on our website. </p> <p>The <code>molfeat</code> plugin registry aims to be the home for all publicly available <code>molfeat</code> plugins. It collects information on the type of plugins provided by your package and which <code>molfeat</code> versions it is compatible with.</p> <p>If you are starting to develop a new plugin or if you already have one, please register it here. We strongly encourage you to register at early stages of development, both to reserve the name of your plugin and to inform the community of your ongoing work.</p> <p>Curious what other plugins exist?</p> <p>Visit Community contributions to learn more about the current plugins!</p>"},{"location":"developers/register-plugin.html#how-to-register-a-plugin","title":"How to register a plugin","text":"<ol> <li>Fork this repository</li> <li>Add your plugin to the end of the <code>plugins.yaml</code> file, e.g.     <pre><code>...\nmolfeat-new:\n    entry_point_prefix: new\n    home_url: ~\n    documentation_url: ~\n    molfeat_version: ~\n</code></pre></li> <li>Create a Pull Request to this repository</li> </ol>"},{"location":"developers/register-plugin.html#valid-keys-for-each-plugin","title":"Valid keys for each plugin","text":"<ul> <li>top-level key (required): the name under which your plugin will be distributed. By convention, names of molfeat plugins are lowercase and prefixed by <code>molfeat-</code> (e.g <code>molfeat-myplugin</code>)</li> </ul> <ul> <li>entry_point_prefix (required): the prefix of all entry points provided by the plugin. By convention, a plugin <code>molfeat-xxx</code> should use <code>entry_point_prefix: xxx</code>. You can also use the module name of your plugin. For example: <code>molfeat-myplugin</code> uses the entry point prefix <code>myplugin</code> and provides numerous entry points, all of which start with <code>myplugin.</code>. The entry point is also how you signal to users how they can load your plugin through molfeat. </li> </ul> <pre><code>from molfeat.trans import MoleculeTransformer\nfrom molfeat.plugins import load_registered_plugins\nload_registered_plugins(add_submodules=True, plugins=[\"new\"])\n</code></pre> <ul> <li>home_url (required): the link to the homepage of the plugin, for example its github repository.</li> </ul> <ul> <li>molfeat_version (required): the molfeat version required for your plugin to work.</li> </ul> <ul> <li>documentation_url (optional): the link to the online documentation for your plugin, for example on readthedocs.org .</li> </ul>"},{"location":"developers/register-plugin.html#model-card-in-pull-request","title":"Model Card in pull request","text":"<p>In you pull request, please  provide a json or yaml file (or its content) that should list information on available models that are offered in your plugin. </p> <p>If your plugin does not provide any additional model, you can ignore this step. An example of such a file is provided below. You will need to provide all keys:</p> <pre><code># name of the featurizer, str\nname: awesome-featurizer \n# description of your featurizer, str\ndescription: Concise description for the awesome-featurizer\n# type of input the featurizer takes, str\ninputs: smiles\n# which group does the featurizer belong to. \n# This helps for the usage card. Ask a maintainer for help\ngroup: \"rdkit\"\n# link to the reference of the featurizer\nreference: https://link-to-the-awesome-paper/\n# type of featurizer, Literal[\"pretrained\", \"hand-crafted\", \"hashed\"]\ntype: \"pretrained\" \n# output representation of the featurizer, Literal[\"graph\", \"line-notation\", \"vector\", \"tensor\", \"other\"]\nrepresentation: vector \n# Whether 3D information are required, Optional[bool]\nrequire_3D: false \n# up to 5 tags you want to add for searching your featurizer, List[str]\ntags:\n    - pretrained\n    - 3D\n    - GNN\nauthors: # list the authors, List[str]\n    - Awesome Team 1\n</code></pre>"},{"location":"tutorials/add_your_own.html","title":"Create your own featurizers","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import numpy as np\nimport datamol as dm\n\nfrom molfeat.trans import MoleculeTransformer\nfrom rdkit.Chem.rdMolDescriptors import CalcNumHeteroatoms\n\nsmiles = dm.freesolv()[\"smiles\"].iloc[:3]\ndef my_calculator(mol):\n    \"\"\"My custom featurizer\"\"\"\n    mol = dm.to_mol(mol)\n    rng = np.random.default_rng(0)\n    return [mol.GetNumAtoms(), mol.GetNumBonds(), CalcNumHeteroatoms(mol), rng.random()]\n\n# This directly works with the MoleculeTransformer\nmol_transf = MoleculeTransformer(my_calculator)\nmol_transf(smiles)\n</pre> import numpy as np import datamol as dm  from molfeat.trans import MoleculeTransformer from rdkit.Chem.rdMolDescriptors import CalcNumHeteroatoms  smiles = dm.freesolv()[\"smiles\"].iloc[:3] def my_calculator(mol):     \"\"\"My custom featurizer\"\"\"     mol = dm.to_mol(mol)     rng = np.random.default_rng(0)     return [mol.GetNumAtoms(), mol.GetNumBonds(), CalcNumHeteroatoms(mol), rng.random()]  # This directly works with the MoleculeTransformer mol_transf = MoleculeTransformer(my_calculator) mol_transf(smiles) Out[2]: <pre>[array([13.        , 13.        ,  3.        ,  0.63696169]),\n array([5.        , 4.        , 4.        , 0.63696169]),\n array([5.        , 4.        , 0.        , 0.63696169])]</pre> <p>If such functions get more complex, it might instead be easier to wrap it in a class. This also ensures the calculator remains serializable.</p> In\u00a0[3]: Copied! <pre>from molfeat.calc import SerializableCalculator\n\n\nclass MyCalculator(SerializableCalculator):\n    def __call__(self, mol):\n        mol = dm.to_mol(mol)\n        rng = np.random.default_rng(0)\n        return [mol.GetNumAtoms(), mol.GetNumBonds(), CalcNumHeteroatoms(mol), rng.random()]\n\n\nmol_transf = MoleculeTransformer(MyCalculator())\nmol_transf(smiles)\n</pre> from molfeat.calc import SerializableCalculator   class MyCalculator(SerializableCalculator):     def __call__(self, mol):         mol = dm.to_mol(mol)         rng = np.random.default_rng(0)         return [mol.GetNumAtoms(), mol.GetNumBonds(), CalcNumHeteroatoms(mol), rng.random()]   mol_transf = MoleculeTransformer(MyCalculator()) mol_transf(smiles) Out[3]: <pre>[array([13.        , 13.        ,  3.        ,  0.63696169]),\n array([5.        , 4.        , 4.        , 0.63696169]),\n array([5.        , 4.        , 0.        , 0.63696169])]</pre> <p>If your calculator can perform featurization of a batch of molecules in an efficient way, then you should implement the optional <code>batch_compute</code> method which will then be used by <code>MoleculeTransformer</code> instead of the default sequential or parallelization process.</p> In\u00a0[4]: Copied! <pre>from molfeat.calc import SerializableCalculator\n\nclass MyBatchableCalculator(SerializableCalculator):\n    def __init__(self, random_seed=42, length=10):\n        self.random_seed = random_seed\n        self.length = length\n        self.rng = np.random.default_rng(self.random_seed)\n\n    def __call__(self, mol):\n        print(\"We are in single compute mode!\")\n        return self.rng.random(self.length)\n    \n    def __len__(self):\n        return self.length\n        \n    def batch_compute(self, mols, **kwargs):\n        # note that dm.parallelized information is passed along with the molecules list\n        print(\"We are in batch mode!\")\n        return self.rng.random((len(mols), self.length))\n\nmol_transf = MoleculeTransformer(MyBatchableCalculator())\nmol_transf(smiles)\n</pre> from molfeat.calc import SerializableCalculator  class MyBatchableCalculator(SerializableCalculator):     def __init__(self, random_seed=42, length=10):         self.random_seed = random_seed         self.length = length         self.rng = np.random.default_rng(self.random_seed)      def __call__(self, mol):         print(\"We are in single compute mode!\")         return self.rng.random(self.length)          def __len__(self):         return self.length              def batch_compute(self, mols, **kwargs):         # note that dm.parallelized information is passed along with the molecules list         print(\"We are in batch mode!\")         return self.rng.random((len(mols), self.length))  mol_transf = MoleculeTransformer(MyBatchableCalculator()) mol_transf(smiles) <pre>We are in batch mode!\n</pre> Out[4]: <pre>array([[0.77395605, 0.43887844, 0.85859792, 0.69736803, 0.09417735,\n        0.97562235, 0.7611397 , 0.78606431, 0.12811363, 0.45038594],\n       [0.37079802, 0.92676499, 0.64386512, 0.82276161, 0.4434142 ,\n        0.22723872, 0.55458479, 0.06381726, 0.82763117, 0.6316644 ],\n       [0.75808774, 0.35452597, 0.97069802, 0.89312112, 0.7783835 ,\n        0.19463871, 0.466721  , 0.04380377, 0.15428949, 0.68304895]])</pre> In\u00a0[5]: Copied! <pre>from sklearn.ensemble import RandomForestRegressor\nfrom molfeat.trans.pretrained import PretrainedMolTransformer\n\n\nclass MyFoundationModel(PretrainedMolTransformer):\n    \"\"\"\n    In this dummy example, we train a RF model to predict the cLogP\n    then use the feature importance of the RF model as the embedding.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(dtype=np.float32)\n        self._featurizer = MoleculeTransformer(\"maccs\", dtype=np.float32)\n        self._model = RandomForestRegressor()\n        self.train_dummy_model()\n\n    def train_dummy_model(self):\n        \"\"\"\n        Load the pretrained model.\n        In this dummy example, we train a RF model to predict the cLogP\n        \"\"\"\n        data = dm.data.freesolv().smiles.values\n        X = self._featurizer(data)\n        y = np.array([dm.descriptors.clogp(dm.to_mol(smi)) for smi in data])\n        self._model.fit(X, y)\n\n    def _convert(self, inputs: list, **kwargs):\n        \"\"\"Convert the molecule to a format that the model expects\"\"\"\n        return self._featurizer(inputs)\n\n    def _embed(self,  mols: list, **kwargs):\n        \"\"\"\n        Embed the molecules using the pretrained model\n        In this dummy example, we simply multiply the features by the importance of the feature\n        \"\"\"\n        return [feats * self._model.feature_importances_ for feats in mols]\n</pre> from sklearn.ensemble import RandomForestRegressor from molfeat.trans.pretrained import PretrainedMolTransformer   class MyFoundationModel(PretrainedMolTransformer):     \"\"\"     In this dummy example, we train a RF model to predict the cLogP     then use the feature importance of the RF model as the embedding.     \"\"\"      def __init__(self):         super().__init__(dtype=np.float32)         self._featurizer = MoleculeTransformer(\"maccs\", dtype=np.float32)         self._model = RandomForestRegressor()         self.train_dummy_model()      def train_dummy_model(self):         \"\"\"         Load the pretrained model.         In this dummy example, we train a RF model to predict the cLogP         \"\"\"         data = dm.data.freesolv().smiles.values         X = self._featurizer(data)         y = np.array([dm.descriptors.clogp(dm.to_mol(smi)) for smi in data])         self._model.fit(X, y)      def _convert(self, inputs: list, **kwargs):         \"\"\"Convert the molecule to a format that the model expects\"\"\"         return self._featurizer(inputs)      def _embed(self,  mols: list, **kwargs):         \"\"\"         Embed the molecules using the pretrained model         In this dummy example, we simply multiply the features by the importance of the feature         \"\"\"         return [feats * self._model.feature_importances_ for feats in mols] In\u00a0[6]: Copied! <pre>mol_transf = MyFoundationModel()\nmol_transf([\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"]).shape\n</pre> mol_transf = MyFoundationModel() mol_transf([\"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"]).shape Out[6]: <pre>(1, 167)</pre> <p>Here is another example that shows how to extend Molfeat with an existing embedding language model for astrochemistry.</p> <pre>pip install astrochem_embedding\n</pre> In\u00a0[7]: Copied! <pre>import torch\nimport datamol as dm\n\nfrom astrochem_embedding import VICGAE\nfrom molfeat.trans.pretrained import PretrainedMolTransformer\n\nclass MyAstroChemFeaturizer(PretrainedMolTransformer):\n    \"\"\"\n    In this more practical example, we use embeddings from VICGAE a variance-invariance-covariance \n    regularized GRU autoencoder trained on SELFIES strings.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)        \n        self.featurizer = VICGAE.from_pretrained()\n    \n    def _embed(self, smiles, **kwargs):\n        return [self.featurizer.embed_smiles(x) for x in smiles]\n\ntransformer = MyAstroChemFeaturizer(dtype=torch.float)\ntransformer(dm.freesolv()[\"smiles\"][:10]).shape\n</pre> import torch import datamol as dm  from astrochem_embedding import VICGAE from molfeat.trans.pretrained import PretrainedMolTransformer  class MyAstroChemFeaturizer(PretrainedMolTransformer):     \"\"\"     In this more practical example, we use embeddings from VICGAE a variance-invariance-covariance      regularized GRU autoencoder trained on SELFIES strings.     \"\"\"     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)                 self.featurizer = VICGAE.from_pretrained()          def _embed(self, smiles, **kwargs):         return [self.featurizer.embed_smiles(x) for x in smiles]  transformer = MyAstroChemFeaturizer(dtype=torch.float) transformer(dm.freesolv()[\"smiles\"][:10]).shape  Out[7]: <pre>torch.Size([10, 32])</pre> In\u00a0[8]: Copied! <pre>import platformdirs\nfrom molfeat.store.modelstore import ModelStore\nfrom molfeat.store import ModelInfo\n\npath = dm.fs.join(platformdirs.user_cache_dir(\"molfeat\"), \"custom_model_store\")\nstore = ModelStore(model_store_bucket=path)\nlen(store.available_models)\n</pre> import platformdirs from molfeat.store.modelstore import ModelStore from molfeat.store import ModelInfo  path = dm.fs.join(platformdirs.user_cache_dir(\"molfeat\"), \"custom_model_store\") store = ModelStore(model_store_bucket=path) len(store.available_models) Out[8]: <pre>1</pre> In\u00a0[9]: Copied! <pre># Let's define our model's info\ninfo = ModelInfo(\n    name = \"my_foundation_model\",\n    inputs = \"smiles\",\n    type=\"pretrained\",\n    group=\"my_group\",\n    version=0,\n    submitter=\"Datamol\",\n    description=\"Solves chemistry!\",\n    representation=\"vector\",\n    require_3D=False,\n    tags = [\"foundation_model\", \"random_forest\"],\n    authors= [\"Datamol\"],\n    reference = \"/fake/ref\"\n)\n\nstore.register(info)\nstore.available_models\n</pre> # Let's define our model's info info = ModelInfo(     name = \"my_foundation_model\",     inputs = \"smiles\",     type=\"pretrained\",     group=\"my_group\",     version=0,     submitter=\"Datamol\",     description=\"Solves chemistry!\",     representation=\"vector\",     require_3D=False,     tags = [\"foundation_model\", \"random_forest\"],     authors= [\"Datamol\"],     reference = \"/fake/ref\" )  store.register(info) store.available_models <pre>  0%|          | 0.00/4.00 [00:00&lt;?, ?B/s]</pre> <pre>2023-04-07 18:59:03.363 | INFO     | molfeat.store.modelstore:register:124 - Successfuly registered model my_foundation_model !\n</pre> Out[9]: <pre>[ModelInfo(name='my_foundation_model', inputs='smiles', type='pretrained', version=0, group='my_group', submitter='Datamol', description='Solves chemistry!', representation='vector', require_3D=False, tags=['foundation_model', 'random_forest'], authors=['Datamol'], reference='/fake/ref', created_at=datetime.datetime(2023, 4, 7, 18, 59, 3, 312234), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1')]</pre>"},{"location":"tutorials/add_your_own.html#define-your-own-calculator","title":"Define your own calculator\u00b6","text":"<p>Remember that a calculator is simply a <code>callable</code> that takes a molecule as input (either a RDKit <code>Chem.Mol</code> object or SMILES string) and returns a dictionary of features. We can thus easily define our own calculator!</p>"},{"location":"tutorials/add_your_own.html#define-your-own-transformer","title":"Define your own transformer\u00b6","text":"<p>The above example shows that in many cases, there's no direct need to create your own transformer class. You can simply use the <code>MoleculeTransformer</code> base class. In more complex cases, such as with pretrained models where batching would be advantageous, it is instead preferable to create your own subclass.</p>"},{"location":"tutorials/add_your_own.html#add-it-to-your-model-store","title":"Add it to your Model Store\u00b6","text":"<p>Molfeat has a Model Store to publish your models in a centralized location. The default is a read-only GCP bucket but you can replace this with your own file storage. This can, for example, be useful to share private featurizers with your team.</p>"},{"location":"tutorials/add_your_own.html#share-with-the-community","title":"Share with the community\u00b6","text":"<p>We invite you to share your featurizers with the community to help progress the field. To learn more, visit the developer documentation.</p>"},{"location":"tutorials/custom_model_store.html","title":"Create a custom modelstore","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import os\nfrom molfeat.store import ModelStore\nfrom molfeat.store import ModelInfo\n</pre> import os from molfeat.store import ModelStore from molfeat.store import ModelInfo In\u00a0[3]: Copied! <pre>ModelInfo.schema()[\"properties\"]\n</pre> ModelInfo.schema()[\"properties\"] Out[3]: <pre>{'name': {'title': 'Name', 'type': 'string'},\n 'inputs': {'title': 'Inputs', 'default': 'smiles', 'type': 'string'},\n 'type': {'title': 'Type',\n  'enum': ['pretrained', 'hand-crafted', 'hashed', 'count'],\n  'type': 'string'},\n 'version': {'title': 'Version', 'default': 0, 'type': 'integer'},\n 'group': {'title': 'Group', 'default': 'all', 'type': 'string'},\n 'submitter': {'title': 'Submitter', 'type': 'string'},\n 'description': {'title': 'Description', 'type': 'string'},\n 'representation': {'title': 'Representation',\n  'enum': ['graph', 'line-notation', 'vector', 'tensor', 'other'],\n  'type': 'string'},\n 'require_3D': {'title': 'Require 3D', 'default': False, 'type': 'boolean'},\n 'tags': {'title': 'Tags', 'type': 'array', 'items': {'type': 'string'}},\n 'authors': {'title': 'Authors', 'type': 'array', 'items': {'type': 'string'}},\n 'reference': {'title': 'Reference', 'type': 'string'},\n 'created_at': {'title': 'Created At',\n  'type': 'string',\n  'format': 'date-time'},\n 'sha256sum': {'title': 'Sha256Sum', 'type': 'string'},\n 'model_usage': {'title': 'Model Usage', 'type': 'string'}}</pre> <p>The current implementation of the <code>modelstore</code> has some limitations:</p> <ul> <li><p>Lack of versioning: The current implementation does not support versioning of models. It treats each model as a unique entity without distinguishing different versions.</p> </li> <li><p>Unique model names: Each model name must be unique within the store. Duplicate model names are not allowed.</p> </li> <li><p>Single store support: Currently, a ModelStore instance can only handle a single store, which means it can index and manage models from only one bucket path at a time.</p> </li> </ul> <p>Now, let's examine the default store.</p> In\u00a0[4]: Copied! <pre>os.environ.pop(\"MOLFEAT_MODEL_STORE_BUCKET\", None)\n</pre> os.environ.pop(\"MOLFEAT_MODEL_STORE_BUCKET\", None) Out[4]: <pre>'/var/folders/zt/ck4vrp4n4vsb0v16tnlh9h9m0000gn/T/tmp4dqvgaqh'</pre> In\u00a0[5]: Copied! <pre>default_store = ModelStore()\n</pre> default_store = ModelStore() In\u00a0[6]: Copied! <pre>default_store.model_store_bucket\n</pre> default_store.model_store_bucket Out[6]: <pre>'gs://molfeat-store-prod/artifacts/'</pre> In\u00a0[7]: Copied! <pre># the length of the model store corresponds to the number of model cards that have been registered\nlen(default_store)\n</pre> # the length of the model store corresponds to the number of model cards that have been registered len(default_store) Out[7]: <pre>45</pre> In\u00a0[8]: Copied! <pre>default_store.available_models[:10]\n</pre> default_store.available_models[:10] Out[8]: <pre>[ModelInfo(name='cats2d', inputs='smiles', type='hashed', version=0, group='all', submitter='Datamol', description='2D version of the 6 Potential Pharmacophore Points CATS (Chemically Advanced Template Search) pharmacophore. This version differs from `pharm2D-cats` on the process to make the descriptors fuzzy, which is closer to the original paper implementation. Implementation is based on work by Rajarshi Guha (08/26/07) and Chris Arthur (1/11/2015)', representation='vector', require_3D=False, tags=['CATS', 'hashed', '2D', 'pharmacophore', 'search'], authors=['Michael Reutlinger', 'Christian P Koch', 'Daniel Reker', 'Nickolay Todoroff', 'Petra Schneider', 'Tiago Rodrigues', 'Gisbert Schneider', 'Rajarshi Guha', 'Chris Arthur'], reference='https://doi.org/10.1021/ci050413p', created_at=datetime.datetime(2023, 5, 3, 0, 7, 6, 534648), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None),\n ModelInfo(name='cats3d', inputs='mol', type='hashed', version=0, group='all', submitter='Datamol', description='3D version of the 6 Potential Pharmacophore Points CATS (Chemically Advanced Template Search) pharmacophore. This version differs from `pharm3D-cats` on the process to make the descriptors fuzzy, which is closer to the original paper implementation. This version uses the 3D distance matrix between pharmacophoric points', representation='vector', require_3D=True, tags=['CATS', 'hashed', '3D', 'pharmacophore', 'search'], authors=['Michael Reutlinger', 'Christian Koch', 'Daniel Reker', 'Nickolay Todoroff', 'Petra Schneider', 'Tiago Rodrigues', 'Gisbert Schneider', 'Rajarshi Guha', 'Chris Arthur'], reference='https://doi.org/10.1021/ci050413p', created_at=datetime.datetime(2023, 5, 3, 0, 7, 9, 952490), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None),\n ModelInfo(name='mordred', inputs='mol', type='hand-crafted', version=0, group='all', submitter='Datamol', description='Mordred calculates over 1800 molecular descriptors, including constitutional, topological, electronic, and geometrical descriptors, among others. Both 2D and 3D descriptors are supported and optional.', representation='vector', require_3D=False, tags=['topological', 'physchem', 'mordred'], authors=['Hirotomo Moriwaki', 'Yu-Shi Tian', 'Norihito Kawashita', 'Tatsuya Takagi'], reference='https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0258-y', created_at=datetime.datetime(2023, 5, 3, 0, 7, 26, 38783), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None),\n ModelInfo(name='scaffoldkeys', inputs='smiles', type='hand-crafted', version=0, group='all', submitter='Datamol', description='Scaffold Keys are a method for representing scaffold using substructure features and were proposed by Peter Ertl in: Identification of Bioisosteric Scaffolds using Scaffold Keys', representation='vector', require_3D=False, tags=['scaffold', 'bioisosters', 'search'], authors=['Peter Ertl'], reference='https://chemrxiv.org/engage/chemrxiv/article-details/60c7558aee301c5479c7b1be', created_at=datetime.datetime(2023, 5, 3, 0, 7, 22, 832077), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None),\n ModelInfo(name='gin_supervised_contextpred', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with supervised learning and context prediction on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 2, 19, 51, 17, 228390), sha256sum='72dc062936b78b515ed5d0989f909ab7612496d698415d73826b974c9171504a', model_usage=None),\n ModelInfo(name='gin_supervised_edgepred', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with supervised learning and edge prediction on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 4, 710823), sha256sum='c1198b37239c3b733f5b48cf265af4c3a1e8c448e2e26cb53e3517fd096213de', model_usage=None),\n ModelInfo(name='gin_supervised_infomax', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with mutual information maximisation on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 6, 967631), sha256sum='78dc0f76cde2151f5aa403cbbffead0f24aeac4ce0b48dbfa2689e1a87b95216', model_usage=None),\n ModelInfo(name='gin_supervised_masking', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with masked modelling on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 9, 221083), sha256sum='c1c797e18312ad44ff089159cb1ed79fd4c67b3d5673c562f61621d95a5d7632', model_usage=None),\n ModelInfo(name='jtvae_zinc_no_kl', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='A JTVAE pre-trained on ZINC for molecule generation, without KL regularization', representation='other', require_3D=False, tags=['JTNN', 'JTVAE', 'dgl', 'pytorch', 'junction-tree', 'graph'], authors=['Wengong Jin', 'Regina Barzilay', 'Tommi Jaakkola'], reference='https://arxiv.org/abs/1802.04364v4', created_at=datetime.datetime(2023, 2, 2, 19, 51, 20, 468939), sha256sum='eab8ecb8a7542a8cdf97410cb27f72aaf374fefef6a1f53642cc5b310cf2b7f6', model_usage=None),\n ModelInfo(name='map4', inputs='smiles', type='hashed', version=0, group='fp', submitter='Datamol', description='MinHashed atom-pair fingerprint up to a diameter of four bonds (MAP4) is suitable for both small and large molecules by combining substructure and atom-pair concepts. In this fingerprint the circular substructures with radii of r\\u2009=\\u20091 and r\\u2009=\\u20092 bonds around each atom in an atom-pair are written as two pairs of SMILES, each pair being combined with the topological distance separating the two central atoms. These so-called atom-pair molecular shingles are hashed, and the resulting set of hashes is MinHashed to form the MAP4 fingerprint.', representation='vector', require_3D=False, tags=['minhashed', 'map4', 'atompair', 'substructure', 'morgan'], authors=['Alice Capecchi', 'Daniel Probst', 'Jean-Louis Reymond'], reference='https://doi.org/10.1186/s13321-020-00445-4', created_at=datetime.datetime(2023, 2, 16, 10, 29, 8, 550063), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None)]</pre> <p>You can also perform searches within the existing model store using either the full model card (which can be partially instantiated) or the information you have about the model.</p> In\u00a0[9]: Copied! <pre># you can use a model card for the search\nmy_model_card = default_store.available_models[0]\ndefault_store.search(my_model_card)\n</pre> # you can use a model card for the search my_model_card = default_store.available_models[0] default_store.search(my_model_card) Out[9]: <pre>[ModelInfo(name='cats2d', inputs='smiles', type='hashed', version=0, group='all', submitter='Datamol', description='2D version of the 6 Potential Pharmacophore Points CATS (Chemically Advanced Template Search) pharmacophore. This version differs from `pharm2D-cats` on the process to make the descriptors fuzzy, which is closer to the original paper implementation. Implementation is based on work by Rajarshi Guha (08/26/07) and Chris Arthur (1/11/2015)', representation='vector', require_3D=False, tags=['CATS', 'hashed', '2D', 'pharmacophore', 'search'], authors=['Michael Reutlinger', 'Christian P Koch', 'Daniel Reker', 'Nickolay Todoroff', 'Petra Schneider', 'Tiago Rodrigues', 'Gisbert Schneider', 'Rajarshi Guha', 'Chris Arthur'], reference='https://doi.org/10.1021/ci050413p', created_at=datetime.datetime(2023, 5, 3, 0, 7, 6, 534648), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None)]</pre> In\u00a0[10]: Copied! <pre># search by name\ndefault_store.search(name=\"jtvae_zinc_no_kl\")\n</pre> # search by name default_store.search(name=\"jtvae_zinc_no_kl\") Out[10]: <pre>[ModelInfo(name='jtvae_zinc_no_kl', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='A JTVAE pre-trained on ZINC for molecule generation, without KL regularization', representation='other', require_3D=False, tags=['JTNN', 'JTVAE', 'dgl', 'pytorch', 'junction-tree', 'graph'], authors=['Wengong Jin', 'Regina Barzilay', 'Tommi Jaakkola'], reference='https://arxiv.org/abs/1802.04364v4', created_at=datetime.datetime(2023, 2, 2, 19, 51, 20, 468939), sha256sum='eab8ecb8a7542a8cdf97410cb27f72aaf374fefef6a1f53642cc5b310cf2b7f6', model_usage=None)]</pre> In\u00a0[11]: Copied! <pre># Assume you forgot the name of the model, but know it is one of the pretrained models that uses graph as representation\ndefault_store.search(type=\"pretrained\", representation=\"graph\")\n</pre> # Assume you forgot the name of the model, but know it is one of the pretrained models that uses graph as representation default_store.search(type=\"pretrained\", representation=\"graph\") Out[11]: <pre>[ModelInfo(name='gin_supervised_contextpred', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with supervised learning and context prediction on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 2, 19, 51, 17, 228390), sha256sum='72dc062936b78b515ed5d0989f909ab7612496d698415d73826b974c9171504a', model_usage=None),\n ModelInfo(name='gin_supervised_edgepred', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with supervised learning and edge prediction on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 4, 710823), sha256sum='c1198b37239c3b733f5b48cf265af4c3a1e8c448e2e26cb53e3517fd096213de', model_usage=None),\n ModelInfo(name='gin_supervised_infomax', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with mutual information maximisation on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 6, 967631), sha256sum='78dc0f76cde2151f5aa403cbbffead0f24aeac4ce0b48dbfa2689e1a87b95216', model_usage=None),\n ModelInfo(name='gin_supervised_masking', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with masked modelling on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 9, 221083), sha256sum='c1c797e18312ad44ff089159cb1ed79fd4c67b3d5673c562f61621d95a5d7632', model_usage=None),\n ModelInfo(name='pcqm4mv2_graphormer_base', inputs='smiles', type='pretrained', version=0, group='graphormer', submitter='Datamol', description='Pretrained Graph Transformer on PCQM4Mv2 Homo-Lumo energy gap prediction using 2D molecular graphs.', representation='graph', require_3D=False, tags=['Graphormer', 'PCQM4Mv2', 'graph', 'pytorch', 'Microsoft'], authors=['Chengxuan Ying', 'Tianle Cai', 'Shengjie Luo', 'Shuxin Zheng', 'Guolin Ke', 'Di He', 'Yanming Shen', 'Tie-Yan Liu'], reference='https://arxiv.org/abs/2106.05234', created_at=datetime.datetime(2023, 2, 2, 19, 51, 19, 330147), sha256sum='9c298d589a2158eb513cb52191144518a2acab2cb0c04f1df14fca0f712fa4a1', model_usage=None)]</pre> <p>You can also load models based on their name, this is not the recommended way to explore models, because some models required a custom loading function</p> In\u00a0[12]: Copied! <pre>gin_model, gin_model_info = default_store.load(model_name=\"gin_supervised_infomax\")\n</pre> gin_model, gin_model_info = default_store.load(model_name=\"gin_supervised_infomax\") In\u00a0[13]: Copied! <pre>gin_model_info\n</pre> gin_model_info Out[13]: <pre>ModelInfo(name='gin_supervised_infomax', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with mutual information maximisation on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 6, 967631), sha256sum='78dc0f76cde2151f5aa403cbbffead0f24aeac4ce0b48dbfa2689e1a87b95216', model_usage=None)</pre> In\u00a0[14]: Copied! <pre>import tempfile\nimport os\n</pre> import tempfile import os <p>Let's start with a simple local temporary model store</p> In\u00a0[15]: Copied! <pre>temp_dir = tempfile.TemporaryDirectory()\ntemp_model_store = ModelStore(temp_dir.name)\ntemp_model_store.available_models\n</pre> temp_dir = tempfile.TemporaryDirectory() temp_model_store = ModelStore(temp_dir.name) temp_model_store.available_models Out[15]: <pre>[]</pre> <p>Let's look at the content of the temp dir</p> In\u00a0[16]: Copied! <pre>%%bash -s \"$temp_dir.name\"\ntree $1\n</pre> %%bash -s \"$temp_dir.name\" tree $1  <pre>/var/folders/zt/ck4vrp4n4vsb0v16tnlh9h9m0000gn/T/tmp5k07n15a\n\n0 directories, 0 files\n</pre> <p>Let's add the GIN model we just downloaded before. To register a new model, you need the following:</p> <ol> <li>Model weights (or None for pretrained models)</li> <li>Model card</li> <li>Serializing function for the model, which determines how to save the model.</li> </ol> <p>You can also pass additional keyword arguments for your <code>save_fn</code> through the <code>save_fn_kwargs</code> parameter. The <code>save_fn</code> is expected to be called as follows:</p> <pre>save_fn(model, &lt;model_upload_path&gt;, **save_fn_kwargs)\n</pre> <p>For example, here's a dummy <code>save_fn</code> using PyTorch:</p> <pre>import torch\nimport fsspec\ndef my_torch_save_fn(model, path, **kwargs):\n    with fsspec.open(path, 'wb') as f:\n        torch.save(model, f, **kwargs)\n    return path\n</pre> <p>Note that if you provide a custom saving function, you are responsible for handling the corresponding loading function that matches your saving function. If you're unsure, it's recommended to use the default loading function, which covers most cases you would encounter.</p> In\u00a0[17]: Copied! <pre>tmp_gin_model_info = gin_model_info.copy()\ntmp_gin_model_info.name = \"tmp_gin_supervised_infomax\"\n</pre> tmp_gin_model_info = gin_model_info.copy() tmp_gin_model_info.name = \"tmp_gin_supervised_infomax\" In\u00a0[18]: Copied! <pre>temp_model_store.register(modelcard=tmp_gin_model_info, model=gin_model)\n</pre> temp_model_store.register(modelcard=tmp_gin_model_info, model=gin_model) <pre>  0%|          | 0.00/7.12M [00:00&lt;?, ?B/s]</pre> <pre>2023-05-19 15:14:52.082 | INFO     | molfeat.store.modelstore:register:150 - Successfuly registered model tmp_gin_supervised_infomax !\n</pre> In\u00a0[19]: Copied! <pre>temp_model_store.available_models\n</pre> temp_model_store.available_models Out[19]: <pre>[ModelInfo(name='tmp_gin_supervised_infomax', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with mutual information maximisation on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 6, 967631), sha256sum='7a100a7eb680e62d98b0e1d3a906bf740f140dceda55b69a86ddf3fd78ace245', model_usage=None)]</pre> In\u00a0[21]: Copied! <pre>temp_model_store.load(\"tmp_gin_supervised_infomax\")\n</pre> temp_model_store.load(\"tmp_gin_supervised_infomax\") <pre>  0%|          | 0.00/663 [00:00&lt;?, ?B/s]</pre> <pre>  0%|          | 0.00/7.12M [00:00&lt;?, ?B/s]</pre> Out[21]: <pre>(GIN(\n   (dropout): Dropout(p=0.5, inplace=False)\n   (node_embeddings): ModuleList(\n     (0): Embedding(120, 300)\n     (1): Embedding(3, 300)\n   )\n   (gnn_layers): ModuleList(\n     (0): GINLayer(\n       (mlp): Sequential(\n         (0): Linear(in_features=300, out_features=600, bias=True)\n         (1): ReLU()\n         (2): Linear(in_features=600, out_features=300, bias=True)\n       )\n       (edge_embeddings): ModuleList(\n         (0): Embedding(6, 300)\n         (1): Embedding(3, 300)\n       )\n       (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n     (1): GINLayer(\n       (mlp): Sequential(\n         (0): Linear(in_features=300, out_features=600, bias=True)\n         (1): ReLU()\n         (2): Linear(in_features=600, out_features=300, bias=True)\n       )\n       (edge_embeddings): ModuleList(\n         (0): Embedding(6, 300)\n         (1): Embedding(3, 300)\n       )\n       (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n     (2): GINLayer(\n       (mlp): Sequential(\n         (0): Linear(in_features=300, out_features=600, bias=True)\n         (1): ReLU()\n         (2): Linear(in_features=600, out_features=300, bias=True)\n       )\n       (edge_embeddings): ModuleList(\n         (0): Embedding(6, 300)\n         (1): Embedding(3, 300)\n       )\n       (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n     (3): GINLayer(\n       (mlp): Sequential(\n         (0): Linear(in_features=300, out_features=600, bias=True)\n         (1): ReLU()\n         (2): Linear(in_features=600, out_features=300, bias=True)\n       )\n       (edge_embeddings): ModuleList(\n         (0): Embedding(6, 300)\n         (1): Embedding(3, 300)\n       )\n       (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n     (4): GINLayer(\n       (mlp): Sequential(\n         (0): Linear(in_features=300, out_features=600, bias=True)\n         (1): ReLU()\n         (2): Linear(in_features=600, out_features=300, bias=True)\n       )\n       (edge_embeddings): ModuleList(\n         (0): Embedding(6, 300)\n         (1): Embedding(3, 300)\n       )\n       (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n ),\n ModelInfo(name='tmp_gin_supervised_infomax', inputs='smiles', type='pretrained', version=0, group='dgllife', submitter='Datamol', description='GIN neural network model pre-trained with mutual information maximisation on molecules from ChEMBL.', representation='graph', require_3D=False, tags=['GIN', 'dgl', 'pytorch', 'graph'], authors=['Weihua Hu', 'Bowen Liu', 'Joseph Gomes', 'Marinka Zitnik', 'Percy Liang', 'Vijay Pande', 'Jure Leskovec'], reference='https://arxiv.org/abs/1905.12265', created_at=datetime.datetime(2023, 2, 14, 17, 42, 6, 967631), sha256sum='7a100a7eb680e62d98b0e1d3a906bf740f140dceda55b69a86ddf3fd78ace245', model_usage=None))</pre> <p>We can see that the new model <code>tmp_gin_supervised_infomax</code> has been saved</p> In\u00a0[22]: Copied! <pre># clean existing env file\n! rm -rf .env\n</pre> # clean existing env file ! rm -rf .env In\u00a0[23]: Copied! <pre>import os\nfrom molfeat.trans.pretrained.dgl_pretrained import PretrainedDGLTransformer\n# making sure that the default bucket is not set\nmodel = PretrainedDGLTransformer(kind=\"tmp_gin_supervised_infomax\", dtype=float)\n</pre> import os from molfeat.trans.pretrained.dgl_pretrained import PretrainedDGLTransformer # making sure that the default bucket is not set model = PretrainedDGLTransformer(kind=\"tmp_gin_supervised_infomax\", dtype=float) In\u00a0[24]: Copied! <pre>model.featurizer.store.model_store_bucket\n</pre> model.featurizer.store.model_store_bucket Out[24]: <pre>'gs://molfeat-store-prod/artifacts/'</pre> In\u00a0[26]: Copied! <pre>model([\"CCO\", \"CCN\"])\n</pre> model([\"CCO\", \"CCN\"]) <pre>\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nFile ~/Code/datamol-org/molfeat-core/molfeat/store/loader.py:99, in PretrainedStoreModel._load_or_raise(cls, name, download_path, store, **kwargs)\n     98 try:\n---&gt; 99     modelcard = store.search(name=name)[0]\n    100     artifact_dir = store.download(modelcard, download_path, **kwargs)\n\nIndexError: list index out of range\n\nDuring handling of the above exception, another exception occurred:\n\nModelStoreError                           Traceback (most recent call last)\n/Users/manu/Code/datamol-org/molfeat-core/docs/tutorials/custom_model_store.ipynb Cell 35 in &lt;cell line: 1&gt;()\n----&gt; &lt;a href='vscode-notebook-cell:/Users/manu/Code/datamol-org/molfeat-core/docs/tutorials/custom_model_store.ipynb#Y111sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; model([\"CCO\", \"CCN\"])\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/trans/base.py:376, in MoleculeTransformer.__call__(self, mols, enforce_dtype, ignore_errors, **kwargs)\n    351 def __call__(\n    352     self,\n    353     mols: List[Union[dm.Mol, str]],\n   (...)\n    356     **kwargs,\n    357 ):\n    358     r\"\"\"\n    359     Calculate features for molecules. Using __call__, instead of transform.\n    360     If ignore_error is True, a list of features and valid ids are returned.\n   (...)\n    374 \n    375     \"\"\"\n--&gt; 376     features = self.transform(mols, ignore_errors=ignore_errors, enforce_dtype=False, **kwargs)\n    377     ids = np.arange(len(features))\n    378     if ignore_errors:\n\nFile ~/.miniconda/envs/molfeat-dev/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140, in _wrap_method_output.&lt;locals&gt;.wrapped(self, X, *args, **kwargs)\n    138 @wraps(f)\n    139 def wrapped(self, X, *args, **kwargs):\n--&gt; 140     data_to_wrap = f(self, X, *args, **kwargs)\n    141     if isinstance(data_to_wrap, tuple):\n    142         # only wrap the first output for cross decomposition\n    143         return (\n    144             _wrap_data_with_container(method, data_to_wrap[0], X, self),\n    145             *data_to_wrap[1:],\n    146         )\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/trans/pretrained/base.py:208, in PretrainedMolTransformer.transform(self, smiles, **kwargs)\n    206 if len(mols) &gt; 0:\n    207     converted_mols = self._convert(mols, **kwargs)\n--&gt; 208     out = self._embed(converted_mols, **kwargs)\n    210     if not isinstance(out, list):\n    211         out = list(out)\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/trans/pretrained/dgl_pretrained.py:221, in PretrainedDGLTransformer._embed(self, smiles, **kwargs)\n    219 def _embed(self, smiles: List[str], **kwargs):\n    220     \"\"\"Embed molecules into a latent space\"\"\"\n--&gt; 221     self._preload()\n    222     dataset, successes = self.graph_featurizer(smiles, kind=self.kind)\n    223     if self.kind in DGLModel.available_models(query=\"^jtvae\"):\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/trans/pretrained/base.py:90, in PretrainedMolTransformer._preload(self)\n     88 \"\"\"Preload the pretrained model for later queries\"\"\"\n     89 if self.featurizer is not None and isinstance(self.featurizer, PretrainedModel):\n---&gt; 90     self.featurizer = self.featurizer.load()\n     91     self.preload = True\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/trans/pretrained/dgl_pretrained.py:85, in DGLModel.load(self)\n     83 if self._model is not None:\n     84     return self._model\n---&gt; 85 download_output_dir = self._artifact_load(\n     86     name=self.name, download_path=self.cache_path, store=self.store\n     87 )\n     88 model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)\n     89 with fsspec.open(model_path, \"rb\") as f:\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/store/loader.py:81, in PretrainedStoreModel._artifact_load(cls, name, download_path, **kwargs)\n     79 if not dm.fs.exists(download_path):\n     80     cls._load_or_raise.cache_clear()\n---&gt; 81 return cls._load_or_raise(name, download_path, **kwargs)\n\nFile ~/Code/datamol-org/molfeat-core/molfeat/store/loader.py:103, in PretrainedStoreModel._load_or_raise(cls, name, download_path, store, **kwargs)\n    101 except Exception as e:\n    102     mess = f\"Can't retrieve model {name} from the store !\"\n--&gt; 103     raise ModelStoreError(mess)\n    104 return artifact_dir\n\nModelStoreError: Can't retrieve model tmp_gin_supervised_infomax from the store !</pre> <p>As expected it's not working, we would need to either load the model first from our store on purpose or change the default loading bucket using the environment variable  <code>MOLFEAT_MODEL_STORE_BUCKET</code>.</p> In\u00a0[27]: Copied! <pre>%%bash -s \"$temp_dir.name\"\necho \"export MOLFEAT_MODEL_STORE_BUCKET=$1\" &gt; .env\n</pre> %%bash -s \"$temp_dir.name\" echo \"export MOLFEAT_MODEL_STORE_BUCKET=$1\" &gt; .env In\u00a0[28]: Copied! <pre># we reimport to reload the store information without restarting the kernel\nimport dotenv\ndotenv.load_dotenv(override=True)\nfrom molfeat.store import ModelStore # noqa: E402\nmodel = PretrainedDGLTransformer(kind=\"tmp_gin_supervised_infomax\", dtype=float)\n</pre> # we reimport to reload the store information without restarting the kernel import dotenv dotenv.load_dotenv(override=True) from molfeat.store import ModelStore # noqa: E402 model = PretrainedDGLTransformer(kind=\"tmp_gin_supervised_infomax\", dtype=float) In\u00a0[29]: Copied! <pre>model.featurizer.store.model_store_bucket\n</pre> model.featurizer.store.model_store_bucket Out[29]: <pre>'/var/folders/zt/ck4vrp4n4vsb0v16tnlh9h9m0000gn/T/tmp5k07n15a'</pre> In\u00a0[30]: Copied! <pre>model([\"CCO\", \"CCN\"]).shape\n</pre> model([\"CCO\", \"CCN\"]).shape Out[30]: <pre>(2, 300)</pre> <p>In the following example, we will explore how to setup a complex pretrained featurizer and load it from a personal modelstore.</p> <p>First, we need to install the following library to provide the embeddings. We are following the template from the previous tutorial to show how we can serialize the custom <code>astrochem_embedding</code> model into our private store.</p> <pre>pip install astrochem_embedding\n</pre> <p>For our customd model, we would need to define the loading process which dictates how the model should be loaded from the store. It's recommended to inherit from <code>PretrainedStoreModel</code> if you have a complex loading process.</p> In\u00a0[31]: Copied! <pre>import datamol as dm\nimport joblib\nimport fsspec\nimport torch\n\nfrom molfeat.trans.pretrained import PretrainedMolTransformer\nfrom molfeat.store.loader import PretrainedStoreModel\n\nclass AstroPretrainedStoreModel(PretrainedStoreModel):\n    r\"\"\"\n    Define a loading class to load the astrochem model from the store\n    \"\"\"\n\n    def load(self):\n        \"\"\"Load VICGAE model\"\"\"\n        download_output_dir = self._artifact_load(\n            name=self.name, download_path=self.cache_path, store=self.store\n        )\n        model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)\n        with fsspec.open(model_path, \"rb\") as f:\n            model = joblib.load(f)\n        model.eval()\n        return model\n</pre> import datamol as dm import joblib import fsspec import torch  from molfeat.trans.pretrained import PretrainedMolTransformer from molfeat.store.loader import PretrainedStoreModel  class AstroPretrainedStoreModel(PretrainedStoreModel):     r\"\"\"     Define a loading class to load the astrochem model from the store     \"\"\"      def load(self):         \"\"\"Load VICGAE model\"\"\"         download_output_dir = self._artifact_load(             name=self.name, download_path=self.cache_path, store=self.store         )         model_path = dm.fs.join(download_output_dir, self.store.MODEL_PATH_NAME)         with fsspec.open(model_path, \"rb\") as f:             model = joblib.load(f)         model.eval()         return model In\u00a0[32]: Copied! <pre># We define the model class for loading and transforming data\nclass MyAstroChemFeaturizer(PretrainedMolTransformer):\n    \"\"\"\n    In this more practical example, we use embeddings from VICGAE a variance-invariance-covariance \n    regularized GRU autoencoder trained on SELFIES strings.\n    \"\"\"\n    def __init__(self, name=\"astrochem_embedding\",  *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # we load the model from the store\n        self.model = AstroPretrainedStoreModel(name=name).load()\n    \n    def _embed(self, smiles, **kwargs):\n        return [self.model.embed_smiles(x) for x in smiles]\n</pre> # We define the model class for loading and transforming data class MyAstroChemFeaturizer(PretrainedMolTransformer):     \"\"\"     In this more practical example, we use embeddings from VICGAE a variance-invariance-covariance      regularized GRU autoencoder trained on SELFIES strings.     \"\"\"     def __init__(self, name=\"astrochem_embedding\",  *args, **kwargs):         super().__init__(*args, **kwargs)         # we load the model from the store         self.model = AstroPretrainedStoreModel(name=name).load()          def _embed(self, smiles, **kwargs):         return [self.model.embed_smiles(x) for x in smiles]  In\u00a0[38]: Copied! <pre>from astrochem_embedding import VICGAE\nmodel = VICGAE.from_pretrained()\n# Let's define our model's info card and then save the model to the store\ninfo = ModelInfo(\n    name = \"astrochem_embedding\",\n    inputs = \"selfies\",\n    type=\"pretrained\",\n    group=\"astrochem\",\n    version=0,\n    submitter=\"Datamol\",\n    description=\"A variance-invariance-covariance regularized GRU autoencoder for astrochemistry using selfies strings!\",\n    representation=\"vector\",\n    require_3D=False,\n    tags = [\"pretrained\", \"astrochemistry\", \"selfies\"],\n    authors= [\"Datamol\"],\n    reference = \"Lee, K. L. K. (2021). Language models for astrochemistry (Version 0.1.2) [Computer software]. https://github.com/laserkelvin/astrochem_embedding\",\n)\n\n# We define how to use the model using a string that can be displayed in the docs\nusage_string = \"\"\"\nimport torch\nimport datamol as dm\n# &lt;how to import MyAstroChemFeaturizer if needed&gt;\ntransformer = MyAstroChemFeaturizer(dtype=torch.float)\ntransformer(dm.freesolv()[\"smiles\"][:10]).shape\n\"\"\"\ninfo.set_usage(usage_string)\n\n# we register the model, this is a simple model that we can just pickle to the store bucket.\ntemp_model_store.register(info, model=model)\n</pre> from astrochem_embedding import VICGAE model = VICGAE.from_pretrained() # Let's define our model's info card and then save the model to the store info = ModelInfo(     name = \"astrochem_embedding\",     inputs = \"selfies\",     type=\"pretrained\",     group=\"astrochem\",     version=0,     submitter=\"Datamol\",     description=\"A variance-invariance-covariance regularized GRU autoencoder for astrochemistry using selfies strings!\",     representation=\"vector\",     require_3D=False,     tags = [\"pretrained\", \"astrochemistry\", \"selfies\"],     authors= [\"Datamol\"],     reference = \"Lee, K. L. K. (2021). Language models for astrochemistry (Version 0.1.2) [Computer software]. https://github.com/laserkelvin/astrochem_embedding\", )  # We define how to use the model using a string that can be displayed in the docs usage_string = \"\"\" import torch import datamol as dm #  transformer = MyAstroChemFeaturizer(dtype=torch.float) transformer(dm.freesolv()[\"smiles\"][:10]).shape \"\"\" info.set_usage(usage_string)  # we register the model, this is a simple model that we can just pickle to the store bucket. temp_model_store.register(info, model=model) <pre>  0%|          | 0.00/509k [00:00&lt;?, ?B/s]</pre> <pre>2023-05-19 15:16:59.293 | INFO     | molfeat.store.modelstore:register:150 - Successfuly registered model astrochem_embedding !\n</pre> In\u00a0[39]: Copied! <pre>print(info.usage())\n</pre> print(info.usage()) <pre>\nimport torch\nimport datamol as dm\n# &lt;how to import MyAstroChemFeaturizer if needed&gt;\ntransformer = MyAstroChemFeaturizer(dtype=torch.float)\ntransformer(dm.freesolv()[\"smiles\"][:10]).shape\n\n</pre> In\u00a0[40]: Copied! <pre># let's execute the test example and check\ntransformer = MyAstroChemFeaturizer(dtype=torch.float)\ntransformer(dm.freesolv()[\"smiles\"][:10]).shape\n</pre> # let's execute the test example and check transformer = MyAstroChemFeaturizer(dtype=torch.float) transformer(dm.freesolv()[\"smiles\"][:10]).shape <pre>  0%|          | 0.00/882 [00:00&lt;?, ?B/s]</pre> <pre>  0%|          | 0.00/509k [00:00&lt;?, ?B/s]</pre> Out[40]: <pre>torch.Size([10, 32])</pre> In\u00a0[41]: Copied! <pre># a bit of cleaning\ntemp_dir.cleanup()\n</pre> # a bit of cleaning temp_dir.cleanup() In\u00a0[42]: Copied! <pre>! rm -rf .env\n</pre> ! rm -rf .env <p>You can now create a private <code>modelstore</code> to save, index and share your custom models.</p>"},{"location":"tutorials/custom_model_store.html#modelstore","title":"Modelstore\u00b6","text":""},{"location":"tutorials/custom_model_store.html#introduction","title":"Introduction\u00b6","text":"<p>In the last tutorial, we learned how to create our own custom featurizer. In this tutorial, we will guide you through the process of creating a new <code>modelstore</code> to store our featurizer cards.</p>"},{"location":"tutorials/custom_model_store.html#key-concepts-of-the-modelstore","title":"Key concepts of the <code>modelstore</code>\u00b6","text":"<p>The ModelStore class allows you to serialize/register and load models. A <code>modelstore</code> is just a path to a bucket or a folder that contains information about our models (artifact such as model weights and a description of the model using the concept of model card).  It also provides functionality to list the available models in the store. Before creating a new model store, let's understand the key concepts:</p> <ul> <li><p>Model Artifact: It refers to the serialized representation of a model, typically the model weights or any object that needs to be saved.</p> </li> <li><p>Model Card: It contains information about a model, such as its name, description, and other metadata. The ModelInfo class represents a model card.</p> </li> <li><p>Model Store: It is a path to a bucket or a folder where the model artifacts and model cards are stored.</p> </li> </ul>"},{"location":"tutorials/custom_model_store.html#model-info-card","title":"Model Info Card\u00b6","text":"<p>A model (info) card, is a datastructure that describes a model. It has some required arguments such as:</p> <pre># name of the featurizer\n  name: ~ \n  # list of authors\n  authors: \n    - author 1\n  # describe the featurizer \n  description: ~ \n  # which type of input does the featurizer expect ? \n  inputs: ~ \n  # reference of the featurizer (a paper or a link)\n  reference: ~ \n  # what does the featurizer return as output for molecular representation ?\n  # one of ['graph', 'line-notation', 'vector', 'tensor', 'other']\n  representation: ~ \n  # does the featurizer require 3D information ?\n  require_3D:  ~ \n  # type of the featurizer, one of [\"pretrained\", \"hand-crafted\", \"hashed\", \"count\"]\n  type: ~ \n  # name of the person that is submitting the featurizer\n  submitter: ~\n</pre> <p>For registration of a model, you will always need to provide the model info card.</p>"},{"location":"tutorials/custom_model_store.html#creating-an-instance-of-modelstore","title":"Creating an instance of ModelStore\u00b6","text":""},{"location":"tutorials/custom_model_store.html#creating-a-custom-model-store","title":"Creating a Custom Model Store\u00b6","text":""},{"location":"tutorials/custom_model_store.html#model-store-bucket","title":"Model Store Bucket\u00b6","text":"<p>To create a custom model store, you need to specify a model store bucket path. By default, the code uses the read-only model store bucket located at <code>gs://molfeat-store-prod/artifacts/</code>. If you want to create a custom <code>modelstore</code> that includes the content of the default bucket, you can copy its contents to your custom bucket.</p> <p>There are two key concepts to understand when building a custom <code>modelstore</code>:</p> <ol> <li><p>Readable and Writable Path: You need to provide a local or remote folder path that is compatible with fsspec. This path will serve as your model store bucket, allowing you to store and access models.</p> </li> <li><p>Multiple Model Stores: You can create multiple instances of the <code>modelstore</code>, each representing a different model store. However, it's important to note that unless you manually load a model, only models present in the default model store bucket path of the <code>modelstore</code> can be loaded by their names. You can override the default model store bucket path by setting the <code>MOLFEAT_MODEL_STORE_BUCKET</code> environment variable. Currently, we use a single source of truth to simplify the registration and loading process.</p> </li> </ol> <p>By understanding these concepts, you can create a custom model store by specifying a suitable model store bucket path and optionally copying the content from the default bucket. This allows you to have control over your model store and manage models according to your specific needs.</p>"},{"location":"tutorials/custom_model_store.html#loading-model-from-a-custom-model-store","title":"Loading model from a custom model store\u00b6","text":""},{"location":"tutorials/custom_model_store.html#going-a-bit-further-serializing-a-custom-pretrained-model-into-a-private-model-store","title":"Going a bit further: serializing a custom pretrained model into a private model store\u00b6","text":""},{"location":"tutorials/datacache.html","title":"The Data Cache","text":"In\u00a0[17]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 <pre>The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n</pre> In\u00a0[18]: Copied! <pre>import datamol as dm\n\nfrom molfeat.trans.base import PrecomputedMolTransformer\nfrom molfeat.utils.cache import DataCache, FileCache\nfrom molfeat.trans.pretrained import FCDTransformer\n</pre> import datamol as dm  from molfeat.trans.base import PrecomputedMolTransformer from molfeat.utils.cache import DataCache, FileCache from molfeat.trans.pretrained import FCDTransformer In\u00a0[19]: Copied! <pre>data = dm.data.freesolv().sample(500)\nsmiles_col = \"smiles\"\nmolecules = data[\"smiles\"].values\ntargets = data[\"expt\"].values\n</pre> data = dm.data.freesolv().sample(500) smiles_col = \"smiles\" molecules = data[\"smiles\"].values targets = data[\"expt\"].values In\u00a0[20]: Copied! <pre># Define cache and transformer. It can be any types of featurizer\n\ncache = FileCache(\n    name=\"fcd_cache_test\",\n    cache_file=\"fcd_cache.parquet\",\n    file_type=\"parquet\",\n    mol_hasher=\"dm.unique_id\",\n)\n\ntransformer = FCDTransformer()\n</pre> # Define cache and transformer. It can be any types of featurizer  cache = FileCache(     name=\"fcd_cache_test\",     cache_file=\"fcd_cache.parquet\",     file_type=\"parquet\",     mol_hasher=\"dm.unique_id\", )  transformer = FCDTransformer() In\u00a0[21]: Copied! <pre># # pregenerate the features and store in cache files\n_ = cache(molecules, transformer)\ncache.save_to_file(filepath=cache.name)\n</pre> # # pregenerate the features and store in cache files _ = cache(molecules, transformer) cache.save_to_file(filepath=cache.name) <p>You can check whether a cache contains a molecule or not</p> In\u00a0[22]: Copied! <pre># benzene\nbenzene = dm.to_mol('c1ccccc1')\nbenzene in cache\n</pre> # benzene benzene = dm.to_mol('c1ccccc1') benzene in cache Out[22]: <pre>True</pre> In\u00a0[23]: Copied! <pre># paracetamol\nparacetamol = dm.to_mol('CC(=O)Nc1ccc(cc1)O')\nparacetamol in cache\n</pre> # paracetamol paracetamol = dm.to_mol('CC(=O)Nc1ccc(cc1)O') paracetamol in cache Out[23]: <pre>False</pre> <p>You can fetch the information of a molecule from the cache</p> In\u00a0[24]: Copied! <pre>fps = cache.get(benzene)\nfps.shape\n</pre> fps = cache.get(benzene) fps.shape Out[24]: <pre>(512,)</pre> <p>You can also serialize a cache by converting it to a state dict</p> In\u00a0[25]: Copied! <pre>cache.to_state_dict()\n</pre> cache.to_state_dict() Out[25]: <pre>{'_cache_name': 'FileCache',\n 'cache_file': 'fcd_cache.parquet',\n 'name': 'fcd_cache_test',\n 'n_jobs': None,\n 'verbose': False,\n 'file_type': 'parquet',\n 'clear_on_exit': True,\n 'parquet_kwargs': {},\n 'mol_hasher': {'hash_name': 'dm.unique_id'}}</pre> <p>You can load a new cache from the serialized state dict or another cache. Or even load a cache from the cache file directly.</p> In\u00a0[26]: Copied! <pre>reload_cache = FileCache.load_from_file(\"fcd_cache.parquet\",\n    file_type=\"parquet\",\n    mol_hasher=\"dm.unique_id\",\n)\nlen(reload_cache)\n</pre> reload_cache = FileCache.load_from_file(\"fcd_cache.parquet\",     file_type=\"parquet\",     mol_hasher=\"dm.unique_id\", ) len(reload_cache) Out[26]: <pre>609</pre> In\u00a0[27]: Copied! <pre>reload_state_dict_cache = FileCache.from_state_dict(cache.to_state_dict())\nlen(reload_state_dict_cache)\n</pre> reload_state_dict_cache = FileCache.from_state_dict(cache.to_state_dict()) len(reload_state_dict_cache) Out[27]: <pre>609</pre> <p>You can copy the content of a cache file into another cache file. Regardless of the type of cache.</p> In\u00a0[28]: Copied! <pre># load pregenerated features from files\nmemorycache = DataCache(\n    name=\"fcd_cache_memory\",\n    n_jobs=-1,\n    mol_hasher=dm.unique_id,\n    delete_on_exit=True # we delete anything related to the cache at py exit\n)\nmemorycache.update(cache)\nlen(memorycache)\n</pre> # load pregenerated features from files memorycache = DataCache(     name=\"fcd_cache_memory\",     n_jobs=-1,     mol_hasher=dm.unique_id,     delete_on_exit=True # we delete anything related to the cache at py exit ) memorycache.update(cache) len(memorycache) Out[28]: <pre>609</pre> In\u00a0[29]: Copied! <pre>%%timeit -n 1 -r 3\ntransformer = PrecomputedMolTransformer(cache=cache, featurizer=FCDTransformer())\ntransformer(molecules)\n</pre> %%timeit -n 1 -r 3 transformer = PrecomputedMolTransformer(cache=cache, featurizer=FCDTransformer()) transformer(molecules) <pre>291 ms \u00b1 21.2 ms per loop (mean \u00b1 std. dev. of 3 runs, 1 loop each)\n</pre> In\u00a0[30]: Copied! <pre>%%timeit -n 1 -r 3\ntransformer = FCDTransformer()\ntransformer(molecules)\n</pre> %%timeit -n 1 -r 3 transformer = FCDTransformer() transformer(molecules) <pre>2.17 s \u00b1 120 ms per loop (mean \u00b1 std. dev. of 3 runs, 1 loop each)\n</pre> <p>By computing the features once on you dataset, you can gain astonishing speed on featurization later.</p> <p>Even better, the <code>PrecomputedMolTransformer</code> class provides a <code>batch_transform</code> function that can leverage parallel computing with shared memory for further performance gains. The <code>batch_transform</code> method allows you to both compute features and cache them in a multiprocessing setting for maximum efficiency. This could be relevant for featurizers that accept a batch of molecules, since the normal caching system computes the feature one molecule at a time.</p> In\u00a0[31]: Copied! <pre>from copy import deepcopy\ncache_empty = deepcopy(cache)\n# clear the empty cache\ncache_empty.clear()\nlen(cache_empty)\n</pre> from copy import deepcopy cache_empty = deepcopy(cache) # clear the empty cache cache_empty.clear() len(cache_empty) Out[31]: <pre>0</pre> In\u00a0[32]: Copied! <pre>%%timeit -n 1 -r 1\ntransformer = PrecomputedMolTransformer(cache=cache_empty, featurizer=FCDTransformer())\ntransformer.batch_transform(transformer, molecules, n_jobs=-1, batch_size=50)\n</pre> %%timeit -n 1 -r 1 transformer = PrecomputedMolTransformer(cache=cache_empty, featurizer=FCDTransformer()) transformer.batch_transform(transformer, molecules, n_jobs=-1, batch_size=50) <pre>Batch compute::   0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>39.7 s \u00b1 0 ns per loop (mean \u00b1 std. dev. of 1 run, 1 loop each)\n</pre> In\u00a0[33]: Copied! <pre># now we have all 500 molecules cached \nlen(cache_empty)\n</pre> # now we have all 500 molecules cached  len(cache_empty) Out[33]: <pre>500</pre>"},{"location":"tutorials/datacache.html#caching-features","title":"Caching features\u00b6","text":"<p>molfeat offers a caching system to accelerate molecular featurization. There are two main types of caching systems offered in Molfeat:</p>"},{"location":"tutorials/datacache.html#datacache","title":"DataCache\u00b6","text":"<p><code>DataCache</code> is the default, mostly in memory caching system of <code>molfeat</code>. The underlying cache system of <code>DataCache</code> is simply a dictionary. To improve efficiency, <code>DataCache</code> also supports shelf for object persistence.  See the relevant documentation to learn more about <code>DataCache</code>.</p>"},{"location":"tutorials/datacache.html#filecache","title":"FileCache\u00b6","text":"<p><code>FileCache</code> takes a file-based serialization approach to establish the underlying caching system. <code>FileCache</code> supports <code>pickle</code>, <code>parquet</code> and <code>csv</code> formats. We recommend the <code>parquet</code> file format for its efficiency.</p> <p>For both <code>FileCache</code> and <code>DataCache</code>, the key used to save and retrieve a molecular representation is <code>datamol.unique_id</code>. Alternatively, you can use inchikey, which is less robust (e.g. does not differentiate tautomers) or even define your own molecular hashing function that you can pass as input to the cache object.</p>"},{"location":"tutorials/datacache.html#cache-properties","title":"Cache properties\u00b6","text":""},{"location":"tutorials/datacache.html#using-a-cache-with-a-precomputed-transformer","title":"Using a cache with a precomputed transformer\u00b6","text":"<p>Some molecular transformers natively support a <code>precompute_cache</code> attribute that can be used to cache featurization or load cache state into a new featurizer.</p> <p>molfeat also provides a <code>PrecomputedMolTransformer</code> class that makes the process easier which allows you to quickly build a new transformer from an existing cache. Similar to any <code>MoleculeTransformer</code>, you can serialize the state of a <code>PrecomputedMolTransformer</code> and reload it easily.</p>"},{"location":"tutorials/graphs.html","title":"Featurizing graphs","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>import datamol as dm\nfrom rdkit.Chem.Draw import IPythonConsole\n\n# Let's use Caffeine as a running example\nsmi = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"\nIPythonConsole.drawOptions.addBondIndices = True\nmol = dm.to_mol(smi)\nmol\n</pre> import datamol as dm from rdkit.Chem.Draw import IPythonConsole  # Let's use Caffeine as a running example smi = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\" IPythonConsole.drawOptions.addBondIndices = True mol = dm.to_mol(smi) mol Out[2]: In\u00a0[3]: Copied! <pre>from molfeat.calc.atom import AtomCalculator\n\nac = AtomCalculator()\nac(smi)[\"hv\"].shape\n</pre> from molfeat.calc.atom import AtomCalculator  ac = AtomCalculator() ac(smi)[\"hv\"].shape Out[3]: <pre>(14, 82)</pre> In\u00a0[4]: Copied! <pre># To get a better sense of what's going on, you can set `concat=False`\nac = AtomCalculator(concat=False)\nac(smi).keys()\n</pre> # To get a better sense of what's going on, you can set `concat=False` ac = AtomCalculator(concat=False) ac(smi).keys() Out[4]: <pre>dict_keys(['atom_one_hot', 'atom_degree_one_hot', 'atom_implicit_valence_one_hot', 'atom_hybridization_one_hot', 'atom_is_aromatic', 'atom_formal_charge', 'atom_num_radical_electrons', 'atom_is_in_ring', 'atom_total_num_H_one_hot', 'atom_chiral_tag_one_hot', 'atom_is_chiral_center'])</pre> In\u00a0[5]: Copied! <pre>ac(smi)[\"atom_one_hot\"].shape\n</pre> ac(smi)[\"atom_one_hot\"].shape Out[5]: <pre>(14, 43)</pre> In\u00a0[6]: Copied! <pre>def is_transition_metal(atom):\n    \"\"\"Check whether an atom is a transition metal\"\"\"\n    n = atom.GetAtomicNum()\n    return [(22 &lt;= n &lt;= 29) or (40 &lt;= n &lt;= 47) or (72 &lt;= n &lt;= 79)]\n\n\nmy_feats = {\"is_transition_metal\": is_transition_metal}\nmy_ac = AtomCalculator(featurizer_funcs=my_feats, concat=False)\nmy_ac(smi)\n</pre> def is_transition_metal(atom):     \"\"\"Check whether an atom is a transition metal\"\"\"     n = atom.GetAtomicNum()     return [(22 &lt;= n &lt;= 29) or (40 &lt;= n &lt;= 47) or (72 &lt;= n &lt;= 79)]   my_feats = {\"is_transition_metal\": is_transition_metal} my_ac = AtomCalculator(featurizer_funcs=my_feats, concat=False) my_ac(smi) Out[6]: <pre>{'is_transition_metal': array([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], dtype=float32)}</pre> <p>By default the input molecule is not ordered in any specific way, so if you want some canonical atom ranking, you would need to take care of that independently. Alternatively, you can use the <code>GraphTransformer</code> classes.</p> In\u00a0[7]: Copied! <pre>from molfeat.calc.bond import BondCalculator\n</pre> from molfeat.calc.bond import BondCalculator In\u00a0[8]: Copied! <pre>bc = BondCalculator()\nout = bc(smi)\nout[\"he\"].shape\n</pre> bc = BondCalculator() out = bc(smi) out[\"he\"].shape Out[8]: <pre>(30, 15)</pre> In\u00a0[9]: Copied! <pre># Or, again, to be more verbose:\nbc = BondCalculator(concat=False)\nout = bc(smi)\nout.keys()\n</pre> # Or, again, to be more verbose: bc = BondCalculator(concat=False) out = bc(smi) out.keys() Out[9]: <pre>dict_keys(['bond_type_one_hot', 'bond_stereo_one_hot', 'bond_is_in_ring', 'bond_is_conjugated', 'bond_direction_one_hot'])</pre> In\u00a0[10]: Copied! <pre># You can also add self-loops: Edges from an atom to itself\nbc = BondCalculator(self_loop=True)\nout = bc(smi)\nout[\"he\"].shape\n</pre> # You can also add self-loops: Edges from an atom to itself bc = BondCalculator(self_loop=True) out = bc(smi) out[\"he\"].shape Out[10]: <pre>(44, 16)</pre> In\u00a0[11]: Copied! <pre>from molfeat.calc.bond import EdgeMatCalculator\n</pre> from molfeat.calc.bond import EdgeMatCalculator In\u00a0[12]: Copied! <pre>edge_feat = EdgeMatCalculator()\nprint(edge_feat.pairwise_atom_funcs)\n</pre> edge_feat = EdgeMatCalculator() print(edge_feat.pairwise_atom_funcs) <pre>{'pairwise_2D_dist': &lt;function pairwise_2D_dist at 0x1704bd630&gt;, 'pairwise_ring_membership': &lt;function pairwise_ring_membership at 0x1704bd900&gt;}\n</pre> In\u00a0[13]: Copied! <pre>edge_feat(smi)[\"he\"].shape\n</pre> edge_feat(smi)[\"he\"].shape Out[13]: <pre>(196, 17)</pre> <p>Let's replace the pairwise 2D distance by a 3D distance</p> In\u00a0[14]: Copied! <pre>from molfeat.calc._atom_bond_features import pairwise_3D_dist\n\nmy_edge_feat = dict(\n    pairwise_ring_membership=edge_feat.pairwise_atom_funcs[\"pairwise_ring_membership\"],\n    pairwise_3D_dist=pairwise_3D_dist,\n)\nnew_edge_feat = EdgeMatCalculator(pairwise_atom_funcs=my_edge_feat)\nlen(new_edge_feat)\n</pre> from molfeat.calc._atom_bond_features import pairwise_3D_dist  my_edge_feat = dict(     pairwise_ring_membership=edge_feat.pairwise_atom_funcs[\"pairwise_ring_membership\"],     pairwise_3D_dist=pairwise_3D_dist, ) new_edge_feat = EdgeMatCalculator(pairwise_atom_funcs=my_edge_feat) len(new_edge_feat) Out[14]: <pre>17</pre> In\u00a0[15]: Copied! <pre># To use the 3D distance, we need to generate 3D conformers\nmol = dm.to_mol(smi)\nmol = dm.conformers.generate(mol)\n</pre> # To use the 3D distance, we need to generate 3D conformers mol = dm.to_mol(smi) mol = dm.conformers.generate(mol) <p>Let's ask for a tensor and also instead of a $({N_{atoms}}^2, Feats)$ features, let ask for a $(N_{atoms}, N_{atoms}, Feats)$ matrix</p> In\u00a0[16]: Copied! <pre>import torch\n\nnew_edge_feat(mol, dtype=torch.float, flat=False)[\"he\"].shape\n</pre> import torch  new_edge_feat(mol, dtype=torch.float, flat=False)[\"he\"].shape Out[16]: <pre>torch.Size([14, 14, 17])</pre> In\u00a0[17]: Copied! <pre>from molfeat.trans.graph import AdjGraphTransformer\nfrom molfeat.trans.graph import DistGraphTransformer3D\nfrom molfeat.trans.graph import DGLGraphTransformer\nfrom molfeat.trans.graph import PYGGraphTransformer\n</pre> from molfeat.trans.graph import AdjGraphTransformer from molfeat.trans.graph import DistGraphTransformer3D from molfeat.trans.graph import DGLGraphTransformer from molfeat.trans.graph import PYGGraphTransformer In\u00a0[18]: Copied! <pre>adj_trans = AdjGraphTransformer(\n    atom_featurizer=AtomCalculator(),\n    bond_featurizer=EdgeMatCalculator(),\n    explicit_hydrogens=True,\n    self_loop=True,\n    canonical_atom_order=True,\n    dtype=torch.float,\n)\nadj_trans.atom_dim, adj_trans.bond_dim\n</pre> adj_trans = AdjGraphTransformer(     atom_featurizer=AtomCalculator(),     bond_featurizer=EdgeMatCalculator(),     explicit_hydrogens=True,     self_loop=True,     canonical_atom_order=True,     dtype=torch.float, ) adj_trans.atom_dim, adj_trans.bond_dim Out[18]: <pre>(82, 17)</pre> In\u00a0[19]: Copied! <pre>features = adj_trans(smi)\ngraph, atom_x, bond_x = features[0]\ngraph.shape, atom_x.shape, bond_x.shape\n</pre> features = adj_trans(smi) graph, atom_x, bond_x = features[0] graph.shape, atom_x.shape, bond_x.shape Out[19]: <pre>(torch.Size([14, 14]), torch.Size([14, 82]), torch.Size([14, 14, 17]))</pre> In\u00a0[20]: Copied! <pre>dist_trans = DistGraphTransformer3D(\n    explicit_hydrogens=False,\n    canonical_atom_order=True,\n    dtype=torch.float,\n)\n\ndist_trans.atom_dim, dist_trans.bond_dim\n</pre> dist_trans = DistGraphTransformer3D(     explicit_hydrogens=False,     canonical_atom_order=True,     dtype=torch.float, )  dist_trans.atom_dim, dist_trans.bond_dim Out[20]: <pre>(82, 0)</pre> In\u00a0[21]: Copied! <pre># we don't have bond feature here\nfeatures = dist_trans(mol)\ngraph, atom_x = features[0]\ngraph.shape, atom_x.shape, bond_x.shape\n</pre> # we don't have bond feature here features = dist_trans(mol) graph, atom_x = features[0] graph.shape, atom_x.shape, bond_x.shape Out[21]: <pre>(torch.Size([14, 14]), torch.Size([14, 82]), torch.Size([14, 14, 17]))</pre> In\u00a0[22]: Copied! <pre># we need the bond featurizer to include self_loop if the featurizer is supposed too\ndgl_trans = DGLGraphTransformer(\n    self_loop=True,\n    bond_featurizer=BondCalculator(self_loop=True),\n    canonical_atom_order=True,\n    dtype=torch.float,\n)\n</pre> # we need the bond featurizer to include self_loop if the featurizer is supposed too dgl_trans = DGLGraphTransformer(     self_loop=True,     bond_featurizer=BondCalculator(self_loop=True),     canonical_atom_order=True,     dtype=torch.float, ) In\u00a0[23]: Copied! <pre>dgl_trans.atom_dim, dgl_trans.bond_dim\n</pre> dgl_trans.atom_dim, dgl_trans.bond_dim Out[23]: <pre>(82, 16)</pre> In\u00a0[24]: Copied! <pre># we don't have bond feature here\nfeatures = dgl_trans(smi)\nfeatures[0]\n</pre> # we don't have bond feature here features = dgl_trans(smi) features[0] Out[24]: <pre>Graph(num_nodes=14, num_edges=44,\n      ndata_schemes={'hv': Scheme(shape=(82,), dtype=torch.float32)}\n      edata_schemes={'he': Scheme(shape=(16,), dtype=torch.float32)})</pre> In\u00a0[25]: Copied! <pre>from dgllife.utils.featurizers import WeaveEdgeFeaturizer\nfrom dgllife.utils.featurizers import WeaveAtomFeaturizer\n</pre> from dgllife.utils.featurizers import WeaveEdgeFeaturizer from dgllife.utils.featurizers import WeaveAtomFeaturizer In\u00a0[26]: Copied! <pre># here we set complete graph to True, which requires compatibility from the atom and bond featurizer\ndgl_trans = DGLGraphTransformer(\n    self_loop=True,\n    atom_featurizer=WeaveAtomFeaturizer(),\n    bond_featurizer=WeaveEdgeFeaturizer(),\n    canonical_atom_order=True,\n    complete_graph=True,\n    verbose=True,\n    dtype=torch.float,\n)\n</pre> # here we set complete graph to True, which requires compatibility from the atom and bond featurizer dgl_trans = DGLGraphTransformer(     self_loop=True,     atom_featurizer=WeaveAtomFeaturizer(),     bond_featurizer=WeaveEdgeFeaturizer(),     canonical_atom_order=True,     complete_graph=True,     verbose=True,     dtype=torch.float, ) In\u00a0[27]: Copied! <pre>dgl_trans.atom_dim, dgl_trans.bond_dim\n</pre> dgl_trans.atom_dim, dgl_trans.bond_dim Out[27]: <pre>(27, 12)</pre> In\u00a0[28]: Copied! <pre>features = dgl_trans(smi)\nfeatures[0]\n</pre> features = dgl_trans(smi) features[0] Out[28]: <pre>Graph(num_nodes=14, num_edges=196,\n      ndata_schemes={'h': Scheme(shape=(27,), dtype=torch.float32)}\n      edata_schemes={'e': Scheme(shape=(12,), dtype=torch.float32)})</pre> In\u00a0[29]: Copied! <pre># You can also create a PyG graph featurizer, the same way you define a DGL graph featurizer\n\npyg_trans = PYGGraphTransformer(\n    atom_featurizer=AtomCalculator(),\n    bond_featurizer=BondCalculator(self_loop=True),\n    self_loop=True,\n    canonical_atom_order=True,\n    dtype=torch.float,\n)\npyg_trans.atom_dim, pyg_trans.bond_dim\n</pre> # You can also create a PyG graph featurizer, the same way you define a DGL graph featurizer  pyg_trans = PYGGraphTransformer(     atom_featurizer=AtomCalculator(),     bond_featurizer=BondCalculator(self_loop=True),     self_loop=True,     canonical_atom_order=True,     dtype=torch.float, ) pyg_trans.atom_dim, pyg_trans.bond_dim Out[29]: <pre>(82, 16)</pre> In\u00a0[30]: Copied! <pre>features = dgl_trans(smi)\nfeatures[0]\n</pre> features = dgl_trans(smi) features[0] Out[30]: <pre>Graph(num_nodes=14, num_edges=196,\n      ndata_schemes={'h': Scheme(shape=(27,), dtype=torch.float32)}\n      edata_schemes={'e': Scheme(shape=(12,), dtype=torch.float32)})</pre> In\u00a0[31]: Copied! <pre>from molfeat.trans.graph import MolTreeDecompositionTransformer\n</pre> from molfeat.trans.graph import MolTreeDecompositionTransformer In\u00a0[32]: Copied! <pre>tree_trans = MolTreeDecompositionTransformer()\ntree_trans.fit([smi])\n</pre> tree_trans = MolTreeDecompositionTransformer() tree_trans.fit([smi]) Out[32]: <pre>MolTreeDecompositionTransformer(featurizer=&lt;molfeat.calc.tree.TreeDecomposer object at 0x1794cead0&gt;,\n                                n_jobs=1, verbose=False)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.MolTreeDecompositionTransformer<pre>MolTreeDecompositionTransformer(featurizer=&lt;molfeat.calc.tree.TreeDecomposer object at 0x1794cead0&gt;,\n                                n_jobs=1, verbose=False)</pre> In\u00a0[33]: Copied! <pre>features = tree_trans(smi)\nfeatures[0]\n</pre> features = tree_trans(smi) features[0] Out[33]: <pre>Graph(num_nodes=7, num_edges=12,\n      ndata_schemes={'hv': Scheme(shape=(), dtype=torch.int64)}\n      edata_schemes={})</pre>"},{"location":"tutorials/graphs.html#graph-transformers","title":"Graph transformers\u00b6","text":"<p>Graph featurizers in Molfeat are organized into pure tensor-based featurizers <code>dgl</code> backed graphs and <code>pyg</code> graphs, all inheriting from <code>molfeat.trans.graph.GraphTransformer</code>. Similar to molecular descriptors and fingerprints, there is a notion of the atom and bond featurizers which you can define to build your own custom graph featurizers. Some of the dgl featurizers are deeply integrated into the <code>dgl</code> and <code>dgllife</code> API allowing you to directly use your custom featurizers with these packages.</p>"},{"location":"tutorials/graphs.html#atomcalculator","title":"AtomCalculator\u00b6","text":"<p>Each atom featurizer takes as input an atom (assuming information on its environment is maintained) and returns its features:</p>"},{"location":"tutorials/graphs.html#add-a-custom-featurizer","title":"Add a custom featurizer\u00b6","text":"<p>Custom descriptors can be added by changing the passing of a dictionary of named Callables. These are Callables that take in the atom and return a list of features.</p>"},{"location":"tutorials/graphs.html#bondcalculator","title":"BondCalculator\u00b6","text":"<p>Bond featurizers are similar in principle to the atom featurizers. They featurize bonds in a molecule. In Molfeat we make the distinction between:</p> <ul> <li><code>BondCalculator</code>: a pure bond featurizer that will only featurize bonds in the molecules (we assume a bigraph)</li> <li><code>EdgeMatCalculator</code>: an edge featurizer that returns features between all pairs of atoms. For example you may want to define some distance-based properties between pairs of atoms.</li> </ul>"},{"location":"tutorials/graphs.html#edgematcalculator","title":"EdgeMatCalculator\u00b6","text":"<p>In the following, we will give an overview of the EdgeMatCalculator. This edge featurizer defines the same bond featurizer but has an additional pairwise distance function.</p> <p>Due to its nature, all features need to be concatenated by default with this featurizer!</p>"},{"location":"tutorials/graphs.html#putting-all-together","title":"Putting all together\u00b6","text":"<p>With the ability to define our own node and edge featurizers, we can define any graph featurizer of interest. Strong defaults are made available in Molfeat:</p>"},{"location":"tutorials/graphs.html#tree-calculator","title":"Tree Calculator\u00b6","text":"<p>The tree calculator is straightforward and only a dgl datatype is supported. It's the tree decomposition behind the Junction Tree Variational Autoencoder.</p>"},{"location":"tutorials/integrations.html","title":"Integration with scikit-learn and PyTorch","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nfrom torch import nn\nimport datamol as dm\nimport matplotlib.pyplot as plt\n</pre> %load_ext autoreload %autoreload 2  import torch from torch import nn import datamol as dm import matplotlib.pyplot as plt <p>All transformers in Molfeat are a subclass of <code>MoleculeTransformer</code> which in turns implements the <code>BaseFeaturizer</code> interface. The <code>BaseFeaturizer</code> interface ensures that transformers are compatible with both Scikit-Learn and deep learning frameworks, such as PyTorch and DGL.</p> In\u00a0[2]: Copied! <pre>from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\n\nfrom molfeat.trans import MoleculeTransformer\n</pre> from sklearn.ensemble import RandomForestRegressor from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split from sklearn.pipeline import Pipeline  from molfeat.trans import MoleculeTransformer In\u00a0[3]: Copied! <pre>df = dm.data.freesolv()\nX, y = df[\"smiles\"], df[\"expt\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n# The Molfeat transformer seemingly integrates with Scikit-learn Pipeline!\ntransf = MoleculeTransformer(\"desc2d\")\npipe = Pipeline([(\"feat\", transf), (\"scaler\", StandardScaler()), (\"rf\", RandomForestRegressor())])\n</pre> df = dm.data.freesolv() X, y = df[\"smiles\"], df[\"expt\"] X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)  # The Molfeat transformer seemingly integrates with Scikit-learn Pipeline! transf = MoleculeTransformer(\"desc2d\") pipe = Pipeline([(\"feat\", transf), (\"scaler\", StandardScaler()), (\"rf\", RandomForestRegressor())]) In\u00a0[4]: Copied! <pre>with dm.without_rdkit_log():\n    pipe.fit(X_train, y_train)\n    score = pipe.score(X_test, y_test)\n    y_pred = pipe.predict(X_test)\n\nprint(score)\n</pre> with dm.without_rdkit_log():     pipe.fit(X_train, y_train)     score = pipe.score(X_test, y_test)     y_pred = pipe.predict(X_test)  print(score) <pre>0.8894267708758367\n</pre> In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots()\nax.scatter(y_pred, y_test)\nax.set_xlabel(\"Prediction\")\nax.set_ylabel(\"Target\");\n</pre> fig, ax = plt.subplots() ax.scatter(y_pred, y_test) ax.set_xlabel(\"Prediction\") ax.set_ylabel(\"Target\"); <p>Molfeat transformers are also compatible with Scikit-Learn's <code>GridSearchCV</code>.</p> In\u00a0[6]: Copied! <pre>from molfeat.trans.fp import FPVecTransformer\nfrom sklearn.model_selection import GridSearchCV\n\n# To search over the featurizer, we use a single transformer that combines several calculators.\nfeat = FPVecTransformer(kind=\"rdkit\")\n\nparam_grid = dict(\n    feat__kind=[\"fcfp:6\", \"ecfp:6\", \"maccs\"],\n    feat__length=[512, 1024],\n    rf__n_estimators=[100, 500],\n)\n\npipe = Pipeline([(\"feat\", feat), (\"scaler\", StandardScaler()), (\"rf\", RandomForestRegressor(n_estimators=100))])\ngrid_search = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1)\n\nwith dm.without_rdkit_log():\n    grid_search.fit(X_train, y_train)\n    score = grid_search.score(X_test, y_test)\n\nscore\n</pre> from molfeat.trans.fp import FPVecTransformer from sklearn.model_selection import GridSearchCV  # To search over the featurizer, we use a single transformer that combines several calculators. feat = FPVecTransformer(kind=\"rdkit\")  param_grid = dict(     feat__kind=[\"fcfp:6\", \"ecfp:6\", \"maccs\"],     feat__length=[512, 1024],     rf__n_estimators=[100, 500], )  pipe = Pipeline([(\"feat\", feat), (\"scaler\", StandardScaler()), (\"rf\", RandomForestRegressor(n_estimators=100))]) grid_search = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1)  with dm.without_rdkit_log():     grid_search.fit(X_train, y_train)     score = grid_search.score(X_test, y_test)  score Out[6]: <pre>0.8986852971188453</pre> In\u00a0[7]: Copied! <pre># We can easily get the dimension of the vector!\ninput_size = len(transf)\n\n# To for example define the first layer of a Neural Network\nmodel = nn.Linear(input_size, 1)\n\n# Easily get the associated collate function,\n# This is for example useful when training a DGL GNN.\ndataloader = torch.utils.data.DataLoader(X_train, collate_fn=transf.get_collate_fn())\n</pre> # We can easily get the dimension of the vector! input_size = len(transf)  # To for example define the first layer of a Neural Network model = nn.Linear(input_size, 1)  # Easily get the associated collate function, # This is for example useful when training a DGL GNN. dataloader = torch.utils.data.DataLoader(X_train, collate_fn=transf.get_collate_fn()) In\u00a0[8]: Copied! <pre>from molfeat.trans.graph import DGLGraphTransformer\n\nsmi = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"\n\n# Get the adjacency matrix\ntransf = DGLGraphTransformer()\nX = transf([smi])[0]\ntype(X)\n</pre> from molfeat.trans.graph import DGLGraphTransformer  smi = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"  # Get the adjacency matrix transf = DGLGraphTransformer() X = transf([smi])[0] type(X) Out[8]: <pre>dgl.heterograph.DGLGraph</pre> In\u00a0[9]: Copied! <pre>transf.get_collate_fn()\n</pre> transf.get_collate_fn() Out[9]: <pre>&lt;function molfeat.trans.graph.adj.DGLGraphTransformer._dgl_collate(batch)&gt;</pre> <p>To learn more about the various graph featurization schemes, please see this tutorial.</p> <p>You can also explore the following two tutorials about integrating Molfeat to train deep neural networks in PyTorch:</p> <ol> <li>train a PyG GNN</li> <li>finetune a Hugging Face transformer</li> </ol>"},{"location":"tutorials/integrations.html#scikit-learn","title":"Scikit-learn\u00b6","text":"<p><code>MoleculeTransformer</code> implements the <code>BaseEstimator</code> and <code>TransformerMixin</code> interfaces from Scikit-Learn. This makes it easy to integrate Molfeat featurizers with Scikit-Learn. In the example below, we create a simple Scikit-learn pipeline to predict the solubility of molecules using a random forest regressor.</p>"},{"location":"tutorials/integrations.html#pytorch","title":"PyTorch\u00b6","text":"<p>The <code>MoleculeTransformer</code> also defines some utilities such as the <code>__len__()</code> method and the <code>get_collate_fn()</code> method which makes it easy to integrate with PyTorch. In the example below, we create a simple PyTorch dataset and dataloader using the Molfeat featurizer.</p>"},{"location":"tutorials/integrations.html#featurization-for-training-neural-networks","title":"Featurization for training Neural Networks\u00b6","text":"<p>Molfeat also includes featurization schemes to convert molecules into a format suited for training neural networks (e.g. tokenized strings or graphs).</p>"},{"location":"tutorials/loading_models_without_disk_storage.html","title":"Loading Models Without Disk Storage Using","text":"In\u00a0[\u00a0]: Copied! <pre>from molfeat.store import InMemoryModelStore\n\n# Initialize the in-memory store\nstore = InMemoryModelStore(model_store_bucket='s3://my-modelstore-bucket')\n\n# Load a model directly into memory\nmodel, model_info = store.load('My-Model')\n</pre> from molfeat.store import InMemoryModelStore  # Initialize the in-memory store store = InMemoryModelStore(model_store_bucket='s3://my-modelstore-bucket')  # Load a model directly into memory model, model_info = store.load('My-Model') <p>The model is now ready for use without any disk I/O overhead</p> In\u00a0[\u00a0]: Copied! <pre>import datamol as dm\nfrom molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer\n\nsmiles = dm.freesolv().iloc[:100].smiles\n\ntransformer = PretrainedHFTransformer(kind=model, notation=model_info.inputs, dtype=float)\nfeatures = transformer(smiles)\n</pre> import datamol as dm from molfeat.trans.pretrained.hf_transformers import PretrainedHFTransformer  smiles = dm.freesolv().iloc[:100].smiles  transformer = PretrainedHFTransformer(kind=model, notation=model_info.inputs, dtype=float) features = transformer(smiles)"},{"location":"tutorials/loading_models_without_disk_storage.html#loading-models-without-disk-storage-using-inmemorymodelstore","title":"Loading Models Without Disk Storage Using <code>InMemoryModelStore</code>\u00b6","text":""},{"location":"tutorials/loading_models_without_disk_storage.html#introduction","title":"Introduction\u00b6","text":"<p>This tutorial introduces the <code>InMemoryModelStore</code> class, an alternative to <code>ModelStore</code> designed for environments with limited disk space. This approach is particularly beneficial when memory is more readily available than disk space or disk access is limited or slow.</p> <p><code>InMemoryModelStore</code> enables model loading directly into memory, bypassing the need for local storage and disk I/O operations.</p>"},{"location":"tutorials/loading_models_without_disk_storage.html#using-inmemorymodelstore","title":"Using InMemoryModelStore\u00b6","text":"<p>Here's how to use <code>InMemoryModelStore</code>:</p>"},{"location":"tutorials/loading_models_without_disk_storage.html#benefits-and-considerations","title":"Benefits and Considerations\u00b6","text":"<ul> <li>Reduced Latency: By loading models directly into memory, you eliminate the time needed for disk reads.</li> <li>Efficient Resource Use: Ideal for serverless environments where disk access might be limited or costly.</li> </ul> <p>However, keep in mind that this approach requires sufficient memory to hold the entire model. Ensure your deployment environment has adequate RAM for your model size.</p>"},{"location":"tutorials/pyg_integration.html","title":"Training a GNN with PyG","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\n</pre> %load_ext autoreload %autoreload 2  import torch import pandas as pd import numpy as np import torch.nn.functional as F from tqdm.auto import tqdm <p>As seen in the molfeat integration tutorial, molfeat integrates easily with the PyTorch ecosystem. In this tutorial, we will demonstrate how you can integrate molfeat with PyG for training SOTA GNNs.</p> <p>To run this tutorial, you will need to install <code>pytorch-geometric</code>.</p> <p><code>mamba install -c conda-forge pytorch_geometric</code></p> In\u00a0[2]: Copied! <pre>from molfeat.trans.graph.adj import PYGGraphTransformer\nfrom molfeat.calc.atom import AtomCalculator\nfrom molfeat.calc.bond import EdgeMatCalculator\n</pre> from molfeat.trans.graph.adj import PYGGraphTransformer from molfeat.calc.atom import AtomCalculator from molfeat.calc.bond import EdgeMatCalculator In\u00a0[3]: Copied! <pre>featurizer = PYGGraphTransformer(\n    atom_featurizer=AtomCalculator(), \n    bond_featurizer=EdgeMatCalculator()\n)\n</pre> featurizer = PYGGraphTransformer(     atom_featurizer=AtomCalculator(),      bond_featurizer=EdgeMatCalculator() ) In\u00a0[4]: Copied! <pre>df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\")\n</pre> df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\") In\u00a0[5]: Copied! <pre>df.head()\n</pre> df.head() Out[5]: CMPD_CHEMBLID exp smiles 0 CHEMBL596271 3.54 Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14 1 CHEMBL1951080 -1.18 COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)... 2 CHEMBL1771 3.69 COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl 3 CHEMBL234951 3.37 OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C... 4 CHEMBL565079 3.10 Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N... <p>Since training a network with PyTorch requires defining a dataset and dataloader, we can define our custom dataset that will take (1) the SMILES, (2) the LogD measurement, and (3) our molfeat transformer as input to generate the data point we need for model training.</p> In\u00a0[6]: Copied! <pre>from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch_geometric.utils import degree\n\n\nclass DTset(Dataset):\n    def __init__(self, smiles, y, featurizer):\n        super().__init__()\n        self.smiles = smiles\n        self.featurizer = featurizer\n        self.featurizer.auto_self_loop()\n        self.y = torch.tensor(y).unsqueeze(-1).float()\n        self.transformed_mols = self.featurizer(smiles)\n        self._degrees = None\n\n    @property\n    def num_atom_features(self):\n        return self.featurizer.atom_dim\n\n    @property\n    def num_output(self):\n        return self.y.shape[-1]\n    \n    def __len__(self):\n        return len(self.transformed_mols)\n    \n    @property\n    def num_bond_features(self):\n        return self.featurizer.bond_dim\n    \n\n    @property\n    def degree(self):\n        if self._degrees is  None:\n            max_degree = -1\n            for data in self.transformed_mols:\n                d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n                max_degree = max(max_degree, int(d.max()))\n            # Compute the in-degree histogram tensor\n            deg = torch.zeros(max_degree + 1, dtype=torch.long)\n            for data in self.transformed_mols:\n                d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n                deg += torch.bincount(d, minlength=deg.numel())\n            self._degrees = deg\n        return self._degrees\n\n    def collate_fn(self, **kwargs):\n        # luckily the molfeat featurizer provides a collate functoin for PyG\n        return self.featurizer.get_collate_fn(**kwargs)\n    \n    def __getitem__(self, index):\n        return self.transformed_mols[index], self.y[index]\n</pre> from torch.utils.data import Dataset from torch.utils.data import DataLoader from torch_geometric.utils import degree   class DTset(Dataset):     def __init__(self, smiles, y, featurizer):         super().__init__()         self.smiles = smiles         self.featurizer = featurizer         self.featurizer.auto_self_loop()         self.y = torch.tensor(y).unsqueeze(-1).float()         self.transformed_mols = self.featurizer(smiles)         self._degrees = None      @property     def num_atom_features(self):         return self.featurizer.atom_dim      @property     def num_output(self):         return self.y.shape[-1]          def __len__(self):         return len(self.transformed_mols)          @property     def num_bond_features(self):         return self.featurizer.bond_dim           @property     def degree(self):         if self._degrees is  None:             max_degree = -1             for data in self.transformed_mols:                 d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)                 max_degree = max(max_degree, int(d.max()))             # Compute the in-degree histogram tensor             deg = torch.zeros(max_degree + 1, dtype=torch.long)             for data in self.transformed_mols:                 d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)                 deg += torch.bincount(d, minlength=deg.numel())             self._degrees = deg         return self._degrees      def collate_fn(self, **kwargs):         # luckily the molfeat featurizer provides a collate functoin for PyG         return self.featurizer.get_collate_fn(**kwargs)          def __getitem__(self, index):         return self.transformed_mols[index], self.y[index] In\u00a0[7]: Copied! <pre>dataset = DTset(df.smiles.values, df.exp.values, featurizer)\ngenerator = torch.Generator().manual_seed(42)\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dt, test_dt = torch.utils.data.random_split(dataset, [train_size, test_size], generator=generator)\n</pre> dataset = DTset(df.smiles.values, df.exp.values, featurizer) generator = torch.Generator().manual_seed(42) train_size = int(0.8 * len(dataset)) test_size = len(dataset) - train_size train_dt, test_dt = torch.utils.data.random_split(dataset, [train_size, test_size], generator=generator) In\u00a0[8]: Copied! <pre>BATCH_SIZE = 64\ntrain_loader = DataLoader(train_dt, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn(return_pair=False))\ntest_loader = DataLoader(test_dt, batch_size=BATCH_SIZE, shuffle=False, collate_fn=dataset.collate_fn(return_pair=False))\n</pre> BATCH_SIZE = 64 train_loader = DataLoader(train_dt, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn(return_pair=False)) test_loader = DataLoader(test_dt, batch_size=BATCH_SIZE, shuffle=False, collate_fn=dataset.collate_fn(return_pair=False))  In\u00a0[9]: Copied! <pre>from torch_geometric.nn.models import PNA\nfrom torch_geometric.nn import global_add_pool\n\nDEVICE = \"cpu\"\nNUM_EPOCHS = 10\nLEARNING_RATE = 5e-4\nPNA_AGGREGATORS = ['mean', 'min', 'max', 'std']\nPNA_SCALERS = ['identity', 'amplification', 'attenuation']\n</pre> from torch_geometric.nn.models import PNA from torch_geometric.nn import global_add_pool  DEVICE = \"cpu\" NUM_EPOCHS = 10 LEARNING_RATE = 5e-4 PNA_AGGREGATORS = ['mean', 'min', 'max', 'std'] PNA_SCALERS = ['identity', 'amplification', 'attenuation'] In\u00a0[10]: Copied! <pre>model = PNA(in_channels=dataset.num_atom_features, \n                    hidden_channels=128, \n                    num_layers=3,\n                    out_channels=dataset.num_output, \n                    dropout=0.1, \n                    act=\"relu\",\n                    edge_dim=dataset.num_bond_features,\n                    aggregators = PNA_AGGREGATORS,\n                    scalers = PNA_SCALERS,\n                    deg=dataset.degree,\n)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n</pre> model = PNA(in_channels=dataset.num_atom_features,                      hidden_channels=128,                      num_layers=3,                     out_channels=dataset.num_output,                      dropout=0.1,                      act=\"relu\",                     edge_dim=dataset.num_bond_features,                     aggregators = PNA_AGGREGATORS,                     scalers = PNA_SCALERS,                     deg=dataset.degree, ) optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) In\u00a0[11]: Copied! <pre># Train\nmodel = model.to(DEVICE).float()\nmodel.train()\nwith tqdm(range(NUM_EPOCHS)) as pbar:\n    for epoch in pbar:\n        losses = []\n        for data in train_loader:\n            data = data.to(DEVICE)\n            optimizer.zero_grad()\n            out = model(data.x, data.edge_index, edge_attr=data.edge_attr)\n            out = global_add_pool(out, data.batch)\n            loss = F.mse_loss(out.squeeze(), data.y)\n            loss.backward()\n            optimizer.step()\n            losses.append(loss.item())\n        pbar.set_description(f\"Epoch {epoch} - Loss {np.mean(losses):.3f}\")\n</pre> # Train model = model.to(DEVICE).float() model.train() with tqdm(range(NUM_EPOCHS)) as pbar:     for epoch in pbar:         losses = []         for data in train_loader:             data = data.to(DEVICE)             optimizer.zero_grad()             out = model(data.x, data.edge_index, edge_attr=data.edge_attr)             out = global_add_pool(out, data.batch)             loss = F.mse_loss(out.squeeze(), data.y)             loss.backward()             optimizer.step()             losses.append(loss.item())         pbar.set_description(f\"Epoch {epoch} - Loss {np.mean(losses):.3f}\") <pre>  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> In\u00a0[12]: Copied! <pre>from sklearn.metrics import r2_score, mean_absolute_error\nfrom matplotlib import pyplot as plt\n\nmodel.eval()\ntest_y_hat = []\ntest_y_true = []\nwith torch.no_grad():\n    for data in test_loader:\n        data = data.to(DEVICE)\n        out = model(data.x, data.edge_index, edge_attr=data.edge_attr)\n        out = global_add_pool(out, data.batch)\n        test_y_hat.append(out.detach().cpu().squeeze())\n        test_y_true.append(data.y)\n\ntest_y_hat = torch.cat(test_y_hat).numpy()\ntest_y_true = torch.cat(test_y_true).numpy()\n\nr2 = r2_score(test_y_true, test_y_hat)\nmae = mean_absolute_error(test_y_true, test_y_hat)\n\nplt.scatter(test_y_true, test_y_hat)\n_ =plt.gca().annotate(\n    \"$R2 = {:.2f}$\\nMAE = {:.2f}\".format(r2, mae), \n    xy=(0.05,0.9),  \n    xycoords='axes fraction', \n    size=8,\n    bbox=dict(boxstyle=\"round\", fc=(1.0, 0.7, 0.7), ec=\"none\")\n)\n</pre> from sklearn.metrics import r2_score, mean_absolute_error from matplotlib import pyplot as plt  model.eval() test_y_hat = [] test_y_true = [] with torch.no_grad():     for data in test_loader:         data = data.to(DEVICE)         out = model(data.x, data.edge_index, edge_attr=data.edge_attr)         out = global_add_pool(out, data.batch)         test_y_hat.append(out.detach().cpu().squeeze())         test_y_true.append(data.y)  test_y_hat = torch.cat(test_y_hat).numpy() test_y_true = torch.cat(test_y_true).numpy()  r2 = r2_score(test_y_true, test_y_hat) mae = mean_absolute_error(test_y_true, test_y_hat)  plt.scatter(test_y_true, test_y_hat) _ =plt.gca().annotate(     \"$R2 = {:.2f}$\\nMAE = {:.2f}\".format(r2, mae),      xy=(0.05,0.9),       xycoords='axes fraction',      size=8,     bbox=dict(boxstyle=\"round\", fc=(1.0, 0.7, 0.7), ec=\"none\") )"},{"location":"tutorials/pyg_integration.html#pyg-integration","title":"PyG integration\u00b6","text":"<p>Community contribution</p> <p>Curious how one would run this tutorial on Graphcore IPUs? See this tutorial contributed by @s-maddrellmander:     </p>"},{"location":"tutorials/pyg_integration.html#featurizer","title":"Featurizer\u00b6","text":"<p>We first start by defining our featurizer. We will use the <code>PYGGraphTransformer</code> from molfeat with atom and bond featurizers</p>"},{"location":"tutorials/pyg_integration.html#dataset","title":"Dataset\u00b6","text":"<p>For the dataset, we will use the <code>Lipophilicity</code> dataset (LogD) from MoleculeNet, which contains experimental results of octanol/water distribution coefficient at pH=7.4</p>"},{"location":"tutorials/pyg_integration.html#network-training","title":"Network + Training\u00b6","text":"<p>We are almost ready to go, we just need to define our GNN. Here we use PNA as our GNN.</p>"},{"location":"tutorials/pyg_integration.html#testing","title":"Testing\u00b6","text":"<p>We can now test our model. For the simplicity of this tutorial, no hyper-parameter search and evaluation of the best atom/bond featurization was performed. This inevitably impacts the performance.</p>"},{"location":"tutorials/save_and_load.html","title":"Save and Load","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport datamol as dm\n</pre> %load_ext autoreload %autoreload 2  import datamol as dm <p>Any Molfeat featurizer should be serializable. This makes it easy to share a specific instantiation of a featurizer. Any featurizer can thus be created from - or saved to - a state dictionary. We support native support to save these state dicts to both YAML and JSON.</p> In\u00a0[2]: Copied! <pre>from molfeat.trans import MoleculeTransformer\n\nfeaturizer = MoleculeTransformer(\"ecfp\")\n</pre> from molfeat.trans import MoleculeTransformer  featurizer = MoleculeTransformer(\"ecfp\") In\u00a0[3]: Copied! <pre>print(featurizer.to_state_yaml())\n</pre> print(featurizer.to_state_yaml()) <pre>_molfeat_version: 0.8.2.dev26+g8b6a1c9.d20230401\nargs:\n  dtype: null\n  featurizer: ecfp\n  n_jobs: 1\n  parallel_kwargs: null\n  verbose: false\nname: MoleculeTransformer\n\n</pre> In\u00a0[4]: Copied! <pre>print(featurizer.to_state_json())\n</pre> print(featurizer.to_state_json()) <pre>{\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"ecfp\", \"n_jobs\": 1, \"verbose\": false, \"dtype\": null, \"parallel_kwargs\": null}, \"_molfeat_version\": \"0.8.2.dev26+g8b6a1c9.d20230401\"}\n</pre> In\u00a0[5]: Copied! <pre>print(featurizer.to_state_dict())\n</pre> print(featurizer.to_state_dict()) <pre>{'name': 'MoleculeTransformer', 'args': {'featurizer': 'ecfp', 'n_jobs': 1, 'verbose': False, 'dtype': None, 'parallel_kwargs': None}, '_molfeat_version': '0.8.2.dev26+g8b6a1c9.d20230401'}\n</pre> In\u00a0[6]: Copied! <pre>print(featurizer.to_state_json())\n</pre> print(featurizer.to_state_json()) <pre>{\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"ecfp\", \"n_jobs\": 1, \"verbose\": false, \"dtype\": null, \"parallel_kwargs\": null}, \"_molfeat_version\": \"0.8.2.dev26+g8b6a1c9.d20230401\"}\n</pre> In\u00a0[7]: Copied! <pre># You can also directly save to files:\nimport tempfile\n\nwith tempfile.TemporaryDirectory() as tmpdir:\n    path = dm.fs.join(tmpdir, \"state_dict.yml\")\n    featurizer.to_state_yaml_file(path)\n    featurizer = MoleculeTransformer.from_state_yaml_file(path)\n</pre> # You can also directly save to files: import tempfile  with tempfile.TemporaryDirectory() as tmpdir:     path = dm.fs.join(tmpdir, \"state_dict.yml\")     featurizer.to_state_yaml_file(path)     featurizer = MoleculeTransformer.from_state_yaml_file(path) In\u00a0[8]: Copied! <pre>FEATURIZERS = [\n    {\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"ecfp\", \"n_jobs\": 1, \"verbose\": False, \"dtype\": None, \"parallel_kwargs\": None}, \"_molfeat_version\": \"0.0.1\"},\n    {\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"maccs\", \"n_jobs\": 1, \"verbose\": False, \"dtype\": None, \"parallel_kwargs\": None}, \"_molfeat_version\": \"0.0.1\"},\n    {\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"fcfp\", \"n_jobs\": 1, \"verbose\": False, \"dtype\": None, \"parallel_kwargs\": None}, \"_molfeat_version\": \"0.0.1\"},\n]\n</pre> FEATURIZERS = [     {\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"ecfp\", \"n_jobs\": 1, \"verbose\": False, \"dtype\": None, \"parallel_kwargs\": None}, \"_molfeat_version\": \"0.0.1\"},     {\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"maccs\", \"n_jobs\": 1, \"verbose\": False, \"dtype\": None, \"parallel_kwargs\": None}, \"_molfeat_version\": \"0.0.1\"},     {\"name\": \"MoleculeTransformer\", \"args\": {\"featurizer\": \"fcfp\", \"n_jobs\": 1, \"verbose\": False, \"dtype\": None, \"parallel_kwargs\": None}, \"_molfeat_version\": \"0.0.1\"}, ] In\u00a0[9]: Copied! <pre>for state_dict in FEATURIZERS:\n    featurizer = MoleculeTransformer.from_state_dict(state_dict)\n    # ... Work your magic!\n</pre> for state_dict in FEATURIZERS:     featurizer = MoleculeTransformer.from_state_dict(state_dict)     # ... Work your magic!"},{"location":"tutorials/save_and_load.html#example","title":"Example\u00b6","text":""},{"location":"tutorials/save_and_load.html#loop-over-multiple-featurizers","title":"Loop over multiple featurizers\u00b6","text":"<p>One implication of this, is that despite the various interfaces, you can easily loop over multiple featurizers.</p>"},{"location":"tutorials/transformer_finetuning.html","title":"Finetuning a pretrained transformer","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport copy\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\n</pre> %load_ext autoreload %autoreload 2  import torch import copy import pandas as pd import numpy as np from tqdm.auto import tqdm <p>We have previously shown how Molfeat integrates with PyTorch in general and even with Pytorch Geometric. Now we will demonstrate how to use molfeat to finetune a pretrained transformer. This tutorial will walk you through an example of finetuning the ChemBERTa pretrained model for molecular property prediction. These same principles can be applied to any pretrained transformers available in molfeat.</p> <p>To run this tutorial, you will need to install <code>transformers</code> and <code>tokenizers</code>.</p> <p><code>mamba install -c conda-forge transformers \"tokenizers &lt;0.13.2\"</code></p> <p>Advanced users</p> <p>This tutorial is for advanced users that are comfortable with the APIs of molfeat and Hugging Face transformers.</p> In\u00a0[2]: Copied! <pre>from molfeat.trans.pretrained import PretrainedHFTransformer\n</pre> from molfeat.trans.pretrained import PretrainedHFTransformer In\u00a0[3]: Copied! <pre>featurizer = PretrainedHFTransformer(kind=\"ChemBERTa-77M-MLM\", pooling=\"bert\", preload=True)\n</pre> featurizer = PretrainedHFTransformer(kind=\"ChemBERTa-77M-MLM\", pooling=\"bert\", preload=True) <ul> <li>Note the use of preload to preload the model in the <code>__init__</code></li> <li>Note how we define a pooling mechanism here. Molfeat provides several poolers that you can explore in the API. Because a pooling layer can already be specified and will be accessible through the <code>_pooling_obj</code> attribute we will not bother defining one later. Instead we will just retrieve the one from the featurizer.</li> </ul> In\u00a0[4]: Copied! <pre>df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/BBBP.csv\")\n</pre> df = pd.read_csv(\"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/BBBP.csv\") In\u00a0[5]: Copied! <pre>df.head()\n</pre> df.head() Out[5]: num name p_np smiles 0 1 Propanolol 1 [Cl].CC(C)NCC(O)COc1cccc2ccccc12 1 2 Terbutylchlorambucil 1 C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl 2 3 40730 1 c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO... 3 4 24 1 C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C 4 5 cloxacillin 1 Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)... <p>Now we just need to define our PyTorch Dataset. As discussed above, we will leverage the internal structure of our transformer</p> In\u00a0[6]: Copied! <pre>from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\n\nclass DTset(Dataset):\n    def __init__(self, smiles, y, mf_featurizer):\n        super().__init__()\n        self.smiles = smiles\n        self.mf_featurizer = mf_featurizer\n        self.y = torch.tensor(y).float()\n        # here we use the molfeat mf_featurizer to convert the smiles to\n        # corresponding tokens based on the internal tokenizer\n        # we just want the data from the batch encoding object\n        self.transformed_mols = self.mf_featurizer._convert(smiles)\n\n    @property\n    def embedding_dim(self):\n        return len(self.mf_featurizer)\n\n    @property\n    def max_length(self):\n        return self.transformed_mols.shape[-1]\n    \n    def __len__(self):\n        return self.y.shape[0]\n    \n    def collate_fn(self, **kwargs):\n        # the default collate fn self.mf_featurizer.get_collate_fn(**kwargs)\n        # returns None, which should just concatenate the inputs\n        # You could also use `transformers.default_data_collator` instead\n        return self.mf_featurizer.get_collate_fn(**kwargs)\n    \n    def __getitem__(self, index):\n        datapoint = dict((name, val[index]) for name, val in self.transformed_mols.items())\n        datapoint[\"y\"] = self.y[index]\n        return datapoint\n</pre> from torch.utils.data import Dataset from torch.utils.data import DataLoader   class DTset(Dataset):     def __init__(self, smiles, y, mf_featurizer):         super().__init__()         self.smiles = smiles         self.mf_featurizer = mf_featurizer         self.y = torch.tensor(y).float()         # here we use the molfeat mf_featurizer to convert the smiles to         # corresponding tokens based on the internal tokenizer         # we just want the data from the batch encoding object         self.transformed_mols = self.mf_featurizer._convert(smiles)      @property     def embedding_dim(self):         return len(self.mf_featurizer)      @property     def max_length(self):         return self.transformed_mols.shape[-1]          def __len__(self):         return self.y.shape[0]          def collate_fn(self, **kwargs):         # the default collate fn self.mf_featurizer.get_collate_fn(**kwargs)         # returns None, which should just concatenate the inputs         # You could also use `transformers.default_data_collator` instead         return self.mf_featurizer.get_collate_fn(**kwargs)          def __getitem__(self, index):         datapoint = dict((name, val[index]) for name, val in self.transformed_mols.items())         datapoint[\"y\"] = self.y[index]         return datapoint In\u00a0[7]: Copied! <pre>dataset = DTset(df.smiles.values, df.p_np.values, featurizer)\ngenerator = torch.Generator().manual_seed(42)\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dt, test_dt = torch.utils.data.random_split(dataset, [train_size, test_size], generator=generator)\n</pre> dataset = DTset(df.smiles.values, df.p_np.values, featurizer) generator = torch.Generator().manual_seed(42) train_size = int(0.8 * len(dataset)) test_size = len(dataset) - train_size train_dt, test_dt = torch.utils.data.random_split(dataset, [train_size, test_size], generator=generator) <pre>  0%|          | 0/2050 [00:00&lt;?, ?it/s]</pre> <pre>  0%|          | 0/2050 [00:00&lt;?, ?it/s]</pre> In\u00a0[8]: Copied! <pre>BATCH_SIZE = 64\ntrain_loader = DataLoader(train_dt, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn())\ntest_loader = DataLoader(test_dt, batch_size=BATCH_SIZE, shuffle=False, collate_fn=dataset.collate_fn())\n</pre> BATCH_SIZE = 64 train_loader = DataLoader(train_dt, batch_size=BATCH_SIZE, shuffle=True, collate_fn=dataset.collate_fn()) test_loader = DataLoader(test_dt, batch_size=BATCH_SIZE, shuffle=False, collate_fn=dataset.collate_fn()) In\u00a0[9]: Copied! <pre>class AwesomeNet(torch.nn.Module):\n    def __init__(self, mf_featurizer, hidden_size=128, dropout=0.1, output_size=1):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        # we get the underlying model from the molfeat featurizer\n        # here we fetch the \"base\" huggingface transformer model \n        # and not the wrapper around for MLM\n        # this is principally to get smaller model and training efficiency\n        base_pretrained_model = getattr(mf_featurizer.featurizer.model, mf_featurizer.featurizer.model.base_model_prefix)\n        self.embedding_layer = copy.deepcopy(base_pretrained_model)\n        self.embedding_dim = mf_featurizer.featurizer.model.config.hidden_size\n        # given that we are not concatenating layers, the following is equivalent\n        # self.embedding_dim = len(mf_featurizer)\n        # we get the the pooling layer from the molfeat featurizer\n        self.pooling_layer = mf_featurizer._pooling_obj\n        self.hidden_layer = torch.nn.Sequential(\n            torch.nn.Dropout(p=dropout),\n            torch.nn.Linear(len(mf_featurizer), self.hidden_size),\n            torch.nn.ReLU()\n        )\n        self.output_layer = torch.nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, *, y=None, **kwargs):\n        # get embeddings\n        x = self.embedding_layer(**kwargs)\n        # we take the last hidden state\n        # you could also set `output_hidden_states` to true above \n        # and take x[\"hidden_states\"][-1] instead\n        emb = x[\"last_hidden_state\"]\n        # run poolings\n        h = self.pooling_layer(\n            emb,\n            kwargs[\"input_ids\"],\n            mask=kwargs.get('attention_mask'),\n        )\n        # run through our custom and optional hidden layer\n        h = self.hidden_layer(h)\n        # run through output layers to get logits\n        return self.output_layer(h)\n</pre> class AwesomeNet(torch.nn.Module):     def __init__(self, mf_featurizer, hidden_size=128, dropout=0.1, output_size=1):         super().__init__()         self.hidden_size = hidden_size         self.output_size = output_size         # we get the underlying model from the molfeat featurizer         # here we fetch the \"base\" huggingface transformer model          # and not the wrapper around for MLM         # this is principally to get smaller model and training efficiency         base_pretrained_model = getattr(mf_featurizer.featurizer.model, mf_featurizer.featurizer.model.base_model_prefix)         self.embedding_layer = copy.deepcopy(base_pretrained_model)         self.embedding_dim = mf_featurizer.featurizer.model.config.hidden_size         # given that we are not concatenating layers, the following is equivalent         # self.embedding_dim = len(mf_featurizer)         # we get the the pooling layer from the molfeat featurizer         self.pooling_layer = mf_featurizer._pooling_obj         self.hidden_layer = torch.nn.Sequential(             torch.nn.Dropout(p=dropout),             torch.nn.Linear(len(mf_featurizer), self.hidden_size),             torch.nn.ReLU()         )         self.output_layer = torch.nn.Linear(self.hidden_size, self.output_size)      def forward(self, *, y=None, **kwargs):         # get embeddings         x = self.embedding_layer(**kwargs)         # we take the last hidden state         # you could also set `output_hidden_states` to true above          # and take x[\"hidden_states\"][-1] instead         emb = x[\"last_hidden_state\"]         # run poolings         h = self.pooling_layer(             emb,             kwargs[\"input_ids\"],             mask=kwargs.get('attention_mask'),         )         # run through our custom and optional hidden layer         h = self.hidden_layer(h)         # run through output layers to get logits         return self.output_layer(h) In\u00a0[10]: Copied! <pre>DEVICE = \"cpu\"\nNUM_EPOCHS = 10\nLEARNING_RATE = 1e-3\nPNA_AGGREGATORS = ['mean', 'min', 'max', 'std']\nPNA_SCALERS = ['identity', 'amplification', 'attenuation']\n\nmodel = AwesomeNet(featurizer, hidden_size=64, dropout=0.1, output_size=1)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nloss_fn = torch.nn.BCEWithLogitsLoss()\n</pre> DEVICE = \"cpu\" NUM_EPOCHS = 10 LEARNING_RATE = 1e-3 PNA_AGGREGATORS = ['mean', 'min', 'max', 'std'] PNA_SCALERS = ['identity', 'amplification', 'attenuation']  model = AwesomeNet(featurizer, hidden_size=64, dropout=0.1, output_size=1) optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) loss_fn = torch.nn.BCEWithLogitsLoss() In\u00a0[11]: Copied! <pre>model = model.to(DEVICE).float()\nmodel = model.train()\n</pre> model = model.to(DEVICE).float() model = model.train() <p>You might want to have a look at the model summary for a sanity check.</p> <pre>! pip install torchinfo\nfrom torchinfo import summary\nsummary(model)\n</pre> <p>You should now see the following output:</p> <pre><code>==========================================================================================\nLayer (type:depth-idx)                                            Param #\n==========================================================================================\nAwesomeNet                                                        --\n\u251c\u2500RobertaForMaskedLM: 1-1                                         --\n\u2502    \u2514\u2500RobertaModel: 2-1                                          --\n\u2502    \u2502    \u2514\u2500RobertaEmbeddings: 3-1                                429,312\n\u2502    \u2502    \u2514\u2500RobertaEncoder: 3-2                                   2,850,288\n\u2502    \u2514\u2500RobertaLMHead: 2-2                                         --\n\u2502    \u2502    \u2514\u2500Linear: 3-3                                           147,840\n\u2502    \u2502    \u2514\u2500LayerNorm: 3-4                                        768\n\u2502    \u2502    \u2514\u2500Linear: 3-5                                           231,000\n\u251c\u2500BertPooler: 1-2                                                 --\n\u2502    \u2514\u2500Linear: 2-3                                                147,840\n\u2502    \u2514\u2500Tanh: 2-4                                                  --\n\u251c\u2500Sequential: 1-3                                                 --\n\u2502    \u2514\u2500Dropout: 2-5                                               --\n\u2502    \u2514\u2500Linear: 2-6                                                24,640\n\u2502    \u2514\u2500ReLU: 2-7                                                  --\n\u251c\u2500Linear: 1-4                                                     65\n==========================================================================================\nTotal params: 3,831,753\nTrainable params: 3,831,753\nNon-trainable params: 0\n==========================================================================================\n</code></pre> In\u00a0[12]: Copied! <pre># Train\nwith tqdm(range(NUM_EPOCHS)) as pbar:\n    for epoch in pbar:\n        losses = []\n        for data in train_loader:\n            optimizer.zero_grad()\n            out = model(**data)\n            loss = loss_fn(out.squeeze(), data[\"y\"])\n            loss.backward()\n            optimizer.step()\n            losses.append(loss.item())\n        pbar.set_description(f\"Epoch {epoch} - Loss {np.mean(losses):.3f}\")\n</pre> # Train with tqdm(range(NUM_EPOCHS)) as pbar:     for epoch in pbar:         losses = []         for data in train_loader:             optimizer.zero_grad()             out = model(**data)             loss = loss_fn(out.squeeze(), data[\"y\"])             loss.backward()             optimizer.step()             losses.append(loss.item())         pbar.set_description(f\"Epoch {epoch} - Loss {np.mean(losses):.3f}\") <pre>  0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> In\u00a0[13]: Copied! <pre>from sklearn.metrics import accuracy_score, roc_auc_score\n\nmodel.eval()\ntest_y_hat = []\ntest_y_true = []\nwith torch.no_grad():\n    for data in test_loader:\n        out = model(**data)\n        # we apply sigmoid\n        out = torch.sigmoid(out)\n        test_y_hat.append(out.detach().cpu().squeeze())\n        test_y_true.append(data[\"y\"])\ntest_y_hat = torch.cat(test_y_hat).squeeze().numpy()\ntest_y_true = torch.cat(test_y_true).squeeze().numpy()\nroc_auc = roc_auc_score(test_y_true, test_y_hat)\nacc = accuracy_score(test_y_true, test_y_hat&gt;=0.5)\nprint(f\"Test ROC AUC: {roc_auc:.3f}\\nTest Accuracy: {acc:.3f}\")\n</pre> from sklearn.metrics import accuracy_score, roc_auc_score  model.eval() test_y_hat = [] test_y_true = [] with torch.no_grad():     for data in test_loader:         out = model(**data)         # we apply sigmoid         out = torch.sigmoid(out)         test_y_hat.append(out.detach().cpu().squeeze())         test_y_true.append(data[\"y\"]) test_y_hat = torch.cat(test_y_hat).squeeze().numpy() test_y_true = torch.cat(test_y_true).squeeze().numpy() roc_auc = roc_auc_score(test_y_true, test_y_hat) acc = accuracy_score(test_y_true, test_y_hat&gt;=0.5) print(f\"Test ROC AUC: {roc_auc:.3f}\\nTest Accuracy: {acc:.3f}\") <pre>Test ROC AUC: 0.964\nTest Accuracy: 0.905\n</pre>"},{"location":"tutorials/transformer_finetuning.html#huggingface-transformer-finetuning","title":"HuggingFace Transformer Finetuning\u00b6","text":"<p>Community contribution</p> <p>Curious how one would run this tutorial on Graphcore IPUs? See this tutorial contributed by @s-maddrellmander:     </p>"},{"location":"tutorials/transformer_finetuning.html#featurizer","title":"Featurizer\u00b6","text":"<p>Pretrained Transformer Featurizer in molfeat have an underlying object <code>featurizer</code> that can handle both tokenization and embedding.</p> <p>We will leverage this structure in molfeat to initialize our transformer model, but also to tokenize our molecules</p> <p>We first start by defining our featurizer. Here we will use the ChemBERTa pretrained model.</p>"},{"location":"tutorials/transformer_finetuning.html#dataset","title":"Dataset\u00b6","text":"<p>For the dataset, we will use the <code>BBBP</code> dataset, which contains binary labels of blood-brain barrier penetration.</p>"},{"location":"tutorials/transformer_finetuning.html#network-training","title":"Network + Training\u00b6","text":"<p>We are ready to go, now we just need to define our Model for finetuning pretrained ChemBerta on the BBBP task.</p>"},{"location":"tutorials/transformer_finetuning.html#testing","title":"Testing\u00b6","text":"<p>We can now test our model.</p>"},{"location":"tutorials/types_of_featurizers.html","title":"Types of featurizers","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport torch\nimport datamol as dm\nimport numpy as np\n</pre> %load_ext autoreload %autoreload 2  import torch import datamol as dm import numpy as np <p>All featurizers in Molfeat inherit from at least one of three classes:</p> <ol> <li><code>molfeat.calc.SerializableCalculator</code>:A calculator is a Callable that featurizes a single molecule.</li> <li><code>molfeat.trans.MoleculeTransformer</code>:A transformer is a class that wraps a calculator in a featurization pipeline.</li> <li><code>molfeat.trans.pretrained.PretrainedMolTransformer</code>:A subclass of <code>MoleculeTransformer</code> that extends the transformer interface to support the usage of pretrained models.</li> </ol> <p>In this tutorial, we will look at each of these classes in more detail.</p> In\u00a0[2]: Copied! <pre>from molfeat.calc import FPCalculator\n\nsmiles = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"\ncalc = FPCalculator(\"maccs\")\nX = calc(smiles)\nX.shape\n</pre> from molfeat.calc import FPCalculator  smiles = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\" calc = FPCalculator(\"maccs\") X = calc(smiles) X.shape Out[2]: <pre>(167,)</pre> <p>The <code>FPCalculator</code> implements several popular molecular fingerprints:</p> In\u00a0[3]: Copied! <pre>from molfeat.calc import FP_FUNCS\nFP_FUNCS.keys()\n</pre> from molfeat.calc import FP_FUNCS FP_FUNCS.keys() Out[3]: <pre>dict_keys(['maccs', 'avalon', 'ecfp', 'fcfp', 'topological', 'atompair', 'rdkit', 'pattern', 'layered', 'map4', 'secfp', 'erg', 'estate', 'avalon-count', 'rdkit-count', 'ecfp-count', 'fcfp-count', 'topological-count', 'atompair-count'])</pre> <p>Switching to any other fingerprint is easy:</p> In\u00a0[4]: Copied! <pre>calc = FPCalculator(\"ecfp\")\nX = calc(smiles)\nX.shape\n</pre> calc = FPCalculator(\"ecfp\") X = calc(smiles) X.shape Out[4]: <pre>(2048,)</pre> <p>Beyond these fingerprints, Molfeat also provides calculators for other molecular descriptors. The list of available options can be further extended through plugins. All available calculator classes, both built-in and plugin-based, can be found through the <code>molfeat.calc</code> module:</p> In\u00a0[5]: Copied! <pre>from molfeat.calc import _CALCULATORS\n_CALCULATORS.keys()\n</pre> from molfeat.calc import _CALCULATORS _CALCULATORS.keys() Out[5]: <pre>dict_keys(['CATS', 'RDKitDescriptors2D', 'MordredDescriptors', 'RDKitDescriptors3D', 'FPCalculator', 'Pharmacophore2D', 'Pharmacophore3D', 'ScaffoldKeyCalculator', 'USRDescriptors', 'ElectroShapeDescriptors'])</pre> <p>Every calculator is serializable, meaning it can be efficiently stored to \u2014 and loaded from \u2014 disk. To learn more, please see the tutorial on saving and loading featurizers.</p> In\u00a0[6]: Copied! <pre>from molfeat.calc import RDKitDescriptors2D\nfrom molfeat.trans import MoleculeTransformer\n\ndata = dm.data.freesolv().smiles.values\n\n# Let's try a different calculator!\n# This is a descriptor with all 2D, physicochemical descriptors from RDKit\ncalc = RDKitDescriptors2D(replace_nan=True)\n\n# Wrap the calculator in a transformer instance\nfeaturizer = MoleculeTransformer(calc, dtype=np.float64)\n\nwith dm.without_rdkit_log():\n    feats = featurizer(data)\n\nfeats.shape\n</pre> from molfeat.calc import RDKitDescriptors2D from molfeat.trans import MoleculeTransformer  data = dm.data.freesolv().smiles.values  # Let's try a different calculator! # This is a descriptor with all 2D, physicochemical descriptors from RDKit calc = RDKitDescriptors2D(replace_nan=True)  # Wrap the calculator in a transformer instance featurizer = MoleculeTransformer(calc, dtype=np.float64)  with dm.without_rdkit_log():     feats = featurizer(data)  feats.shape Out[6]: <pre>(642, 214)</pre> <p>The <code>MoleculeTransformer</code> class provides a number of useful methods to customize the featurization pipeline. For example, you can easily change the dtype of the features or use parallelization.</p> In\u00a0[7]: Copied! <pre>feats.dtype\n</pre> feats.dtype Out[7]: <pre>dtype('float64')</pre> In\u00a0[8]: Copied! <pre># To save on memory, we would rather use `float32` than `float64`. Let's change that!\nfeaturizer = MoleculeTransformer(calc, dtype=np.float32)\n\nwith dm.without_rdkit_log():\n    feats = np.stack(featurizer(data))\n\nfeats.dtype\n</pre> # To save on memory, we would rather use `float32` than `float64`. Let's change that! featurizer = MoleculeTransformer(calc, dtype=np.float32)  with dm.without_rdkit_log():     feats = np.stack(featurizer(data))  feats.dtype Out[8]: <pre>dtype('float32')</pre> In\u00a0[9]: Copied! <pre># Even better, let's directly cast to Torch vectors so we can use them in PyTorch!\nfeaturizer = MoleculeTransformer(calc, dtype=torch.float32)\n\nwith dm.without_rdkit_log():\n    feats = featurizer(data)\nfeats.dtype\n</pre> # Even better, let's directly cast to Torch vectors so we can use them in PyTorch! featurizer = MoleculeTransformer(calc, dtype=torch.float32)  with dm.without_rdkit_log():     feats = featurizer(data) feats.dtype Out[9]: <pre>torch.float32</pre> In\u00a0[10]: Copied! <pre>%%timeit\n# Let's time our current featurization pipeline\nfeaturizer = MoleculeTransformer(calc, n_jobs=1, dtype=torch.float32)\nwith dm.without_rdkit_log():\n    X = featurizer(data)\n</pre> %%timeit # Let's time our current featurization pipeline featurizer = MoleculeTransformer(calc, n_jobs=1, dtype=torch.float32) with dm.without_rdkit_log():     X = featurizer(data) <pre>19.8 s \u00b1 4.42 s per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> In\u00a0[11]: Copied! <pre>%%timeit\n# With transformer classes, it's really easy to add parallelization! Let's try speed this up.\nfeaturizer = MoleculeTransformer(calc, n_jobs=4, dtype=torch.float32)\nwith dm.without_rdkit_log():\n    X = featurizer(data)\n</pre> %%timeit # With transformer classes, it's really easy to add parallelization! Let's try speed this up. featurizer = MoleculeTransformer(calc, n_jobs=4, dtype=torch.float32) with dm.without_rdkit_log():     X = featurizer(data) <pre>5.79 s \u00b1 180 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</pre> <p>Even with such a small dataset, we can already see some performance improvements.</p> In\u00a0[12]: Copied! <pre>from molfeat.trans.fp import FPVecTransformer\n\n# We will use the FPVecTransformer to automatically create a calculator by name\nmaccs = FPVecTransformer(\"maccs\", dtype=np.float32)\necfp4 = FPVecTransformer(\"ecfp:4\", dtype=np.float32)\n\nmaccs([smiles]).shape, ecfp4([smiles]).shape\n</pre> from molfeat.trans.fp import FPVecTransformer  # We will use the FPVecTransformer to automatically create a calculator by name maccs = FPVecTransformer(\"maccs\", dtype=np.float32) ecfp4 = FPVecTransformer(\"ecfp:4\", dtype=np.float32)  maccs([smiles]).shape, ecfp4([smiles]).shape Out[12]: <pre>((1, 167), (1, 2000))</pre> In\u00a0[13]: Copied! <pre>from molfeat.trans.concat import FeatConcat\n\nfeaturizer = FeatConcat([maccs, ecfp4], dtype=np.float32)\nfeaturizer([smiles]).shape\n</pre> from molfeat.trans.concat import FeatConcat  featurizer = FeatConcat([maccs, ecfp4], dtype=np.float32) featurizer([smiles]).shape Out[13]: <pre>(1, 2167)</pre> <p>Alternatively you can use a list of strings corresponding to the <code>FPVecTransformer</code> name and even define parameters for each featurizer.</p> In\u00a0[14]: Copied! <pre>from molfeat.trans.concat import FeatConcat\n\necfp_params = {'radius':2}\nfeaturizer = FeatConcat([\"maccs\", \"ecfp\"], params=dict(ecfp=ecfp_params), dtype=np.float32)\nfeaturizer([smiles]).shape\n</pre> from molfeat.trans.concat import FeatConcat  ecfp_params = {'radius':2} featurizer = FeatConcat([\"maccs\", \"ecfp\"], params=dict(ecfp=ecfp_params), dtype=np.float32) featurizer([smiles]).shape Out[14]: <pre>(1, 2167)</pre>"},{"location":"tutorials/types_of_featurizers.html#calculators","title":"Calculators\u00b6","text":"<p>A calculator is a Callable that takes an RDKit <code>Chem.Mol</code> object or a SMILES string and returns a feature vector. In the following example, we will use the <code>FPCalculator</code>.</p>"},{"location":"tutorials/types_of_featurizers.html#transformers","title":"Transformers\u00b6","text":"<p>In practice, you won't want to featurize a single molecule, but rather a batch of molecules. This is where transformers come in. A transformer is a class that wraps a calculator in a featurization pipeline. The <code>MoleculeTransformer</code> class provides a convenient interface for featurizing a batch of molecules. It also provides a number of useful methods to customize the featurization pipeline.</p>"},{"location":"tutorials/types_of_featurizers.html#concatenate-featurizers","title":"Concatenate featurizers\u00b6","text":"<p>Another interesting feature offered in Molfeat is the ability to concatenate multiple featurizers. However, feature concatenation has some limitations. The most significant being the inability to set the parameters of all transformers in a single call unless you are passing a list of strings corresponding to the calculator names at initialization.</p> <p>It might therefore not be compatible with the Scikit-learn grid search CV API and you will need to handle the update of the parameters of the concatenated featurizer yourself.</p>"},{"location":"tutorials/types_of_featurizers.html#further-reading","title":"Further reading\u00b6","text":"<p>This has only scratched the surface of what the <code>MoleculeTransformer</code> class offers. Subsequent tutorials will dive into more detail:</p> <ul> <li>Easily add your own featurizers: learn how to easily add your own featurizers to Molfeat to take full control.</li> <li>Integrations with ML frameworks: learn how to easily integrate Molfeat with PyTorch and Scikit-learn.</li> </ul>"},{"location":"tutorials/types_of_featurizers.html#pretrained-transformers","title":"Pretrained transformers\u00b6","text":"<p>Finally, the <code>PretrainedMolTransformer</code> class extends the transformer interface to support the usage of pretrained models. This class is a subclass of <code>MoleculeTransformer</code> and inherits all its methods. In addition, it adds the <code>_embed()</code>, and <code>_convert()</code>.</p> <ul> <li><code>_embed()</code>: since pre-trained models benefit from batched featurization, this method is called by the transformer instead of the calculator.</li> <li><code>_convert()</code>: this method is called by the transformer to convert the input. For example:<ul> <li>For a pre-trained language model, we convert from a SMILES string or Mol object to a SELFIES string.</li> <li>For a pre-trained GNN, we convert from a SMILES string or Mol object to a DGL graph.</li> </ul> </li> </ul> <p>Furthermore, the <code>PretrainedMolTransformer</code> supports the use of a caching system. To learn more, see the tutorial on the cache.</p>"}]}